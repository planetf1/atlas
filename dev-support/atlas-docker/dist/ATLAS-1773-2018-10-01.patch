From 718d020199a3b1f914e3b89018f018b4f74c2a2e Mon Sep 17 00:00:00 2001
From: Graham Wallis <graham_wallis@uk.ibm.com>
Date: Fri, 17 Aug 2018 15:16:20 +0100
Subject: [PATCH] ATLAS-1773: Atlas OMRS Repository Connector first round
 review updates and restart with instance status lists, update of saved
 relationship copy and correct exception from verifyTypeDef and addTypeDef

ATLAS-1773: learning mode support (refreshEntityReferenceCopy only), improved exception handling with typeRegistry, saveRelationship accepts null relationship GUID,

ATLAS-1773: classifyEntity, declassifyEntity and updateEntityClassification should all set replaceClassification true on entityStore.createOrUpdate, plus classifyEntity should include supertypes in valid entity check

ATLAS-1773: Updates to classification code and exception handling

ATLAS-1773 - fix for relationship save exception mapping, plus classification fixes
---
 .../janus/AtlasJanusGraphDatabase.java        |     1 +
 open-metadata/pom.xml                         |   151 +
 .../AtlasOMRSRepositoryEventMapper.java       |   514 +
 ...tlasOMRSRepositoryEventMapperProvider.java |    64 +
 .../AtlasAttributeDefMapper.java              |   965 +
 .../AtlasAttributeMapper.java                 |   267 +
 .../AtlasBaseTypeDefMapper.java               |   223 +
 .../AtlasClassificationDefMapper.java         |   394 +
 .../AtlasEntityDefMapper.java                 |   501 +
 .../AtlasEntityMapper.java                    |   679 +
 .../AtlasRelationshipDefMapper.java           |   678 +
 .../AtlasRelationshipMapper.java              |   531 +
 .../repositoryconnector/AtlasStoresProxy.java |    41 +
 .../AtlasStoresProxyImpl.java                 |    76 +
 .../repositoryconnector/Comparator.java       |  1639 ++
 .../repositoryconnector/DSLQueryHelper.java   |   258 +
 .../repositoryconnector/EntityDefMapper.java  |    99 +
 .../repositoryconnector/FamousFive.java       |   240 +
 .../repositoryconnector/ISpringBridge.java    |    43 +
 .../LocalAtlasOMRSErrorCode.java              |   245 +
 .../LocalAtlasOMRSMetadataCollection.java     | 15290 ++++++++++++++++
 .../LocalAtlasOMRSRepositoryConnector.java    |    59 +
 ...lAtlasOMRSRepositoryConnectorProvider.java |    44 +
 .../repositoryconnector/SpringBridge.java     |    94 +
 .../TypeDefsByCategory.java                   |   231 +
 .../repositoryconnector/TypeNameUtils.java    |    72 +
 .../spring/OpenMetadataAdminResource.java     |   647 +
 .../TestAtlasClassificationDefMapper.java     |   394 +
 .../TestAtlasEntityDefMapper.java             |   342 +
 .../TestAtlasEntityMapper.java                |   746 +
 .../TestAtlasRelationshipDefMapper.java       |   514 +
 .../TestAtlasRelationshipMapper.java          |   568 +
 pom.xml                                       |     9 +-
 webapp/pom.xml                                |    43 +
 .../webapp/WEB-INF/openMetadataContext.xml    |    33 +
 webapp/src/main/webapp/WEB-INF/web.xml        |    18 +
 36 files changed, 26712 insertions(+), 1 deletion(-)
 create mode 100644 open-metadata/pom.xml
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapperProvider.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasBaseTypeDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasClassificationDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxy.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxyImpl.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/Comparator.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/DSLQueryHelper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/EntityDefMapper.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/FamousFive.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/ISpringBridge.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSErrorCode.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSMetadataCollection.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnector.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnectorProvider.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/SpringBridge.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeDefsByCategory.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeNameUtils.java
 create mode 100644 open-metadata/src/main/java/org/apache/atlas/openmetadata/admin/server/spring/OpenMetadataAdminResource.java
 create mode 100644 open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasClassificationDefMapper.java
 create mode 100644 open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityDefMapper.java
 create mode 100644 open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityMapper.java
 create mode 100644 open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipDefMapper.java
 create mode 100644 open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipMapper.java
 create mode 100644 webapp/src/main/webapp/WEB-INF/openMetadataContext.xml

diff --git a/graphdb/janus/src/main/java/org/apache/atlas/repository/graphdb/janus/AtlasJanusGraphDatabase.java b/graphdb/janus/src/main/java/org/apache/atlas/repository/graphdb/janus/AtlasJanusGraphDatabase.java
index 47e561bbe..b5180c14e 100644
--- a/graphdb/janus/src/main/java/org/apache/atlas/repository/graphdb/janus/AtlasJanusGraphDatabase.java
+++ b/graphdb/janus/src/main/java/org/apache/atlas/repository/graphdb/janus/AtlasJanusGraphDatabase.java
@@ -100,6 +100,7 @@ public class AtlasJanusGraphDatabase implements GraphDatabase<AtlasJanusVertex,
                     Configuration config;
                     try {
                         config = getConfiguration();
+                        LOG.info("AtlasJanusGraphDatabase: getGraphInstance has wait-time config {}",config.getProperty("storage.lock.wait-time"));
                     } catch (AtlasException e) {
                         throw new RuntimeException(e);
                     }
diff --git a/open-metadata/pom.xml b/open-metadata/pom.xml
new file mode 100644
index 000000000..08b5eaf1e
--- /dev/null
+++ b/open-metadata/pom.xml
@@ -0,0 +1,151 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one
+  ~ or more contributor license agreements.  See the NOTICE file
+  ~ distributed with this work for additional information
+  ~ regarding copyright ownership.  The ASF licenses this file
+  ~ to you under the Apache License, Version 2.0 (the
+  ~ "License"); you may not use this file except in compliance
+  ~ with the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an "AS IS" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+
+<project xmlns="http://maven.apache.org/POM/4.0.0"
+         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
+
+    <modelVersion>4.0.0</modelVersion>
+
+    <parent>
+        <artifactId>apache-atlas</artifactId>
+        <groupId>org.apache.atlas</groupId>
+        <version>2.0.0-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>open-metadata</artifactId>
+
+    <name>Open Metadata support for Atlas</name>
+    <description>Open Metadata Repository Services (OMRS) connector and event mapper to enable Atlas to join OM cohorts</description>
+
+    <packaging>jar</packaging>
+
+    <dependencies>
+
+        <dependency>
+            <groupId>commons-collections</groupId>
+            <artifactId>commons-collections</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>commons-io</groupId>
+            <artifactId>commons-io</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.testng</groupId>
+            <artifactId>testng</artifactId>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.atlas</groupId>
+            <artifactId>atlas-repository</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.springframework</groupId>
+            <artifactId>spring-web</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>com.fasterxml.jackson.core</groupId>
+            <artifactId>jackson-databind</artifactId>
+            <version>${jackson.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>org.mockito</groupId>
+            <artifactId>mockito-all</artifactId>
+        </dependency>
+
+        <!-- Dependencies on the Egeria project -->
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>repository-services-implementation</artifactId>
+            <version>${egeria.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>ch.qos.logback</groupId>
+                    <artifactId>*</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.slf4j</groupId>
+                    <artifactId>log4j-over-slf4j</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>admin-services-server</artifactId>
+            <version>${egeria.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>ch.qos.logback</groupId>
+                    <artifactId>*</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.slf4j</groupId>
+                    <artifactId>log4j-over-slf4j</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>kafka-open-metadata-topic-connector</artifactId>
+            <version>${egeria.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>ch.qos.logback</groupId>
+                    <artifactId>*</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.slf4j</groupId>
+                    <artifactId>log4j-over-slf4j</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.atlas</groupId>
+            <artifactId>atlas-notification</artifactId>
+        </dependency>
+
+    </dependencies>
+
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-jar-plugin</artifactId>
+                <version>2.4</version>
+                <executions>
+                    <execution>
+                        <goals>
+                            <goal>test-jar</goal>
+                        </goals>
+                    </execution>
+                </executions>
+            </plugin>
+        </plugins>
+    </build>
+</project>
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapper.java
new file mode 100644
index 000000000..40089fa65
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapper.java
@@ -0,0 +1,514 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.eventmapper;
+
+
+
+import org.apache.atlas.ApplicationProperties;
+import org.apache.atlas.AtlasException;
+import org.apache.atlas.model.instance.AtlasEntityHeader;
+import org.apache.atlas.model.notification.EntityNotification;
+import org.apache.atlas.notification.entity.EntityMessageDeserializer;
+import org.apache.atlas.openmetadata.adapters.repositoryconnector.LocalAtlasOMRSErrorCode;
+import org.apache.atlas.openmetadata.adapters.repositoryconnector.LocalAtlasOMRSMetadataCollection;
+import org.apache.atlas.openmetadata.adapters.repositoryconnector.LocalAtlasOMRSRepositoryConnector;
+import static org.apache.atlas.kafka.KafkaNotification.ATLAS_ENTITIES_TOPIC;
+
+import org.apache.atlas.util.AtlasRepositoryConfiguration;
+import org.apache.commons.lang3.StringUtils;
+import org.apache.kafka.clients.consumer.*;
+import org.apache.kafka.common.serialization.StringDeserializer;
+
+import org.odpi.openmetadata.frameworks.connectors.ffdc.ConnectorCheckedException;
+import org.odpi.openmetadata.repositoryservices.auditlog.OMRSAuditLog;
+import org.odpi.openmetadata.repositoryservices.auditlog.OMRSAuditingComponent;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.EntityDetail;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceType;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryeventmapper.OMRSRepositoryEventMapperBase;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryeventmapper.OMRSRepositoryEventMapperConnector;
+import org.odpi.openmetadata.repositoryservices.events.OMRSEventCategory;
+import org.odpi.openmetadata.repositoryservices.events.OMRSEventOriginator;
+import org.odpi.openmetadata.repositoryservices.events.OMRSInstanceEventType;
+import org.odpi.openmetadata.repositoryservices.events.beans.v1.OMRSEventV1;
+import org.odpi.openmetadata.repositoryservices.events.beans.v1.OMRSEventV1InstanceSection;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Collections;
+import java.util.Date;
+import java.util.Properties;
+
+
+
+
+/**
+ * AtlasOMRSRepositoryEventMapper provides an implementation of a repository event mapper for the
+ * Apache Atlas metadata repository.
+ */
+
+public class AtlasOMRSRepositoryEventMapper extends OMRSRepositoryEventMapperConnector {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasOMRSRepositoryEventMapper.class);
+    private static final OMRSAuditLog AUDITLOG = new OMRSAuditLog(OMRSAuditingComponent.LOCAL_REPOSITORY_EVENT_MAPPER);
+
+    // Kafka Topic Consumer
+    // Some properties can be hard coded but the bootstrap server need to be read from the Atlas properties
+    private static final String TOPIC_NAME                 = ATLAS_ENTITIES_TOPIC;
+    private static final String CONSUMER_GROUP_ID          = "AtlasOMRSRepositoryEventMapperConsumerGroup";  // OK to hard code - only the event mapper should be using this
+    private static final String BOOTSTRAP_SERVERS_DEFAULT  = "localhost:9027";
+    private static final String BOOTSTRAP_SERVERS_PROPERTY = "atlas.kafka.bootstrap.servers";
+
+    private String                           bootstrapServers   = null;
+    private RunnableConsumer                 runnableConsumer   = null;
+    private Thread                           consumerThread     = null;
+    private EntityMessageDeserializer        deserializer       = new EntityMessageDeserializer();
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+
+    /**
+     * Default constructor
+     */
+    public AtlasOMRSRepositoryEventMapper() throws RepositoryErrorException {
+        super();
+        LOG.debug("AtlasOMRSRepositoryEventMapper constructor invoked");
+
+        try {
+            bootstrapServers = ApplicationProperties.get().getString(BOOTSTRAP_SERVERS_PROPERTY, BOOTSTRAP_SERVERS_DEFAULT);
+            LOG.debug("AtlasOMRSRepositoryEventMapper: bootstrapServers {}",bootstrapServers);
+        } catch (AtlasException e) {
+            LOG.error("AtlasOMRSRepositoryEventMapper: Could not find bootstrap servers, giving up");
+            String actionDescription = "LocalAtlasOMRSMetadataCollection Constructor";
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ATLAS_CONFIGURATION;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage();
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    actionDescription,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        this.runnableConsumer = createConsumer();
+
+    }
+
+    private RunnableConsumer createConsumer() {
+
+        KafkaConsumer consumer = null;
+
+        final Properties props = new Properties();
+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
+        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_ID);
+
+        // Deserialization - at this level should support Kafka records - String,String should be sufficient
+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
+
+        consumer = new KafkaConsumer<>(props);
+        consumer.subscribe(Collections.singletonList(TOPIC_NAME));
+
+        RunnableConsumer runnableConsumer = new RunnableConsumer(consumer);
+
+        return runnableConsumer;
+
+    }
+
+    public class RunnableConsumer implements Runnable {
+        private final KafkaConsumer consumer;
+        private       boolean       keepOnRunning;
+
+        // package-private
+        RunnableConsumer(KafkaConsumer consumer) {
+            this.consumer = consumer;
+            keepOnRunning = true;
+        }
+
+        // package-private
+        void stopRunning() {
+            keepOnRunning = false;
+        }
+
+        @Override
+        public void run() {
+
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("==> AtlasOMRSRepositoryEventMapper RunnableConsumer.run()");
+            }
+
+            while (keepOnRunning) {
+
+                ConsumerRecords<?, ?> records  = consumer.poll(1000);
+                if (records != null) {
+
+                     /* Since the resolution to ATLAS-2853, it is safe to immediately process any notifications, because
+                      * the Atlas graph transaction will already have committed prior to the notification having been semt.
+                      */
+
+                    for (ConsumerRecord<?, ?> record : records) {
+                        if (LOG.isDebugEnabled()) {
+                            LOG.debug("Received Message topic = {}, partition = {}, offset = {}, key = {}, value = {}",
+                                    record.topic(), record.partition(), record.offset(), record.key(), record.value());
+                        }
+
+                        EntityNotification entityNotification = deserializer.deserialize(record.value().toString());
+                        if (entityNotification != null) {
+                            processEntityNotification(entityNotification);
+                        }
+                    }
+                }
+                consumer.commitAsync();
+            }
+            consumer.close();
+
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("<== RunnableConsumer.run() ending");
+            }
+        }
+    }
+
+    /**
+     * Indicates that the connector is completely configured and can begin processing.
+     *
+     * @throws ConnectorCheckedException there is a problem within the connector.
+     */
+    public void start() throws ConnectorCheckedException  {
+
+        final String methodName = "start";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> AtlasOMRSRepositoryEventMapper start()");
+        }
+        super.start();
+
+        LOG.debug("AtlasOMRSRepositoryEventMapper.start: metadataCollectionId {}, repositoryConnector {}, localServerUserId {}", localMetadataCollectionId, repositoryConnector, localServerUserId);
+
+        // Get and verify the metadataCollection...
+        boolean metadataCollectionOK = false;
+        LocalAtlasOMRSRepositoryConnector repositoryConnector = (LocalAtlasOMRSRepositoryConnector) this.repositoryConnector;
+        try {
+            metadataCollection = (LocalAtlasOMRSMetadataCollection) repositoryConnector.getMetadataCollection();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("AtlasOMRSRepositoryEventMapper.start: Exception from getMetadataCollection, message = {}", e.getMessage());
+            metadataCollectionOK = false;
+        }
+        if (metadataCollection != null) {
+            // Check that the metadataCollection is responding...
+            try {
+                String id = metadataCollection.getMetadataCollectionId();
+                if (id.equals(localMetadataCollectionId)) {
+                    LOG.debug("AtlasOMRSRepositoryEventMapper.start: metadataCollection verified");
+                    metadataCollectionOK = true;
+                } else {
+                    LOG.error("AtlasOMRSRepositoryEventMapper.start: Could not retrieve metadataCollection");
+                    metadataCollectionOK = false;
+                }
+            } catch (RepositoryErrorException e) {
+                metadataCollectionOK = false;
+            }
+        }
+        if (!metadataCollectionOK) {
+            LOG.error("AtlasOMRSRepositoryEventMapper.ctor: Could not access metadata collection");
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.METADATA_COLLECTION_NOT_FOUND;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(localMetadataCollectionId);
+
+            throw new ConnectorCheckedException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+
+        /* Register the event mapper with the metadataCollection. This is so that the metadataCollection can respond
+         * to requests such as refreshEntityReferenceCopy by delegating to the event mapper to call the event processor.
+         */
+        LOG.debug("AtlasOMRSRepositoryEventMapper: set eventMapper in metadataCollection");
+        metadataCollection.setEventMapper(this);
+
+        if (this.runnableConsumer == null) {
+            LOG.error("AtlasOMRSRepositoryEventMapper: No runnable consumer!!!");
+
+           OMRSErrorCode errorCode = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(repositoryEventMapperName, methodName, "RunnableConsumer not created");
+
+            throw new ConnectorCheckedException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        else {
+            consumerThread = new Thread(runnableConsumer);
+            consumerThread.setDaemon(true);
+            consumerThread.start();
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== AtlasOMRSRepositoryEventMapper start()");
+        }
+    }
+
+
+    /**
+     * Free up any resources held since the connector is no longer needed.
+     *
+     * @throws ConnectorCheckedException - there is a problem within the connector.
+     */
+    public void disconnect() throws ConnectorCheckedException {
+        LOG.debug("AtlasOMRSRepositoryEventMapper disconnect()");
+        runnableConsumer.stopRunning();
+        LOG.debug("AtlasOMRSRepositoryEventMapper: runnable consumer thread told to stop");
+        super.disconnect();
+
+    }
+
+    /**
+     * Method to process an EntityNotification message
+     *
+     * @param notification - EntityNotification received from ATLAS_ENTITIES topic
+     */
+    public void processEntityNotification(EntityNotification notification) {
+
+        LOG.debug("AtlasOMRSRepositoryEventMapper.processMessage {}", notification);
+
+        // check the notification version (sometimes referred to as 'type')
+        EntityNotification.EntityNotificationType version = notification.getType();
+        switch (version) {
+
+            case ENTITY_NOTIFICATION_V2:
+                EntityNotification.EntityNotificationV2 notificationV2 = (EntityNotification.EntityNotificationV2)notification;
+                handleAtlasEntityNotification(notificationV2);
+                break;
+
+            case ENTITY_NOTIFICATION_V1:
+            default:
+                LOG.error("AtlasOMRSRepositoryEventMapper.processMessage: Message skipped!! - not expecting a V1 entity notification...");
+                // skip the message...
+                break;
+        }
+
+    }
+
+
+    private void handleAtlasEntityNotification(EntityNotification.EntityNotificationV2 notification) {
+
+        final String methodName = "AtlasOMRSRepositoryEventMapper.processEvent";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("{}: notification={}", methodName, notification);
+        }
+
+        /*
+         * Depending on the operation being notified, this method needs to retrieve slightly different
+         * things to pass to the event processor. In almost all cases, it needs to retrieve the entity detail
+         * from the store. In the case of a purge (hard) delete there will be no entity detail in the store,
+         * but the event processor for purge only needs the entity GUID, type name and type GUID. The first two
+         * of these are available in the AtlasEntityHeader given in the notification. The type GUID will require
+         * a request to the AtlasTypeStore or TypeRegistry. The event mapper makes use of the metadatacollection
+         * for all access to Atlas.
+         *
+         * The key thing to establish is a) whether this is an entity deleted notification and b) whether Atlas
+         * is configured for hard delete. If both of those are true then we need to use the type name to retrieve
+         * the TypeDefGUID from Atlas.
+         */
+
+        EntityNotification.EntityNotificationV2.OperationType operationType = notification.getOperationType();
+        long notificationTime = notification.getEventTime();
+        // No way yet to pass timestamp to event processor methods, but have raised EGERIA-52. For now just log it (again)...
+        LOG.debug("Notification has eventTime {}", notificationTime);
+
+        AtlasEntityHeader atlasEntityHeader = notification.getEntity();
+        LOG.debug("{}: atlasEntityHeader={}", methodName, atlasEntityHeader);
+
+        String atlasEntityGuid = atlasEntityHeader.getGuid();
+        String atlasTypeName = atlasEntityHeader.getTypeName();
+        String typeDefGUID = null;
+
+        EntityDetail entityDetail = null;
+
+        try {
+            // Check if the entity is a proxy and if so ignore it...
+            boolean isProxy = metadataCollection.isEntityProxy(atlasEntityGuid);
+            if (isProxy) {
+                // The entity is a proxy - it was added by an OMRS action and we are not interested in this atlas event
+                LOG.debug("{}: event relates to an EntityProxy with guid {} - ignored", methodName, atlasEntityGuid);
+                return;
+            }
+            // Check if it is a remote object and if so ignore it ...
+            boolean isLocal = metadataCollection.isEntityLocal(atlasEntityGuid);
+            if (!isLocal) {
+                // The entity is remote - we are not interested in this atlas event
+                LOG.debug("{}: event relates to a remotely mastered Entity with guid {} - ignored", methodName, atlasEntityGuid);
+                return;
+            }
+            // (!isProxy && isLocal)
+            LOG.debug("{}: event relates to a locally mastered Entity with guid {} - process", methodName, atlasEntityGuid);
+
+            // If this is a delete notification we need to establish whether Atlas is performing hard dor soft deletes.
+
+            if (operationType == EntityNotification.EntityNotificationV2.OperationType.ENTITY_DELETE && metadataCollection.isAtlasConfiguredForHardDelete() == true) {
+                // Use the entity type name to retrieve the type GUID, to pass to the purge processor.
+                typeDefGUID = metadataCollection._getTypeDefGUIDByAtlasTypeName(this.localServerUserId, atlasTypeName);
+                LOG.debug("{}: typeDefGUID = {}", methodName, typeDefGUID);
+            }
+            else {
+                // Retrieve the EntityDetail, to pass to the purge processor.
+                entityDetail = metadataCollection.getEntityDetail(this.localServerUserId, atlasEntityGuid);
+                LOG.debug("{}: entity detail = {}", methodName, entityDetail);
+            }
+
+
+        } catch (Exception e) {
+            LOG.error("{}: Exception from metadataCollection, message={}", methodName, e.getMessage());
+            // It is possible that the event is plain wrong. Ignore the event...
+            return;
+        }
+
+
+        // By this point we either have a typeDefGUID, typeName and entityGUID or we have a complete entityDetail...
+
+        // We have not yet set the eventType but that is done inline below with the call to the event processor...
+
+        // Atlas does not yet generate undone, purged, restored, rehomed, reidentified or retyped events or refresh requests or events
+        // It doesn't support relationship events yet either
+        // Nor is there any support for conflicting types or conflicting instances events
+
+
+        LOG.debug("{}: Handle event: operationType {}, typeDefGUID {}, typeDefName {}",
+                    methodName, operationType, typeDefGUID, atlasTypeName );
+
+        switch (operationType) {
+
+            case ENTITY_CREATE:
+                LOG.debug("{}: invoke processNewEntityEvent", methodName);
+                repositoryEventProcessor.processNewEntityEvent(
+                        repositoryEventMapperName,
+                        localMetadataCollectionId,
+                        localServerName,
+                        localServerType,
+                        localOrganizationName,
+                        entityDetail);
+                break;
+
+            case ENTITY_UPDATE:
+                LOG.debug("{}: invoke processUpdatedEntityEvent", methodName);
+                repositoryEventProcessor.processUpdatedEntityEvent(
+                        repositoryEventMapperName,
+                        localMetadataCollectionId,
+                        localServerName,
+                        localServerType,
+                        localOrganizationName,
+                        null,        // We do not have the old entity - this will be addressed further up the stack if available
+                        entityDetail);
+                break;
+
+            case ENTITY_DELETE:
+                // If hard delete, invoke purge processor, else invoke delete processor...
+                if (metadataCollection.isAtlasConfiguredForHardDelete() == true) {
+                    LOG.debug("{}: invoke processDeletedEntityEvent", methodName);
+                    repositoryEventProcessor.processPurgedEntityEvent(
+                            repositoryEventMapperName,
+                            localMetadataCollectionId,
+                            localServerName,
+                            localServerType,
+                            localOrganizationName,
+                            typeDefGUID,
+                            atlasTypeName,
+                            atlasEntityGuid);
+                } else {
+                    LOG.debug("{}: invoke processDeletedEntityEvent", methodName);
+                    repositoryEventProcessor.processDeletedEntityEvent(
+                            repositoryEventMapperName,
+                            localMetadataCollectionId,
+                            localServerName,
+                            localServerType,
+                            localOrganizationName,
+                            entityDetail);
+                }
+                break;
+
+            case CLASSIFICATION_ADD:
+                LOG.debug("{}: invoke processClassifiedEntityEvent", methodName);
+                repositoryEventProcessor.processClassifiedEntityEvent(
+                        repositoryEventMapperName,
+                        localMetadataCollectionId,
+                        localServerName,
+                        localServerType,
+                        localOrganizationName,
+                        entityDetail);
+                break;
+
+            case CLASSIFICATION_UPDATE:
+                LOG.debug("{}: invoke processReclassifiedEntityEvent", methodName);
+                repositoryEventProcessor.processReclassifiedEntityEvent(
+                        repositoryEventMapperName,
+                        localMetadataCollectionId,
+                        localServerName,
+                        localServerType,
+                        localOrganizationName,
+                        entityDetail);
+                break;
+
+            case CLASSIFICATION_DELETE:
+                LOG.debug("{}: invoke processDeclassifiedEntityEvent", methodName);
+                repositoryEventProcessor.processDeclassifiedEntityEvent(
+                        repositoryEventMapperName,
+                        localMetadataCollectionId,
+                        localServerName,
+                        localServerType,
+                        localOrganizationName,
+                        entityDetail);
+                break;
+
+            default:
+                LOG.error("{}: operation type {} not supported", methodName, operationType);
+                break;
+        }
+
+    }
+
+
+    /*
+     * Helper method for repository connector metadata collection
+     */
+    public void processRefreshEvent(EntityDetail entityDetail) {
+        final String methodName = "processRefreshEvent";
+
+        LOG.debug("{}: invoke processNewEntityEvent", methodName);
+
+        repositoryEventProcessor.processRefreshEntityEvent(
+                repositoryEventMapperName,
+                localMetadataCollectionId,
+                localServerName,
+                localServerType,
+                localOrganizationName,
+                entityDetail);
+    }
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapperProvider.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapperProvider.java
new file mode 100644
index 000000000..0ce889ae9
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/eventmapper/AtlasOMRSRepositoryEventMapperProvider.java
@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.eventmapper;
+
+import org.odpi.openmetadata.frameworks.connectors.properties.beans.ConnectorType;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryConnectorProviderBase;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * In the Egeria Open Connector Framework (OCF), a ConnectorProvider is a factory for a specific type of connector.
+ * The AtlasOMRSRepositoryEventMapperProvider is the connector provider for the AtlasOMRSRepositoryEventMapper.
+ * It extends OMRSRepositoryEventMapperProviderBase which in turn extends the OCF ConnectorProviderBase.
+ * ConnectorProviderBase supports the creation of connector instances.
+ *
+ * The AtlasOMRSRepositoryEventMapperProvider must initialize ConnectorProviderBase with the Java class
+ * name of the OMRS Connector implementation (by calling super.setConnectorClassName(className)).
+ * Then the connector provider will work.
+ */
+public class AtlasOMRSRepositoryEventMapperProvider extends OMRSRepositoryConnectorProviderBase
+{
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasOMRSRepositoryEventMapperProvider.class);
+
+    static final String  CONNECTOR_TYPE_GUID = "121ea5d1-2f9c-4580-9f40-442ea503b2ec";
+    static final String  CONNECTOR_TYPE_NAME = "OMRS Atlas Event Mapper Connector";
+    static final String  CONNECTOR_TYPE_DESCRIPTION = "OMRS Atlas Event Mapper Connector that processes events from an Atlas repository.";
+    /**
+     * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific
+     * OMRS Connector implementation.
+     */
+    public AtlasOMRSRepositoryEventMapperProvider()
+    {
+        LOG.debug("AtlasOMRSRepositoryEventMapperProvider invoked");
+
+        Class    connectorClass = AtlasOMRSRepositoryEventMapper.class;
+
+        super.setConnectorClassName(connectorClass.getName());
+
+        ConnectorType connectorType = new ConnectorType();
+        connectorType.setType(ConnectorType.getConnectorTypeType());
+        connectorType.setGUID(CONNECTOR_TYPE_GUID);
+        connectorType.setQualifiedName(CONNECTOR_TYPE_NAME);
+        connectorType.setDisplayName(CONNECTOR_TYPE_NAME);
+        connectorType.setDescription(CONNECTOR_TYPE_DESCRIPTION);
+        connectorType.setConnectorProviderClassName(this.getClass().getName());
+
+        super.connectorTypeBean = connectorType;
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeDefMapper.java
new file mode 100644
index 000000000..6c1218855
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeDefMapper.java
@@ -0,0 +1,965 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.AtlasErrorCode;
+import org.apache.atlas.exception.AtlasBaseException;
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasBaseTypeDef;
+import org.apache.atlas.model.typedef.AtlasEnumDef;
+import org.apache.atlas.model.typedef.AtlasStructDef;
+import static org.apache.atlas.model.TypeCategory.*;
+import static org.apache.atlas.model.typedef.AtlasBaseTypeDef.*;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+import org.apache.atlas.type.AtlasTypeUtil;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.OMRSLogicErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeDefNotKnownException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryHelper;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.AttributeCardinality.*;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.AttributeTypeDefCategory.COLLECTION;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_ARRAY;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_MAP;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.UUID;
+
+
+
+public class AtlasAttributeDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasAttributeDefMapper.class);
+
+    private final LocalAtlasOMRSMetadataCollection       metadataCollection;
+    private       String                                 metadataCollectionId = null;
+    private final String                                 userId;
+    private final AtlasTypeDefStore                      typeDefStore;
+    private final AtlasTypeRegistry                      typeRegistry;
+    private final OMRSRepositoryHelper                   repositoryHelper;
+    private final TypeDefsByCategory                     typeDefsForAPI;
+    private final List<AtlasStructDef.AtlasAttributeDef> aads;
+
+    private boolean useRegistry = true;
+
+
+    public AtlasAttributeDefMapper(LocalAtlasOMRSMetadataCollection        metadataCollection,
+                                   String                                  userId,
+                                   AtlasTypeDefStore                       typeDefStore,
+                                   AtlasTypeRegistry                       typeRegistry,
+                                   OMRSRepositoryHelper                    repositoryHelper,
+                                   TypeDefsByCategory                      typeDefsForAPI,
+                                   List<AtlasStructDef.AtlasAttributeDef>  aads  )
+        throws
+            RepositoryErrorException
+    {
+
+        this.metadataCollection = metadataCollection;
+        this.userId             = userId;
+        this.typeDefStore       = typeDefStore;
+        this.typeRegistry       = typeRegistry;
+        this.repositoryHelper   = repositoryHelper;
+        this.aads               = aads;
+        this.typeDefsForAPI     = typeDefsForAPI;
+
+        try {
+
+            this.metadataCollectionId = metadataCollection.getMetadataCollectionId();
+
+        } catch (Exception e) {
+            LOG.error("AtlasAttributeDefMapper: metadataCollectionId not available", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID",metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+    }
+
+    // Convert a List of AtlasAttributeDef to a List of OMRS TypeDefAttribute
+    // package private
+    List<TypeDefAttribute> convertAtlasAttributeDefs()
+            throws
+            TypeErrorException
+
+    {
+
+        ArrayList<TypeDefAttribute> omrsTypeDefAttributes;
+        if (aads == null || aads.isEmpty()) {
+
+            LOG.debug("convertAtlasAttributeDefs: Atlas attributes are missing {}", aads);
+            return null;
+
+        } else {
+            LOG.debug("convertAtlasAttributeDefs: convert Atlas attributes {}", aads);
+            omrsTypeDefAttributes = new ArrayList<>();
+
+            for (AtlasStructDef.AtlasAttributeDef aad : aads) {
+                LOG.debug("convertAtlasAttributeDefs: convert Atlas attribute {}", aad);
+                // Map from AtlasAttributeDef to OMRS TypeDefAttribute
+                try {
+                    TypeDefAttribute tda = convertAtlasAttributeDef(aad);
+                    if (tda != null)
+                        omrsTypeDefAttributes.add(tda);
+                }
+                catch (TypeDefNotKnownException e) {
+                    // Failed to process one of the attribute types; give up by explicitly throwing a ConversionException
+                    LOG.error("convertAtlasAttributeDefs: Failed to convert Atlas attribute def {}", aad.getName(), e);
+
+                    // Throw an error here - which will cause the whole type to be skipped.
+                    OMRSErrorCode errorCode = OMRSErrorCode.BAD_ATTRIBUTE_TYPE;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aad.getName(), aad.getTypeName());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "convertAtlasAttributeDefs",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+
+                }
+            }
+        }
+        return omrsTypeDefAttributes;
+    }
+
+
+    // Convert an individual attribute def
+    private TypeDefAttribute convertAtlasAttributeDef(AtlasStructDef.AtlasAttributeDef aad)
+        throws
+            TypeErrorException,
+            TypeDefNotKnownException
+    {
+
+        // Convert AtlasAttributeDef to OMRS TypeDefAttribute
+        //
+        //
+        // AtlasAttributeDef has:                             OMRS TypeDefAttribute has:
+        //
+        // String name             ------------------>        String attributeName
+        // String typeName         -- USED (MULTI) -->        AttributeTypeDef attributeType:
+        //                                                       ---------------------------------------------------------------------------------
+        //                                                       AttributeTypeDefCategory category:
+        //                                                          OM defines the following values { UNKNOWN_DEF | PRIMITIVE | COLLECTION | ENUM_DEF }
+        //                                                          Figure out the Atlas TypeCategory (see below) then map as follows:
+        //                                                          [atlas]            [omrs]
+        //                                                          PRIMITIVE       -> PRIMITIVE
+        //                                                          OBJECT_ID_TYPE  -> UNKNOWN_DEF / AUDIT LOG!!
+        //                                                          ENUM            -> ENUM_DEF
+        //                                                          STRUCT          -> UNKNOWN_DEF / AUDIT LOG!!
+        //                                                          CLASSIFICATION  -> UNKNOWN_DEF / AUDIT LOG!!
+        //                                                          ENTITY          -> UNKNOWN_DEF / AUDIT LOG!!
+        //                                                          ARRAY           -> COLLECTION
+        //                                                          MAP             -> COLLECTION
+        //                                                          RELATIONSHIP    -> UNKNOWN_DEF / AUDIT LOG!!
+        //                                                       String guid  = will have to fabricate guid or leave null
+        //                                                       String name  = AtlasAttributeDef.typeName
+        //                                                       ---------------------------------------------------------------------------------
+        //                                                     String attributeDescription = AtlasAttributeDef.description (see below)
+        // boolean isOptional       ----- USED -------->       in OMRS AttributeCardinality (see below)
+        // Cardinality cardinality  ----> USED -------->       AttributeCardinality cardinality:
+        //                                                         atlas           -> omrs
+        //                                                         any other combination  -> UNKNOWN
+        //                                                         isOptional && SINGLE   -> AT_MOST_ONE
+        //                                                         !isOptional && SINGLE  -> ONE_ONLY
+        //                                                         !isOptional && LIST    -> AT_LEAST_ONE_ORDERED
+        //                                                         !isOptional && SET     -> AT_LEAST_ONE_UNORDERED
+        //                                                         isOptional && LIST     -> ANY_NUMBER_ORDERED
+        //                                                         isOptional && SET      -> ANY_NUMBER_UNORDERED
+        // int valuesMinCount       -------------------->      int valuesMinCount
+        // int valuesMaxCount       -------------------->      int valuesMaxCount
+        // boolean isIndexable      -------------------->      boolean isIndexable
+        // boolean isUnique         -------------------->      boolean isUnique
+        // String defaultValue      -------------------->      String defaultValue
+        // String description       ----- USED --------->      used to set attributeDescription (see above)
+        // List<AtlasConstraintDef> ---- IGNORED x             There are no constraints in OM so Atlas constraints are deliberately ignored
+        //         n/a              ----- FABRICATE ---->      ArrayList<ExternalStandardMapping> externalStandardMappings = null (always)
+        //
+
+        LOG.debug("convertAtlasAttributeDef: AtlasAttributeDef is {}", aad);
+
+        if (aad == null) {
+            return null;
+        }
+
+        // Validate AtlasAttributeDef - make sure the named type exists in the type registry (or is primitive) and that we can find/set category
+        String atlasTypeName = aad.getTypeName();
+        TypeCategory atlasCategory = null;
+
+        // We need to establish the Atlas type category.
+        // If this is a PRIMITIVE, MAP or ARRAY then it will not have a TypeDef so we need to use other means to determine
+        // what category it has. If, after exhausting these means, we still do not have a valid category then we can assume that
+        // there is a TypeDef so we query the Atlas TypeDefStore.
+        //
+
+        // If the type is a PRIMITIVE it will not have a valid category for us to use - so we must identify that the
+        // type name represents a primitive and set the category explicitly to PRIMITIVE.
+        for (String atlasPrimitive : AtlasBaseTypeDef.ATLAS_PRIMITIVE_TYPES) {
+            if (atlasTypeName.equals(atlasPrimitive)) {
+                // This attribute is of a primitive type
+                atlasCategory = PRIMITIVE;
+                break;
+            }
+        }
+
+        // If the type is a DATE it will not have a valid category for us to use - so we must identify that the
+        // type name represents a primitive and set the category explicitly. In the specific case of 'date' we
+        // have to provide special handling - 'date' is not a primitive in Atlas, but it is a a primitive in OM.
+        if (atlasTypeName.equals(ATLAS_TYPE_DATE)) {
+            // This attribute is handled in OM as a primitive type - although for Atlas it is not considered a primitive
+            // It will be handled below along with the Atlas types that are primitive
+            LOG.debug("convertAtlasAttributeDef: AtlasAttributeDef is a date");
+            atlasCategory = PRIMITIVE;
+        }
+
+        // Similarly if the Atlas typeName uses the array prefix then we should set the category to array
+        if (atlasCategory == null && AtlasTypeUtil.isArrayType(atlasTypeName)) {
+            LOG.debug("convertAtlasAttributeDef: AtlasAttributeDef is an array");
+            atlasCategory = ARRAY;
+        }
+
+        // Similarly if the Atlas typeName uses the map prefix then we should set the category to map
+        if (atlasCategory == null && AtlasTypeUtil.isMapType(atlasTypeName)) {
+            LOG.debug("convertAtlasAttributeDef: AtlasAttributeDef is a map");
+            atlasCategory = MAP;
+        }
+
+        // Finally, if none of the above succeeded then we may be looking at an Enum (or anything else, but they are
+        // not supported in OM and will result in error). Need to look in the TypeDefStore to find the category.
+        // If none of the above were true then we need to find out what category of Atlas type we are dealing with....
+        // Perform a typedefstore.getByName to get an AtlasBaseTypeDef which will have a category, i.e. one of
+        // PRIMITIVE, OBJECT_ID_TYPE, ENUM, STRUCT, CLASSIFICATION, ENTITY, ARRAY, MAP, RELATIONSHIP
+        // If PRIMITIVE, MAP or ARRAY then we already have a category anyway - will process below
+        // If ENUM - then we will process as an Enum attribute - see below
+        // All of PRIMITIVE, ARRAY, MAP and ENUM are handled in the switch below.
+        // If CLASSIFICATION, ENTITY, RELATIONSHIP then this is not used as an attribute - log as an error
+        // If OBJECT_ID_TYPE, STRUCT we do not support these in OM so log as an error
+        if (atlasCategory == null) {
+            AtlasBaseTypeDef abtd;
+            try {
+                if (!useRegistry) {
+                    // Look in the Atlas type def store
+                    // This will throw an AtlasBaseException with error code TYPE_NAME_INVALID if name is blank,
+                    // or TYPE_NAME_NOT_FOUND is type is unknown.
+                    abtd = typeDefStore.getByName(atlasTypeName);
+                } else {
+                    // Using registry
+                    // If type is not found this will return null.
+                    abtd = typeRegistry.getTypeDefByName(atlasTypeName);
+                }
+
+            } catch (AtlasBaseException e) {
+
+                if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                    LOG.error("convertAtlasAttributeDef: Atlas does not have the type with name {} ", atlasTypeName, e);
+                    // The AttributeTypeDef was not found - return null
+                    abtd = null;
+
+                } else {
+
+                    LOG.debug("convertAtlasAttributeDef: caught exception from Atlas typeDefStore.getByName or Atlas typeRegistry getTypeDefByName, looking for name {}", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage( metadataCollectionId, "convertAtlasAttributeDef", e.getMessage());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "convertAtlasAttributeDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+            }
+
+
+            if (abtd == null) {
+
+                OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NAME_NOT_KNOWN;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasTypeName, "convertAtlasAttributeDef", metadataCollectionId);
+
+                throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "convertAtlasAttributeDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            // abtd is known to be good
+
+            atlasCategory = abtd.getCategory();
+            LOG.debug("convertAtlasAttributeDef: Retrieved typedef from store - attribute category is {}", atlasCategory);
+            if (atlasCategory != ENUM) {
+                // This is not a type of attribute that we can support in OM, we need to fail the conversion of the enclosing def...
+                // This is the end of the road for attributes of type category OBJECT_ID_TYPE, STRUCT, CLASSIFICATION, ENTITY, RELATIONSHIP
+                LOG.error("convertAtlasAttributeDef: The Atlas attribute category {} is not represented in OM - giving up on typedef {}", atlasCategory, atlasTypeName);
+
+                // Throw an error here - which will cause the whole type to be skipped.
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(aad.getName(), aad.getTypeName());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "convertAtlasAttributeDefs",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+        }
+        LOG.debug("convertAtlasAttributeDef: AtlasAttributeDef {} handled as {}", atlasTypeName, atlasCategory);
+
+
+        // Create OMRS TypeDefAttribute
+        TypeDefAttribute omrsTypeDefAttribute = new TypeDefAttribute();
+
+        // Set attributeName
+        omrsTypeDefAttribute.setAttributeName(aad.getName());
+
+        // For OMRS we need to construct an AttributeTypeDef with an AttributeTypeDefCategory, plus guid and name.
+        // This is based on the (already known) atlasCategory.
+        // Iff category is PRIMITIVE, ARRAY, MAP or ENUM create AttributeTypeDef else throw exception.
+        // AttributeTypeDef is abstract so we must wait till we know the category before instantiating relevant implementation subclass.
+        // AttributeTypeDef requires String name, String guid and AttributeTypeDefCategory category
+
+        AttributeTypeDef existingAttributeTypeDef;
+
+        switch (atlasCategory) {
+
+            case PRIMITIVE:
+                // Convert Atlas primitive or date to OM PrimitiveDef
+                // The TypeDefCategory (AttributeTypeDefCategory.PRIMITIVE) is set in the CTOR of PrimitiveDef
+                // The Atlas primitive type is given by the atlasTypeName (which is a String).
+                // Create a PrimitiveDefCategory to pass to the constructor of PrimitiveDef and set the
+                // guid and name to the values found in the PrimitiveDefCategory.
+                PrimitiveDefCategory omrs_primitive_category = TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(atlasTypeName);
+                // Speculatively create an ATD and then compare it to our own list and to the ATDs known by the RC<...if we find a match we drop it
+                AttributeTypeDef primitiveDef = new PrimitiveDef(omrs_primitive_category);
+                primitiveDef.setName(atlasTypeName);
+                primitiveDef.setGUID(omrs_primitive_category.getGUID());
+                // Using the typeDescription from the AttributeTypeDefCategory
+                primitiveDef.setDescription(primitiveDef.getCategory().getDescription());
+                // descriptionGuid is always set to null - until it is implemented
+                primitiveDef.setDescriptionGUID(null);
+
+                // Look for an ATD with the required category
+                LOG.debug("Look for a matching ATD in the RCM for primitive type {}", atlasTypeName);
+
+                // Ask RepositoryContentManager whether there is an AttributeTypeDef with the name we resolved above
+                String source = metadataCollectionId;
+                try {
+                    existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(source, atlasTypeName);
+
+                } catch (OMRSLogicErrorException e) {
+                    LOG.error("convertAtlasAttributeDef: caught exception from RepositoryHelper", e);
+                    OMRSErrorCode errorCode = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                    throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "atlasTypeName",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+
+                if (existingAttributeTypeDef == null) {
+                    // No existing ATD was found in RH so use the candidate attribute type def
+                    LOG.debug("convertAtlasAttributeDef: repository content manager returned name not found - generate GUIDs and publish");
+                    // Check (by name) whether we have already added one to current TDBC - e.g. if there are
+                    // multiple attributes of the same type - they should refer to the same ATD in TDBC.
+                    // So if it does not already exist add the new ATD (plus GUIDs) to the TDBC and use it in TDA.
+                    // If there is already a TDBC copy of the ATD then reuse that as-is in the TDA.
+                    PrimitiveDef tdbcCopy = typeDefsForAPI.getPrimitiveDef(primitiveDef.getName());
+                    if (tdbcCopy != null) {
+                        // Found - so reuse it
+                        LOG.debug("convertAtlasAttributeDef: found existing ATD in typeDefsForAPI");
+                        primitiveDef = tdbcCopy;
+                    } else {
+                        // Not found - so add it
+                        LOG.debug("convertAtlasAttributeDef: did not find existing ATD in typeDefsForAPI");
+                        // Set the GUID to a new generated value and descriptionGUID to null
+                        String newGuid = UUID.randomUUID().toString();
+                        primitiveDef.setGUID(newGuid);
+                        primitiveDef.setDescriptionGUID(null);
+                        // Add to TDBC
+                        typeDefsForAPI.addPrimitiveDef(primitiveDef);
+                    }
+                    omrsTypeDefAttribute.setAttributeType(primitiveDef);
+
+                } else {
+                    // name matched
+                    LOG.debug("convertAtlasAttributeDef: there is an AttributeTypeDef with name {} : {}", atlasTypeName, existingAttributeTypeDef);
+                    if (existingAttributeTypeDef.getCategory() == AttributeTypeDefCategory.PRIMITIVE) {
+                        LOG.debug("convertAtlasAttributeDef: existing AttributeTypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                        // There is an existing primitive with this name - perform deep compare and only publish if exact match
+                        // Perform a deep compare of the known type and new type
+                        Comparator comp = new Comparator();
+                        PrimitiveDef existingPrimitiveDef = (PrimitiveDef) existingAttributeTypeDef;
+                        PrimitiveDef newPrimitiveDef = (PrimitiveDef) primitiveDef;
+                        LOG.debug("convertAtlasAttributeDef: check equivalence of existing and new AttributeTypeDef {} vs {} ", existingAttributeTypeDef, newPrimitiveDef);
+                        boolean typematch = comp.equivalent(existingPrimitiveDef, newPrimitiveDef);
+                        // If compare matches then we can proceed to publish the def
+                        if (typematch) {
+                            // There is exact match in the ReposHelper - we will add that to our TDG and use it in our TDA
+                            LOG.debug("convertAtlasAttributeDef: using the existing ATD for type name {}", atlasTypeName);
+                            typeDefsForAPI.addPrimitiveDef(existingAttributeTypeDef);
+                            omrsTypeDefAttribute.setAttributeType(existingAttributeTypeDef);
+                        } else {
+                            // If compare failed abandon processing of this EnumDef
+                            LOG.error("convertAtlasAttributeDef: existing AttributeTypeDef did not match");
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "atlasTypeName",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+
+                        }
+                    } else {
+                        // There is a type of this name but it is not an EnumDef - fail!
+                        LOG.error("convertAtlasAttributeDef: existing AttributeTypeDef not a Primitive - has category {}", existingAttributeTypeDef.getCategory());
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "atlasTypeName",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+                }
+
+                break;
+
+            case ARRAY:
+                // Attribute is an array - of primitive elements.
+                // If we are dealing with an ArrayDef then we can use the structure of the typename to derive the element type
+                if (!(atlasTypeName.startsWith(ATLAS_TYPE_ARRAY_PREFIX) && atlasTypeName.endsWith(ATLAS_TYPE_ARRAY_SUFFIX))) {
+                    // sanity check failed - there is something more subtle about this name, log it and give up
+                    LOG.error("convertAtlasAttributeDef: could not parse atlas type name {}", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "atlasTypeName",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                } else {
+
+                    int startIdx = ATLAS_TYPE_ARRAY_PREFIX.length();
+                    int endIdx = atlasTypeName.length() - ATLAS_TYPE_ARRAY_SUFFIX.length();
+                    String elementTypeName = atlasTypeName.substring(startIdx, endIdx);
+                    LOG.debug("convertAtlasAttributeDef OK : handling an Atlas array in which the elements are of type {}", elementTypeName);
+                    // Convert this into a CollectionDef of the appropriate element type...
+                    CollectionDef omrsCollectionDef = new CollectionDef(OM_COLLECTION_ARRAY);
+                    // CollectionDefCategory and argumentCount are set by constructor.
+                    // We need to set up the argument types...
+                    ArrayList<PrimitiveDefCategory> argTypes = new ArrayList<>();
+                    PrimitiveDefCategory pdc = TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(elementTypeName);
+                    argTypes.add(pdc);
+                    omrsCollectionDef.setArgumentTypes(argTypes);
+
+                    // The collection name can be generated from the template name in the collection def cat with parameter substitution.
+                    String nameTemplate = omrsCollectionDef.getCollectionDefCategory().getName();
+                    // I'm not sure how this was intended to be used so this might be rather odd but here goes...
+                    LOG.debug("convertAtlasAttributeDef Generate Array Attributes: name template is {}", nameTemplate);
+                    String[] parts = nameTemplate.split("[{}]");
+                    String omrsArrayTypeName = parts[0] + elementTypeName + parts[2];
+                    LOG.debug("name resolved to {}", omrsArrayTypeName);
+                    omrsCollectionDef.setName(omrsArrayTypeName);
+
+                    // For now we do not need the version, versionName and description. They will be needed if the type is new (below).
+
+                    // Look for an ATD with the required category
+                    LOG.debug("Look for a matching ATD in the RCM for array type {}", atlasTypeName);
+
+                    // Look in the RCM
+
+                    // Ask RepositoryContentManager whether there is an AttributeTypeDef with the name we resolved above
+                    try {
+                        existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(metadataCollectionId, omrsArrayTypeName);
+                    } catch (OMRSLogicErrorException e) {
+                        LOG.error("convertAtlasAttributeDef: caught exception from RepositoryHelper, giving up trying to convert attribute {}", omrsArrayTypeName, e);
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "atlasTypeName",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+
+                    }
+                    if (existingAttributeTypeDef == null) {
+                        // No existing ATD was found in RH so use the candidate attribute type def
+                        LOG.debug("convertAtlasAttributeDef: repository content manager returned name not found - generate GUIDs and publish");
+                        // Check (by name) whether we have already added one to current TDBC - e.g. if there are
+                        // multiple attributes of the same type - they should refer to the same ATD in TDBC.
+                        // So if it does not already exist add the new ATD (plus GUIDs) to the TDBC and use it in TDA.
+                        // If there is already a TDBC copy of the ATD then reuse that as-is in the TDA.
+                        CollectionDef tdbcCopy = typeDefsForAPI.getCollectionDef(omrsCollectionDef.getName());
+                        if (tdbcCopy != null) {
+                            // Found - so reuse it
+                            LOG.debug("convertAtlasAttributeDef: found existing ATD in typeDefsForAPI");
+                            omrsCollectionDef = tdbcCopy;
+                        } else {
+                            // Not found - so add it
+                            LOG.debug("convertAtlasAttributeDef: did not find existing ATD in typeDefsForAPI");
+                            // Set the GUID to a new generated value and descriptionGUID to null
+                            String newGuid = UUID.randomUUID().toString();
+                            omrsCollectionDef.setGUID(newGuid);
+                            omrsCollectionDef.setVersion(1);
+                            omrsCollectionDef.setDescription("An array of " + elementTypeName);
+                            omrsCollectionDef.setDescriptionGUID(null);
+                            // Add to TDBC
+                            typeDefsForAPI.addCollectionDef(omrsCollectionDef);
+                        }
+                        omrsTypeDefAttribute.setAttributeType(omrsCollectionDef);
+
+                    } else {
+
+                        // name matched
+                        LOG.debug("convertAtlasAttributeDef: there is an AttributeTypeDef with name {} : {}", omrsArrayTypeName, existingAttributeTypeDef);
+                        if (existingAttributeTypeDef.getCategory() == COLLECTION) {
+                            LOG.debug("convertAtlasAttributeDef: existing AttributeTypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                            // There is an existing collection (array) with this name - perform deep compare and only publish if exact match
+                            // Perform a deep compare of the known type and new type
+                            Comparator comp = new Comparator();
+                            CollectionDef existingCollectionDef = (CollectionDef) existingAttributeTypeDef;
+
+                            // Before performing the compare - we need to assist things a little
+                            // A CollectionDef needs a guid but cannot get it from Atlas.
+                            // Since the RCM knows about this collection type we must have added it already and it must have a GUID
+                            // So adopt the GUID found in the RCM. May as well adopt version and description as well...
+                            omrsCollectionDef.setGUID(existingCollectionDef.getGUID());
+                            omrsCollectionDef.setVersion(existingCollectionDef.getVersion());
+                            omrsCollectionDef.setDescription(existingCollectionDef.getDescription());
+
+                            // Compare existing versus new collection def
+                            boolean typematch = comp.compare(true, existingCollectionDef, omrsCollectionDef);
+                            // If compare matches then we can proceed to publish the def
+                            if (typematch) {
+                                // There is exact match in the ReposHelper - we will add that to our TDG and use it in our TDA
+                                LOG.debug("convertAtlasAttributeDef: using the existing ATD for type name {}", omrsArrayTypeName);
+                                typeDefsForAPI.addCollectionDef(existingAttributeTypeDef);
+                                omrsTypeDefAttribute.setAttributeType(existingAttributeTypeDef);
+                            } else {
+                                // If compare failed generate AUDIT log entry and abandon processing of this EnumDef
+                                LOG.error("convertAtlasAttributeDef: repository content manager found clashing def with name {}", omrsArrayTypeName);
+                                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                                String errorMessage = errorCode.getErrorMessageId()
+                                        + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                        this.getClass().getName(),
+                                        "atlasTypeName",
+                                        errorMessage,
+                                        errorCode.getSystemAction(),
+                                        errorCode.getUserAction());
+                            }
+                        } else {
+                            // There is a type of this name but it is not a CollectionDef - fail!
+                            LOG.error("convertAtlasAttributeDef: repository content manager found type but not a Collection - has category {}", existingAttributeTypeDef.getCategory());
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "atlasTypeName",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+                    }
+                }
+                break;
+
+            case MAP:
+                // Attribute is a map - from AtlasType to AtlasType - where these are assumed to be primitive.
+                // If we are dealing with a MapDef then we can use the structure of the typename to derive the element type
+                if (!(atlasTypeName.startsWith(ATLAS_TYPE_MAP_PREFIX) && atlasTypeName.endsWith(ATLAS_TYPE_MAP_SUFFIX))) {
+                    // sanity check failed - there is something more subtle about this name, log it and give up
+                    LOG.error("convertAtlasAttributeDef: could not parse atlas type name {}", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "atlasTypeName",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                } else {
+
+                    int startIdx = ATLAS_TYPE_MAP_PREFIX.length();
+                    int endIdx = atlasTypeName.length() - ATLAS_TYPE_MAP_SUFFIX.length();
+                    String[] keyValueTypes = atlasTypeName.substring(startIdx, endIdx).split(ATLAS_TYPE_MAP_KEY_VAL_SEP, 2);
+                    String keyTypeName = keyValueTypes.length > 0 ? keyValueTypes[0] : null;
+                    String valueTypeName = keyValueTypes.length > 1 ? keyValueTypes[1] : null;
+
+                    LOG.debug("convertAtlasAttributeDef: handling Atlas map with elements of type {} {}", keyTypeName, valueTypeName);
+                    // Convert this into a CollectionDef of the appropriate element type...
+                    CollectionDef omrsCollectionDef = new CollectionDef(OM_COLLECTION_MAP);
+
+                    // Set up the list of argument types...
+                    ArrayList<PrimitiveDefCategory> argTypes = new ArrayList<>();
+                    PrimitiveDefCategory pdck = TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(keyTypeName);
+                    PrimitiveDefCategory pdcv = TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(valueTypeName);
+                    argTypes.add(pdck);
+                    argTypes.add(pdcv);
+                    omrsCollectionDef.setArgumentTypes(argTypes);
+
+
+                    // Set name
+                    // The collection name can be generated from the name in the collection def cat with suitable parameter substitution...
+                    String nameTemplate = omrsCollectionDef.getCollectionDefCategory().getName();
+                    // I'm not sure how this was intended to be used so this might be rather odd but here goes...
+                    LOG.debug("Generate Map Attributes: name template is {}", nameTemplate);
+                    String[] parts = nameTemplate.split("[{}]");
+                    String omrsMapTypeName = parts[0] + keyTypeName + ',' + valueTypeName + parts[4];
+                    LOG.debug("name resolved to {}", omrsMapTypeName);
+                    omrsCollectionDef.setName(omrsMapTypeName);
+
+                    // Need to find out if we ave seen this OMRS attribute type def before - look in local cache and ask RCM
+
+                    // Look for an ATD with the required category
+                    LOG.debug("Look for a matching ATD in the RCM for map type {}", atlasTypeName);
+
+                    // Look in the RCM
+                    // Ask RepositoryContentManager whether there is an AttributeTypeDef with the name we resolved above
+                    try {
+                        existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(metadataCollectionId, omrsMapTypeName);
+                    } catch (OMRSLogicErrorException e) {
+                        LOG.error("convertAtlasAttributeDef: caught exception from RepositoryHelper, giving up trying to convert attribute {}", omrsMapTypeName, e);
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "atlasTypeName",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+                    if (existingAttributeTypeDef == null) {
+                        // No existing ATD was found in RH so use the candidate attribute type def
+                        LOG.debug("convertAtlasAttributeDef: repository content manager returned name not found - generate GUIDs and publish");
+                        // Check (by name) whether we have already added one to current TDBC - e.g. if there are
+                        // multiple attributes of the same type - they should refer to the same ATD in TDBC.
+                        // So if it does not already exist add the new ATD (plus GUIDs) to the TDBC and use it in TDA.
+                        // If there is already a TDBC copy of the ATD then reuse that as-is in the TDA.
+                        CollectionDef tdbcCopy = typeDefsForAPI.getCollectionDef(omrsCollectionDef.getName());
+                        if (tdbcCopy != null) {
+                            // Found - so reuse it
+                            LOG.debug("convertAtlasAttributeDef: found existing ATD in typeDefsForAPI");
+                            omrsCollectionDef = tdbcCopy;
+                        } else {
+                            // Not found - so add it
+                            LOG.debug("convertAtlasAttributeDef: did not find existing ATD in typeDefsForAPI");
+                            // Set the GUID to a new generated value and descriptionGUID to null
+                            String newGuid = UUID.randomUUID().toString();
+                            omrsCollectionDef.setGUID(newGuid);
+                            omrsCollectionDef.setVersion(1);
+                            omrsCollectionDef.setDescription("A map of " + keyTypeName + " to " + valueTypeName);
+                            omrsCollectionDef.setDescriptionGUID(null);
+                            // Add to TDBC
+                            typeDefsForAPI.addCollectionDef(omrsCollectionDef);
+                        }
+                        omrsTypeDefAttribute.setAttributeType(omrsCollectionDef);
+
+                    } else {
+                        // name matched
+                        LOG.debug("convertAtlasAttributeDef: there is an AttributeTypeDef with name {} : {}", omrsMapTypeName, existingAttributeTypeDef);
+                        if (existingAttributeTypeDef.getCategory() == COLLECTION) {
+                            LOG.debug("convertAtlasAttributeDef: existing AttributeTypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                            // There is an existing collection (map) with this name - perform deep compare and only publish if exact match
+                            // Perform a deep compare of the known type and new type
+                            Comparator comp = new Comparator();
+                            CollectionDef existingCollectionDef = (CollectionDef) existingAttributeTypeDef;
+
+                            // Before performing the compare - we need to assist things a little
+                            // A CollectionDef needs a guid but cannot get it from Atlas.
+                            // Since the RCM knows about this collection type we must have added it already and it must have a GUID
+                            // So adopt the GUID found in the RCM. May as well adopt version and description as well...
+                            omrsCollectionDef.setGUID(existingCollectionDef.getGUID());
+                            omrsCollectionDef.setVersion(existingCollectionDef.getVersion());
+                            omrsCollectionDef.setDescription(existingCollectionDef.getDescription());
+
+                            // Compare existing versus new collection def
+                            boolean typematch = comp.compare(true, existingCollectionDef, omrsCollectionDef);
+                            // If compare matches then we can proceed to publish the def
+                            if (typematch) {
+                                // There is exact match in the ReposHelper - we will add that to our TDG and use it in our TDA
+                                LOG.debug("convertAtlasAttributeDef: using the existing ATD for type name {}", omrsMapTypeName);
+                                typeDefsForAPI.addCollectionDef(existingAttributeTypeDef);
+                                omrsTypeDefAttribute.setAttributeType(existingAttributeTypeDef);
+                            } else {
+                                // If compare failed generate AUDIT log entry and abandon processing of this EnumDef
+                                LOG.error("convertAtlasAttributeDef: repository content manager found clashing def with name {}", omrsMapTypeName);
+                                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                                String errorMessage = errorCode.getErrorMessageId()
+                                        + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                        this.getClass().getName(),
+                                        "atlasTypeName",
+                                        errorMessage,
+                                        errorCode.getSystemAction(),
+                                        errorCode.getUserAction());
+                            }
+                        } else {
+                            // There is a type of this name but it is not an EnumDef - fail!
+                            LOG.error("convertAtlasAttributeDef: repository content manager found type but not a Collection - has category {}", existingAttributeTypeDef.getCategory());
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "atlasTypeName",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+                    }
+                }
+                break;
+
+            case ENUM:
+                // The attribute is an enum. The OM TypeDefAttribute needs to contain an ATD pointing to the OM EnumDef.
+                // To create this we need to locate the atlas type def used for the enum - and convert that to an OM EnumDef.
+                // The AtlasType.typeName is equal to the AtlasTypeDef.name - so take the typeName and look in the def store
+                // Note that we already looked this enum up before - when refactored we save this this extra lookup
+                AtlasEnumDef atlasEnumDef;
+                AtlasBaseTypeDef atlasBaseTypeDef;
+                try {
+                    if (!useRegistry) {
+                        // Look in the Atlas type def store
+                        atlasBaseTypeDef = typeDefStore.getByName(atlasTypeName);
+                    }
+                    else {
+                        // Using registry
+                        atlasBaseTypeDef = typeRegistry.getTypeDefByName(atlasTypeName);
+                    }
+                }
+                catch (AtlasBaseException e) {
+                    // handle below
+                    LOG.error("convertAtlasAttributeDef: Caught exception from type def store, looking for type def with name {}", atlasTypeName, e);
+                    atlasBaseTypeDef = null;
+                }
+                if (atlasBaseTypeDef == null || atlasBaseTypeDef.getCategory() != ENUM) {
+                    // Either no type def was found or the type def found is not a type of attribute that we can support in OM.
+                    // We need to fail the conversion of the enclosing def...
+                    // This is the end of the road for attributes of type category OBJECT_ID_TYPE, STRUCT, CLASSIFICATION, ENTITY,
+                    // RELATIONSHIP
+                    LOG.error("convertAtlasAttributeDef: could not find an EnumDef for name {}", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("AtlasEnumDef", "AtlasEnumDef", "convertAtlasAttributeDef", metadataCollectionId);
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "convertAtlasAttributeDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+
+                // We have an AtlasBaseTypeDef with category ENUM.
+                // We can call convertAtlasEnumDefToOMRSEnumDef(AtlasEnumDef atlasEnumDef) to ensure the EnumDef is on our TDBC ATD list.
+                // We can then retrieve it from the TDBC list and refer to it in the TDA
+                // If that retrieval fails then the Atlas enum was not converted into an OM EnumDef so we give up the Attribute conversion...
+                atlasEnumDef = (AtlasEnumDef) atlasBaseTypeDef;
+                LOG.debug("convertAtlasAttributeDef: Retrieved AtlasEnumDef from store {}", atlasEnumDef);
+
+                // Attempt the conversion to OM
+
+                try {
+
+                    metadataCollection.processAtlasEnumDef(atlasEnumDef);
+
+                }
+                catch (TypeErrorException e) {
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("AtlasEnumDef", "AtlasEnumDef", "convertAtlasAttributeDef", metadataCollectionId);
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "convertAtlasAttributeDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+
+                // Retrieve the result
+                boolean enumdef_matched = false;
+                AttributeTypeDef omrsEnumDef = null;
+                if (typeDefsForAPI.getEnumDefs() != null) {
+                    for (AttributeTypeDef atd : typeDefsForAPI.getEnumDefs()) {
+                        if (atd.getName().equals(atlasTypeName)) {
+                            enumdef_matched = true;
+                            omrsEnumDef = atd;
+                            break;
+                        }
+                    }
+                }
+                if (enumdef_matched) {
+                    // We found the OM EnumDef - refer to it from the TDA; it will already have been added to TDB so will go in the TDG.
+                    LOG.debug("convertAtlasAttributeDef: located OM EnumDef with name {}", omrsEnumDef.getName());
+                    omrsTypeDefAttribute.setAttributeType(omrsEnumDef);
+                } else {
+                    LOG.error("convertAtlasAttributeDef: could not locate OM EnuMDef with name {}", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "atlasTypeName",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+                break;
+
+            default:
+
+                LOG.error("convertAtlasAttributeDef: Could not handle Atlas attribute category {}", atlasCategory);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasTypeName, "atlasTypeName",metadataCollectionId);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "atlasTypeName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+
+
+        // Copy description
+        omrsTypeDefAttribute.setAttributeDescription(aad.getDescription());
+
+        /* Cardinality
+         * Map the Atlas value to an OMRS value
+         *
+         * Atlas has Cardinality values (as below) plus isOptional (boolean):
+         *        SINGLE
+         *        LIST
+         *        SET
+         * OMRS AttributeCardinality is:
+         *        UNKNOWN                (0, "<Unknown>",                "Unknown or uninitialized cardinality"),
+         *        AT_MOST_ONE            (1, "At Most One",              "0..1 - Zero or one instances. 0..1."),
+         *        ONE_ONLY               (2, "One Only",                 "1 - One instance, no more and no less"),
+         *        AT_LEAST_ONE_ORDERED   (3, "At Least One (Ordered)",   "1..* - One or more instances (stored in specific order)"),
+         *        AT_LEAST_ONE_UNORDERED (4, "At Least One (Unordered)", "1..* - One or more instances (stored in any order)"),
+         *        ANY_NUMBER_ORDERED     (5, "Any Number (Ordered)",     "0..* - Any number of instances (stored in a specific order)"),
+         *        ANY_NUMBER_UNORDERED   (6, "Any Number (Unordered)",   "0..* - Any number of instances (stored in any order)");
+         *
+         * The Atlas values map to the OMRS values follows:
+         *    atlas                ->   omrs
+         *  isOptional && SINGLE   ->  AT_MOST_ONE
+         *  !isOptional && SINGLE  ->  ONE_ONLY
+         *  !isOptional && LIST    ->  AT_LEAST_ONE_ORDERED
+         *  !isOptional && SET     ->  AT_LEAST_ONE_UNORDERED
+         *  isOptional && LIST     ->  ANY_NUMBER_ORDERED
+         *  isOptional && SET      ->  ANY_NUMBER_UNORDERED
+         *  any other combination  ->  UNKNOWN
+         */
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality = aad.getCardinality();
+        AttributeCardinality omrsCardinality;
+        boolean isOptional = aad.getIsOptional();
+        switch (atlasCardinality) {
+            case SINGLE:
+                omrsCardinality = isOptional ? AT_MOST_ONE : ONE_ONLY;
+                break;
+            case LIST:
+                omrsCardinality = isOptional ? ANY_NUMBER_ORDERED : AT_LEAST_ONE_UNORDERED;
+                break;
+            case SET:
+                omrsCardinality = isOptional ? ANY_NUMBER_UNORDERED : AT_LEAST_ONE_UNORDERED;
+                break;
+            default:
+                omrsCardinality = AttributeCardinality.UNKNOWN;
+                break;
+        }
+        omrsTypeDefAttribute.setAttributeCardinality(omrsCardinality);
+
+        // Map other fields
+        omrsTypeDefAttribute.setValuesMinCount(aad.getValuesMinCount());
+        omrsTypeDefAttribute.setValuesMaxCount(aad.getValuesMaxCount());
+        omrsTypeDefAttribute.setIndexable(aad.getIsIndexable());
+        omrsTypeDefAttribute.setUnique(aad.getIsUnique());
+        omrsTypeDefAttribute.setDefaultValue(aad.getDefaultValue());
+        omrsTypeDefAttribute.setExternalStandardMappings(null);
+
+        LOG.debug("convertAtlasAttributeDef: OMRS TypeDefAttribute is {}", omrsTypeDefAttribute);
+        return omrsTypeDefAttribute;
+    }
+
+
+
+
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeMapper.java
new file mode 100644
index 000000000..28c5d4f2b
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasAttributeMapper.java
@@ -0,0 +1,267 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_ARRAY;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_MAP;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+public class AtlasAttributeMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasAttributeMapper.class);
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+    private String userId                                       = null;
+
+    public AtlasAttributeMapper(LocalAtlasOMRSMetadataCollection metadataCollection, String userId) {
+        this.metadataCollection = metadataCollection;
+        this.userId = userId;
+
+    }
+
+
+    /*
+     * Utility method to parse AtlasAttributes into an OM InstanceProperties map.
+     *
+     * @param typeDef
+     * @param atlasAttrs
+     * @return InstanceProperties
+     */
+    public InstanceProperties convertAtlasAttributesToOMProperties(TypeDef typeDef, Map<String, Object> atlasAttrs, boolean uniqueOnly) {
+
+        // Approach:
+        // Start with the TypeDef of the immediate type - and work your way up the supertypes. At
+        // each level in the inheritance graph observe the property names - i.e. TypeDefAttributes
+        // for properties defined at that level, and look for them in the Atlas instance.
+        // Stop when you reach the top.
+        //
+        // For each TDA match by attributeName to key in Atlas entity attributes map.
+        // For each matched key, form an OM IPV and put it into an IP map.
+        // Finally return the IP map.
+
+        // If uniqueOnly is set then only include attributes that are defined as unique (in the TDA)
+
+        InstanceProperties instanceProperties = null;
+        List<TypeDefAttribute> typeDefAttributes = typeDef.getPropertiesDefinition();
+        if (typeDefAttributes != null) {
+            instanceProperties = new InstanceProperties();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                if ( !uniqueOnly || typeDefAttribute.isUnique() ) {
+                    String attrName = typeDefAttribute.getAttributeName();
+                    // try to access the atlas attribute with this name
+                    Object atlasAttrValue = atlasAttrs.get(attrName);
+                    if (atlasAttrValue != null) {
+                        AttributeTypeDef attributeTypeDef = typeDefAttribute.getAttributeType();
+                        AttributeTypeDefCategory category = attributeTypeDef.getCategory();
+                        String typeGuid = attributeTypeDef.getGUID();
+                        String typeName = attributeTypeDef.getName();
+                        InstancePropertyValue instancePropertyValue = null;
+                        switch (category) {
+
+                            case PRIMITIVE:
+                                PrimitiveDef primitiveDef = (PrimitiveDef) attributeTypeDef;
+                                PrimitiveDefCategory primitiveDefCategory = primitiveDef.getPrimitiveDefCategory();
+                                PrimitivePropertyValue primitivePropertyValue = new PrimitivePropertyValue();
+                                primitivePropertyValue.setPrimitiveDefCategory(primitiveDefCategory);
+                                primitivePropertyValue.setTypeGUID(typeGuid);
+                                primitivePropertyValue.setTypeName(typeName);
+                                primitivePropertyValue.setPrimitiveValue(atlasAttrValue);
+                                instancePropertyValue = primitivePropertyValue;
+                                break;
+
+                            case COLLECTION:
+                                CollectionDef collectionDef = (CollectionDef) attributeTypeDef;
+                                CollectionDefCategory collectionDefCategory = collectionDef.getCollectionDefCategory();
+                                if (collectionDefCategory == OM_COLLECTION_ARRAY) {
+                                    // We are expecting to find an array attribute in the atlas attributes...
+                                    int collectionDefArgCount = collectionDef.getArgumentCount();
+                                    // An array property must have exactly 1 type.
+                                    if (collectionDefArgCount != 1) {
+                                        LOG.error("convertAtlasAttributesToOMProperties: array collection attributeTypeDef has {} type arguments", collectionDefArgCount);
+                                        // instancePropertyValue remains null - attribute will be skipped at end of loop
+                                    }
+                                    // OM only deals with collections of primitives.
+                                    PrimitiveDefCategory primDefCat = collectionDef.getArgumentTypes().get(0);
+                                    // Get the object value from Atlas and create an OM property value of appropriate type, we are expecting type defined by primDefCat
+                                    ArrayPropertyValue arrayPropertyValue = null;
+                                    ArrayList atlasArray = (ArrayList)atlasAttrValue;
+                                    int atlasArrayLen = atlasArray.size();
+                                    if (atlasArrayLen > 0) {
+                                        arrayPropertyValue = new ArrayPropertyValue();
+                                        arrayPropertyValue.setTypeGUID(typeGuid);
+                                        arrayPropertyValue.setTypeName(typeName);
+                                        // InstanceProperties is map from String to InstancePropertyValue
+                                        // InstancePropertyValue needs typeName, typeGuid and InstancePropertyCategory
+                                        // InstancePropertyCategory must be primitive (see above)
+                                        InstanceProperties arrayProps = new InstanceProperties();
+                                        for (int i=0; i<atlasArrayLen; i++) {
+                                            Object val = atlasArray.get(i);
+                                            // Create an InstancePropertyValue
+                                            PrimitivePropertyValue ppv = new PrimitivePropertyValue();
+                                            ppv.setPrimitiveDefCategory(primDefCat);
+                                            ppv.setTypeName(primDefCat.getName());
+                                            ppv.setTypeGUID(primDefCat.getGUID());
+                                            ppv.setPrimitiveValue(val);
+                                            // OM array is a map with String keys reflecting array indices...
+                                            arrayProps.setProperty(""+i,ppv);
+                                        }
+                                        arrayPropertyValue.setArrayValues(arrayProps);
+                                        arrayPropertyValue.setArrayCount(atlasArrayLen);
+                                    }
+                                    instancePropertyValue = arrayPropertyValue;
+                                }
+                                else  if (collectionDefCategory == OM_COLLECTION_MAP) {
+                                    // We are expecting to find a map attribute in the atlas attributes...
+                                    int collectionDefArgCount = collectionDef.getArgumentCount();
+                                    // A map property must have exactly 2 type arguments
+                                    if (collectionDefArgCount != 2) {
+                                        LOG.error("convertAtlasAttributesToOMProperties: map collection attributeTypeDef has {} type arguments", collectionDefArgCount);
+                                        // instancePropertyValue remains null - attribute will be skipped at end of loop
+                                    }
+                                    // OM only deals with collections of primitives.
+                                    // In general, maps are always <String,String> but tolerate <String,Primitive> - cannot relax the key type as InstanceProperties defines key type as String
+                                    PrimitiveDefCategory primDefCatKey = collectionDef.getArgumentTypes().get(0);
+                                    PrimitiveDefCategory primDefCatVal = collectionDef.getArgumentTypes().get(1);
+                                    // Get the object value from Atlas and create an OM property value of appropriate type, we are expecting type defined by primDefCat
+                                    MapPropertyValue mapPropertyValue = null;
+                                    try {
+                                        Map<String, Object> atlasMap = (Map<String, Object>) atlasAttrValue;
+
+                                        int atlasMapSize = atlasMap.size();
+                                        if (atlasMapSize > 0) {
+                                            mapPropertyValue = new MapPropertyValue();
+                                            mapPropertyValue.setTypeGUID(typeGuid);
+                                            mapPropertyValue.setTypeName(typeName);
+                                            // InstanceProperties is map from String to InstancePropertyValue
+                                            // InstancePropertyValue needs typeName, typeGUID and InstancePropertyCategory (which is set on construction of subtype)
+                                            // InstancePropertyCategory must be primitive (see above)
+                                            InstanceProperties mapProps = new InstanceProperties();
+
+                                            for (Object oKey : atlasMap.keySet()) {                      // for each Atlas map entry
+                                                if (oKey instanceof String) {            // otherwise this map entry will be skipped
+                                                    String key = (String) oKey;
+                                                    Object val = atlasMap.get(key);
+                                                    // Create an InstancePropertyValue
+                                                    PrimitivePropertyValue ppv = new PrimitivePropertyValue();
+                                                    ppv.setPrimitiveDefCategory(primDefCatVal);
+                                                    ppv.setTypeName(primDefCatVal.getName());
+                                                    ppv.setTypeGUID(primDefCatVal.getGUID());
+                                                    ppv.setPrimitiveValue(val);
+                                                    // OM array is a map with String keys reflecting array indices...
+                                                    mapProps.setProperty(key, ppv);
+                                                }
+                                            }
+                                            mapPropertyValue.setMapValues(mapProps);
+                                        }
+                                        instancePropertyValue = mapPropertyValue;
+                                    }
+                                    catch (ClassCastException e) {
+                                        // Could not cast atlas attribute to Map<String,Object> - game over...
+                                        LOG.debug("convertAtlasAttributesToOMProperties: cannot handle an Atlas attribute {} as it is not a map<String,Object>", attrName);
+                                        // instancePropertyValue remains null - attribute will be skipped at end of loop
+                                    }
+                                }
+                                else {
+                                    LOG.debug("convertAtlasAttributesToOMProperties: ignoring collection attribute {} - not an array or map",attrName);
+                                    // instancePropertyValue remains null - attribute will be skipped at end of loop
+                                }
+
+                                break;
+
+                            case ENUM_DEF:
+                                EnumPropertyValue enumPropertyValue = new EnumPropertyValue();
+                                enumPropertyValue.setTypeGUID(typeGuid);
+                                enumPropertyValue.setTypeName(typeName);
+                                EnumDef enumDef = (EnumDef) attributeTypeDef;
+                                List<EnumElementDef> elems = enumDef.getElementDefs();
+                                boolean matched = false;
+                                for (EnumElementDef elem : elems) {
+                                    if (elem.getValue().equals(atlasAttrValue)) {
+                                        enumPropertyValue.setSymbolicName(elem.getValue());
+                                        enumPropertyValue.setOrdinal(elem.getOrdinal());
+                                        enumPropertyValue.setDescription(elem.getDescription());
+                                        matched = true;
+                                        break;
+                                    }
+                                }
+                                if (matched) {
+                                    instancePropertyValue = enumPropertyValue;
+                                } else {
+                                    LOG.debug("convertAtlasAttributesToOMProperties: could not match enum value in attribute {}", attrName);
+                                    // instancePropertyValue remains null - attribute will be skipped at end of loop
+                                }
+                                break;
+
+                            case UNKNOWN_DEF:
+                            default:
+                                LOG.debug("convertAtlasAttributesToOMProperties: attribute {} has unknown category - attribute ignored", attrName);
+                                break;
+                        }
+                        // Add the IPV to the IP map
+                        if (instancePropertyValue != null) {
+                            instanceProperties.setProperty(attrName, instancePropertyValue);
+                        }
+                    } else {
+                        LOG.debug("convertAtlasAttributesToOMProperties: attribute {} value is null - attribute ignored", attrName);
+                    }
+                }
+            }
+        }
+        // Visit the next type in the supertype hierarchy, if any
+        TypeDefLink superTypeLink = typeDef.getSuperType();
+        if (superTypeLink != null) {
+            // Retrieve the supertype - the TDL gives us its GUID and name
+            if (superTypeLink.getName() != null) {
+                TypeDef superTypeDef = null;
+                try {
+                    superTypeDef = metadataCollection._getTypeDefByName(userId, superTypeLink.getName());
+                } catch (Exception e) {
+                    LOG.error("convertAtlasAttributesToOMProperties: caught exception from getTypeDefByName for {}", superTypeLink.getName(), e);
+                }
+                if (superTypeDef != null) {
+                    InstanceProperties additionalProps = convertAtlasAttributesToOMProperties(superTypeDef, atlasAttrs, uniqueOnly);
+                    if (additionalProps != null) {
+                        // Add the additional properties to any we already found at this level...
+                        if (instanceProperties == null) {
+                            // We did not already find any properties (at the original instance level) so need
+                            // to allocate the InstanceProperties now.
+                            instanceProperties = new InstanceProperties();
+                        }
+                        Iterator<String> propIter = additionalProps.getPropertyNames();
+                        while (propIter.hasNext()) {
+                            String propName = propIter.next();
+                            instanceProperties.setProperty(propName, additionalProps.getPropertyValue(propName));
+                        }
+                    }
+                }
+            }
+        }
+        return instanceProperties;
+    }
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasBaseTypeDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasBaseTypeDefMapper.java
new file mode 100644
index 000000000..f0df825c4
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasBaseTypeDefMapper.java
@@ -0,0 +1,223 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasBaseTypeDef;
+import org.apache.atlas.model.typedef.AtlasEnumDef;
+import static org.apache.atlas.model.TypeCategory.PRIMITIVE;
+import static org.apache.atlas.model.typedef.AtlasBaseTypeDef.*;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_ARRAY;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.CollectionDefCategory.OM_COLLECTION_MAP;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class AtlasBaseTypeDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasAttributeMapper.class);
+
+
+    private AtlasBaseTypeDef abtd         = null;
+
+    public AtlasBaseTypeDefMapper(AtlasBaseTypeDef abtd) {
+        this.abtd = abtd;
+    }
+
+
+    // Convert an AtlasBaseTypeDef into an AttributeTypeDef
+    //
+    // GUID will always be wild for a collection (MAP or ARRAY) - use the one from the repos helper or create a new UUID
+    // descriptionGUID is will always be wild for all categories -  use the one from the repos helper or create a new UUID
+    // Until it is used properly, descriptionGUID is always set to null.
+    //
+    // package private
+    AttributeTypeDef toAttributeTypeDef() {
+
+
+        LOG.debug("toAttributeTypeDef: AtlasBaseTypeDef is {}", abtd);
+
+        if (abtd == null) {
+            return null;
+        }
+
+        AttributeTypeDef ret;
+
+        // Find the category
+        String atlasTypeName = abtd.getName();
+        TypeCategory atlasCategory;
+        if (atlasTypeName.equals(ATLAS_TYPE_DATE)) {
+            // In Atlas dates are handled as primitives, so we need to adopt a category of PRIMITIVE
+            atlasCategory = PRIMITIVE;
+        } else {
+            atlasCategory = abtd.getCategory();
+        }
+
+        LOG.debug("toAttributeTypeDef: atlasTypeName {} atlasCategory {}", atlasTypeName, atlasCategory);
+
+        // Based on the Atlas type category., produce the appropriate category of OM ATD
+        AttributeTypeDef attributeTypeDef;
+        switch (atlasCategory) {
+
+            case PRIMITIVE:
+
+                // Handle atlas primitives and date
+                PrimitiveDefCategory primDefCat =  TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(atlasTypeName);
+                LOG.debug("toAttributeTypeDef : handling an Atlas primitive {}", primDefCat);
+                PrimitiveDef primitiveDef = new PrimitiveDef(primDefCat);
+                primitiveDef.setGUID(primDefCat.getGUID());
+                primitiveDef.setName(atlasTypeName);
+                AttributeTypeDefCategory primitiveDefCategory = primitiveDef.getCategory();
+                if (primitiveDefCategory != null)
+                    primitiveDef.setDescription(primitiveDefCategory.getDescription());
+                primitiveDef.setDescriptionGUID(null);
+                attributeTypeDef = primitiveDef;
+                ret = attributeTypeDef;
+                break;
+
+            case ARRAY:
+
+                int startIdx = ATLAS_TYPE_ARRAY_PREFIX.length();
+                int endIdx = atlasTypeName.length() - ATLAS_TYPE_ARRAY_SUFFIX.length();
+                String elementTypeName = atlasTypeName.substring(startIdx, endIdx);
+                LOG.debug("toAttributeTypeDef : handling an Atlas array in which the elements are of type {}", elementTypeName);
+                // Convert this into a CollectionDef of the appropriate element type...
+                CollectionDef collectionDef = new CollectionDef(OM_COLLECTION_ARRAY);
+                // Set up the list of argument types...
+                ArrayList<PrimitiveDefCategory> argTypes = new ArrayList<>();
+                PrimitiveDefCategory pdc = TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(elementTypeName);
+                argTypes.add(pdc);
+                collectionDef.setArgumentTypes(argTypes);
+                // The collection name can be generated from the template name in the collection def cat with parameter substitution.
+                String nameTemplate = collectionDef.getCollectionDefCategory().getName();
+                // I'm not sure how this was intended to be used so this might be rather odd but here goes...
+                LOG.debug("toAttributeTypeDef: Generate Array Attributes: name template is {}", nameTemplate);
+                String[] parts = nameTemplate.split("[{}]");
+                String omrsArrayTypeName = parts[0] + elementTypeName + parts[2];
+                LOG.debug("toAttributeTypeDef: name resolved to {}", omrsArrayTypeName);
+                collectionDef.setName(omrsArrayTypeName);
+
+                /* Set inherited ATD fields
+                 * protected String                   guid
+                 * protected String                   name
+                 * protected String                   description
+                 * protected String                   descriptionGUID
+                 */
+
+                // Set Guid to wildcard
+                collectionDef.setGUID(null);
+                collectionDef.setName(atlasTypeName);
+                collectionDef.setDescription(collectionDef.getCategory().getDescription());
+                collectionDef.setDescriptionGUID(null);
+                attributeTypeDef = collectionDef;
+                ret = attributeTypeDef;
+                break;
+
+            case MAP:
+
+                int mapStartIdx = ATLAS_TYPE_MAP_PREFIX.length();
+                int mapEndIdx = atlasTypeName.length() - ATLAS_TYPE_MAP_SUFFIX.length();
+                String[] keyValueTypes = atlasTypeName.substring(mapStartIdx, mapEndIdx).split(ATLAS_TYPE_MAP_KEY_VAL_SEP, 2);
+                String keyTypeName = keyValueTypes.length > 0 ? keyValueTypes[0] : null;
+                String valueTypeName = keyValueTypes.length > 1 ? keyValueTypes[1] : null;
+                LOG.debug("toAttributeTypeDef : handling an Atlas map in which the elements are of type {} {}", keyTypeName, valueTypeName);
+                // Convert this into a CollectionDef of the appropriate element type...
+                CollectionDef omrsCollectionDef = new CollectionDef(OM_COLLECTION_MAP);
+                // Set up the list of argument types...
+                ArrayList<PrimitiveDefCategory> mapArgTypes = new ArrayList<>();
+                PrimitiveDefCategory pdck =  TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(keyTypeName);
+                PrimitiveDefCategory pdcv =  TypeNameUtils.convertAtlasTypeNameToPrimitiveDefCategory(valueTypeName);
+                mapArgTypes.add(pdck);
+                mapArgTypes.add(pdcv);
+                omrsCollectionDef.setArgumentTypes(mapArgTypes);
+                // The collection name can be generated from the name in the collection def cat with suitable parameter substitution...
+                String mapNameTemplate = omrsCollectionDef.getCollectionDefCategory().getName();
+                // I'm not sure how this was intended to be used so this might be rather odd but here goes...
+                LOG.debug("toAttributeTypeDef: Generate Map Attributes: name template is {}", mapNameTemplate);
+                String[] mapNameParts = mapNameTemplate.split("[{}]");
+                String omrsMapTypeName = mapNameParts[0] + keyTypeName + mapNameParts[2] + valueTypeName + mapNameParts[4];
+                LOG.debug("toAttributeTypeDef: name resolved to {}", omrsMapTypeName);
+                omrsCollectionDef.setName(omrsMapTypeName);
+
+                // Set inherited ATD fields
+                omrsCollectionDef.setGUID(null);
+                omrsCollectionDef.setName(atlasTypeName);
+                AttributeTypeDefCategory collectionDefCategory = omrsCollectionDef.getCategory();
+                if (collectionDefCategory != null) {
+                    omrsCollectionDef.setDescription(collectionDefCategory.getDescription());
+                }
+                omrsCollectionDef.setDescriptionGUID(null);
+                attributeTypeDef = omrsCollectionDef;
+                ret = attributeTypeDef;
+                break;
+
+            case ENUM:
+
+                LOG.debug("toAttributeTypeDef : handling an Atlas enum {}");
+                EnumDef enumDef = new EnumDef();
+                // Set common fields
+                enumDef.setGUID(abtd.getGuid());
+                enumDef.setName(abtd.getName());
+                enumDef.setDescription(abtd.getDescription());
+                enumDef.setDescriptionGUID(null);
+
+                // Additional fields on an AtlasEnumDef and OM EnumDef are elementDefs and defaultValue
+                // Initialize the Atlas and OMRS default values so we can test and set default value in the loop
+                AtlasEnumDef atlasEnumDef = (AtlasEnumDef) abtd;
+                String atlasDefaultValue = atlasEnumDef.getDefaultValue();
+                EnumElementDef omrsDefaultValue = null;
+                ArrayList<EnumElementDef> omrsElementDefs = null;
+                List<AtlasEnumDef.AtlasEnumElementDef> atlasElemDefs = atlasEnumDef.getElementDefs();
+                if (atlasElemDefs != null) {
+                    omrsElementDefs = new ArrayList<>();
+                    for (AtlasEnumDef.AtlasEnumElementDef atlasElementDef : atlasElemDefs) {
+                        EnumElementDef omrsEnumElementDef = new EnumElementDef();
+                        omrsEnumElementDef.setValue(atlasElementDef.getValue());
+                        omrsEnumElementDef.setDescription(atlasElementDef.getDescription());
+                        omrsEnumElementDef.setOrdinal(atlasElementDef.getOrdinal());
+                        omrsEnumElementDef.setDescriptionGUID(null);
+                        omrsElementDefs.add(omrsEnumElementDef);
+                        if (atlasElementDef.getValue().equals(atlasDefaultValue)) {
+                            omrsDefaultValue = omrsEnumElementDef;
+                        }
+                    }
+                }
+                enumDef.setElementDefs(omrsElementDefs);
+                enumDef.setDefaultValue(omrsDefaultValue);
+
+                attributeTypeDef = enumDef;
+                ret = attributeTypeDef;
+
+                break;
+
+            default:
+                LOG.debug("toAttributeTypeDef: cannot convert Atlas type with category {} to an AttributeTypeDef", atlasCategory);
+                return null;
+
+        }
+
+        return ret;
+    }
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasClassificationDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasClassificationDefMapper.java
new file mode 100644
index 000000000..91e92712e
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasClassificationDefMapper.java
@@ -0,0 +1,394 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasClassificationDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryHelper;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Set;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus.ACTIVE;
+
+
+public class AtlasClassificationDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasClassificationDefMapper.class);
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+    private String                           userId = null;
+    private AtlasClassificationDef           atlasClassificationDef = null;
+    private String                           metadataCollectionId = null;
+
+
+    public AtlasClassificationDefMapper(LocalAtlasOMRSMetadataCollection metadataCollection,
+                                        String                           userId,
+                                        AtlasClassificationDef           atlasClassificationDef)
+            throws
+            RepositoryErrorException
+    {
+        this.metadataCollection = metadataCollection;
+        this.userId = userId;
+        this.atlasClassificationDef = atlasClassificationDef;
+        try {
+            this.metadataCollectionId = this.metadataCollection.getMetadataCollectionId();
+        } catch (RepositoryErrorException e) {
+            LOG.error("AtlasClassificationDefMapper: could not initialize metadataCollectionId", e);
+            throw e;
+        }
+    }
+
+
+    public ClassificationDef toOMClassificationDef()
+        throws
+            TypeErrorException,
+            RepositoryErrorException
+    {
+
+        // Convert an AtlasClassificationDef to an OM ClassificationDef
+        //
+        // Convert the AtlasClassificationDef into the corresponding OM ClassificationDef and (implicitly)
+        // validate the content of the OM ClassificationDef
+        //
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> toOMClassificationDef(atlasClassificationDef={}", atlasClassificationDef);
+        }
+
+        final String methodName = "AtlasClassificationDefMapper.toOMClassificationDef";
+
+        OMRSRepositoryHelper repositoryHelper = metadataCollection.getRepositoryHelper();
+
+        if (atlasClassificationDef == null) {
+            // Give up now
+            LOG.error("toOMClassificationDef: Cannot convert null AtlasClassificationDef to OM ClassificationDef");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasClassificationDef", "toOMClassificationDef",metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMClassificationDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (atlasClassificationDef.getName() == null || atlasClassificationDef.getGuid() == null ) {
+            // Give up now
+            LOG.error("toOMClassificationDef: Cannot convert AtlasRelationshipDef to OM ClassificationDef, name or guid is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasClassificationDef", "toOMClassificationDef",metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMClassificationDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        String typeName = atlasClassificationDef.getName();
+
+        // Convert Atlas type into a valid OM type
+
+        // Allocate OMRS ClassificationDef, which will set AttributeTypeDefCategory automatically
+        ClassificationDef omClassificationDef = new ClassificationDef();
+
+        // Set common fields
+        omClassificationDef.setGUID(atlasClassificationDef.getGuid());
+        omClassificationDef.setName(atlasClassificationDef.getName());
+
+        // Care needed with version field - in case it is null - Atlas uses Long, OM uses long
+        Long version = atlasClassificationDef.getVersion();
+        if (version == null) {
+            // Long (the wrapper class) can have null value, but long (the primitive class) cannot
+            LOG.error("toOMClassificationDef: Cannot convert AtlasEntityDef to OM ClassificationDef - version is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("null", "version", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMClassificationDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        omClassificationDef.setVersion(version);
+
+        omClassificationDef.setVersionName(atlasClassificationDef.getTypeVersion());
+
+        // Additional fields on an AtlasClassificationDef and OM ClassificationDef are ...
+
+        // Copy across the fields that can be simply assigned
+        omClassificationDef.setDescription(atlasClassificationDef.getDescription());
+        omClassificationDef.setCreatedBy(atlasClassificationDef.getCreatedBy());
+        omClassificationDef.setUpdatedBy(atlasClassificationDef.getUpdatedBy());
+        omClassificationDef.setCreateTime(atlasClassificationDef.getCreateTime());
+        omClassificationDef.setUpdateTime(atlasClassificationDef.getUpdateTime());
+        omClassificationDef.setOptions(atlasClassificationDef.getOptions());
+
+
+        /* For those fields we will need to check whether the TypeDef is known by the RCM:
+         * For all fields where nothing is stored in Atlas, use the RCM if possible to determine how to set the OM ClassificationDef
+         * apart from the origin field - which is set to this metadataCollectionId.
+         * There are a couple of cases to consider:
+         *
+         * 1. The first is where this is a known type (by name) in the RCM. In this case the RCM will have an opinion about values
+         *    for the fields we cannot derive from the Atlas object. SO we use the RCM values; these should pass any subsequent
+         *    object comparison (obviously).
+         * 2. The second case is where this is a new type and is not yet known by the RCM. This is the situation where a type is introduced
+         *    into the repository but not via OMRS, e.g. via the Atlas REST/UI interfaces. In this situation, we will not get a type back
+         *    from the RCM; but it's OK - we can just adopt the defaults, which we will have anyway by virtue of having called the
+         *    appropriate def constructor.
+         */
+        TypeDef rcmTypeDef = repositoryHelper.getTypeDefByName(metadataCollectionId, typeName);
+        if (rcmTypeDef != null) {
+            // If we didn't get a typedef from the RCM then we would adopt the defaults, but we can use the RCM values...
+            if (rcmTypeDef.getCategory() != TypeDefCategory.CLASSIFICATION_DEF) {
+                LOG.error("toOMClassificationDef: The RepositoryContentManager has a type of this name that is not a ClassificationDef!");
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, atlasClassificationDef.getGuid(), "atlasClassificationDef", methodName, metadataCollectionId, atlasClassificationDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMClassificationDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+            ClassificationDef rcmClassificationDef = (ClassificationDef) rcmTypeDef;
+            boolean rcmPropagatable = rcmClassificationDef.isPropagatable();
+            List<ExternalStandardMapping> rcmExternalStandardMappings = rcmClassificationDef.getExternalStandardMappings();
+            List<InstanceStatus> rcmInstanceStatusList = rcmClassificationDef.getValidInstanceStatusList();
+            InstanceStatus rcmInitialStatus = rcmClassificationDef.getInitialStatus();
+            LOG.debug("Fields acquired from RCM: propagatable = {}, validInstanceStatusList = {}, initialStatus = {}, externalStandardMappings = {}",
+                    rcmPropagatable, rcmInstanceStatusList, rcmInitialStatus, rcmExternalStandardMappings);
+
+            // The origin is the metadataCollectionId for this connector.
+            omClassificationDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for whether the classification is propagatable. Consult the RCM to set up the OM ClassificationDef
+            omClassificationDef.setPropagatable(rcmPropagatable);
+
+            // Atlas does not have a field for external standard mappings. Consult the RCM to set up the OM ClassificationDef
+            // Atlas does not have external standard mappings. OMRS ExternalStandardMappings ArrayList<ExternalStandardMapping>
+            omClassificationDef.setExternalStandardMappings(rcmExternalStandardMappings);
+
+            // Atlas does not have a field for valid instance statuses. Consult the RCM to set up the OM ClassificationDef
+            // Atlas does not have valid instance statuses. OMRS ValidInstanceStatusList ArrayList<InstanceStatus>
+            omClassificationDef.setValidInstanceStatusList(rcmInstanceStatusList);
+
+            // Atlas does not have a field for initial status. Consult the RCM to set up the OM ClassificationDef
+            omClassificationDef.setInitialStatus(rcmInitialStatus);
+        }
+        else {
+            // The RCM does not have the type - either the type is new or we are doing a verify following a
+            // restart - so the type has been retrieved from Atlas but the RCM does not yet have it cached.
+            // In either case we should adopt sensible default values - which for the most part is done by
+            // the object constructor, but explicitly set the fields here. We need to do enough to get past
+            // the equivalence check.
+
+            // The origin is the metadataCollectionId for this connector.
+            omClassificationDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for external standard mappings. We can only assume here that this
+            // should be set to null in what we return.
+            omClassificationDef.setExternalStandardMappings(null);
+
+            // Atlas does not have a field for valid instance statuses. Set a sensible default, which assumes
+            // that either ACTIVE or DELETED states are OK.
+            ArrayList<InstanceStatus> statusList = new ArrayList<>();
+            statusList.add(InstanceStatus.ACTIVE);
+            statusList.add(InstanceStatus.DELETED);
+            omClassificationDef.setValidInstanceStatusList(statusList);
+
+            // Atlas does not have a field for initial status. Default to ACTIVE
+            omClassificationDef.setInitialStatus(ACTIVE);
+        }
+
+        // Handle fields that require conversion - i.e. supertypes, entityTypes, attributeDefs
+        // subtypes are deliberately ignored
+
+        // Atlas supertypes are Set<String>. OMRS supertypes are ArrayList<TypeDefLink>
+        // Convert a Set<String> of Atlas type names to an OMRS List<TypeDefLink>
+        // use separate utility method for conversion of Atlas type name to TypeDefLink with name and GUID and vice versa
+        Set<String> atlasSuperTypes = atlasClassificationDef.getSuperTypes();
+        TypeDefLink omrsSuperType = null;
+        // If atlas typedef has no supertypes we can just leave OM superType as null
+        if (atlasSuperTypes != null && !(atlasSuperTypes.isEmpty())) {
+            // Atlas has at least one supertype.
+            LOG.debug("toOMClassificationDef: Atlas def has supertypes {}", atlasSuperTypes);
+            if (atlasSuperTypes.size() > 1) {
+                // Atlas has more than one supertype - we cannot model this typedef in OM
+                // Failed to process the Atlas superType list; throw TypeErrorException
+                LOG.error("toOMClassificationDef: Failed to convert Atlas type {} because it has multiple supertypes", typeName);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, atlasClassificationDef.getGuid(),
+                        "atlasClassificationDef", "toOMClassificationDef", metadataCollectionId,atlasClassificationDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMClassificationDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+            else {
+                // The Atlas def has exactly one supertype - we can attempt to model this typedef in OM
+                // Validate the supertype in the Atlas typedef store. There is no point looking in our own
+                // cache or in the RCM as we may not have processed the Atlas type yet, so explicitly ask
+                // the typedef store for the name and guid. If this fails, fail the conversion.
+                // Go back to Atlas to get the GUID...
+                String atlasSuperTypeName = atlasSuperTypes.iterator().next();
+
+                omrsSuperType = metadataCollection.constructTypeDefLink(atlasSuperTypeName,  TypeCategory.CLASSIFICATION);
+                if (omrsSuperType == null) {
+                    LOG.error("toOMClassificationDef: Could not resolve supertype with name {} for AtlasClassificationDef",atlasSuperTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(typeName, atlasClassificationDef.getGuid(),
+                            "atlasClassificationDef", "toOMClassificationDef", metadataCollectionId,atlasClassificationDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "toOMClassificationDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+            }
+        }
+        omClassificationDef.setSuperType(omrsSuperType);
+        LOG.debug("toOMClassificationDef: has supertypes {}", omClassificationDef.getSuperType());
+
+        // Atlas subtypes are explicitly ignored in OM
+
+        // Atlas entityTypes are Set<String>. OMRS validEntityDefs are ArrayList<TypeDefLink>
+        // Convert a Set<String> of Atlas type names to an OMRS List<TypeDefLink>
+        // ALL the listed entityDefs must exist for the overall type def to match; so if it is found that ANY of the
+        // entity types is unknown then the overall def will not be converted.
+
+        // Note that if any of the validEntityDefs are in famous five then they must be switched.
+        // The references to VEDs in famous five will be in Atlas format (prefixed), whereas the
+        // OM references should be non-prefixed.
+
+        boolean convert_ok = true;
+        ArrayList<TypeDefLink> validEntityDefs = null;
+        Set<String> entityTypes = atlasClassificationDef.getEntityTypes();
+        LOG.debug("toOMClassificationDef: Atlas def has entity types {}", entityTypes);
+        if (entityTypes != null && !entityTypes.isEmpty()) {
+            // Iterate over the entity type names to ensure they are all known and fail if any is unknown
+            validEntityDefs = new ArrayList<TypeDefLink>();
+
+            for (String s : entityTypes) {
+
+                if (FamousFive.atlasTypeRequiresSubstitution(s)) {
+                    String omEntityTypeName = FamousFive.getOMTypeName(s);
+                    String omEntityTypeGUID = null;
+                    if (omEntityTypeName != null) {
+                        omEntityTypeGUID = FamousFive.getRecordedGUID(omEntityTypeName);
+                        if (omEntityTypeGUID != null) {
+                            TypeDefLink omEntityType = new TypeDefLink();
+                            omEntityType.setName(omEntityTypeName);
+                            omEntityType.setGUID(omEntityTypeGUID);
+                            validEntityDefs.add(omEntityType);
+                        }
+                    }
+                    if (omEntityTypeName == null || omEntityTypeGUID == null ) {
+                        LOG.error("toOMClassificationDef: Could not get omTypeName for Atlas type {}", s);
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(typeName, atlasClassificationDef.getGuid(),
+                                "atlasClassificationDef", "toOMClassificationDef", metadataCollectionId,atlasClassificationDef.toString());
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "toOMClassificationDef",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+
+                }
+                else {
+                    // entity type is not a member of famous five
+                    // Map the Atlas entity type name (String) to an OM TypeDefLink (which has name and guid)
+                    LOG.debug("toOMClassificationDef: try to find entity type {}", s);
+                    // Create a TypeDefLink for the type with the name given by s
+                    TypeDefLink omTypeDefLink = null;
+                    omTypeDefLink = metadataCollection.constructTypeDefLink(s, TypeCategory.ENTITY);
+                    if (omTypeDefLink == null) {
+                        // Error case - if there is no type def for the listed entity type then the classification cannot be processed...
+                        LOG.error("toOMClassificationDef: Could not resolve type with name {} for AtlasClassificationDef", s);
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(typeName, atlasClassificationDef.getGuid(),
+                                "atlasClassificationDef", "toOMClassificationDef", metadataCollectionId,atlasClassificationDef.toString());
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "toOMClassificationDef",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    } else {
+                        LOG.debug("toOMClassificationDef: TypeDefLink allocated for entity type {} {}", s, omTypeDefLink);
+                        validEntityDefs.add(omTypeDefLink);
+                    }
+                }
+            }
+        }
+        // If we reached this point then the valid entity defs are OK to add to the classification def
+        omClassificationDef.setValidEntityDefs(validEntityDefs);
+
+
+        // Atlas Attribute defs
+
+        try {
+            List<TypeDefAttribute> omrsTypeDefAttributes = metadataCollection.convertAtlasAttributeDefs(userId, atlasClassificationDef.getAttributeDefs());
+            omClassificationDef.setPropertiesDefinition(omrsTypeDefAttributes);
+        }
+        catch (RepositoryErrorException | TypeErrorException e) {
+            // Failed to process the attribute types; give up trying to convert this entity def
+            // Give up at this point by returning without having added the OM def to typeDefsForAPI
+            LOG.debug("ConvertAtlasRelationshipDef: Failed to convert the attributes of an AtlasClassificationDef");
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== toOMClassificationDef(omClassificationDef={}", omClassificationDef);
+        }
+        return omClassificationDef;
+
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityDefMapper.java
new file mode 100644
index 000000000..ac394901d
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityDefMapper.java
@@ -0,0 +1,501 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasEntityDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryHelper;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus.ACTIVE;
+
+
+public class AtlasEntityDefMapper {
+
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasEntityDefMapper.class);
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+    private String                           userId = null;
+    private AtlasEntityDef                   atlasEntityDef = null;
+    private String                           metadataCollectionId = null;
+
+
+    // package private
+    AtlasEntityDefMapper(LocalAtlasOMRSMetadataCollection metadataCollection,
+                         String                           userId,
+                         AtlasEntityDef                   atlasEntityDef)
+        throws
+            RepositoryErrorException
+    {
+
+        this.metadataCollection = metadataCollection;
+        this.userId = userId;
+        this.atlasEntityDef = atlasEntityDef;
+        try {
+            this.metadataCollectionId = this.metadataCollection.getMetadataCollectionId();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("AtlasEntityDefMapper: could not initialize metadataCollectionId", e);
+            throw e;
+        }
+    }
+
+
+    /**
+     * Convert Atlas type into a valid OM type
+     * Convert the AtlasEntityDef into the corresponding OM EntityDef and (implicitly)
+     * validate the content of the OM EntityDef
+     */
+
+    // package private
+    EntityDef toOMEntityDef()
+        throws
+            TypeErrorException,
+            RepositoryErrorException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> toOMEntityDef(atlasEntityDef={}", atlasEntityDef);
+        }
+
+        final String methodName = "AtlasEntityDefMapper.toOMEntityDef";
+
+        OMRSRepositoryHelper repositoryHelper = metadataCollection.getRepositoryHelper();
+
+        String atlasTypeName = null;
+        String atlasTypeGUID = null;
+        String omTypeName = null;
+        String omTypeGUID = null;
+
+        boolean famousFive = false;
+
+        if (atlasEntityDef != null) {
+
+            atlasTypeName = atlasEntityDef.getName();
+            atlasTypeGUID = atlasEntityDef.getGuid();
+            omTypeName = atlasTypeName;
+            omTypeGUID = atlasTypeGUID;
+
+            // If the type has been extended by Famous Five then do reverse name and GUID substitution
+            if (atlasTypeName != null && FamousFive.atlasTypeRequiresSubstitution(atlasTypeName)) {
+                LOG.debug("toOMEntityDef: famous five type {}", atlasTypeName);
+                famousFive = true;
+                omTypeName = FamousFive.getOMTypeName(atlasTypeName);
+                omTypeGUID = FamousFive.getRecordedGUID(omTypeName);
+            }
+        }
+
+        if (atlasEntityDef == null || atlasTypeName == null || atlasTypeGUID == null || omTypeName == null ) {
+            // Give up now
+            LOG.error("toOMEntityDef: Cannot convert AtlasEntityDef to OM EntityDef");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasEntityDef", "toOMEntityDef",metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMEntityDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Allocate OM EntityDef, which will set AttributeTypeDefCategory automatically
+        EntityDef omEntityDef = new EntityDef();
+
+        // Set common fields
+        omEntityDef.setGUID(omTypeGUID);
+        omEntityDef.setName(omTypeName);
+
+        // Care needed with version field - in case it is null - Atlas uses Long, OM uses long
+        Long version = atlasEntityDef.getVersion();
+        if (version == null) {
+            // Long (the wrapper class) can have null value, but long (the primitive class) cannot
+            LOG.error("toOMEntityDef: Cannot convert AtlasEntityDef to OM EntityDef - version is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("null", "version", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMEntityDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        omEntityDef.setVersion(version);
+
+        omEntityDef.setVersionName(atlasEntityDef.getTypeVersion());
+
+        // Copy across the fields that can be simply assigned
+        omEntityDef.setDescription(atlasEntityDef.getDescription());
+        omEntityDef.setCreatedBy(atlasEntityDef.getCreatedBy());
+        omEntityDef.setUpdatedBy(atlasEntityDef.getUpdatedBy());
+        omEntityDef.setCreateTime(atlasEntityDef.getCreateTime());
+        omEntityDef.setUpdateTime(atlasEntityDef.getUpdateTime());
+        omEntityDef.setOptions(atlasEntityDef.getOptions());
+
+
+
+        /* For those fields we will need to check whether the TypeDef is known by the RCM:
+         * For all fields where nothing is stored in Atlas, use the RCM if possible to determine how to set the OM EntityDef
+         * apart from the origin field - which is set to this metadataCollectionId.
+         * There are a couple of cases to consider:
+         *
+         * 1. The first is where this is a known type (by name) in the RCM. In this case the RCM will have an opinion about values
+         *    for the fields we cannot derive from the Atlas object. SO we use the RCM values; these should pass any subsequent
+         *    object comparison (obviously).
+         * 2. The second case is where this is a new type and is not yet known by the RCM. This is the situation where a type is introduced
+         *    into the repository but not via OMRS, e.g. via the Atlas REST/UI interfaces. In this situation, we will not get a type back
+         *    from the RCM; but it's OK - we can just adopt the defaults, which we will have anyway by virtue of having called the
+         *    appropriate def constructor.
+         */
+        TypeDef rcmTypeDef = repositoryHelper.getTypeDefByName(metadataCollectionId, omTypeName);
+        if (rcmTypeDef != null) {
+            // If we didn't get a typedef from the RCM then we would adopt the defaults, but we can use the RCM values...
+            if (rcmTypeDef.getCategory() != TypeDefCategory.ENTITY_DEF) {
+                LOG.error("toOMEntityDef: The RepositoryContentManager has a type of this name that is not a EntityDef!");
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(omTypeName, atlasEntityDef.getGuid(), "atlasEntityDef", methodName, metadataCollectionId, atlasEntityDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+            EntityDef rcmEntityDef = (EntityDef) rcmTypeDef;
+            List<ExternalStandardMapping> rcmExternalStandardMappings = rcmEntityDef.getExternalStandardMappings();
+            List<InstanceStatus> rcmInstanceStatusList = rcmEntityDef.getValidInstanceStatusList();
+            InstanceStatus rcmInitialStatus = rcmEntityDef.getInitialStatus();
+            LOG.debug("Fields acquired from RCM: validInstanceStatusList = {}, initialStatus = {}, externalStandardMappings = {}",
+                    rcmInstanceStatusList, rcmInitialStatus, rcmExternalStandardMappings);
+
+            // The origin is the metadataCollectionId for this connector.
+            omEntityDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for external standard mappings. Consult the RCM to set up the OM EntityDef
+            // Atlas does not have external standard mappings. OMRS ExternalStandardMappings ArrayList<ExternalStandardMapping>
+            omEntityDef.setExternalStandardMappings(rcmExternalStandardMappings);
+
+            // Atlas does not have a field for valid instance statuses. Consult the RCM to set up the OM EntityDef
+            // Atlas does not have valid instance statuses. OMRS ValidInstanceStatusList ArrayList<InstanceStatus>
+            omEntityDef.setValidInstanceStatusList(rcmInstanceStatusList);
+
+            // Atlas does not have a field for initial status. Consult the RCM to set up the OM EntityDef
+            omEntityDef.setInitialStatus(rcmInitialStatus);
+        }
+        else {
+            // The RCM does not have the type - either the type is new or we are doing a verify following a
+            // restart - so the type has been retrieved from Atlas but the RCM does not yet have it cached.
+            // In either case we should adopt sensible default values - which for the most part is done by
+            // the object constructor, but explicitly set the fields here. We need to do enough to get past
+            // the equivalence check.
+
+            // The origin is the metadataCollectionId for this connector.
+            omEntityDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for external standard mappings. We can only assume here that this
+            // should be set to null in what we return.
+            omEntityDef.setExternalStandardMappings(null);
+
+            // Atlas does not have a field for valid instance statuses. Set a sensible default, which assumes
+            // that either ACTIVE or DELETED states are OK.
+            ArrayList<InstanceStatus> statusList = new ArrayList<>();
+            statusList.add(InstanceStatus.ACTIVE);
+            statusList.add(InstanceStatus.DELETED);
+            omEntityDef.setValidInstanceStatusList(statusList);
+
+            // Atlas does not have a field for initial status. Default to ACTIVE
+            omEntityDef.setInitialStatus(ACTIVE);
+        }
+
+
+        // Handle fields that require conversion - i.e. supertypes, attributeDefs
+        // Atlas subtypes are deliberately ignored
+
+        // Convert Atlas Set<String> supertypes containing Atlas type names to an OM List<TypeDefLink>
+        // OM enforces single inheritance, so fail conversion if Atlas has multiple supertypes but
+        // Famous Five types must be recognised before the supertype count is checked.
+        if (!famousFive) {
+            Set<String> atlasSuperTypes = atlasEntityDef.getSuperTypes();
+            TypeDefLink omSuperType;
+            // If atlas typedef has no supertypes we can just leave omrs superType as null
+            if (atlasSuperTypes != null && !(atlasSuperTypes.isEmpty())) {
+                // Atlas has at least one supertype.
+                LOG.debug("toOMEntityDef: Atlas def has supertypes {}", atlasSuperTypes);
+                if (atlasSuperTypes.size() > 1) {
+                    // Atlas has more than one supertype - we cannot model this typedef in OM
+                    // Failed to process the Atlas superType list; give up without adding the entity def to the TDG
+                    LOG.error("toOMEntityDef: Failed to convert Atlas type {} because it has multiple supertypes", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                                "atlasEntityDef", "toOMEntityDef", metadataCollectionId,atlasEntityDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "toOMEntityDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                } else {
+                    // The Atlas def has exactly one supertype - we can attempt to model this typedef in OM
+                    // Validate the supertype in the Atlas typedef store. There is no point looking in our own
+                    // cache or in the RCM as we may not have processed the Atlas type yet, so explicitly ask
+                    // the typedef store for the name and guid. If this fails, fail the conversion.
+                    // Go back to Atlas to get the GUID...
+                    String atlasSuperTypeName = atlasSuperTypes.iterator().next();
+                    String omSuperTypeName;
+                    if (FamousFive.atlasTypeRequiresSubstitution(atlasSuperTypeName)) {
+                        // supertype is in famous five
+                        // Strip off the OM_ prefix
+                        LOG.debug("toOMEntityDef: famous five supertype {}", atlasSuperTypeName);
+                        omSuperTypeName = FamousFive.getOMTypeName(atlasSuperTypeName);
+                        String omSuperTypeGUID = null;
+                        if (omSuperTypeName != null) {
+                            omSuperTypeGUID = FamousFive.getRecordedGUID(omSuperTypeName);
+                            if (omSuperTypeGUID != null) {
+                                omSuperType = new TypeDefLink();
+                                omSuperType.setName(omSuperTypeName);
+                                omSuperType.setGUID(omSuperTypeGUID);
+                                omEntityDef.setSuperType(omSuperType);
+                            }
+                        }
+                        if (omSuperTypeName == null || omSuperTypeGUID == null) {
+                            LOG.error("toOMEntityDef: Could not resolve supertype with name {} for AtlasEntityDef", atlasSuperTypeName);
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                                    "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "toOMEntityDef",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+                    }
+                    else {
+                        // supertype is not famous five
+                        omSuperType = metadataCollection.constructTypeDefLink(atlasSuperTypeName, TypeCategory.ENTITY);
+                        if (omSuperType != null) {
+                            omEntityDef.setSuperType(omSuperType);
+                        }
+                        else {
+                            LOG.error("toOMEntityDef: Could not resolve supertype with name {} for AtlasEntityDef", atlasSuperTypeName);
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                                    "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "toOMEntityDef",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+
+                    }
+                }
+            }
+        }
+        else {
+            // This is a famousFive type so it will have artificially high number of supertypes
+            // Remove the Atlas-specific supertype (with the stripped self-name, then check supertypes etc)
+
+            Set<String> atlasSuperTypes = atlasEntityDef.getSuperTypes();
+
+            // We would expect there to be one or more supertype (since this is famous five).
+            // Spin through the supertypes and look for the artificially added supertype.
+
+            if (atlasSuperTypes == null || atlasSuperTypes.isEmpty()) {
+                // This is not a valid state for the supertypes of a famous five type
+                LOG.error("toOMEntityDef: Famous five type {} has no supertypes", atlasTypeName);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                        "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMEntityDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            /* We know we have at least one supertype, look for (and remove) the artificial one
+             * which will be the one with the original OM type name.
+             */
+            boolean found = false;
+            Set<String> realSuperTypes = new HashSet<>();
+            for (String atlasSuperTypeName : atlasSuperTypes ) {
+                if (atlasSuperTypeName.equals(omTypeName)) {
+                    found = true;
+                    // skip this supertype
+                }
+                else {
+                    realSuperTypes.add(atlasSuperTypeName);
+                }
+            }
+            if (!found) {
+                LOG.error("toOMEntityDef: Famous five type {} is missing supertype {}", atlasTypeName, omTypeName);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                        "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMEntityDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            // The supertypes have been compacted
+
+            TypeDefLink omSuperType = null;
+            // If atlas typedef has no real supertypes we can just leave omrs superType as null
+            if (!realSuperTypes.isEmpty()) {
+                // Atlas has at least one real supertype.
+                LOG.debug("toOMEntityDef: Atlas def has supertypes {}", realSuperTypes);
+                if (realSuperTypes.size() > 1) {
+                    // Atlas has more than one real supertype - we cannot model this typedef in OM
+                    // Failed to process the Atlas superType list; give up without adding the entity def to the TDG
+                    LOG.error("toOMEntityDef: Failed to convert Atlas type {} because it has multiple supertypes", atlasTypeName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                            "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "toOMEntityDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                } else {
+
+                    // The Atlas def has exactly one supertype - we can attempt to model this typedef in OM
+                    // Validate the supertype in the Atlas typedef store. There is no point looking in our own
+                    // cache or in the RCM as we may not have processed the Atlas type yet, so explicitly ask
+                    // the typedef store for the name and guid. If this fails, fail the conversion.
+                    // Go back to Atlas to get the GUID...
+                    String atlasSuperTypeName = atlasSuperTypes.iterator().next();
+                    String omSuperTypeName;
+                    if (FamousFive.atlasTypeRequiresSubstitution(atlasSuperTypeName)) {
+                        // supertype is in famous five
+                        LOG.debug("toOMEntityDef: famous five supertype {}", atlasSuperTypeName);
+                        omSuperTypeName = FamousFive.getOMTypeName(atlasSuperTypeName);
+                        String omSuperTypeGUID = null;
+                        if (omSuperTypeName != null) {
+                            omSuperTypeGUID = FamousFive.getRecordedGUID(omSuperTypeName);
+                            if (omSuperTypeGUID != null) {
+                                omSuperType = new TypeDefLink();
+                                omSuperType.setName(omSuperTypeName);
+                                omSuperType.setGUID(omSuperTypeGUID);
+                                omEntityDef.setSuperType(omSuperType);
+                            }
+                        }
+                        if (omSuperTypeName == null || omSuperTypeGUID == null) {
+                            LOG.error("toOMEntityDef: Could not resolve supertype with name {} for AtlasEntityDef", atlasSuperTypeName);
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                                    "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "toOMEntityDef",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+
+                    }
+                    else {
+                        // supertype is not famous five
+                        omSuperType = metadataCollection.constructTypeDefLink(atlasSuperTypeName, TypeCategory.ENTITY);
+                        if (omSuperType == null) {
+                            LOG.error("toOMEntityDef: Could not resolve supertype with name {} for AtlasEntityDef", atlasSuperTypeName);
+                            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(atlasTypeName, atlasEntityDef.getGuid(),
+                                    "atlasEntityDef", "toOMEntityDef", metadataCollectionId, atlasEntityDef.toString());
+
+                            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    "toOMEntityDef",
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                        }
+                        else {
+                            omEntityDef.setSuperType(omSuperType);
+                        }
+                    }
+                }
+            }
+            omEntityDef.setSuperType(omSuperType);
+        }
+        LOG.debug("toOMEntityDef: omEntityDef has supertype {}", omEntityDef.getSuperType());
+
+        // Atlas subtypes are explicitly ignored in OM
+
+        // Atlas Attribute defs
+        try {
+            List<TypeDefAttribute> omrsTypeDefAttributes = metadataCollection.convertAtlasAttributeDefs(userId, atlasEntityDef.getAttributeDefs());
+            omEntityDef.setPropertiesDefinition(omrsTypeDefAttributes);
+        }
+        catch (RepositoryErrorException | TypeErrorException e) {
+            // Failed to process the attribute types; give up trying to convert this entity def
+            // Give up at this point by returning without having added the OM def to typeDefsForAPI
+            LOG.error("toOMEntityDef: caught exception during conversion of Atlas attributes", e);
+            throw e;
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== toOMEntityDef(omEntityDef={}", omEntityDef);
+        }
+        return omEntityDef;
+
+    }
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityMapper.java
new file mode 100644
index 000000000..d476a552f
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasEntityMapper.java
@@ -0,0 +1,679 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.instance.AtlasClassification;
+import org.apache.atlas.model.instance.AtlasEntity;
+import org.apache.atlas.model.instance.AtlasRelatedObjectId;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.InvalidEntityException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeDefNotKnownException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefCategory.CLASSIFICATION_DEF;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefCategory.ENTITY_DEF;
+
+
+// package private
+class AtlasEntityMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(LocalAtlasOMRSMetadataCollection.class);
+
+    /**
+     *  Mapper with methods for different output objects EntityDetail, EntityProxy,
+     *  EntitySummary and EntityUniverse
+     *
+     *  To use this class, construct a new AtlasEntityMapper and then invoke the
+     *  method corresponding to the type of OM entity object you want as output.
+     */
+
+    /*
+     * AtlasEntity has:
+     *
+     * String                    typeName
+     * Map<String, Object>       attributes
+     * String                    guid
+     * Status                    status
+     * String                    createdBy
+     * String                    updatedBy
+     * Date                      createTime
+     * Date                      updateTime
+     * Long                      version
+     * Map<String, Object>       relationshipAttributes;
+     * List<AtlasClassification> classifications;
+     *
+     * EntityDetail has:
+     *
+     * InstanceType              type
+     * String                    createdBy
+     * String                    updatedBy
+     * Date                      createTime
+     * Date                      updateTime
+     * Long                      version
+     * InstanceStatus            currentStatus
+     * InstanceStatus            statusOnDelete
+     * InstanceProvenanceType    instanceProvenanceType
+     * String                    metadataCollectionId
+     * String                    guid
+     * String                    instanceURL
+     * ArrayList<Classification> classifications
+     *
+     * We need to retrieve the AtlasEntity's type (by name) as a TypeDef from the repository.
+     * This can be converted into an OM EntityDef - which can then be used to construct the
+     * InstanceType.
+     *
+     */
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection   = null;
+    private String                           metadataCollectionId = null;
+    private AtlasEntity                      atlasEntity          = null;
+    private String                           userId               = null;
+    private EntityDef entityDef            = null;
+
+    /**
+     * AtlasEntityMapper converts an AtlasEntity to an OM Entity - choice of output formats
+     * @param metadataCollection - the metadataCollection of the repository connector
+     * @param userId             - the security context of the operation
+     * @param atlasEntity        - the AtlasEntity to be converted
+     * @throws TypeErrorException        - if conversion fails due to type errors
+     * @throws RepositoryErrorException  - if conversion fails due to repository malfunction
+     */
+
+    // package private
+    AtlasEntityMapper(LocalAtlasOMRSMetadataCollection metadataCollection,
+                      String                           userId,
+                      AtlasEntity                      atlasEntity)
+        throws
+            TypeErrorException,
+            RepositoryErrorException
+    {
+
+        final String methodName = "AtlasEntityMapper";
+
+        LOG.debug("AtlasEntityMapper: atlasEntity {}", atlasEntity);
+
+        this.metadataCollection = metadataCollection;
+        try {
+            metadataCollectionId = metadataCollection.getMetadataCollectionId();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("AtlasEntityMapper: caught repository exception - could not get metadataCollectionId", e);
+            // Re-throw the error
+            throw e;
+        }
+
+        LOG.debug("AtlasEntityMapper: metadataCollectionId {}", metadataCollectionId);
+
+        if (atlasEntity == null) {
+
+            LOG.error("AtlasEntityMapper: atlasEntity is null");
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.NULL_INSTANCE;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasEntity");
+
+            LOG.error("AtlasEntityMapper: {}", errorMessage);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        this.atlasEntity = atlasEntity;
+        this.userId = userId;
+
+        try {
+            this.entityDef = getEntityDef(atlasEntity);
+        }
+        catch (TypeErrorException e) {
+            LOG.error("AtlasEntityMapper: caught type exception - could not retrieve entity def for typename {}", atlasEntity.getTypeName(),e);
+            // Re-throw - exception will be caught in the MDC
+            throw e;
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("AtlasEntityMapper: caught repository exception - could not retrieve entity def for typename {}", atlasEntity.getTypeName(), e);
+            // Re-throw - exception will be caught in the MDC
+            throw e;
+        }
+
+    }
+
+    // package private
+    EntitySummary toEntitySummary() throws TypeErrorException, InvalidEntityException {
+        if (this.atlasEntity == null) {
+            return null;
+        }
+        EntitySummary entitySummary = new EntitySummary();
+        completeEntitySummary(entitySummary);
+        return entitySummary;
+    }
+
+    // package private
+    EntityProxy toEntityProxy() throws TypeErrorException, InvalidEntityException {
+        if (this.atlasEntity == null) {
+            return null;
+        }
+        EntityProxy entityProxy = new EntityProxy();
+        completeEntityProxy(entityProxy);
+        return entityProxy;
+    }
+
+    // package private
+    EntityDetail toEntityDetail() throws TypeErrorException, InvalidEntityException {
+        if (this.atlasEntity == null) {
+            return null;
+        }
+        EntityDetail entityDetail = new EntityDetail();
+        completeEntityDetail(entityDetail);
+        return entityDetail;
+    }
+
+    // package private
+    EntityUniverse toEntityUniverse()
+        throws
+            RepositoryErrorException,
+            TypeErrorException,
+            InvalidEntityException
+    {
+        if (this.atlasEntity == null) {
+            return null;
+        }
+        EntityUniverse entityUniverse = new EntityUniverse();
+        // Can throw RepositoryErrorException - not caught - let it surface to the caller.
+        completeEntityUniverse(entityUniverse);
+        return entityUniverse;
+    }
+
+    private void completeEntitySummary(EntitySummary entitySummary)
+        throws
+            TypeErrorException, InvalidEntityException
+    {
+
+        final String methodName = "completeEntitySummary";
+
+        InstanceType instanceType = createInstanceType(entityDef);
+
+        // Construct an EntitySummary object
+        // Set fields from InstanceAuditHeader
+        entitySummary.setType(instanceType);
+        entitySummary.setCreatedBy(atlasEntity.getCreatedBy());
+        entitySummary.setCreateTime(atlasEntity.getCreateTime());
+        entitySummary.setUpdatedBy(atlasEntity.getUpdatedBy());
+        entitySummary.setUpdateTime(atlasEntity.getUpdateTime());
+
+        // Care needed with version field - in case it is null - Atlas uses Long, OM uses long
+        Long version = atlasEntity.getVersion();
+        if (version == null) {
+            // Long (the wrapper class) can have null value, but long (the primitive class) cannot
+            LOG.error("toOMEntitySummary: Cannot convert AtlasEntity to OM EntitySummary - version is null");
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.NULL_VERSION;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage( "atlasEntity version", metadataCollectionId);
+
+            throw new InvalidEntityException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        entitySummary.setVersion(version);
+
+
+        if (atlasEntity.getStatus() == AtlasEntity.Status.ACTIVE) {
+            entitySummary.setStatus(InstanceStatus.ACTIVE);
+        } else {
+            entitySummary.setStatus(InstanceStatus.DELETED);
+        }
+
+        // Set fields from InstanceHeader
+        entitySummary.setMetadataCollectionId(atlasEntity.getHomeId());
+        entitySummary.setGUID(atlasEntity.getGuid());
+        entitySummary.setInstanceURL(null);
+
+        // Set fields from EntitySummary
+
+        // Set classifications
+        // AtlasEntity provides a List<AtlasClassification>
+        List<AtlasClassification> atlasClassifications = atlasEntity.getClassifications();
+        ArrayList<Classification> omClassifications = null;
+        if (atlasClassifications != null) {
+            omClassifications = new ArrayList<>();
+            for (AtlasClassification atlasClassification : atlasClassifications) {
+                LOG.debug("AtlasEntityMapper toEntitySummary: processing classification {}", atlasClassification);
+                Classification omClassification = convertAtlasClassificationToOMClassification(atlasClassification);
+                omClassifications.add(omClassification);
+            }
+        }
+        entitySummary.setClassifications(omClassifications);
+
+    }
+
+    private void completeEntityProxy(EntityProxy entityProxy)
+        throws
+            TypeErrorException, InvalidEntityException
+
+    {
+        completeEntitySummary(entityProxy);
+
+        /*
+         * Add the EntityProxy portion...
+         * Take only the unique attributes from AtlasEntity and set the entityProperties for OM EntityProxy
+         */
+
+        Map<String, Object> atlasAttrs = atlasEntity.getAttributes();
+        AtlasAttributeMapper atlasAttributeMapper = new AtlasAttributeMapper(metadataCollection, userId);
+        InstanceProperties instanceProperties = atlasAttributeMapper.convertAtlasAttributesToOMProperties(entityDef, atlasAttrs, true); // uniqueOnly == true => unique attributes only
+        entityProxy.setUniqueProperties(instanceProperties);
+
+    }
+
+    private void completeEntityDetail(EntityDetail entityDetail)
+        throws
+            TypeErrorException, InvalidEntityException
+    {
+        final String methodName = "completeEntityDetail";
+
+        LOG.debug("completeEntityDetail: atlasEntity = {}", atlasEntity);
+        LOG.debug("completeEntityDetail: isProxy = {}", atlasEntity.isProxy());
+
+        if (atlasEntity.isProxy() == true) {
+            // This is only a proxy entity - you cannot create an EntityDetail (or any subtype of EntityDetail) from it.
+            LOG.error("completeEntityDetail: the AtlasEntity with GUID {} is a proxy - it cannot be used as EntityDetail ", atlasEntity.getGuid());
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ENTITY_NOT_DELETED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(atlasEntity.getGuid(), methodName, metadataCollectionId);
+
+            throw new InvalidEntityException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        completeEntitySummary(entityDetail);
+
+        /*
+         * Add the EntityDetail portion...
+         * Take all the attributes from AtlasEntity and set the entityProperties for OM EntityDetail
+         */
+        Map<String, Object> atlasAttrs = atlasEntity.getAttributes();
+        AtlasAttributeMapper atlasAttributeMapper = new AtlasAttributeMapper(metadataCollection, userId);
+        InstanceProperties instanceProperties = atlasAttributeMapper.convertAtlasAttributesToOMProperties(entityDef, atlasAttrs, false); // uniqueOnly == false => all attributes
+        entityDetail.setProperties(instanceProperties);
+    }
+
+    private void completeEntityUniverse(EntityUniverse entityUniverse)
+        throws
+            TypeErrorException,
+            RepositoryErrorException,
+            InvalidEntityException
+    {
+
+        final String methodName = "completeEntityUniverse";
+
+        completeEntityDetail(entityUniverse);
+
+        /*
+         * Add the universe fields:
+         * ArrayList<Relationship>    entityRelationships
+         * ArrayList<Relationship>    relationships
+         *
+         * Find all the relationships that this entity has...
+         * Each relationshipAttribute may be a reference to a specific object id or it may be
+         * a list of atlas object id references - in which case we need to walk the list and
+         * add a relationship for each of the remote entities.
+         *
+         */
+        Map<String, Object> atlasEntRelAttrs = atlasEntity.getRelationshipAttributes();
+        if (atlasEntRelAttrs != null && !(atlasEntRelAttrs.isEmpty())) {
+            ArrayList<Relationship> relationships = new ArrayList<>();
+            for (String key : atlasEntity.getRelationshipAttributes().keySet()) {
+                Object obj = atlasEntRelAttrs.get(key);
+                // If the obj is null then it represents an absence of relationships of this type, so tolerate/ignore it
+                if (obj != null) {
+
+                    if (obj instanceof AtlasRelatedObjectId) {
+                        // The relationshipAttribute is for a single relationship to another entity...
+                        LOG.debug("completeEntityUniverse: relationship attribute is AtlasRelatedObjectId {}", obj);
+                        AtlasRelatedObjectId aroId = (AtlasRelatedObjectId) obj;
+                        Relationship relationship = convertAtlasRelatedObjectIdToOMRelationship(aroId);
+                        if (relationship != null) {
+                            relationships.add(relationship);
+                        }
+
+                    } else if (obj instanceof ArrayList) {
+                        /*
+                         * The relationshipAttribute is for an array of relationships to other entities,
+                         * each defined by an AtlasRelatedObjectId.
+                         */
+                        ArrayList list = (ArrayList) obj;
+                        if (!list.isEmpty()) {
+                            for (Object element : list) {
+                                // Make no assumptions about element type...
+                                if (element instanceof AtlasRelatedObjectId) {
+                                    AtlasRelatedObjectId aroId = (AtlasRelatedObjectId) element;
+                                    LOG.debug("completeEntityUniverse: relationship contains AtlasRelatedObjectId {}", aroId);
+                                    Relationship relationship = convertAtlasRelatedObjectIdToOMRelationship(aroId);
+                                    if (relationship != null) {
+                                        relationships.add(relationship);
+                                    }
+                                }
+                            }
+                        }
+
+                    } else {
+                        LOG.error("completeEntityUniverse: relationship attribute with key {} is of unsupported type {} ", key, obj.getClass());
+                        OMRSErrorCode errorCode = OMRSErrorCode.ATTRIBUTE_TYPEDEF_NOT_KNOWN;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(key, "attribute key", methodName, metadataCollectionId);
+
+                        throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                methodName,
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+                }
+                else {
+                    // Record that we have seen a null object, but do not treat it as an error
+                    LOG.debug("completeEntityUniverse: relationship attribute with key {} has null value", key);
+                }
+            }
+            entityUniverse.setEntityRelationships(relationships);
+        }
+
+    }
+
+    private Relationship convertAtlasRelatedObjectIdToOMRelationship(AtlasRelatedObjectId aroId) {
+        String relationshipGuid = aroId.getRelationshipGuid();
+        Relationship relationship;
+        try {
+            relationship = metadataCollection.getRelationship(userId, relationshipGuid);
+        } catch (Exception e) {
+            LOG.debug("getEntityUniverse: Caught exception from getRelationship {}", e);
+            relationship = null;
+        }
+        return relationship;
+    }
+
+    /**
+     * Helper method to create InstanceType from an EntityDef
+     * @param entityDef - the type definition from which the instance type is generated
+     * @return instanceType
+     */
+    private InstanceType createInstanceType(EntityDef entityDef) {
+        /*
+         * Create an instance type - this uses a combination of things from the entity type and the atlas entity.
+         * An OM EntityDef only has one superType - so retrieve it and wrap into a list of length one...
+         */
+        ArrayList<TypeDefLink> listSuperTypes = new ArrayList<>();
+        if (entityDef.getSuperType() != null) {
+            listSuperTypes.add(entityDef.getSuperType());
+        }
+
+        // Collate the valid instance properties
+        EntityDefMapper entityDefMapper = new EntityDefMapper(metadataCollection, userId, entityDef);
+        ArrayList<String> validInstanceProperties = entityDefMapper.getValidPropertyNames();
+
+        InstanceType instanceType = new InstanceType(
+                entityDef.getCategory(),
+                entityDef.getGUID(),
+                entityDef.getName(),
+                entityDef.getVersion(),
+                entityDef.getDescription(),
+                entityDef.getDescriptionGUID(),
+                listSuperTypes,
+                entityDef.getValidInstanceStatusList(),
+                validInstanceProperties);
+
+        LOG.debug("createInstanceType: InstanceType is {}", instanceType);
+        return instanceType;
+    }
+
+    /**
+     * Utility method to parse AtlasClassification into an OM Classification.
+     *
+     * @param atlasClassification - the AtlasClassification to convert
+     * @return Classification     - converted from AtlasClassification
+     */
+    private Classification convertAtlasClassificationToOMClassification(AtlasClassification atlasClassification)
+        throws
+            TypeErrorException
+    {
+
+        String methodName = "convertAtlasClassificationToOMClassification";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> convertAtlasClassificationToOMClassification(atlasClassification={})", atlasClassification);
+        }
+
+        if (atlasClassification == null) {
+            return null;
+        }
+
+        TypeDef typeDef;
+        String typeName = atlasClassification.getTypeName();
+        try {
+            typeDef = metadataCollection._getTypeDefByName(userId, typeName);
+        }
+        catch (Exception e) {
+            // Catch this and handle below
+            typeDef = null;
+        }
+        if (typeDef == null || typeDef.getCategory() != CLASSIFICATION_DEF) {
+            LOG.error("could not retrieve typedef from Classification Def from store by name {} ", typeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, "ClassificationDef", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        ClassificationDef classificationDef;
+        try {
+            classificationDef = (ClassificationDef) typeDef;
+        }
+        catch (ClassCastException e) {
+            LOG.error("convertAtlasRelationshipToOMRelationship: TypeDef with name {} is not a ClassificationDef", typeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, "unknown", "classificationTypeName", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        Classification omClassification = new Classification();
+        /* To convert from Atlas to OM:
+         * Atlas:
+         * entityGuid      ignored
+         * propagate       ignored - in OM this is set in ClassificationDef.propagatable rather than on the instance
+         * validityPeriod  ignored - for now - there is no support for this in OM
+         * typeName        use this to look up ClassificationDef
+         *                 this in turn will let you construct the InstanceType for the OM Classification
+         * attributes      translate these across to Classification.classificationProperties
+         * xxx             origin - this indicates whether the classification was assigned or propagated, but this is not known from AC
+         * xxx             originGUID - this is the GUID of the entity from where the classification propagated, but this is not known from AC
+         */
+
+        // The OM classificationName is set to the name of the AtlasClassificationDef - e.g. "Confidentiality"
+        omClassification.setName(typeName);
+
+        // Copy the classification attributes across from Atlas to OM
+        Map<String, Object> atlasClassAttrs = atlasClassification.getAttributes();
+        AtlasAttributeMapper atlasAttributeMapper = new AtlasAttributeMapper(metadataCollection, userId);
+        InstanceProperties omClassProps = atlasAttributeMapper.convertAtlasAttributesToOMProperties(classificationDef, atlasClassAttrs, false); // uniqueOnly == false => all attributes
+        omClassification.setProperties(omClassProps);
+
+
+        // Clear the classification origin info. Cannot tell from Atlas classification if it was assigned or propagated.
+        omClassification.setClassificationOrigin(null);
+        omClassification.setClassificationOriginGUID(null);
+
+        /*
+         * InstanceType
+         * Create an InstanceType for the classification
+         */
+
+        /* Supertypes - an OM ClassificationDef only has one superType - if there is one,
+         * retrieve it and wrap into a list of length one...
+         */
+        TypeDefLink superType = classificationDef.getSuperType();
+        ArrayList<TypeDefLink> listSuperTypes = null;
+        if (superType != null) {
+            listSuperTypes = new ArrayList<>();
+            listSuperTypes.add(superType);
+        }
+
+        /* ValidInstanceProperties
+         * Walk the supertype hierarchy and find all possible instance properties.
+         */
+        List<TypeDefAttribute> allClassificationProperties;
+        try {
+            allClassificationProperties = metadataCollection.getAllDefinedProperties(userId, classificationDef);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("ClassificationDef", "ClassificationDef", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        ArrayList<String> validInstProps = null;
+        if (allClassificationProperties != null) {
+            // Convert allClassificationProperties into a list of string property keys...
+            validInstProps = new ArrayList<>();
+            for (TypeDefAttribute classificationProperty : allClassificationProperties) {
+                String classificationPropertyName = classificationProperty.getAttributeName();
+                validInstProps.add(classificationPropertyName);
+            }
+        }
+
+        InstanceType instanceType = new InstanceType(
+                classificationDef.getCategory(),
+                classificationDef.getGUID(),
+                classificationDef.getName(),
+                classificationDef.getVersion(),
+                classificationDef.getDescription(),
+                classificationDef.getDescriptionGUID(),
+                listSuperTypes,
+                classificationDef.getValidInstanceStatusList(),
+                validInstProps);
+
+        omClassification.setType(instanceType);
+
+        // Set the other fields from InstanceAuditHeader
+        omClassification.setCreatedBy(classificationDef.getCreatedBy());
+        omClassification.setUpdatedBy(classificationDef.getUpdatedBy());
+        omClassification.setCreateTime(classificationDef.getCreateTime());
+        omClassification.setUpdateTime(classificationDef.getUpdateTime());
+        omClassification.setStatus(InstanceStatus.ACTIVE);
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== convertAtlasClassificationToOMClassification(omClassification={})", omClassification);
+        }
+        return omClassification;
+    }
+
+    private EntityDef getEntityDef(AtlasEntity atlasEntity)
+        throws
+            TypeErrorException,
+            RepositoryErrorException {
+
+        String methodName = "getEntityDef";
+
+        // Find the entityDef for the specified entity
+        String entityTypeName = atlasEntity.getTypeName();
+        TypeDef typeDef;
+        try {
+
+            typeDef = metadataCollection._getTypeDefByName(userId, entityTypeName);
+
+        } catch (TypeDefNotKnownException | RepositoryErrorException e) {
+            LOG.error("getEntityDef: caught exception from attempt to locate typedef for type {}", entityTypeName, e);
+            // handle below
+            typeDef = null;
+        }
+        if (typeDef == null || typeDef.getCategory() != ENTITY_DEF) {
+            LOG.error("getEntityDef: could not find typedef for type {}", entityTypeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeName, "EntityDef", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        EntityDef entityDef;
+        try {
+            entityDef = (EntityDef) typeDef;
+        }
+        catch (ClassCastException e) {
+            LOG.error("getEntityDef: TypeDef with name {} is not an EntityDef", entityTypeName, e);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeName, "unknown", "entityTypeName", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("getEntityDef: EntityDef found {}", entityDef);
+        return entityDef;
+    }
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipDefMapper.java
new file mode 100644
index 000000000..7bd7be847
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipDefMapper.java
@@ -0,0 +1,678 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.instance.AtlasRelationship;
+import org.apache.atlas.model.typedef.AtlasRelationshipDef;
+import org.apache.atlas.model.typedef.AtlasRelationshipEndDef;
+import org.apache.atlas.model.typedef.AtlasStructDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryHelper;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import sun.security.jca.GetInstance;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus.ACTIVE;
+
+//import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.AttributeCardinality.ANY_NUMBER_UNORDERED;
+//import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.AttributeCardinality.AT_MOST_ONE;
+
+public class AtlasRelationshipDefMapper {
+
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasRelationshipDefMapper.class);
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+    private String                           userId = null;
+    private AtlasRelationshipDef             atlasRelationshipDef = null;
+    private String                           metadataCollectionId = null;
+
+
+    public AtlasRelationshipDefMapper(LocalAtlasOMRSMetadataCollection metadataCollection,
+                                      String                           userId,
+                                      AtlasRelationshipDef             atlasRelationshipDef)
+            throws
+            RepositoryErrorException
+    {
+        this.metadataCollection = metadataCollection;
+        this.userId = userId;
+        this.atlasRelationshipDef = atlasRelationshipDef;
+        try {
+            this.metadataCollectionId = this.metadataCollection.getMetadataCollectionId();
+        } catch (RepositoryErrorException e) {
+            LOG.error("AtlasRelationshipDefMapper: could not initialize metadataCollectionId", e);
+            throw e;
+        }
+    }
+
+
+    /**
+     * Method to convert AtlasRelationshipDef to corresponding OM RelationshipDef
+     * @return RelationshipDef
+     * @throws TypeErrorException
+     */
+    public RelationshipDef toOMRelationshipDef()
+        throws
+            TypeErrorException,
+            RepositoryErrorException
+    {
+
+        // Convert the AtlasRelationshipDef into the corresponding OM RelationshipDef and (implicitly) validate the content of the OM RelationshipDef
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> toOMRelationshipDef(atlasRelationshipDef={}", atlasRelationshipDef);
+        }
+
+        final String methodName = "AtlasRelationshipDefMapper.toOMRelationshipDef";
+
+        OMRSRepositoryHelper repositoryHelper = metadataCollection.getRepositoryHelper();
+
+
+        if (atlasRelationshipDef == null) {
+            // Give up now
+            LOG.error("toOMRelationshipDef: Cannot convert null AtlasRelationshipDef to OM RelationshipDef");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasRelationshipDef", "toOMRelationshipDef",metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (atlasRelationshipDef.getName() == null || atlasRelationshipDef.getGuid() == null ) {
+            // Give up now
+            LOG.error("toOMRelationshipDef: Cannot convert AtlasRelationshipDef to OM RelationshipDef, name or guid is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasRelationshipDef", "toOMRelationshipDef",metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        String typeName = atlasRelationshipDef.getName();
+
+        // Convert Atlas type into a valid OM type
+
+        // Allocate OMRS RelationshipDef
+        RelationshipDef omRelationshipDef = new RelationshipDef();
+
+        // Set common fields
+        omRelationshipDef.setGUID(atlasRelationshipDef.getGuid());
+        omRelationshipDef.setName(atlasRelationshipDef.getName());
+
+        // Care needed with version field - in case it is null - Atlas uses Long, OM uses long
+        Long version = atlasRelationshipDef.getVersion();
+        if (version == null) {
+            // Long (the wrapper class) can have null value, but long (the primitive class) cannot
+            LOG.error("toOMRelationshipDef: Cannot convert AtlasEntityDef to OM RelationshipDef - version is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("null", "version", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        omRelationshipDef.setVersion(version);
+
+        omRelationshipDef.setVersionName(atlasRelationshipDef.getTypeVersion());
+
+        // Additional fields on an AtlasRelationshipDef and OM RelationshipDef are ...
+
+        // Copy across the fields that can be simply assigned
+        omRelationshipDef.setDescription(atlasRelationshipDef.getDescription());
+        omRelationshipDef.setCreatedBy(atlasRelationshipDef.getCreatedBy());
+        omRelationshipDef.setUpdatedBy(atlasRelationshipDef.getUpdatedBy());
+        omRelationshipDef.setCreateTime(atlasRelationshipDef.getCreateTime());
+        omRelationshipDef.setUpdateTime(atlasRelationshipDef.getUpdateTime());
+        omRelationshipDef.setOptions(atlasRelationshipDef.getOptions());
+
+        // ------------------
+        /* For those fields we will need to check whether the TypeDef is known by the RCM:
+         * For all fields where nothing is stored in Atlas, use the RCM if possible to determine how to set the OM RelationshipDef
+         * apart from the origin field - which is set to this metadataCollectionId.
+         * There are a couple of cases to consider:
+         *
+         * 1. The first is where this is a known type (by name) in the RCM. In this case the RCM will have an opinion about values
+         *    for the fields we cannot derive from the Atlas object. SO we use the RCM values; these should pass any subsequent
+         *    object comparison (obviously).
+         * 2. The second case is where this is a new type and is not yet known by the RCM. This is the situation where a type is introduced
+         *    into the repository but not via OMRS, e.g. via the Atlas REST/UI interfaces. In this situation, we will not get a type back
+         *    from the RCM; but it's OK - we can just adopt the defaults, which we will have anyway by virtue of having called the
+         *    appropriate def constructor.
+         */
+        TypeDef rcmTypeDef = repositoryHelper.getTypeDefByName(metadataCollectionId, typeName);
+        if (rcmTypeDef != null) {
+            // If we didn't get a typedef from the RCM then we would adopt the defaults, but we can use the RCM values...
+            if (rcmTypeDef.getCategory() != TypeDefCategory.RELATIONSHIP_DEF) {
+                LOG.error("toOMRelationshipDef: The RepositoryContentManager has a type of this name that is not a RelationshipDef!");
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, atlasRelationshipDef.getGuid(), "atlasRelationshipDef", methodName, metadataCollectionId, atlasRelationshipDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+            RelationshipDef rcmRelationshipDef = (RelationshipDef) rcmTypeDef;
+            List<ExternalStandardMapping> rcmExternalStandardMappings = rcmRelationshipDef.getExternalStandardMappings();
+            List<InstanceStatus> rcmInstanceStatusList = rcmRelationshipDef.getValidInstanceStatusList();
+            InstanceStatus rcmInitialStatus = rcmRelationshipDef.getInitialStatus();
+            LOG.debug("Fields acquired from RCM: validInstanceStatusList = {}, initialStatus = {}, externalStandardMappings = {}",
+                    rcmInstanceStatusList, rcmInitialStatus, rcmExternalStandardMappings);
+
+            // The origin is the metadataCollectionId for this connector.
+            omRelationshipDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for external standard mappings. Consult the RCM to set up the OM RelationshipDef
+            // Atlas does not have external standard mappings. OMRS ExternalStandardMappings ArrayList<ExternalStandardMapping>
+            omRelationshipDef.setExternalStandardMappings(rcmExternalStandardMappings);
+
+            // Atlas does not have a field for valid instance statuses. Consult the RCM to set up the OM RelationshipDef
+            // Atlas does not have valid instance statuses. OMRS ValidInstanceStatusList ArrayList<InstanceStatus>
+            omRelationshipDef.setValidInstanceStatusList(rcmInstanceStatusList);
+
+            // Atlas does not have a field for initial status. Consult the RCM to set up the OM RelationshipDef
+            omRelationshipDef.setInitialStatus(rcmInitialStatus);
+        }
+        else {
+            // The RCM does not have the type - either the type is new or we are doing a verify following a
+            // restart - so the type has been retrieved from Atlas but the RCM does not yet have it cached.
+            // In either case we should adopt sensible default values - which for the most part is done by
+            // the object constructor, but explicitly set the fields here. We need to do enough to get past
+            // the equivalence check.
+
+            // The origin is the metadataCollectionId for this connector.
+            omRelationshipDef.setOrigin(this.metadataCollectionId);
+
+            // Atlas does not have a field for external standard mappings. We can only assume here that this
+            // should be set to null in what we return.
+            omRelationshipDef.setExternalStandardMappings(null);
+
+            // Atlas does not have a field for valid instance statuses. Set a sensible default, which assumes
+            // that either ACTIVE or DELETED states are OK.
+            ArrayList<InstanceStatus> statusList = new ArrayList<>();
+            statusList.add(InstanceStatus.ACTIVE);
+            statusList.add(InstanceStatus.DELETED);
+            omRelationshipDef.setValidInstanceStatusList(statusList);
+
+            // Atlas does not have a field for initial status. Default to ACTIVE
+            omRelationshipDef.setInitialStatus(ACTIVE);
+        }
+
+        // Handle fields that require conversion - i.e. supertypes, entityTypes, attributeDefs
+        // subtypes are deliberately ignored
+
+        // superType is always forced to null - Atlas does not have superTypes on AtlasRelationshipDef
+        omRelationshipDef.setSuperType(null);
+
+        // Atlas subtypes are explicitly ignored in OM
+
+        // Convert Atlas relationshipCategory to OM
+
+        /*
+         * If in future OM RelationshipDef supports different categories of relationship, the following conversion will be needed:
+         *
+         *   RelationshipCategory relCat = convertAtlasRelationshipCategoryToOMRelationshipCategory(atlasRelationshipDef.getRelationshipCategory());
+         *   omRelationshipDef.setRelationshipCategory(relCat);
+         *
+         * Until then, if the Atlas relationship def is for anything other than an association then do not convert it...
+         */
+        AtlasRelationshipDef.RelationshipCategory atlasRelCat = atlasRelationshipDef.getRelationshipCategory();
+        if (atlasRelCat == null || atlasRelCat != AtlasRelationshipDef.RelationshipCategory.ASSOCIATION) {
+            String atlasRelCatAsString = "null";
+            // Try to improve the diagnostic is possible...
+            if (atlasRelCat != null) {
+                switch (atlasRelCat) {
+                    case AGGREGATION:
+                        atlasRelCatAsString = "AGGREGATION";
+                        break;
+                    case COMPOSITION:
+                        atlasRelCatAsString = "COMPOSITION";
+                        break;
+                }
+            }
+            LOG.error("toOMRelationshipDef: Cannot convert AtlasRelationshipDef with category {}", atlasRelCatAsString);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(atlasRelCatAsString, "atlasRelCat", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+
+        /* Convert the end defs
+         * Note that the types of attributes is transposed between OM and Atlas, so we transpose the types of the ends.
+         *
+         * If in future OM RelationshipDef supports COMPOSITION and/or AGGREGATION, then we will need to discover which end is
+         * the container (if either) to use later
+         */
+         boolean end1Container = false;
+         boolean end2Container = false;
+
+        /*
+         * Get both ends now so that we can transpose the names, descriptions and cardinality when needed
+         */
+
+        // END1
+        RelationshipEndDef ored1 = new RelationshipEndDef();
+        AtlasRelationshipEndDef ared1 = atlasRelationshipDef.getEndDef1();
+
+        // END2
+        RelationshipEndDef ored2 = new RelationshipEndDef();
+        AtlasRelationshipEndDef ared2 = atlasRelationshipDef.getEndDef2();
+
+        if (ared1 == null || ared2 == null) {
+            LOG.error("toOMRelationshipDef: Could not resolve AtlasRelationshipDef with missing end defs; endDef1 = {}, endDef2 = {}", ared1, ared2);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(null, ared1 == null ? "relationship endDef1" : "relationship endDef2" ,
+                    "RelationshipEndDef", "toOMRelationshipDef", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Process END1
+
+        /*
+         * If OM RelationshipDef supports COMPOSITION or AGGREGATION, will need to know which end is the container
+         */
+         if (ared1.getIsContainer())
+             end1Container = true;
+
+
+        /* Entity Type
+         * First find out if the entity type is known - if not we cannot convert the rel def.
+         * If it is a known entity type then produce a TDL for it....
+         */
+
+        TypeDefLink omrsTypeDefLink1 = null;
+        String entityTypeName1 = ared1.getType();
+
+        // Famous Five
+        if (FamousFive.atlasTypeRequiresSubstitution(entityTypeName1)) {
+            // entity type is in famous five
+            LOG.debug("toOMRelationshipDef: famous five entity type {}", entityTypeName1);
+            String omEntityTypeName1 = FamousFive.getOMTypeName(entityTypeName1);
+            String omEntityTypeGUID1 = null;
+            if (omEntityTypeName1 != null) {
+                omEntityTypeGUID1 = FamousFive.getRecordedGUID(omEntityTypeName1);
+                if (omEntityTypeName1 != null) {
+                    TypeDefLink omEntityType1 = new TypeDefLink();
+                    omEntityType1.setName(omEntityTypeName1);
+                    omEntityType1.setGUID(omEntityTypeGUID1);
+                    omrsTypeDefLink1 = omEntityType1;
+                }
+            }
+            if (omEntityTypeName1 == null || omEntityTypeGUID1 == null) {
+                LOG.error("toOMRelationshipDef: Could not resolve entity type with name {} for AtlasEntityDef", entityTypeName1);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityTypeName1, "guid unknown",
+                        "relationshipEnd1", "toOMRelationshipDef", metadataCollectionId, entityTypeName1);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        else {
+            // not Famous Five
+            omrsTypeDefLink1 = metadataCollection.constructTypeDefLink(entityTypeName1, TypeCategory.ENTITY);
+            if (omrsTypeDefLink1 == null) {
+                LOG.error("toOMRelationshipDef: Could not resolve type with name {} for AtlasEntityDef", entityTypeName1);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, atlasRelationshipDef.getGuid(),
+                        "atlasRelationshipDef", "toOMRelationshipDef", metadataCollectionId, atlasRelationshipDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        // We found an EntityDef with the desired name in our own cache
+        ored1.setEntityType(omrsTypeDefLink1);
+
+
+        // The attribute names, descriptions and cardinality must be swapped end to end when converting between OM and Atlas, or vice versa
+        ored1.setAttributeName(ared2.getName());               // attribute names are deliberately transposed between OM and Atlas
+        ored1.setAttributeDescription(ared2.getDescription()); // attribute descriptions are deliberately transposed between OM and Atlas
+
+        /* Cardinality
+         *
+         * Cardinality is mapped from Atlas Cardinality { SINGLE, LIST, SET } to OM AttributeCardinality
+         * { AT_MOST_ONE, ANY_NUMBER_UNORDERED } which correspond to 0..1 and 0..* respectively.
+         * A relationship end def is always 'optional' and always UNORDERED. This allows the creation of a
+         * relationship between a pair of entities as a one-to-one, one-to-many, many-to-one, many-to-many.
+         */
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality1 = ared2.getCardinality();    // attribute cardinality deliberately transposed between OM and Atlas
+        RelationshipEndCardinality omrsCardinality1;
+        switch (atlasCardinality1) {
+            case SINGLE:
+                omrsCardinality1 = RelationshipEndCardinality.AT_MOST_ONE;
+                break;
+
+            case SET:
+                omrsCardinality1 = RelationshipEndCardinality.ANY_NUMBER;
+                break;
+
+            default:
+                /* Any other cardinality is unexpected - all OM RelationshipDefs are associations with optional, unordered ends.
+                 * There is no sensible way to proceed here.
+                 */
+                LOG.error("toOMRelationshipDef: Atlas end cardinality {} for relationship end def 1 in relationship def {} is not supported by open metadata ", atlasCardinality1, atlasRelationshipDef.getName());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("atlasCardinality1", "Value not supported",
+                        "atlasCardinality1", "toOMRelationshipDef", metadataCollectionId, "end1 cardinality");
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+        ored1.setAttributeCardinality(omrsCardinality1);
+
+        // Add the OM relationship end def to the relationship def
+        omRelationshipDef.setEndDef1(ored1);
+
+
+        // Process END2
+
+        /*
+         * If OM RelationshipDef supports COMPOSITION or AGGREGATION, will need to know which end is the container
+         */
+         if (ared2.getIsContainer())
+             end2Container = true;
+
+
+
+        /* Entity Type
+         * First find out if the entity type is known - if not we cannot convert the rel def.
+         * If it is a known entity type then produce a TDL for it....
+         */
+
+        TypeDefLink omrsTypeDefLink2 = null;
+        String entityTypeName2 = ared2.getType();
+
+        // Famous Five
+        if (FamousFive.atlasTypeRequiresSubstitution(entityTypeName2)) {
+            // entity type is in famous five
+            LOG.debug("toOMRelationshipDef: famous five entity type {}", entityTypeName2);
+            String omEntityTypeName2 = FamousFive.getOMTypeName(entityTypeName2);
+            String omEntityTypeGUID2 = null;
+            if (omEntityTypeName2 != null) {
+                omEntityTypeGUID2 = FamousFive.getRecordedGUID(omEntityTypeName2);
+                if (omEntityTypeName2 != null) {
+                    TypeDefLink omEntityType2 = new TypeDefLink();
+                    omEntityType2.setName(omEntityTypeName2);
+                    omEntityType2.setGUID(omEntityTypeGUID2);
+                    omrsTypeDefLink2 = omEntityType2;
+                }
+            }
+            if (omEntityTypeName2 == null || omEntityTypeGUID2 == null) {
+                LOG.error("toOMRelationshipDef: Could not resolve entity type with name {} for AtlasEntityDef", entityTypeName2);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityTypeName2, "guid unknown",
+                        "relationshipEnd2", "toOMRelationshipDef", metadataCollectionId, entityTypeName2);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        else {
+            // not Famous Five
+            omrsTypeDefLink2 = metadataCollection.constructTypeDefLink(entityTypeName2, TypeCategory.ENTITY);
+            if (omrsTypeDefLink2 == null) {
+                LOG.error("toOMRelationshipDef: Could not resolve type with name {} for AtlasEntityDef", entityTypeName2);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, atlasRelationshipDef.getGuid(),
+                        "atlasRelationshipDef", "toOMRelationshipDef", metadataCollectionId, atlasRelationshipDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        // We found an EntityDef with the desired name in our own cache
+        ored2.setEntityType(omrsTypeDefLink2);
+
+
+        // Note that attribute names and cardinality must be swapped end to end when converting between OM and Atlas, or vice versa
+        ored2.setAttributeName(ared1.getName());     // attribute names are deliberately transposed between OM and Atlas
+        ored2.setAttributeDescription(ared1.getDescription()); // attribute descriptions are deliberately transposed between OM and Atlas
+
+        /* Cardinality
+         *
+         * Cardinality is mapped from Atlas Cardinality { SINGLE, LIST, SET } to OM AttributeCardinality
+         * { AT_MOST_ONE, ANY_NUMBER_UNORDERED } which correspond to 0..1 and 0..* respectively.
+         * A relationship end def is always 'optional' and always UNORDERED. This allows the creation of a
+         * relationship between a pair of entities as a one-to-one, one-to-many, many-to-one, many-to-many.
+         */
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality2 = ared1.getCardinality();    // attribute cardinality deliberately transposed between OM and Atlas
+        RelationshipEndCardinality omrsCardinality2;
+        switch (atlasCardinality2) {
+            case SINGLE:
+                omrsCardinality2 = RelationshipEndCardinality.AT_MOST_ONE;
+                break;
+
+            case SET:
+                omrsCardinality2 = RelationshipEndCardinality.ANY_NUMBER;
+                break;
+
+            default:
+                /* Any other cardinality is unexpected - all OM RelationshipDefs are associations with optional, unordered ends.
+                 * There is no sensible way to proceed here.
+                 */
+                LOG.error("toOMRelationshipDef: Atlas end cardinality {} for relationship end def 2 in relationship def {} is not supported by open metadata ", atlasCardinality2, atlasRelationshipDef.getName());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("atlasCardinality2", "Value not supported",
+                        "atlasCardinality2", "toOMRelationshipDef", metadataCollectionId, "end2 cardinality");
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "toOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+        ored2.setAttributeCardinality(omrsCardinality2);
+
+        // Add the OM relationship end def to the relationship def
+        omRelationshipDef.setEndDef2(ored2);
+
+
+        /*
+         * If in future OM RelationshipDefs support COMPOSITION and/or AGGREGATION then a conversion
+         * will be needed to set the container end information
+         *
+         * Until then, if either end is marked as a container then this is something that is not modelled in OM
+         * so fail the conversion...
+         */
+        if (end1Container || end2Container) {
+            LOG.error("ConvertAtlasRelationshipDef: For an association, neither end should be a container");
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, atlasRelationshipDef.getGuid(),
+                    "atlasRelationshipDef", "toOMRelationshipDef", metadataCollectionId, atlasRelationshipDef.toString());
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "toOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Convert propagateTags to propagationRule
+        AtlasRelationshipDef.PropagateTags atlasPropTags = atlasRelationshipDef.getPropagateTags();
+        boolean propTagsMissingOrInvalid = false;
+        if (atlasPropTags == null) {
+            LOG.error("ConvertAtlasRelationshipDef: could not convert AtlasRelationshipDef, propagateTags is null");
+            propTagsMissingOrInvalid = true; // handle below
+        }
+        else {
+             switch (atlasPropTags) {
+                 case NONE:
+                     omRelationshipDef.setPropagationRule(ClassificationPropagationRule.NONE);
+                     break;
+                 case ONE_TO_TWO:
+                     omRelationshipDef.setPropagationRule(ClassificationPropagationRule.ONE_TO_TWO);
+                     break;
+                 case TWO_TO_ONE:
+                     omRelationshipDef.setPropagationRule(ClassificationPropagationRule.TWO_TO_ONE);
+                     break;
+                 case BOTH:
+                     omRelationshipDef.setPropagationRule(ClassificationPropagationRule.BOTH);
+                     break;
+                 default:
+                     LOG.error("ConvertAtlasRelationshipDef: could not convert Atlas propagateTags value {}", atlasPropTags);
+                     propTagsMissingOrInvalid = true; // handle below
+             }
+         }
+         if (propTagsMissingOrInvalid) {
+             OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+             String errorMessage = errorCode.getErrorMessageId()
+                     + errorCode.getFormattedErrorMessage(typeName, "getPropagateTags",
+                     "atlasRelationshipDef", "toOMRelationshipDef", metadataCollectionId, atlasRelationshipDef.toString());
+
+             throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                     this.getClass().getName(),
+                     "toOMRelationshipDef",
+                     errorMessage,
+                     errorCode.getSystemAction(),
+                     errorCode.getUserAction());
+         }
+
+        // Handle Attribute Defs
+        LOG.debug("toOMRelationshipDef: attributeDefs {}", atlasRelationshipDef.getAttributeDefs());
+        try {
+            List<TypeDefAttribute> omrsTypeDefAttributes =
+                    metadataCollection.convertAtlasAttributeDefs(userId, atlasRelationshipDef.getAttributeDefs());
+            LOG.debug("toOMRelationshipDef: omrsTypeDefAttributes={}", omrsTypeDefAttributes);
+            omRelationshipDef.setPropertiesDefinition(omrsTypeDefAttributes);
+        }
+        catch (RepositoryErrorException | TypeErrorException e) {
+            // Failed to process the attribute types; give up trying to convert this entity def
+            // Give up at this point by returning without having added the OM def to typeDefsForAPI
+            LOG.debug("ConvertAtlasRelationshipDef: Failed to convert attributes of AtlasRelationshipDef");
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== toOMRelationshipDef(omRelationshipDef={}", omRelationshipDef);
+        }
+
+        return omRelationshipDef;
+    }
+
+
+    /*
+     * Utility method to convert from an Atlas relCat to equivalent OM type
+     *
+     * For now this method is redundant but will be needed if OM RelationshipDefs support categories other than ASSOCIATION.
+     */
+    //private RelationshipCategory convertAtlasRelationshipCategoryToOMRelationshipCategory(AtlasRelationshipDef.RelationshipCategory atlasRelCat) {
+    //
+    //    RelationshipCategory ret;
+    //    if (atlasRelCat == null) {
+    //        LOG.debug("convertAtlasRelCatToOM: relationship category is null");
+    //        ret = null;
+    //    }
+    //    else {
+    //        switch (atlasRelCat) {
+    //            case ASSOCIATION:
+    //                ret = RelationshipCategory.ASSOCIATION;
+    //                break;
+    //            case AGGREGATION:
+    //                ret = RelationshipCategory.AGGREGATION;
+    //                break;
+    //            case COMPOSITION:
+    //                ret = RelationshipCategory.COMPOSITION;
+    //                break;
+    //            default:
+    //                LOG.debug("convertAtlasRelCatToOM: unknown relationship category {}", atlasRelCat);
+    //                ret = RelationshipCategory.UNKNOWN;
+    //                break;
+    //        }
+    //    }
+    //    return ret;
+    //}
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipMapper.java
new file mode 100644
index 000000000..60c859886
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasRelationshipMapper.java
@@ -0,0 +1,531 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.exception.AtlasBaseException;
+import org.apache.atlas.model.instance.AtlasEntity;
+import org.apache.atlas.model.instance.AtlasObjectId;
+import org.apache.atlas.model.instance.AtlasRelationship;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.RelationshipDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.RelationshipEndDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefAttribute;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefCategory.RELATIONSHIP_DEF;
+
+
+public class AtlasRelationshipMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AtlasRelationshipMapper.class);
+
+    /*
+     *  Mapper with method for output as OM Relationship
+     *  Always construct from an AtlasRelationship
+     *
+     *  To use this class, construct a new AtlasRelationshipMapper and then invoke the
+     *  method corresponding to output OM Relationship
+     */
+
+    /* AtlasRelationship has:
+     *
+     * String              typeName
+     * Map<String, Object> attributes
+     * String              guid
+     * AtlasObjectId       end1
+     * AtlasObjectId       end2
+     * String              label
+     * PropagateTags       propagateTags
+     * Status              status
+     * String              createdBy
+     * String              updatedBy
+     * Date                createTime
+     * Date                updateTime
+     * Long                version
+     *
+     * OM Relationship needs:
+     *
+     *
+     * InstanceAuditHeader fields
+     *
+     * InstanceType              type
+     * String                    createdBy
+     * String                    updatedBy
+     * Date                      createTime
+     * Date                      updateTime
+     * Long                      version
+     * InstanceStatus            currentStatus
+     * InstanceStatus            statusOnDelete
+     *
+     * Instance Header fields
+     *
+     * InstanceProvenanceType    instanceProvenanceType
+     * String                    metadataCollectionId
+     * String                    guid
+     * String                    instanceURL
+     *
+     * Relationship fields
+     *
+     *   InstanceProperties    relationshipProperties
+     *   String                entityOnePropertyName   -- Retrieve this from the RelDef.RelEndDef for end1
+     *   EntityProxy           entityOneProxy
+     *   String                entityTwoPropertyName   --  Retrieve this from the RelDef.RelEndDef for end2
+     *   EntityProxy           entityTwoProxy
+     */
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection   = null;
+    private String                           metadataCollectionId = null;
+    private String                           userId               = null;
+    private AtlasEntityStore                 entityStore          = null;
+    private AtlasRelationship                atlasRelationship    = null;
+    private RelationshipDef                  relationshipDef      = null;
+    private AtlasEntity                      atlasEntity1         = null;
+    private AtlasEntity                      atlasEntity2         = null;
+
+
+    public AtlasRelationshipMapper(LocalAtlasOMRSMetadataCollection metadataCollection,
+                                   String                           userId,
+                                   AtlasRelationship                atlasRelationship,
+                                   AtlasEntityStore                 entityStore)
+
+            throws
+            TypeErrorException,
+            RepositoryErrorException,
+            InvalidParameterException,
+            InvalidRelationshipException,
+            EntityNotKnownException
+
+    {
+
+        final String methodName = "AtlasRelationshipMapper";
+
+        LOG.debug("AtlasRelationshipMapper: userId={}, atlasRelationship={} ", userId, atlasRelationship);
+
+        if (metadataCollection == null) {
+            // We are not going to get far...
+            LOG.error("AtlasRelationshipMapper: metadataCollection is null ");
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.NULL_PARAMETER;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("metadataCollection", methodName);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        if (atlasRelationship == null) {
+            // We are not going to get far...
+            LOG.error("AtlasRelationshipMapper: atlasRelationship is null ");
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.NULL_PARAMETER;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasRelationship", methodName);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        this.metadataCollection = metadataCollection;
+        try {
+            this.metadataCollectionId = metadataCollection.getMetadataCollectionId();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("AtlasRelationshipMapper: caught repository exception - could not get metadataCollectionId", e);
+            // re-throw error
+            throw e;
+        }
+        this.entityStore = entityStore;
+        this.atlasRelationship = atlasRelationship;
+        this.userId = userId;
+        // Get the relationship def
+        try {
+            this.relationshipDef = getRelationshipDef(atlasRelationship);
+        }
+        catch (TypeErrorException e) {
+            LOG.error("AtlasRelationshipMapper: caught type exception - could not retrieve relationship def for typename {}", atlasRelationship.getTypeName(), e);
+            // Re-throw - exception will be caught in the MDC
+            throw e;
+        }
+        // Get the two entities
+        try {
+            this.atlasEntity1 = getAtlasEntity(atlasRelationship,1);
+            this.atlasEntity2 = getAtlasEntity(atlasRelationship,2);
+        }
+        catch (EntityNotKnownException | InvalidParameterException | InvalidRelationshipException e) {
+            LOG.error("AtlasRelationshipMapper: caught type exception - could not retrieve entity from relationship", e);
+            // Re-throw - exception will be caught in the MDC
+            throw e;
+        }
+    }
+
+
+    /**
+     * Method to convert the mapper's AtlasRelationship to an OM Relationship
+     * @return The retrieved and converted OM Relationship
+     * @throws TypeErrorException       - there is something wrong with the typedefs
+     * @throws RepositoryErrorException - the repository threw an exception
+     * @throws InvalidEntityException   - one of the relationship's entities was invalid
+     */
+    public Relationship toOMRelationship() throws TypeErrorException, RepositoryErrorException, InvalidEntityException {
+        if (this.atlasRelationship == null) {
+            return null;
+        }
+        Relationship omRelationship = new Relationship();
+        try {
+            completeRelationship(omRelationship);
+            return omRelationship;
+        }
+        catch (TypeErrorException e) {
+            LOG.error("toOMRelationship: caught TypeErrorException {}", e);
+            throw e;
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("toOMRelationship: caught RepositoryErrorException {}", e);
+            throw e;
+        }
+        catch (InvalidEntityException e) {
+            LOG.error("toOMRelationship: caught InvalidEntityException {}", e);
+            throw e;
+        }
+    }
+
+    /*
+     * Private method to retrieve RelationshipDef corresponding to specified relationship.
+     */
+    private RelationshipDef getRelationshipDef(AtlasRelationship atlasRelationship) throws TypeErrorException {
+
+        final String methodName = "getRelationshipDef";
+
+        // Get the RelationshipDef using the typeName
+        String relationshipTypeName = atlasRelationship.getTypeName();
+        LOG.debug("getRelationshipDef: atlas relationship has typename {}", relationshipTypeName);
+        TypeDef typeDef;
+        try {
+
+            typeDef = metadataCollection._getTypeDefByName(userId, relationshipTypeName);
+
+        } catch (TypeDefNotKnownException | RepositoryErrorException e) {
+
+            LOG.error("getRelationshipDef: Caught exception from getTypeDefByName {}", e);
+            // handle the exception below
+            typeDef = null;
+        }
+
+        // Validate it
+        if (typeDef == null || typeDef.getCategory() != RELATIONSHIP_DEF) {
+
+            LOG.error("getRelationshipDef: Could not find relationship def with name {} ", relationshipTypeName);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeName, "relationshipTypeName", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        /* Have done all we can to ensure this is a RelationshipDef, but protect against a
+         * possible class cast exception anyway...
+         */
+        RelationshipDef relationshipDef;
+        try {
+            relationshipDef = (RelationshipDef) typeDef;
+        }
+        catch (ClassCastException e) {
+            LOG.error("getRelationshipDef: TypeDef with  name {} is not a RelationshipDef", relationshipTypeName, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeName, "unknown", "relationshipTypeName", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("getRelationshipDef: located relationshipDef {}", relationshipDef);
+
+        // Validate RelationshipDef
+        // Make sure it has two end defs - each with an attributeName
+        RelationshipEndDef relEndDef1 = relationshipDef.getEndDef1();
+        RelationshipEndDef relEndDef2 = relationshipDef.getEndDef2();
+        if (relEndDef1 == null || relEndDef1.getAttributeName() == null ||
+            relEndDef2 == null || relEndDef2.getAttributeName() == null) {
+
+            LOG.error("getRelationshipDef: RelationshipDef {} does not have valid ends", relationshipTypeName);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeName, "unknown", "relationshipTypeName", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        return relationshipDef;
+    }
+
+
+    /*
+     * Private method to retrieve entity from specified end of relationship.
+     */
+    private AtlasEntity getAtlasEntity(AtlasRelationship atlasRelationship,
+                                       int               end)
+            throws
+            InvalidParameterException,
+            InvalidRelationshipException,
+            EntityNotKnownException
+    {
+        // Retrieve the AtlasEntity objects from the repository and create an EntityProxy object for each...
+        // The AtlasRelationship has AtlasObjectID for end1 and end2.
+        final String methodName = "getAtlasEntity";
+
+        String entityGuid;
+
+        AtlasObjectId atlasEnd;
+        switch (end) {
+            case 1:
+                atlasEnd = atlasRelationship.getEnd1();
+                break;
+            case 2:
+                atlasEnd = atlasRelationship.getEnd2();
+                break;
+            default:
+                LOG.error("getAtlasEntity: invalid end identifier {}", end);
+
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_PARAMETER;
+
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("" + end, "end", methodName);
+
+                throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+        if (atlasEnd != null) {
+            entityGuid = atlasEnd.getGuid();
+        }
+        else {
+            LOG.error("getAtlasEntity: relationship end {} is null", end);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_RELATIONSHIP_FROM_STORE;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(atlasRelationship.getGuid(), metadataCollectionId, methodName);
+
+            throw new InvalidRelationshipException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+        try {
+
+            atlasEntWithExt = this.entityStore.getById(entityGuid);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("getAtlasEntity: Caught exception from Atlas entityStore get by guid {}, {}", entityGuid, e);
+            // handle below
+            atlasEntWithExt = null;
+
+        }
+        if (atlasEntWithExt == null) {
+
+            LOG.error("getAtlasEntity: Could not find entity with guid {} ", entityGuid);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGuid, "entityGuid", methodName, metadataCollectionId);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+        // Extract the entity
+       return atlasEntWithExt.getEntity();
+
+    }
+
+    /**
+     * completeRelationship
+     * @param omRelationship - Relationship object to be completed
+     * @throws TypeErrorException       - a type error occurred
+     * @throws RepositoryErrorException - a repository error occurred
+     */
+    private void completeRelationship(Relationship omRelationship) throws TypeErrorException,RepositoryErrorException, InvalidEntityException {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> completeRelationship(omRelationship={})", omRelationship);
+        }
+        // Create instance type
+        InstanceType instanceType = createInstanceType(relationshipDef);
+        omRelationship.setType(instanceType);
+
+        // Set fields from InstanceAuditHeader
+        omRelationship.setType(instanceType);
+        omRelationship.setCreatedBy(atlasRelationship.getCreatedBy());
+        omRelationship.setCreateTime(atlasRelationship.getCreateTime());
+        omRelationship.setUpdatedBy(atlasRelationship.getUpdatedBy());
+        omRelationship.setUpdateTime(atlasRelationship.getUpdateTime());
+        omRelationship.setVersion(atlasRelationship.getVersion());
+
+        if (atlasRelationship.getStatus() == AtlasRelationship.Status.ACTIVE) {
+            omRelationship.setStatus(InstanceStatus.ACTIVE);
+        } else {
+            omRelationship.setStatus(InstanceStatus.DELETED);
+        }
+
+        // Set fields from InstanceHeader
+        omRelationship.setMetadataCollectionId(atlasRelationship.getHomeId());
+        omRelationship.setGUID(atlasRelationship.getGuid());
+        omRelationship.setInstanceURL(null);
+
+        // Set fields from Relationship
+        // Take the attributes from AtlasRelationship and set the Properties for OM Relationship
+        Map<String, Object> atlasAttrs = atlasRelationship.getAttributes();
+        AtlasAttributeMapper atlasAttributeMapper = new AtlasAttributeMapper(metadataCollection, userId);
+        InstanceProperties omRelProps = atlasAttributeMapper.convertAtlasAttributesToOMProperties(relationshipDef, atlasAttrs, false);
+        omRelationship.setProperties(omRelProps);
+        LOG.debug("completeRelationship: completed properties {}", omRelationship);
+
+        // Add the ends to the Relationship
+        RelationshipEndDef relEndDef1 = relationshipDef.getEndDef1();
+        String endDef1AttributeName = relEndDef1.getAttributeName();
+        omRelationship.setEntityOnePropertyName(endDef1AttributeName);
+
+        RelationshipEndDef relEndDef2 = relationshipDef.getEndDef2();
+        String endDef2AttributeName = relEndDef2.getAttributeName();
+        omRelationship.setEntityTwoPropertyName(endDef2AttributeName);
+
+
+        // Convert each AtlasEntity into an OM EntityProxy
+        try {
+            AtlasEntityMapper atlasEntityMapper1 = new AtlasEntityMapper(metadataCollection, userId, atlasEntity1);
+            EntityProxy end1Proxy = atlasEntityMapper1.toEntityProxy();
+            LOG.debug("completeRelationship: om entity1 {}", end1Proxy);
+            omRelationship.setEntityOneProxy(end1Proxy);
+
+            AtlasEntityMapper atlasEntityMapper2 = new AtlasEntityMapper(metadataCollection, userId, atlasEntity2);
+            EntityProxy end2Proxy = atlasEntityMapper2.toEntityProxy();
+            LOG.debug("completeRelationship: om entity2 {}", end2Proxy);
+            omRelationship.setEntityTwoProxy(end2Proxy);
+        }
+        catch (TypeErrorException e) {
+            LOG.error("completeRelationship: caught TypeErrorException from entity mapper {}", e);
+            throw e;
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("completeRelationship: caught RepositoryErrorException from entity mapper {}", e);
+            throw e;
+        }
+        catch (InvalidEntityException e) {
+            LOG.error("completeRelationship: caught InvalidEntityException from entity mapper {}", e);
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== completeRelationship(): return={}", omRelationship);
+        }
+
+    }
+
+    /**
+     * Helper method to create InstanceType from an RelationshipDef
+     * @param relationshipDef - the RelationshipDef for which an InstanceType is needed
+     * @return - the created InstanceType
+     */
+    private InstanceType createInstanceType(RelationshipDef relationshipDef) {
+        // Create an instance type - this uses a combination of things from the relationship type and the atlas relationship
+
+        // Collate the valid instance properties - no supertypes to traverse for a relationship def
+        ArrayList<String> validInstanceProperties = null;
+        List<TypeDefAttribute> typeDefAttributes = relationshipDef.getPropertiesDefinition();
+        if (typeDefAttributes != null) {
+            validInstanceProperties = new ArrayList<>();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                String attrName = typeDefAttribute.getAttributeName();
+                validInstanceProperties.add(attrName);
+            }
+        }
+
+        // An OM RelationshipDef has no superType - so we just set that to null
+        InstanceType instanceType = new InstanceType(
+                relationshipDef.getCategory(),
+                relationshipDef.getGUID(),
+                relationshipDef.getName(),
+                relationshipDef.getVersion(),
+                relationshipDef.getDescription(),
+                relationshipDef.getDescriptionGUID(),
+                null,
+                relationshipDef.getValidInstanceStatusList(),
+                validInstanceProperties);
+
+        return instanceType;
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxy.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxy.java
new file mode 100644
index 000000000..4d82a1f60
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxy.java
@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.discovery.EntityDiscoveryService;
+import org.apache.atlas.kafka.KafkaNotification;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+import org.apache.atlas.repository.store.graph.AtlasRelationshipStore;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+
+
+public interface AtlasStoresProxy {
+
+    public AtlasTypeRegistry getTypeRegistry();
+
+    public AtlasTypeDefStore getTypeDefStore();
+
+    public AtlasEntityStore getEntityStore();
+
+    public AtlasRelationshipStore getRelationshipStore();
+
+    public EntityDiscoveryService getEntityDiscoveryService();
+
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxyImpl.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxyImpl.java
new file mode 100644
index 000000000..91db230c9
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/AtlasStoresProxyImpl.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+
+import org.apache.atlas.discovery.EntityDiscoveryService;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+import org.apache.atlas.repository.store.graph.AtlasRelationshipStore;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+import org.springframework.stereotype.Component;
+
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
+
+@Singleton
+@Component
+public class AtlasStoresProxyImpl implements AtlasStoresProxy {
+
+
+    private AtlasTypeRegistry      typeRegistry;
+    private AtlasTypeDefStore      typeDefStore;
+    private AtlasEntityStore       entityStore;
+    private AtlasRelationshipStore relationshipStore;
+    private EntityDiscoveryService entityDiscoveryService;
+
+    @Inject
+    public AtlasStoresProxyImpl(AtlasTypeRegistry      typeRegistry,
+                                AtlasTypeDefStore      typeDefStore,
+                                AtlasEntityStore       entityStore,
+                                AtlasRelationshipStore relationshipStore,
+                                EntityDiscoveryService entityDiscoveryService) {
+
+        this.typeRegistry           = typeRegistry;
+        this.typeDefStore           = typeDefStore;
+        this.entityStore            = entityStore;
+        this.relationshipStore      = relationshipStore;
+        this.entityDiscoveryService = entityDiscoveryService;
+    }
+
+    public AtlasTypeRegistry getTypeRegistry() {
+        return typeRegistry;
+    }
+
+    public AtlasTypeDefStore getTypeDefStore() {
+        return typeDefStore;
+    }
+
+    public AtlasEntityStore getEntityStore() {
+        return entityStore;
+    }
+
+    public AtlasRelationshipStore getRelationshipStore() {
+        return relationshipStore;
+    }
+
+    public EntityDiscoveryService getEntityDiscoveryService() {
+        return entityDiscoveryService;
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/Comparator.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/Comparator.java
new file mode 100644
index 000000000..af8e20d5e
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/Comparator.java
@@ -0,0 +1,1639 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.typedef.AtlasRelationshipDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceStatus;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Date;
+import java.util.List;
+import java.util.Map;
+
+
+/* Comparison utility class to compare complex objects.
+ * This class is needed because equals() is defined differently for OMRS classes
+ * that may be deemed to be equal if they match only by name and guid. We need a
+ * more detailed comparison or exact matches and equivalence checks.
+ *
+ * The compare() method performs an exact match comparison, whereas an equivalent()
+ * performs a semantic equivalence check.
+ *
+ * The first few methods may seem gratuitous but they make everything consistent.
+ */
+
+public class Comparator {
+
+    private static final Logger LOG = LoggerFactory.getLogger(Comparator.class);
+
+    // All arrays are assumed to be order significant unless specified in the list below.
+    private static final boolean ARRAY_ORDER_SIGNIFICANT = true;
+    private static final boolean ARRAY_ORDER_SIGNIFICANCE_SUPERTYPES = false;
+    private static final boolean ARRAY_ORDER_SIGNIFICANCE_VALID_ENTITY_DEFS = false;
+
+    private boolean compare(int a, int b) {
+        return (a == b);
+    }
+
+    private boolean compare(boolean a, boolean b) {
+        return (a == b);
+    }
+
+    private boolean compare(Long a, Long b) {
+        return (a.equals(b));
+    }
+
+    private boolean compare(String a, String b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare String: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare String: the {} string is null", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.equals(b))) {
+            LOG.debug("Compare String: compare failed, {} vs {}", a,b);
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(Date a, Date b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare Date: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare Date: the {} date is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.equals(b))) {
+            LOG.debug("Compare Date: the dates are different {} vs {}", a, b);
+            return false;
+        }
+        return true;
+
+    }
+
+    private boolean compare(Map<String, String> a, Map<String, String> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare Map: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare Map: the {} map is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare Map: maps are different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        for (String key : a.keySet()) {
+            if (!(compare(a.get(key), b.get(key)))) {
+                LOG.debug("Compare Map: map values are different {} vs {}", a.get(key), b.get(key));
+                return false;
+            }
+        }
+        return true;
+    }
+
+    public boolean compare(TypeDefLink a, TypeDefLink b) {
+        return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, TypeDefLink a, TypeDefLink b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDefLink: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDefLink: the {} TypeDefLink is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getGUID(), b.getGUID()))) {
+            LOG.debug("Compare TypeDefLink: GUID did not match {} vs {}", a.getGUID(), b.getGUID());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare TypeDefLink: Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        // Would need to delegate upward to TypeDefElementHeader if we also want to compare type version
+        return true;
+    }
+
+    private boolean compare(TypeDefCategory a, TypeDefCategory b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDefCategory: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDefCategory: the {} TypeDefCategory is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Compare TypeDefCategory: TypeCode did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare TypeDefCategory: TypeName did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare TypeDefCategory: TypeDescription did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(TypeDefSummary a, TypeDefSummary b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDefSummary: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDefSummary: the {} TypeDefSummary is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getVersion(),b.getVersion()))) {
+            LOG.debug("Compare TypeDefSummary: Version did not match {} vs {}", a.getVersion(), b.getVersion());
+            return false;
+        }
+        if (!(compare(a.getVersionName(),b.getVersionName()))) {
+            LOG.debug("Compare TypeDefSummary: VersionName did not match {} vs {}", a.getVersionName(), b.getVersionName());
+            return false;
+        }
+        if (!(compare(a.getCategory(),b.getCategory()))) {
+            LOG.debug("Compare TypeDefSummary: Category did not match {} vs {}", a.getCategory(), b.getCategory());
+            return false;
+        }
+        // Delegate upwards
+        if (!(compare((TypeDefLink)a,(TypeDefLink)b))) {
+            LOG.debug("Compare TypeDefSummary: TypeDefLink did not match");
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(ExternalStandardMapping a, ExternalStandardMapping b) {
+        return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, ExternalStandardMapping a, ExternalStandardMapping b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare ExternalStandardMapping: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare ExternalStandardMapping: the {} ExternalStandardMapping is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getStandardName(),b.getStandardName()))) {
+            LOG.debug("Compare ExternalStandardMapping: StandardName did not match {} vs {}", a.getStandardName(), b.getStandardName());
+            return false;
+        }
+        if (!(compare(a.getStandardOrganization(),b.getStandardOrganization()))) {
+            LOG.debug("Compare ExternalStandardMapping: StandardOrganization did not match {} vs {}", a.getStandardOrganization(), b.getStandardOrganization());
+            return false;
+        }
+        if (!(compare(a.getStandardTypeName(),b.getStandardTypeName()))) {
+            LOG.debug("Compare ExternalStandardMapping: StandardTypeName did not match {} vs {}", a.getStandardTypeName(), b.getStandardTypeName());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(AttributeCardinality a, AttributeCardinality b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare AttributeCardinality: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare AttributeCardinality: the {} AttributeCardinality is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Compare AttributeCardinality: Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare AttributeCardinality: Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare AttributeCardinality: Description did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        return true;
+    }
+
+
+    private boolean compare(RelationshipEndCardinality a, RelationshipEndCardinality b) {
+        if (a != b) {
+            LOG.debug("Compare RelationshipEndCardinality: did not match {} vs {}", a, b);
+            return false;
+        }
+        return true;
+    }
+
+
+    // Method is private because AttributeTypeDef is abstract
+    // This method is delegated to by comparators for concrete classes:
+    //  CollectionDef
+    //  EnumDef
+    //  PrimitiveDef
+    private boolean compare(AttributeTypeDef a, AttributeTypeDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare AttributeTypeDef: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare AttributeTypeDef: the {} AttributeTypeDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getCategory(),b.getCategory()))) {
+            LOG.debug("Compare AttributeTypeDef: Category did not match {} vs {}", a.getCategory(), b.getCategory());
+            return false;
+        }
+        if (!(compare(a.getGUID(),b.getGUID()))) {
+            LOG.debug("Compare AttributeTypeDef: GUID did not match: {} vs {}", a.getGUID(), b.getGUID());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare AttributeTypeDef: Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare AttributeTypeDef: Description did not match {} vs {}", a.getDescription(),b.getDescription());
+            return false;
+        }
+        if (!(compare(a.getDescriptionGUID(),b.getDescriptionGUID()))) {
+            LOG.debug("Compare AttributeTypeDef: descriptionGUID did not match {} vs {}", a.getDescriptionGUID(), b.getDescriptionGUID());
+            return false;
+        }
+        // Delegate up to TypeDefElementHeader if we also need to compare type version
+        return true;
+    }
+
+
+    public boolean compare(boolean strict, CollectionDef a, CollectionDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare CollectionDef: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare CollectionDef: the {} CollectionDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getCollectionDefCategory(),b.getCollectionDefCategory()))) {
+            LOG.debug("Compare CollectionDef: CollectionDefCategory did not match {} vs {}", a.getCollectionDefCategory(), b.getCollectionDefCategory());
+            return false;
+        }
+        if (!(compare(a.getArgumentCount(),b.getArgumentCount()))) {
+            LOG.debug("Compare CollectionDef: ArgumentCount did not match {} vs {}", a.getArgumentCount(), b.getArgumentCount());
+            return false;
+        }
+        if (!(compareListPrimitiveDefCategory(ARRAY_ORDER_SIGNIFICANT,a.getArgumentTypes(),b.getArgumentTypes()))) {
+            LOG.debug("Compare CollectionDef: ArgumentTypes did not match {} vs {}", a.getArgumentTypes(), b.getArgumentTypes());
+            return false;
+        }
+        // Delegate up to AttributeTypeDef
+        if (!(compare((AttributeTypeDef)a,(AttributeTypeDef)b))) {
+            LOG.debug("Compare CollectionDef: AttributeTypeDefs did not match");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean compare(EnumDef a, EnumDef b) {
+        return compare(false, a, b);
+    }
+    public boolean compare(boolean strict, EnumDef a, EnumDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare EnumDef: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare EnumDef: the {} EnumDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compareListEnumElementDef(strict,a.getElementDefs(),b.getElementDefs()))) {
+            LOG.debug("Compare EnumDef: ElementDefs did not match {} vs {}", a.getElementDefs(), b.getElementDefs());
+            return false;
+        }
+        if (!(compare(a.getDefaultValue(),b.getDefaultValue()))) {
+            LOG.debug("Compare EnumDef: DefaultValue did not match {} vs {}", a.getDefaultValue(), b.getDefaultValue());
+            return false;
+        }
+        // Delegate up to AttributeTypeDef
+        if (!(compare((AttributeTypeDef)a,(AttributeTypeDef)b))) {
+            LOG.debug("Compare EnumDef: AttributeTypeDefs did not match");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean compare(boolean strict, PrimitiveDef a, PrimitiveDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare PrimitiveDef: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare PrimitiveDef: the {} PrimitiveDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(true, a.getPrimitiveDefCategory(),b.getPrimitiveDefCategory()))) {
+            LOG.debug("Compare PrimitiveDef: PrimitiveDefCategory did not match {} vs {}", a.getPrimitiveDefCategory(), b.getPrimitiveDefCategory());
+            return false;
+        }
+        // Delegate up to AttributeTypeDef
+        if (!(compare((AttributeTypeDef)a,(AttributeTypeDef)b))) {
+            LOG.debug("Compare PrimitiveDef: AttributeTypeDefs did not match");
+            return false;
+        }
+        return true;
+    }
+
+
+    private boolean compareListEnumElementDef(boolean strict, List<EnumElementDef> a,  List<EnumElementDef> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<EnumElementDef>: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<EnumElementDef>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<EnumElementDef>: Arrays of EnumElementDef have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict,a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<EnumElementDef>: Elements are different {} vs {}",a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    //LOG.debug("compare i={},left={},j={},right={}",i,j,a.get(i),b.get(j));
+                    if (compare(strict,a.get(i), b.get(j))) {
+                        //LOG.debug("compare succeeded");
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<EnumElementDef>: Did not find {} in {}",a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    private boolean compare(EnumElementDef a, EnumElementDef b) {
+        return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, EnumElementDef a, EnumElementDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare EnumElementDef: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare EnumElementDef: the {} EnumElementDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            // likely to be in a list so only issue debug on a mismatch if in strict mode; handling for ordinal will suffice
+            if (strict) LOG.debug("Compare EnumElementDef: Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getValue(),b.getValue()))) {
+            LOG.debug("Compare EnumElementDef: Value did not match {} vs {}", a.getValue(), b.getValue());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare EnumElementDef: Description did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        // Delegate up to TypeDefElementHeader if we also need to compare type version
+        return true;
+    }
+
+    private boolean compare(CollectionDefCategory a, CollectionDefCategory b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare CollectionDefCategory: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare CollectionDefCategory: the {} CollectionDefCategory is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Compare CollectionDefCategory: Code did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare CollectionDefCategory: Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getArgumentCount(),b.getArgumentCount()))) {
+            LOG.debug("Compare CollectionDefCategory: ArgumentCount did not match {} vs {}", a.getArgumentCount(), b.getArgumentCount());
+            return false;
+        }
+        if (!(compare(a.getJavaClassName(),b.getJavaClassName()))) {
+            LOG.debug("Compare CollectionDefCategory: JavaClassName did not match {} vs {}", a.getJavaClassName(), b.getJavaClassName());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compareListPrimitiveDefCategory(boolean strict, List<PrimitiveDefCategory> a, List<PrimitiveDefCategory> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<PrimitiveDefCategory>: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<PrimitiveDefCategory>: ListPrimitiveDefCategory: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<PrimitiveDefCategory>: Arrays of PrimitiveDefCategory have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<PrimitiveDefCategory>: Entries different {} vs {}", a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<PrimitiveDefCategory>: Could not find {} in {}", a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    private boolean compare(PrimitiveDefCategory a, PrimitiveDefCategory b) {
+        return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, PrimitiveDefCategory a, PrimitiveDefCategory b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare PrimitiveDefCategory: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare PrimitiveDefCategory: the {} PrimitiveDefCategory is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Compare PrimitiveDefCategory: Code did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare PrimitiveDefCategory: Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getJavaClassName(),b.getJavaClassName()))) {
+            LOG.debug("Compare PrimitiveDefCategory: JavaClassName did not match {} vs {}", a.getJavaClassName(), b.getJavaClassName());
+            return false;
+        }
+        if (!(compare(a.getGUID(),b.getGUID()))) {
+            LOG.debug("Compare PrimitiveDefCategory: GUID did not match {} vs {}", a.getGUID(), b.getGUID());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(AttributeTypeDefCategory a, AttributeTypeDefCategory b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare AttributeTypeDefCategory: both null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare AttributeTypeDefCategory: the {} AttributeTypeDefCategory is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Compare AttributeTypeDefCategory: TypeCode did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare AttributeTypeDefCategory: TypeName did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare AttributeTypeDefCategory: TypeDescription did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compare(TypeDefAttribute a, TypeDefAttribute b) {
+            return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, TypeDefAttribute a, TypeDefAttribute b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDefAttribute: both TypeDefAttributes are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDefAttribute: TypeDefAttribute: the {} TypeDefAttribute is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getAttributeName(),b.getAttributeName()))) {
+            LOG.debug("Compare TypeDefAttribute: AttributeName did not match {} vs {}", a.getAttributeName(), b.getAttributeName());
+            return false;
+        }
+        if (!(compare(a.getAttributeType(),b.getAttributeType()))) {
+            LOG.debug("Compare TypeDefAttribute: AttributeType did not match {} vs {}", a.getAttributeType(), b.getAttributeType());
+            return false;
+        }
+        if (!(compare(a.getAttributeDescription(),b.getAttributeDescription()))) {
+            LOG.debug("Compare TypeDefAttribute: AttributeDescription did not match {} vs {}", a.getAttributeDescription(), b.getAttributeDescription());
+            return false;
+        }
+        if (!(compare(a.getAttributeCardinality(),b.getAttributeCardinality()))) {
+            LOG.debug("Compare TypeDefAttribute: AttributeCardinality did not match {} vs {}", a.getAttributeCardinality(), b.getAttributeCardinality());
+            return false;
+        }
+        if (!(compare(a.getValuesMinCount(),b.getValuesMinCount()))) {
+            LOG.debug("Compare TypeDefAttribute: ValuesMinCount did not match {} vs {}", a.getValuesMinCount(), b.getValuesMinCount());
+            return false;
+        }
+        if (!(compare(a.getValuesMaxCount(),b.getValuesMaxCount()))) {
+            LOG.debug("Compare TypeDefAttribute: ValuesMaxCount did not match {} vs {}", a.getValuesMaxCount(), b.getValuesMaxCount());
+            return false;
+        }
+        if (!(compare(a.isIndexable(),b.isIndexable()))) {
+            LOG.debug("Compare TypeDefAttribute: isIndexable did not match {} vs {}", a.isIndexable(), b.isIndexable());
+            return false;
+        }
+        if (!(compare(a.isUnique(),b.isUnique()))) {
+            LOG.debug("Compare TypeDefAttribute: Unique did not match {} vs {}", a.isUnique(), b.isUnique());
+            return false;
+        }
+        if (!(compare(a.getDefaultValue(),b.getDefaultValue()))) {
+            LOG.debug("Compare TypeDefAttribute: DefaultValue did not match {} vs {}", a.getDefaultValue(), b.getDefaultValue());
+            return false;
+        }
+        if (!(compareListExternalStandardMappings(ARRAY_ORDER_SIGNIFICANT, a.getExternalStandardMappings(),b.getExternalStandardMappings()))) {
+            LOG.debug("Compare TypeDefAttribute: ExternalStandardMappings did not match {} vs {}", a.getExternalStandardMappings(), b.getExternalStandardMappings());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compareListExternalStandardMappings(boolean strict, List<ExternalStandardMapping> a, List<ExternalStandardMapping> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<ExternalStandardMappings>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<ExternalStandardMappings>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<ExternalStandardMappings>: Arrays of ExternalStandardMappings have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<ExternalStandardMappings>: elements are different {} vs {}", a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<ExternalStandardMappings>: could not find {} in {}", a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    private boolean compareListTypeDefAttribute(boolean strict, List<TypeDefAttribute> a, List<TypeDefAttribute> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<TypeDefAttribute>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<TypeDefAttribute>: ListTypeDefAttribute: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<TypeDefAttribute>: Arrays of TypeDef have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<TypeDefAttribute>: elements differ {} vs {}", a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<TypeDefAttribute>: could not find {} in {}", a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    public boolean compareListTypeDefLink(List<TypeDefLink> a, List<TypeDefLink> b) { return compareListTypeDefLink(true, a,b); }
+    private boolean compareListTypeDefLink(boolean strict, List<TypeDefLink> a, List<TypeDefLink> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<TypeDefLink>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<TypeDefLink>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<TypeDefLink>: Arrays of TypeDefLink have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<TypeDefLink>: elements different {} vs {}",a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<TypeDefLink>: could not find {} in {}",a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    private boolean compareListExternalStandardMapping(boolean strict, List<ExternalStandardMapping> a, List<ExternalStandardMapping> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<ExternalStandardMapping>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<ExternalStandardMapping>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<ExternalStandardMapping>: Arrays of ExternalStandardMapping have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<ExternalStandardMapping>: elements different {} vs {}",  a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<ExternalStandardMapping>: could not find {} in {}",  a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    private boolean compare(InstanceStatus a, InstanceStatus b) {
+            return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, InstanceStatus a, InstanceStatus b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare InstanceStatus: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare InstanceStatus: InstanceStatus: the {} InstanceStatus is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            // Only flag a mismatch if struct. Non-strict is used in comparison of a list of instance status
+            if (strict) LOG.debug("Compare InstanceStatus: Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Compare InstanceStatus: StatusName did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare InstanceStatus: StatusDescription did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        return true;
+    }
+
+    private boolean compareListInstanceStatus(boolean strict, List<InstanceStatus> a, List<InstanceStatus> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<InstanceStatus>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<InstanceStatus>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<InstanceStatus>: Arrays of InstanceStatus have different sizes {} vs {}",a.size(),b.size());
+            return false;
+        }
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compare(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<InstanceStatus>: elements different {} vs {}",a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compare(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<InstanceStatus>: could not find {} in {}",a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    // Method is private because TypeDef is abstract
+    // This method is delegated to by List comparator and comparators for concrete classes:
+    //  ClassificationDef
+    //  EntityDef
+    //  RelationshipDef
+    private boolean compare(TypeDef a,TypeDef b) {
+        return compare(true, a, b);
+    }
+    private boolean compare(boolean strict, TypeDef a,TypeDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDef: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDef: the {} parameter is null {}", a==null?"first":"second");
+            return false;
+        }
+        // assumed non-strict because order of superTypes does not matter
+        if (!(compare(a.getSuperType(),b.getSuperType()))) {
+            LOG.debug("Compare TypeDef: SuperTypes did not match {} vs {}", a.getSuperType(),b.getSuperType());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Compare TypeDef: Description did not match {} vs {}", a.getDescription(),b.getDescription());
+            return false;
+        }
+        if (!(compare(a.getDescriptionGUID(),b.getDescriptionGUID()))) {
+            LOG.debug("Compare TypeDef: descriptionGUID did not match {} vs {}", a.getDescriptionGUID(), b.getDescriptionGUID());
+            return false;
+        }
+        if (!(compare(a.getOrigin(),b.getOrigin()))) {
+            LOG.debug("Compare TypeDef: Origin did not match {} vs {}", a.getOrigin(),b.getOrigin());
+            return false;
+        }
+        if (!(compare(a.getCreatedBy(),b.getCreatedBy()))) {
+            LOG.debug("Compare TypeDef: CreatedBy did not match {} vs {}", a.getCreatedBy(),b.getCreatedBy());
+            return false;
+        }
+        if (!(compare(a.getUpdatedBy(),b.getUpdatedBy()))) {
+            LOG.debug("Compare TypeDef: UpdatedBy did not match {} vs {}", a.getUpdatedBy(),b.getUpdatedBy());
+            return false;
+        }
+        if (!(compare(a.getCreateTime(),b.getCreateTime()))) {
+            LOG.debug("Compare TypeDef: CreateTime did not match {} vs {}", a.getCreateTime(),b.getCreateTime());
+            return false;
+        }
+        if (!(compare(a.getUpdateTime(),b.getUpdateTime()))) {
+            LOG.debug("Compare TypeDef: UpdateTime did not match {} vs {}", a.getUpdateTime(),b.getUpdateTime());
+            return false;
+        }
+        if (!(compare(a.getOptions(),b.getOptions()))) {
+            LOG.debug("Compare TypeDef: Options did not match {} vs {}", a.getOptions(),b.getOptions());
+            return false;
+        }
+        if (!(compareListExternalStandardMapping(ARRAY_ORDER_SIGNIFICANT,a.getExternalStandardMappings(),b.getExternalStandardMappings()))) {
+            LOG.debug("Compare TypeDef: ExternalStandardMappings did not match {} vs {}", a.getExternalStandardMappings(),b.getExternalStandardMappings());
+            return false;
+        }
+        if (!(compareListInstanceStatus(ARRAY_ORDER_SIGNIFICANT,a.getValidInstanceStatusList(),b.getValidInstanceStatusList()))) {
+            LOG.debug("Compare TypeDef: ValidInstanceStatusList did not match {} vs {}", a.getValidInstanceStatusList(),b.getValidInstanceStatusList());
+            return false;
+        }
+        if (!(compare(a.getInitialStatus(),b.getInitialStatus()))) {
+            LOG.debug("Compare TypeDef: InitialStatus did not match {} vs {}", a.getInitialStatus(),b.getInitialStatus());
+            return false;
+        }
+        if (!(compareListTypeDefAttribute(ARRAY_ORDER_SIGNIFICANT,a.getPropertiesDefinition(),b.getPropertiesDefinition()))) {
+            LOG.debug("Compare TypeDef: PropertiesDefinition did not match {} vs {}", a.getPropertiesDefinition(),b.getPropertiesDefinition());
+            return false;
+        }
+        // Delegate upwards
+        if (!(compare((TypeDefSummary)a,(TypeDefSummary)b))) {
+            LOG.debug("Compare TypeDef: TypeDefSummary did not match");
+            return false;
+        }
+        return true;
+    }
+
+
+    // This method enables us to compare arrays of heterogeneous def types - e.g. a mixture of ClassificationDef, EntityDef, etc..
+    public boolean compareListTypeDef(boolean strict, List<TypeDef> a, List<TypeDef> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<TypeDef>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<TypeDef>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<TypeDef>: arrays have different sizes {} vs {}", a.size(), b.size());
+            return false;
+        }
+        // Compare the arrays - for each element do not call TypeDef compare directly because TypeDef is abstract - instead call the concrete class comparator
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compareConcreteTypeDefs(strict,  a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<TypeDef>: elements different {} vs {}", a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) {
+                    if (compareConcreteTypeDefs(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<TypeDef>: could not find {} in {}", a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    // This method enables us to compare arrays of attribute type defs
+    public boolean compareListAttributeTypeDef(boolean strict, List<AttributeTypeDef> a, List<AttributeTypeDef> b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare List<AttributeTypeDef>: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare List<AttributeTypeDef>: the {} array is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(a.size() == b.size())) {
+            LOG.debug("Compare List<AttributeTypeDef>: arrays have different sizes {} vs {}", a.size(), b.size());
+            return false;
+        }
+        // Compare the arrays - for each element do not call AttributeTypeDef compare directly because AttributeTypeDef is abstract -
+        // instead call the concrete class comparator - e.g. compare PrimitiveDef, CollectionDef, EnumDef etc.
+        if (strict) {
+            for (int i=0; i<a.size();i++) {
+                if (!(compareConcreteAttributeTypeDefs(strict, a.get(i),b.get(i)))) {
+                    LOG.debug("Compare List<AttributeTypeDef>: elements different {} vs {}", a.get(i),b.get(i));
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (!strict) {
+            for (int i = 0; i < a.size(); i++) {
+                boolean found = false;
+                for (int j = 0; j < b.size(); j++) { ;
+                    if (compareConcreteAttributeTypeDefs(strict, a.get(i), b.get(j))) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    LOG.debug("Compare List<AttributeTypeDef>: could not find {} in {}", a.get(i),b);
+                    return false;
+                }
+            }
+            return true;
+        }
+        return true;
+    }
+
+    // strict is only used to disable debugging in the case where we are performing non-strict compares
+    private boolean compareConcreteAttributeTypeDefs(boolean strict, AttributeTypeDef a, AttributeTypeDef b) {
+        // Check they are the same class
+        String aClass = a.getClass().getSimpleName();
+        String bClass = b.getClass().getSimpleName();
+        if (!(aClass.equals(bClass))) {
+            LOG.debug("ConcreteAttributeTypeDef classes different {} vs {}", aClass, bClass);
+            return false;
+        }
+        // Compare the concrete class objects
+        switch (aClass) {
+            case "PrimitiveDef":
+                if (!(compare(strict, (PrimitiveDef) a, (PrimitiveDef) b))) {
+                    LOG.debug("Compare PrimitiveDef: returned false");
+                    return false;
+                }
+                break;
+            case "CollectionDef":
+                if (!(compare(strict, (CollectionDef)a,(CollectionDef)b))) {
+                    LOG.debug("Compare CollectionDef: returned false");
+                    return false;
+                }
+                break;
+            case "EnumDef":
+                if (!(compare(strict, (EnumDef)a,(EnumDef)b))) {
+                    LOG.debug("Compare EnumDef: returned false");
+                    return false;
+                }
+                break;
+        }
+        return true;
+    }
+
+
+    // strict is only used to disable debug logging where we are performing non-strict compares
+    private boolean compareConcreteTypeDefs(boolean strict, TypeDef a, TypeDef b) {
+        // Check they are the same class
+        String aClass = a.getClass().getSimpleName();
+        String bClass = b.getClass().getSimpleName();
+        if (!(aClass.equals(bClass))) {
+            LOG.debug("TypeDef classes different {} vs {}", aClass, bClass);
+            return false;
+        }
+        // Compare the concrete class objects
+        switch (aClass) {
+            case "ClassificationDef":
+                if (!(compare(strict, (ClassificationDef) a, (ClassificationDef) b))) {
+                    LOG.debug("Compare ClassificationDef: returned false");
+                    return false;
+                }
+                break;
+            case "EntityDef":
+                if (!(compare(strict, (EntityDef)a,(EntityDef)b))) {
+                    LOG.debug("Compare EntityDef: returned false");
+                    return false;
+                }
+                break;
+            case "RelationshipDef":
+                if (!(compare(strict, (RelationshipDef)a,(RelationshipDef)b))) {
+                    LOG.debug("Compare RelationshipDef: returned false");
+                    return false;
+                }
+                break;
+        }
+        return true;
+    }
+
+    public boolean compare(ClassificationDef a, ClassificationDef b) {
+            return compare(true, a, b);
+    }
+    public boolean compare(boolean strict, ClassificationDef a, ClassificationDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare ClassificationDef: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare ClassificationDef: the {} ClassificationDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compareListTypeDefLink(ARRAY_ORDER_SIGNIFICANCE_VALID_ENTITY_DEFS,a.getValidEntityDefs(),b.getValidEntityDefs()))) {
+            LOG.debug("Compare ClassificationDef: validEntityDefs did not match {} vs {}", a.getValidEntityDefs(),b.getValidEntityDefs());
+            return false;
+        }
+        if (!(compare(a.isPropagatable(),b.isPropagatable()))) {
+            LOG.debug("Compare ClassificationDef: isPropagatable did not match {} vs {}", a.isPropagatable(),b.isPropagatable());
+            return false;
+        }
+        // Delegate upwards
+        if (!(compare(strict, (TypeDef)a,(TypeDef)b))) {
+            LOG.debug("Compare ClassificationDef: TypeDef did not match");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean compare(EntityDef a, EntityDef b) {
+        return compare(true, a, b);
+    }
+    public boolean compare(boolean strict, EntityDef a, EntityDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare EntityDef: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare EntityDef: the {} EntityDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        // Delegate upwards
+        if (!(compare(strict, (TypeDef)a,(TypeDef)b))) {
+            LOG.debug("Compare EntityDef: TypeDef did not match");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean compare(RelationshipDef a, RelationshipDef b) {
+        return compare(true, a, b);
+    }
+    public boolean compare(boolean strict, RelationshipDef a, RelationshipDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare RelationshipDef: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare RelationshipDef: the {} RelationshipDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        // The following code is preserved in case relationship category and containership are re-introduced.
+        // if (!(compare(a.getRelationshipCategory(),b.getRelationshipCategory()))) {
+        //    LOG.debug("RelationshipDef: RelationshipCategory did not match {} vs {}", a.getRelationshipCategory(),b.getRelationshipCategory());
+        //    return false;
+        //}
+        // if (!(compare(a.getRelationshipContainerEnd(),b.getRelationshipContainerEnd()))) {
+        //    LOG.debug("RelationshipDef: RelationshipContainerEnd did not match {} vs {}", a.getRelationshipContainerEnd(),b.getRelationshipContainerEnd());
+        //    return false;
+        //}
+        if (!(compare(a.getPropagationRule(),b.getPropagationRule()))) {
+            LOG.debug("Compare RelationshipDef: ClassificationPropagationRule did not match {} vs {}", a.getPropagationRule(),b.getPropagationRule());
+            return false;
+        }
+        if (!(compare(a.getEndDef1(),b.getEndDef1()))) {
+            LOG.debug("Compare RelationshipDef: RelationshipEndDef endDef1 did not match {} vs {}", a.getEndDef1(),b.getEndDef1());
+            return false;
+        }
+        if (!(compare(a.getEndDef2(),b.getEndDef2()))) {
+            LOG.debug("Compare RelationshipDef: RelationshipEndDef endDef2 did not match {} vs {}", a.getEndDef2(),b.getEndDef2());
+            return false;
+        }
+        // Delegate upwards
+        if (!(compare(strict, (TypeDef)a,(TypeDef)b))) {
+            LOG.debug("Compare RelationshipDef: TypeDef did not match");
+            return false;
+        }
+        return true;
+    }
+
+//    public boolean compare(RelationshipCategory a, RelationshipCategory b) {
+//        if (a == null && b == null) {
+//            LOG.debug("Compare RelationshipCategory: both are null");
+//            return true;
+//        }
+//        if (a == null ^ b == null) {
+//            LOG.debug("Compare RelationshipCategory: the {} RelationshipCategory is null {}", a==null?"first":"second");
+//            return false;
+//        }
+//        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+//            LOG.debug("Compare RelationshipCategory: Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+//            return false;
+//        }
+//        if (!(compare(a.getName(),b.getName()))) {
+//            LOG.debug("Compare RelationshipCategory: Name did not match {} vs {}", a.getName(), b.getName());
+//            return false;
+//        }
+//        if (!(compare(a.getDescription(),b.getDescription()))) {
+//            LOG.debug("Compare RelationshipCategory: Description did not match {} vs {}", a.getDescription(), b.getDescription());
+//            return false;
+//        }
+//        return true;
+//    }
+
+
+
+//    public boolean compare(RelationshipContainerEnd a, RelationshipContainerEnd b) {
+//        if (a == null && b == null) {
+//            LOG.debug("Compare RelationshipContainerEnd: both are null");
+//            return true;
+//       }
+//        if (a == null ^ b == null) {
+//            LOG.debug("Compare RelationshipContainerEnd: the {} RelationshipContainerEnd is null {}", a==null?"first":"second");
+//            return false;
+//        }
+//        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+//            LOG.debug("Compare RelationshipContainerEnd: Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+//            return false;
+//        }
+//        if (!(compare(a.getName(),b.getName()))) {
+//            LOG.debug("Compare RelationshipContainerEnd: Name did not match {} vs {}", a.getName(), b.getName());
+//            return false;
+//        }
+//        if (!(compare(a.getDescription(),b.getDescription()))) {
+//            LOG.debug("Compare RelationshipContainerEnd: Description did not match {} vs {}", a.getDescription(), b.getDescription());
+//            return false;
+//        }
+//        return true;
+//    }
+
+
+    public boolean compare(ClassificationPropagationRule a, ClassificationPropagationRule b) {
+        if (a == null && b == null) {
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("ClassificationPropagationRule: the {} ClassificationPropagationRule is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getOrdinal(),b.getOrdinal()))) {
+            LOG.debug("Ordinal did not match {} vs {}", a.getOrdinal(), b.getOrdinal());
+            return false;
+        }
+        if (!(compare(a.getName(),b.getName()))) {
+            LOG.debug("Name did not match {} vs {}", a.getName(), b.getName());
+            return false;
+        }
+        if (!(compare(a.getDescription(),b.getDescription()))) {
+            LOG.debug("Description did not match {} vs {}", a.getDescription(), b.getDescription());
+            return false;
+        }
+        return true;
+    }
+
+    public boolean compare(RelationshipEndDef a, RelationshipEndDef b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare RelationshipEndDef: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare RelationshipEndDef: the {} RelationshipEndDef is null {}", a==null?"first":"second");
+            return false;
+        }
+        if (!(compare(a.getEntityType(),b.getEntityType()))) {
+            LOG.debug("Compare RelationshipEndDef: EntityType did not match {} vs {}", a.getEntityType(), b.getEntityType());
+            return false;
+        }
+        if (!(compare(a.getAttributeName(),b.getAttributeName()))) {
+            LOG.debug("Compare RelationshipEndDef: AttributeName did not match {} vs {}", a.getAttributeName(), b.getAttributeName());
+            return false;
+        }
+        if (!(compare(a.getAttributeDescription(),b.getAttributeDescription()))) {
+            LOG.debug("Compare RelationshipEndDef: AttributeDescription did not match {} vs {}", a.getAttributeDescription(), b.getAttributeDescription());
+            return false;
+        }
+        if (!(compare(a.getAttributeCardinality(),b.getAttributeCardinality()))) {
+            LOG.debug("Compare RelationshipEndDef: AttributeCardinality did not match {} vs {}", a.getAttributeCardinality(), b.getAttributeCardinality());
+            return false;
+        }
+        return true;
+    }
+
+    // Compare TypeDefGallery objects
+    // This method enables us to compare arrays of heterogeneous def types - e.g. a mixture of ClassificationDef, EntityDef, etc..
+    public boolean compare(boolean strict, TypeDefGallery a, TypeDefGallery b) {
+        if (a == null && b == null) {
+            LOG.debug("Compare TypeDefGallery: both are null");
+            return true;
+        }
+        if (a == null ^ b == null) {
+            LOG.debug("Compare TypeDefGallery: the {} gallery is null {}", a==null?"first":"second");
+            return false;
+        }
+        // Compare the galleries
+        LOG.debug("Compare TypeDefGallery: compare lists of TypeDef");
+        if (!(compareListTypeDef(strict, a.getTypeDefs(), b.getTypeDefs())))
+            return false;
+        LOG.debug("Compare TypeDefGallery: compare lists of AttributeTypeDef");
+        if (!(compareListAttributeTypeDef(strict, a.getAttributeTypeDefs(), b.getAttributeTypeDefs())))
+            return false;
+        return true;
+    }
+
+
+
+    /**
+     * This method performs an 'equivalence' check on a pair of TypeDef objects. They can be considered
+     * equivalent if the following fields match:
+     *   category
+     *   name
+     *   guid
+     *   supertypes,
+     *   properties,
+     *   classifications,
+     *   valid status list,
+     *   relationship end defs
+     *   cardinality,
+     *   relationship category - e.g. association vs composition
+     *   version??
+     *   versionName??
+     *
+     * All other fields can differ. Specifically, this method does not care about the following:
+     *   createdBy
+     *   updatedBy
+     *   createdTime
+     *   updatedTime
+     *   externalStandardsMappings
+     *   origin
+     *   description and descriptionGUID
+     *   initialStatus
+     *
+     * This type of check is needed during verifyTypeDef().
+     *
+     * @param def1 - the first TypeDef in the equivalence check
+     * @param def2 - the second TypeDef in the equivalence check
+     * @return - whether or not the objects are equivalent
+     */
+    public boolean equivalent(TypeDef def1, TypeDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent TypeDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent TypeDef: the {} Typedef is null {}", def1==null?"first":"second");
+            return false;
+        }
+
+        // Delegate up to Compare for TypeDefSummary (everything at that level and above must match).
+        if ( !compare( (TypeDefSummary)def1,(TypeDefSummary)def2 ) ) {
+            LOG.debug("Equivalent TypeDef: TypeDefSummary different {} vs {}", def1, def2);
+            return false;
+        }
+
+        // Compare just the necessary subset of fields of TypeDef
+        if ( !compare(def1.getOptions(),def2.getOptions()) ) {
+            LOG.debug("Equivalent TypeDef: Options different {} vs {}", def1.getOptions(),def2.getOptions());
+            return false;
+        }
+        if ( !compareListInstanceStatus(false, def1.getValidInstanceStatusList(),def2.getValidInstanceStatusList()) ) {
+            LOG.debug("Equivalent TypeDef: ValidInstanceStatusList different {} vs {}", def1.getValidInstanceStatusList(),def2.getValidInstanceStatusList());
+            return false;
+        }
+        if ( !compareListTypeDefAttribute(false, def1.getPropertiesDefinition(),def2.getPropertiesDefinition()) ) {
+            LOG.debug("Equivalent TypeDef: PropertiesDefinition different {} vs {}", def1.getPropertiesDefinition(),def2.getPropertiesDefinition());
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(EntityDef def1, EntityDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent EntityDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent EntityDef: the {} EntityDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        /*
+         * Delegate up to TypeDef equivalence check
+         */
+        if (!equivalent((TypeDef) def1, (TypeDef) def2)) {
+            LOG.debug("Equivalent EntityDef: TypeDefs are not equivalent");
+            return false;
+        }
+        /*
+         * EntityDef adds no further significant fields
+         */
+        return true;
+    }
+
+    public boolean equivalent(ClassificationDef def1, ClassificationDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent ClassificationDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent ClassificationDef: the {} ClassificationDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        /*
+         * Delegate up to TypeDef equivalence check
+         */
+        if (!equivalent((TypeDef) def1, (TypeDef) def2)) {
+            LOG.debug("Equivalent ClassificationDef: TypeDefs are not equivalent");
+            return false;
+        }
+        /*
+         * ClassificationDef adds the following significant fields
+         *   validEntityDefs
+         *   propagatable
+         */
+        if ( !compareListTypeDefLink(false, def1.getValidEntityDefs(),def2.getValidEntityDefs()) ) {
+            LOG.debug("Equivalent ClassificationDef: Compare of getValidEntityDefs failed");
+            return false;
+        }
+        if ( !compare(def1.isPropagatable(),def2.isPropagatable()) ) {
+            LOG.debug("Equivalent ClassificationDef: Compare of isPropagatable failed");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(RelationshipDef def1, RelationshipDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent RelationshipDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent RelationshipDef: the {} RelationshipDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        /*
+         * Delegate up to TypeDef equivalence check
+         */
+        if (!equivalent((TypeDef) def1, (TypeDef) def2)) {
+            LOG.debug("Equivalent RelationshipDef: TypeDefs are not equivalent");
+            return false;
+        }
+        /*
+         * RelationshipDef adds the following significant fields
+         *   relationshipCategory
+         *   relationshipContainerEnd
+         *   propagationRule
+         *   endDef1
+         *   endDef2
+         */
+        // The following code is preserved in case relationship category and containership are re-introduced.
+        // if ( !compare(def1.getRelationshipCategory(),def2.getRelationshipCategory()) )
+        //    return false;
+        // if ( !compare(def1.getRelationshipContainerEnd(),def2.getRelationshipContainerEnd()) )
+        //    return false;
+        if ( !compare(def1.getPropagationRule(),def2.getPropagationRule()) ) {
+            LOG.debug("Equivalent RelationshipDef: compare getPropagationRule failed");
+            return false;
+        }
+        // We don't need the ends to match exactly - descriptions and descriptionGUIDs can differ....
+        if ( !equivalent(def1.getEndDef1(),def2.getEndDef1()) ) {
+            LOG.debug("Equivalent RelationshipDef: equivalent getEndDef1 failed");
+            return false;
+        }
+        if ( !equivalent(def1.getEndDef2(),def2.getEndDef2()) ) {
+            LOG.debug("Equivalent RelationshipDef: equivalent getEndDef2 failed");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(RelationshipEndDef def1, RelationshipEndDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent RelationshipEndDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent RelationshipEndDef: the {} RelationshipEndDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        /*
+         * RelationshipEndDef adds the following significant fields
+         *   entityType
+         *   attributeName
+         *   attributeCardinality
+         */
+        if ( !compare(def1.getEntityType(), def2.getEntityType())) {
+            LOG.debug("Equivalent RelationshipEndDef: compare getEntityType failed");
+            return false;
+        }
+        if ( !compare(def1.getAttributeName(), def2.getAttributeName())) {
+            LOG.debug("Equivalent RelationshipEndDef: compare getAttributeName failed");
+            return false;
+        }
+        if ( !compare(def1.getAttributeCardinality(), def2.getAttributeCardinality())) {
+            LOG.debug("Equivalent RelationshipEndDef: compare getAttributeCardinality failed");
+            return false;
+        }
+        return true;
+    }
+
+
+
+    /**
+     * This method performs an 'equivalence' check on a pair of AttributeTypeDef objects. They can be considered
+     * equivalent if the following fields match:
+     *   category
+     *   name
+     *   guid
+     *
+     * All other fields can differ. Specifically, this method does not care about the following:
+     *   description and descriptionGUID
+     *
+     * This type of check is needed during verifyAttributeTypeDef().
+     *
+     * @param def1 - the first TypeDef in the equivalence check
+     * @param def2 - the second TypeDef in the equivalence check
+     * @return - whether or not the objects are equivalent
+     */
+    public boolean equivalent(AttributeTypeDef def1, AttributeTypeDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent AttributeTypeDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent AttributeTypeDef: the {} AttributeTypeDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        // Compare just the necessary subset of fields of AttributeTypeDef
+        if (!compare(def1.getCategory(), def2.getCategory())) {
+            LOG.debug("Equivalent AttributeTypeDef: compare category failed");
+            return false;
+        }
+        if (!compare(def1.getGUID(), def2.getGUID())) {
+            LOG.debug("Equivalent AttributeTypeDef: compare GUID failed");
+            return false;
+        }
+        if (!compare(def1.getName(), def2.getName())) {
+            LOG.debug("Equivalent AttributeTypeDef: compare name failed");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(PrimitiveDef def1, PrimitiveDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent PrimitiveDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent PrimitiveDef: the {} PrimitiveDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+        /*
+         * Delegate up to AttributeTypeDef equivalence check
+         */
+        if ( !equivalent( (AttributeTypeDef)def1, (AttributeTypeDef)def2) ) {
+            LOG.debug("Equivalent PrimitiveDef: equivalent AttributeTypeDef failed");
+            return false;
+        }
+        /*
+         * PrimitiveDef adds the following fields...
+         */
+        if ( !compare(def1.getPrimitiveDefCategory(),def2.getPrimitiveDefCategory()) ) {
+            LOG.debug("Equivalent PrimitiveDef: compare getPrimitiveDefCategory failed");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(CollectionDef def1, CollectionDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent CollectionDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent CollectionDef: the {} CollectionDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+         /*
+         * Delegate up to AttributeTypeDef equivalence check
+         */
+        if ( !equivalent( (AttributeTypeDef)def1, (AttributeTypeDef)def2) ) {
+            LOG.debug("Equivalent CollectionDef: equivalent AttributeTypeDef failed");
+            return false;
+        }
+        /*
+         * CollectionDef adds the following fields...
+         *   collectionDefCategory
+         *   argumentCount
+         *   argumentTypes
+         */
+        if ( !compare(def1.getCollectionDefCategory(),def2.getCollectionDefCategory()) ) {
+            LOG.debug("Equivalent CollectionDef: compare getCollectionDefCategory failed");
+            return false;
+        }
+        if ( !compare(def1.getArgumentCount(),def2.getArgumentCount()) ) {
+            LOG.debug("Equivalent CollectionDef: compare getArgumentCount failed");
+            return false;
+        }
+        if ( !compareListPrimitiveDefCategory(true, def1.getArgumentTypes(),def2.getArgumentTypes()) ) {
+            LOG.debug("Equivalent CollectionDef: compare ListPrimitiveDefCategory failed");
+            return false;
+        }
+        return true;
+    }
+
+    public boolean equivalent(EnumDef def1, EnumDef def2) {
+        if (def1 == null && def2 == null) {
+            LOG.debug("Equivalent EnumDef: both are null");
+            return true;
+        }
+        if (def1 == null ^ def2 == null) {
+            LOG.debug("Equivalent EnumDef: the {} EnumDef is null {}", def1==null?"first":"second");
+            return false;
+        }
+         /*
+         * Delegate up to AttributeTypeDef equivalence check
+         */
+        if ( !equivalent( (AttributeTypeDef)def1, (AttributeTypeDef)def2) ) {
+            LOG.debug("Equivalent EnumDef: equivalent AttributeTypeDef failed");
+            return false;
+        }
+        /*
+         * EnumDef adds the following fields...
+         *   elementDefs
+         *   defaultValue
+         */
+        // possibly too strict...may want to allow enum elements to appear in any order....
+        if ( !compareListEnumElementDef(true, def1.getElementDefs(),def2.getElementDefs()) ) {
+            LOG.debug("Equivalent EnumDef: compare ListEnumElementDef failed");
+            return false;
+        }
+        if ( !compare(def1.getDefaultValue(),def2.getDefaultValue()) ) {
+            LOG.debug("Equivalent EnumDef: compare getDefaultValue failed");
+            return false;
+        }
+        return true;
+    }
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/DSLQueryHelper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/DSLQueryHelper.java
new file mode 100644
index 000000000..ece53f3d5
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/DSLQueryHelper.java
@@ -0,0 +1,258 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.PropertyErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.MatchCriteria;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstanceProperties;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstancePropertyCategory;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.InstancePropertyValue;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.PrimitivePropertyValue;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.PrimitiveDefCategory;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Iterator;
+import java.util.List;
+
+
+public class DSLQueryHelper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(DSLQueryHelper.class);
+
+    public DSLQueryHelper() {
+
+    }
+
+    public String createWhereClause(String typeName, InstanceProperties matchProperties, MatchCriteria matchCriteria, List<String> limitResultsByClassification)
+            throws
+            PropertyErrorException,
+            RepositoryErrorException
+    {
+
+        // Work out whether there are any criteria (match properties or classifications) that require
+        // a WHERE clause. If so we need to begin and end the WHERE clause and populate it
+
+        StringBuilder whereClauseBuilder = null;
+        String whereClause = null;
+
+        try {
+            String propertyClause = createPropertyClause(matchProperties, matchCriteria);
+            String classificationClause = createClassificationClause(limitResultsByClassification, typeName);
+
+            if (propertyClause != null || classificationClause != null) {
+                // There is at least some reason to include a WHERE clause
+                whereClauseBuilder = new StringBuilder();
+                whereClauseBuilder.append(" WHERE ( ");
+
+                // If there is a propertyClause only - simply include it.
+                // If there is a classificationClause only - simply include it
+                // If there are both then surround each with parentheses and combine with AND operator
+                String combinator = null;
+                if (propertyClause != null && classificationClause != null) {
+                    combinator = "AND";
+                    StringBuilder nestedPropertyClauseBuilder = new StringBuilder();
+                    nestedPropertyClauseBuilder.append("(");
+                    nestedPropertyClauseBuilder.append(propertyClause);
+                    nestedPropertyClauseBuilder.append(")");
+                    propertyClause = nestedPropertyClauseBuilder.toString();
+                    StringBuilder nestedClassificationClauseBuilder = new StringBuilder();
+                    nestedClassificationClauseBuilder.append("(");
+                    nestedClassificationClauseBuilder.append(classificationClause);
+                    nestedClassificationClauseBuilder.append(")");
+                    classificationClause = nestedClassificationClauseBuilder.toString();
+                }
+
+                if (propertyClause != null)
+                    whereClauseBuilder.append(propertyClause);
+
+                if (combinator != null)
+                    whereClauseBuilder.append(" " + combinator + " ");
+
+                if (classificationClause != null)
+                    whereClauseBuilder.append(classificationClause);
+
+                // Finalize...
+                whereClauseBuilder.append(" ) ");
+                // Harvest the resulting string
+                whereClause = whereClauseBuilder.toString();
+            }
+            LOG.debug("createWhereClause: where clause {}", whereClause);
+            return whereClause;
+        }
+        catch (PropertyErrorException e) {
+            LOG.error("createWhereClause: re-throwing exception from createPropertyClause {}", e);
+            throw e;
+        }
+    }
+
+    private String createPropertyClause(InstanceProperties matchProperties, MatchCriteria matchCriteria)
+            throws PropertyErrorException, RepositoryErrorException
+    {
+
+        // Where a property is of type String the match value should be used as a substring (fuzzy) match.
+        // For all other types of property the match value needs to be an exact match.
+
+        final String methodName = "createPropertyClause";
+
+        StringBuilder propertyClauseBuilder;
+        String propertyClause = null;
+
+        if (matchProperties != null) {
+            // Handle matchProperties (and matchCriteria)
+            String condition;
+            String operator;
+            boolean negate = false;
+            if (matchCriteria == null) {
+                // Adopt default value for matchCriteria of ALL
+                matchCriteria = MatchCriteria.ALL;
+            }
+            switch (matchCriteria) {
+                case ALL:
+                    condition = "AND";
+                    operator = "=";
+                    break;
+                case ANY:
+                    condition = "OR";
+                    operator = "=";
+                    break;
+                case NONE:
+                    // Currently does not support NONE - would need to negate substring match patterns
+                    // This would be based on condition = "AND" and negate = true
+                    // It may be possible to support this if a not() step were introduced to Atlas gremlin.
+                    // Deliberately drop through to default case...
+                default:
+                    LOG.debug("createPropertyClause: only supports matchCriteria ALL, ANY");
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("matchCriteria", "matchCriteria", methodName, "LocalAtlasOMRSMetadataCollection");
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+            }
+
+            // Add each property in the matchProperties to the search expression in the form:
+            //   propName = propValue , combining entries with the op operator.
+            Iterator<String> matchNames = matchProperties.getPropertyNames();
+
+            if (matchNames.hasNext()) {
+
+                propertyClauseBuilder = new StringBuilder();
+
+                boolean first = true;
+
+                while (matchNames.hasNext()) {
+                    // Extract the name and value as strings for the query
+                    String mName = matchNames.next();
+                    boolean stringProp = false;
+                    String strValue = null;
+                    InstancePropertyValue matchValue = matchProperties.getPropertyValue(mName);
+                    InstancePropertyCategory cat = matchValue.getInstancePropertyCategory();
+                    switch (cat) {
+                        case PRIMITIVE:
+                            // matchValue is a PPV
+                            PrimitivePropertyValue ppv = (PrimitivePropertyValue) matchValue;
+                            // Find out if this is a string property
+                            PrimitiveDefCategory pdc = ppv.getPrimitiveDefCategory();
+                            if (pdc == PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING)
+                                stringProp = true;
+                            // We need a string for DSL query - this does not reflect the property type
+                            strValue = ppv.getPrimitiveValue().toString();
+                            break;
+                        case ARRAY:
+                        case MAP:
+                        case ENUM:
+                        case STRUCT:
+                        case UNKNOWN:
+                        default:
+                            LOG.error("createPropertyClause: match property of cat {} not supported", cat);
+
+                            OMRSErrorCode errorCode = OMRSErrorCode.BAD_PROPERTY_FOR_INSTANCE;
+
+                            String errorMessage = errorCode.getErrorMessageId()
+                                    + errorCode.getFormattedErrorMessage(mName, "matchProperties", methodName, "LocalAtlasOMRSMetadataCollection");
+
+                            throw new PropertyErrorException(errorCode.getHTTPErrorCode(),
+                                    this.getClass().getName(),
+                                    methodName,
+                                    errorMessage,
+                                    errorCode.getSystemAction(),
+                                    errorCode.getUserAction());
+                    }
+
+                    // Insert each property and check if we need an op
+                    if (first) {
+                        first = false;
+                    } else {
+                        propertyClauseBuilder.append(" " + condition + " ");
+                    }
+
+                    // Override the operator (locally, only for this property) if it is a string
+                    String localOperator = stringProp ? " LIKE " : operator;
+                    // Surround the search string with single quotes and asterisks for regex
+                    String updatedStrValue = stringProp ? "'*"+strValue+"*'" : strValue;
+                    if (!negate)
+                        propertyClauseBuilder.append(" " + mName + localOperator + updatedStrValue );
+                    else // negating for NONE
+                        propertyClauseBuilder.append(" " + mName + localOperator + updatedStrValue );
+                }
+
+                // Finalize...
+                propertyClause = propertyClauseBuilder.toString();
+            }
+        }
+        LOG.debug("createPropertyClause: property clause {}", propertyClause);
+        return propertyClause;
+    }
+
+    private String createClassificationClause(List<String> limitResultsByClassification, String typeName)
+    {
+        StringBuilder classificationClauseBuilder = null;
+        String classificationClause = null;
+
+        if (limitResultsByClassification != null) {
+            classificationClauseBuilder = new StringBuilder();
+            boolean first = true;
+            for (String classificationName : limitResultsByClassification ) {
+                if (first) {
+                    first = false;
+                } else {
+                    classificationClauseBuilder.append(" OR ");
+                }
+                classificationClauseBuilder.append( typeName + " ISA " + "'"+classificationName+"'" );
+            }
+
+            // Finalize...
+            classificationClause = classificationClauseBuilder.toString();
+        }
+
+        LOG.debug("createClassificationClause: classification clause {}", classificationClause);
+        return classificationClause;
+    }
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/EntityDefMapper.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/EntityDefMapper.java
new file mode 100644
index 000000000..c0f2a9e50
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/EntityDefMapper.java
@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.EntityDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDef;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefAttribute;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefLink;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class EntityDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(EntityDefMapper.class);
+
+    private LocalAtlasOMRSMetadataCollection metadataCollection = null;
+    private String userId                                       = null;
+    private EntityDef entityDef                                 = null;
+
+
+    public EntityDefMapper(LocalAtlasOMRSMetadataCollection metadataCollection, String userId, EntityDef entityDef) {
+        this.metadataCollection = metadataCollection;
+        this.userId = userId;
+        this.entityDef = entityDef;
+    }
+
+
+    public ArrayList<String> getValidPropertyNames() {
+        // Convenience method to iterate over superType hierarchy and collate properties
+       return getValidPropertyNames(entityDef);
+    }
+
+    private ArrayList<String> getValidPropertyNames(TypeDef typeDef) {
+
+        ArrayList<String> validPropNames = null;
+        List<TypeDefAttribute> typeDefAttributes = typeDef.getPropertiesDefinition();
+        if (typeDefAttributes != null) {
+            validPropNames = new ArrayList<>();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                String attrName = typeDefAttribute.getAttributeName();
+                validPropNames.add(attrName);
+            }
+        }
+
+        // Visit the next type in the supertype hierarchy, if any
+        TypeDefLink superTypeDefLink = typeDef.getSuperType();
+        if (superTypeDefLink != null) {
+            // Retrieve the supertype - the TDL gives us its GUID and name
+            if (superTypeDefLink.getName() != null) {
+                TypeDef superTypeDef = null;
+                try {
+                    superTypeDef = metadataCollection._getTypeDefByName(userId, superTypeDefLink.getName());
+                } catch (Exception e) {
+                    LOG.error("getValidPropertyNames: could not get supertype {} using getTypeDefByName {}", superTypeDefLink.getName(), e);
+                    return null;
+                }
+                if (superTypeDef != null) {
+                    ArrayList<String> additionalPropNames = getValidPropertyNames(superTypeDef);
+
+                    if (additionalPropNames != null) {
+                        // Add the additional properties to any we already found at this level...
+                        if (validPropNames == null) {
+                            // We did not already find any properties (at the original instance level) so need
+                            // to allocate the InstanceProperties now.
+                            validPropNames = new ArrayList<>();
+                        }
+                        for (String propName : additionalPropNames) {
+                            validPropNames.add(propName);
+                        }
+                    }
+                }
+            }
+        }
+
+        return validPropNames;
+    }
+
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/FamousFive.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/FamousFive.java
new file mode 100644
index 000000000..9239df86b
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/FamousFive.java
@@ -0,0 +1,240 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ * This class provides the mapping between a number of high level types in OM and Atlas that
+ * have the same name but different GUIDs and slightly different properties. These types are
+ * all entity types and are all generally high up in any inheritance hierarchy, so are used
+ * in superType chains. They will also be found in relationship end definitions and lists of
+ * valid entity types in classification defs.
+ *
+ * The types involved are coded into a list below, so that if necessary other types can be added.
+ * Initially the list only needs Referenceable, Asset, DataSet, Infrastructure and Process - these
+ * are referred to collectively as the "Famous Five". In most of these types, the OM type and Atlas
+ * type have identical properties, but there are a couple of notable differences - OM's Referenceable
+ * has 'additionalProperties' and Atlas's Process has 'inputs' and 'outputs'.
+ *
+ * The LocalAtlasOMRSConnector spans the OM and Atlas domains, so it needs to accommodate the
+ * differences between these types and convert between them appropriately. Whenever one of the OM
+ * types is referenced it must be substituted by a type that can be stored into Atlas without
+ * clashing (since the names are the same), and when one of the Atlas types is encountered it
+ * needs to be converted to the appropriate OM type. For example, an OM 'Referenceable' is
+ * converted and stored as 'OM_Referenceable' to avoid clashing with Atlas's 'Referenceable'.
+ * Furthermore, the OM_Referenceable depends upon and extends the Atlas type.
+ *
+ * The way this is to be achieved is to introduce five new types that are stored in the Atlas
+ * repository (during startup). When the connector stack is first started, the local connector
+ * will call the Atlas connector's verifyTypeDef() method for each of the types defined in the
+ * type archive. This set of around 350 types includes the types referred to as the Famous Five.
+ * The parameters to verifyTypeDef() include the TypeDef, containing the type name and the type
+ * GUID. In normal circumstances, when the connector is asked to verify a type, it tests whether
+ * the type name is known and the type definition matches the existing type. If so, the type is
+ * verified and the verifyTypeDef() methods returns true. If the type is not known the method
+ * returns false. If a type is not supportable or clashes with an Atlas type an exception is
+ * thrown.
+ *
+ * When the verifyTypeDef() method encounters any of the Famous Five types, it should return
+ * that they are supportable but not known. The Local Connector will immediately issue an addTypeDef()
+ * call to define the type. This provides the opportunity to define the additional type described
+ * above. The addTypeDef() method needs to recognise that the type is a member of the Famous Five,
+ * and create the modified type in Atlas, extending the original Atlas type.
+ *
+ * The Atlas Connector keeps track of the original OM GUID of the types that it has mapped in this way,
+ * so that they can be converted back.
+ *
+ * Using Referenceable as an example, the result of these type additions during startup should result
+ * in the following additional type being defined in Atlas:
+ *
+ * OM                          Connector                                         Atlas
+ *
+ * 'Referenceable'  ---------> addTypeDef (typeDef)
+ *                             typeDef.name = 'Referenceable'
+ *                             typeDef.GUID = <OM_GUID>
+ *                             recognise type name E F5
+ *                             create Atlas type
+ *                             type.name = 'OM_Referenceable'
+ *                             type.guid = <OM_GUID>
+ *                             type.supertype = (Atlas) Referenceable
+ *                             adds additionalProperties      ----------------> OM_Referenceable (OM_GUID)
+ *                                                                              extends Atlas Referenceable
+ *
+ * Whenever a request is made (from an OMRS application/caller/connector) that refers to one of the
+ * Famous Five types, the connector needs to switch the name to the OM-specific type name as stored
+ * in the repository. For example:
+ *
+ * OM                           Connector                                         Atlas
+ *
+ * Simple references
+ *
+ * reference to type
+ *  name = 'Referenceable'
+ *  GUID = '12345'     ------>  detect name E F5
+ *                              prepend name with 'OM_'
+ *                              name = 'OM_Referenceable'
+ *                              GUID = '12345'   --------------------------->  Look up type
+ *                                                                             name = 'OM_Referenceable'
+ *                                                                             GUID = '12345'
+ *                                               <---------------------------
+ *                              remove name prefix so name
+ *                              reverts to 'Referenceable'
+ *          <-------------------
+ *
+ *
+ *
+ * Supertype references
+ *
+ *  Type 'A' refers to
+ *  supertype with:
+ *  name = 'Referenceable'
+ *  GUID = '12345'     ------>  detect name E F5
+ *                              OM supertype remains as Referenceable
+ *                              For Atlas persistence/lookup, name is
+ *                              prefixed with 'OM_' so supertype changed
+ *                              to OM_Referenceable (which in Atlas extends
+ *                              from Atlas Referenceable so chain is
+ *                              complete.                               ---------->  Type 'A' supertype = OM_Referenceable
+ *                                                                                   OM_Referenceable supertype = Referenceable
+ *                              Atlas-side, update supertype
+ *                              reference to:
+ *                              name = 'OM_Referenceable'
+ *                              GUID = '12345'
+ *                              with supertype = null
+ *
+ *                              OM-side, although in Atlas OM_Referenceable
+ *                              extends Atlas Referenceable, this is not
+ *                              surfaced to OM
+ */
+
+ // package private
+ class FamousFive {
+
+    private static final Logger LOG = LoggerFactory.getLogger(FamousFive.class);
+
+    // In map keys are OM type names; values are corresponding Atlas type names
+
+    private static Map<String,String> nameSubstitution = new HashMap<>();
+
+    private static final String OM_PREFIX = "OM_";
+
+    static {
+        // Map of common name to extended name
+        nameSubstitution.put("Referenceable",  OM_PREFIX+"Referenceable");
+        nameSubstitution.put("Asset",          OM_PREFIX+"Asset");
+        nameSubstitution.put("DataSet",        OM_PREFIX+"DataSet");
+        nameSubstitution.put("Process",        OM_PREFIX+"Process");
+        nameSubstitution.put("Infrastructure", OM_PREFIX+"Infrastructure");
+    }
+
+    // Second map is to keep track of OM GUIDs associated with common names. These are needed for reverse mappings.
+    private static Map<String,String> omNameToGUID = new HashMap<>();
+
+    private FamousFive() {
+        // do nothing
+    }
+
+    // package private
+    static boolean omTypeRequiresSubstitution(String typeName) {
+        // Look in the map keys for the specified name
+        String val = nameSubstitution.get(typeName);
+        if (val != null) {
+            LOG.debug("omTypeRequiresSubstitution: OM type name {} requires substitution", typeName);
+            return true;
+        }
+        return false;
+    }
+
+
+    // package private
+    static boolean atlasTypeRequiresSubstitution(String typeName) {
+        // Look in the map values for the specified name
+        boolean found = false;
+        Collection<String> atlasTypeNames = nameSubstitution.values();
+        if (atlasTypeNames != null) {
+            for (String s : atlasTypeNames) {
+                if (typeName.equals(s)) {
+                    LOG.debug("atlasTypeRequiresSubstitution: Atlas type name {} requires substitution", typeName);
+                    found = true;
+                    break;
+                }
+            }
+        }
+        return found;
+    }
+
+    // package private
+    static String getAtlasTypeName(String omTypeName, String guid) {
+        String atlasTypeName = nameSubstitution.get(omTypeName);
+        if (atlasTypeName != null) {
+            LOG.debug("getAtlasTypeName: Atlas type name {} ", atlasTypeName);
+            if (guid != null) {
+                String recordedGUID = omNameToGUID.get(omTypeName);
+                if (recordedGUID == null) {
+                    // record the new guid
+                    LOG.debug("getAtlasTypeName: OM type name {} recorded GUID {} ", omTypeName, guid);
+                    omNameToGUID.put(omTypeName, guid);
+                } else if (!recordedGUID.equals(guid)) {
+                    // update the recorded GUID - log this
+                    LOG.debug("getAtlasTypeName: OM type name {} update recorded GUID {} ", omTypeName, guid);
+                    omNameToGUID.put(omTypeName, guid);
+                }
+            }
+        }
+        else {
+            LOG.error("getAtlasTypeName: Atlas type name was null");
+        }
+        return atlasTypeName;
+    }
+
+    // package private
+    static String getOMTypeName(String atlasTypeName) {
+        Set<String> omTypeNames = nameSubstitution.keySet();
+        if (omTypeNames != null) {
+            for (String s : omTypeNames) {
+                String atlasName = nameSubstitution.get(s);
+                if (atlasName.equals(atlasTypeName)) {
+                    LOG.debug("getOMTypeName: OM type name {} ", s);
+                    return s;
+                }
+            }
+        }
+        return null;
+    }
+
+    // package private
+    static String getRecordedGUID(String omTypeName) {
+        String recordedGUID = omNameToGUID.get(omTypeName);
+        if (recordedGUID == null)
+            LOG.error("getAtlasTypeName: OM type name {} has no recorded GUID", omTypeName);
+        return recordedGUID;
+    }
+
+
+
+
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/ISpringBridge.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/ISpringBridge.java
new file mode 100644
index 000000000..6a0ceae07
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/ISpringBridge.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.discovery.EntityDiscoveryService;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+import org.apache.atlas.repository.store.graph.AtlasRelationshipStore;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+
+
+/**
+ * This interface represents a list of Spring Beans (services) which need to be referenced from a non Spring class.
+ * This provides a means of bridging from the AtlasConnector the Atlas stores it depends upon.
+ */
+public interface ISpringBridge {
+
+    public AtlasTypeDefStore getTypeDefStore();
+
+    public AtlasTypeRegistry getTypeRegistry();
+
+    public AtlasEntityStore getEntityStore();
+
+    public AtlasRelationshipStore getRelationshipStore();
+
+    public EntityDiscoveryService getEntityDiscoveryService();
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSErrorCode.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSErrorCode.java
new file mode 100644
index 000000000..b0bfa65c4
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSErrorCode.java
@@ -0,0 +1,245 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.text.MessageFormat;
+import java.util.Arrays;
+
+
+/**
+ * The LocalAtlasOMRSErrorCode contains additional error codes specific to the AtlasConnector that are not in OMRSErrorCode.
+ *
+ * The 5 fields in the enum are:
+ * <ul>
+ *     <li>HTTP Error Code - for translating between REST and JAVA - Typically the numbers used are:</li>
+ *     <li><ul>
+ *         <li>500 - internal error</li>
+ *         <li>501 - not implemented </li>
+ *         <li>503 - Service not available</li>
+ *         <li>400 - invalid parameters</li>
+ *         <li>401 - unauthorized</li>
+ *         <li>404 - not found</li>
+ *         <li>405 - method not allowed</li>
+ *         <li>409 - data conflict errors - eg item already defined</li>
+ *     </ul></li>
+ *     <li>Error Message Id - to uniquely identify the message</li>
+ *     <li>Error Message Text - includes placeholder to allow additional values to be captured</li>
+ *     <li>SystemAction - describes the result of the error</li>
+ *     <li>UserAction - describes how a user should correct the error</li>
+ * </ul>
+ */
+
+public enum LocalAtlasOMRSErrorCode
+{
+    NULL_INSTANCE(400, "OMRS-ATLAS-REPOSITORY-400-001 ",
+            "The value specified for \"{0}\" is null",
+            "The system is unable to proceed because no instance has been provided.",
+            "Check the system logs and diagnose or report the problem."),
+    NULL_VERSION(400, "OMRS-ATLAS-REPOSITORY-400-002 ",
+            "The value specified for \"{0}\" is null",
+            "The system is unable to proceed because the value is invalid.",
+            "Check the system logs and diagnose or report the problem."),
+    NULL_PARAMETER(400, "OMRS-ATLAS-REPOSITORY-400-003 ",
+            "The value specified for \"{0}\" passed to method \"{1}\" is null",
+            "The system is unable to proceed because the value is invalid.",
+            "Check the system logs and diagnose or report the problem."),
+    INVALID_PARAMETER(400, "OMRS-ATLAS-REPOSITORY-400-004 ",
+            "The value specified for \"{0}\" passed to method \"{1}\" is invalid",
+            "The system is unable to proceed because the value is invalid.",
+            "Check the system logs and diagnose or report the problem."),
+    ATLAS_CONFIGURATION(400, "OMRS-ATLAS-REPOSITORY-400-005 ",
+            "Could not access the delete handler configuration for Atlas repository",
+            "The connector is unable to proceed",
+            "Check the system logs and diagnose or report the problem."),
+    ATLAS_CONFIGURATION_HARD(400, "OMRS-ATLAS-REPOSITORY-400-006 ",
+            "A soft delete cannot be performed for the instance with GUID \"{0}\" by method \"{1}\" on repository \"{2}\"",
+            "The repository is configured to perform hard (permanent) deletes",
+            "Check the repository configuration or use purge instead."),
+    ENTITY_NOT_DELETED(400, "OMRS-ATLAS-REPOSITORY-400-007 ",
+            "A purge of an entity resulted in an exception, entity GUID \"{0}\" by method \"{1}\" on repository \"{2}\"",
+            "The repository failed to purge an entity",
+            "Check the existence and state of the entity in the repository."),
+    RELATIONSHIP_NOT_DELETED(400, "OMRS-ATLAS-REPOSITORY-400-007 ",
+            "A purge of an relationship resulted in an exception, relationship GUID \"{0}\" by method \"{1}\" on repository \"{2}\"",
+            "The repository failed to purge an relationship",
+            "Check the existence and state of the relationship in the repository."),
+    ENTITY_IS_PROXY(400, "OMRS-ATLAS-REPOSITORY-400-008 ",
+            "The Atlas entity with GUID \"{0}\" is a proxy, as reported by method \"{1}\" on repository \"{2}\"",
+            "The Atlas entity cannot be projected as an EntityDetail",
+            "Check why the caller is expecting to find a complete entity."),
+    INVALID_PROPAGATION_RULE(400, "OMRS-ATLAS-REPOSITORY-400-009 ",
+            "The propagation rule \"{0}\" is not valid, as reported by method \"{1}\" on repository \"{2}\"",
+            "The propagation rule cannot be converted to an Atlas propagateTags value",
+            "Check the propagation rule supplied."),
+    INVALID_PROPERTY_CATEGORY(400, "OMRS-ATLAS-REPOSITORY-400-010 ",
+            "The property category \"{0}\" is not valid, as reported by method \"{1}\" on repository \"{2}\"",
+            "The property category is not supported by the Atlas connector",
+            "Check the property category supplied."),
+    INVALID_TYPEDEF_CATEGORY(400, "OMRS-ATLAS-REPOSITORY-400-011 ",
+            "The category \"{0}\" of typedef \"{1}\" is not valid, as reported by method \"{2}\" on repository \"{3}\"",
+            "The typedef category is not supported by the Atlas connector",
+            "Check the typedef category supplied."),
+    REPOSITORY_TYPEDEF_CREATE_FAILED(400, "OMRS-ATLAS-REPOSITORY-400-012 ",
+            "The typedef \"{0}\" could not be created, as reported by method \"{1}\" on repository \"{2}\"",
+            "The typedef could not be created by the Atlas repository",
+            "Check the typedef supplied and the state of the repository."),
+    INVALID_EVENT_FORMAT(400, "OMRS-ATLAS-REPOSITORY-400-013 ",
+            "Event \"{0}\" on topic \"{1}\" could not be parsed, by the Atlas event mapper",
+            "The system is unable to process the request.",
+            "Verify the format of events published to the topic."),
+    ATLAS_CONFIGURATION_BOOTSTRAP_SERVERS(400, "OMRS-ATLAS-REPOSITORY-400-013 ",
+            "Could not access the bootstrap server configuration for Atlas repository",
+            "The connector is unable to proceed",
+            "Check the system logs and diagnose or report the problem."),
+    METADATA_COLLECTION_NOT_FOUND(400, "OMRS-ATLAS-REPOSITORY-400-014 ",
+            "Could not access the metadata collection with id \"{0}\" for the Atlas repository",
+            "The connector is unable to proceed",
+            "Check the system logs and diagnose or report the problem."),
+    ENTITY_NOT_CREATED(400, "OMRS-ATLAS-REPOSITORY-400-015 ",
+            "Failed to store the entity \"{0}\" in method \"{1}\" into the Atlas repository \"{2}\"",
+            "The entity could not be stored in the repository",
+            "Check the system logs and diagnose or report the problem."),
+    PAGING_ERROR(400, "OMRS-ATLAS-REPOSITORY-400-016 ",
+            "Applying offset \"{0}\" and pageSize \"{1}\" to the result list failed in method \"{2}\" into the Atlas repository \"{3}\"",
+            "The entity result list could not be processed",
+            "Check the system logs and diagnose or report the problem."),
+    EVENT_MAPPER_NOT_INITIALIZED(400, "OMRS-ATLAS-REPOSITORY-400-017 ",
+            "There is no valid event mapper for repository \"{1}\"",
+            "The refresh request could not be processed",
+            "Check the system logs and diagnose or report the problem."),
+    REPOSITORY_ERROR(400, "OMRS-ATLAS-REPOSITORY-400-018 ",
+            "Caught an exception repository \"{1}\"",
+            "The requested operation failed",
+            "Examine the exception to diagnose or report the problem.")
+
+
+
+    ;
+
+    private int    httpErrorCode;
+    private String errorMessageId;
+    private String errorMessage;
+    private String systemAction;
+    private String userAction;
+
+    private static final Logger log = LoggerFactory.getLogger(LocalAtlasOMRSErrorCode.class);
+
+
+    /**
+     * The constructor for LocalAtlasOMRSErrorCode expects to be passed one of the enumeration rows defined in
+     * LocalAtlasOMRSErrorCode above.   For example:
+     *
+     *     LocalAtlasOMRSErrorCode   errorCode = LocalAtlasOMRSErrorCode.NULL_INSTANCE;
+     *
+     * This will expand out to the 5 parameters shown below.
+     *
+     * @param newHTTPErrorCode - error code to use over REST calls
+     * @param newErrorMessageId - unique Id for the message
+     * @param newErrorMessage - text for the message
+     * @param newSystemAction - description of the action taken by the system when the error condition happened
+     * @param newUserAction - instructions for resolving the error
+     */
+    LocalAtlasOMRSErrorCode(int  newHTTPErrorCode, String newErrorMessageId, String newErrorMessage, String newSystemAction, String newUserAction)
+    {
+        this.httpErrorCode  = newHTTPErrorCode;
+        this.errorMessageId = newErrorMessageId;
+        this.errorMessage   = newErrorMessage;
+        this.systemAction   = newSystemAction;
+        this.userAction     = newUserAction;
+    }
+
+
+    public int getHTTPErrorCode()
+    {
+        return httpErrorCode;
+    }
+
+
+    /**
+     * Returns the unique identifier for the error message.
+     *
+     * @return errorMessageId
+     */
+    public String getErrorMessageId()
+    {
+        return errorMessageId;
+    }
+
+
+    /**
+     * Returns the error message with placeholders for specific details.
+     *
+     * @return errorMessage (unformatted)
+     */
+    public String getUnformattedErrorMessage()
+    {
+        return errorMessage;
+    }
+
+
+    /**
+     * Returns the error message with the placeholders filled out with the supplied parameters.
+     *
+     * @param params - strings that plug into the placeholders in the errorMessage
+     * @return errorMessage (formatted with supplied parameters)
+     */
+    public String getFormattedErrorMessage(String... params)
+    {
+        if (log.isDebugEnabled())
+        {
+            log.debug(String.format("==> LocalAtlasOMRSErrorCode.getMessage(%s)", Arrays.toString(params)));
+        }
+
+        MessageFormat mf = new MessageFormat(errorMessage);
+        String result = mf.format(params);
+
+        if (log.isDebugEnabled())
+        {
+            log.debug(String.format("<== LocalAtlasOMRSErrorCode.getMessage(%s): %s", Arrays.toString(params), result));
+        }
+
+        return result;
+    }
+
+
+    /**
+     * Returns a description of the action taken by the system when the condition that caused this exception was
+     * detected.
+     *
+     * @return systemAction
+     */
+    public String getSystemAction()
+    {
+        return systemAction;
+    }
+
+
+    /**
+     * Returns instructions of how to resolve the issue reported in this exception.
+     *
+     * @return userAction
+     */
+    public String getUserAction()
+    {
+        return userAction;
+    }
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSMetadataCollection.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSMetadataCollection.java
new file mode 100644
index 000000000..96ecec811
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSMetadataCollection.java
@@ -0,0 +1,15290 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+
+import org.apache.atlas.AtlasConfiguration;
+import org.apache.atlas.AtlasErrorCode;
+import org.apache.atlas.discovery.EntityDiscoveryService;
+import org.apache.atlas.exception.AtlasBaseException;
+import org.apache.atlas.model.SearchFilter;
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.discovery.AtlasSearchResult;
+import org.apache.atlas.model.discovery.SearchParameters;
+import org.apache.atlas.model.instance.*;
+import org.apache.atlas.model.typedef.*;
+import org.apache.atlas.openmetadata.adapters.eventmapper.AtlasOMRSRepositoryEventMapper;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+import org.apache.atlas.repository.store.graph.AtlasRelationshipStore;
+import org.apache.atlas.repository.store.graph.v1.DeleteHandlerV1;
+import org.apache.atlas.repository.store.graph.v2.AtlasEntityStream;
+import org.apache.atlas.repository.store.graph.v2.AtlasEntityStreamForImport;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+import org.apache.atlas.type.AtlasTypeUtil;
+import org.apache.atlas.util.AtlasRepositoryConfiguration;
+
+import static org.apache.atlas.model.discovery.SearchParameters.Operator.EQ;
+import static org.apache.atlas.model.instance.AtlasRelationship.Status.ACTIVE;
+import static org.apache.atlas.model.instance.AtlasRelationship.Status.DELETED;
+import static org.apache.atlas.model.typedef.AtlasBaseTypeDef.*;
+import static org.apache.atlas.model.typedef.AtlasStructDef.AtlasAttributeDef.Cardinality.*;
+
+import org.eclipse.jetty.util.StringUtil;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.odpi.openmetadata.repositoryservices.ffdc.OMRSErrorCode;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryHelper;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryValidator;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.OMRSMetadataCollection;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.MatchCriteria;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.SequencingOrder;
+
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.AttributeTypeDefCategory.ENUM_DEF;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.TypeDefCategory.*;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.*;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+
+/**
+ *  The LocalAtlasOMRSMetadataCollection represents a local metadata repository.
+ *  Requests to this metadata collection are mapped to requests to the local repository.
+ *
+ *  The metadata collection reads typedefs from Atlas and will attempt to convert them to OM typedefs - and
+ *  vice versa. During these conversions it will check the validity of the content of the type defs as far as
+ *  possible, giving up on a typedef that it cannot verify or convert.
+ *
+ *  This implementation of the metadata collection does not use the java implementations of the REST APIs because
+ *  the REST interface is servlet and http oriented. This implementation uses lower level classes in Atlas.
+ *  The behaviour still respects transactions because they are implemented at levels below the REST implementation.
+ *  The transactions are implemented by annotation in the underlying implementations of the AtlasTypeDefStore
+ *  interface.
+ */
+
+
+public class LocalAtlasOMRSMetadataCollection extends OMRSMetadataCollection {
+
+    private static final Logger LOG = LoggerFactory.getLogger(LocalAtlasOMRSMetadataCollection.class);
+
+    /*
+     * The MetadataCollection makes use of a pair of TypeDefsByCategory objects.
+     *
+     * A TypeDefsByCategory is a more fully explicated rendering of the TypeDefGallery - it makes
+     * it easier to store and search for a type def of a particular category. The TDBC objects are only
+     * used internally - they do not form part of the API; being rendered as a TypeDefGallery just before
+     * return from getTypeDefs. The MDC uses two TDBC objects - one is transient and the other is longer lived.
+     *
+     * The typeDefsCache is a long-lived TypeDefsByCategory used to remember the TypeDefs from Atlas (that can be
+     * modeled in OM). It is allocated at the start of loadTypeDefs so can be refreshed by a fresh call to loadTypeDefs.
+     * The typeDefsCache is therefore effectively a cache of type defs. To refresh it call loadTypeDefs again - this
+     * will clear it and reload it.
+     * The typeDefsCache is retained across API calls; unlike typeDefsForAPI which is not.
+     */
+
+
+    /*
+     * typeDefsForAPI is a transient TDBC object - it is reallocated at the start of each external API call.
+     * It's purpose is to marshall the results for the current API (only), which can then be extracted or
+     * turned into a TDG, depending on return type of the API.
+     */
+    private TypeDefsByCategory typeDefsForAPI = null;
+
+    /*
+     * Declare the Atlas stores the connector will use - these are injected via AtlasStoresProxy.
+     */
+    private AtlasTypeRegistry typeRegistry = null;
+    private AtlasTypeDefStore typeDefStore = null;
+    private AtlasEntityStore entityStore = null;
+    private AtlasRelationshipStore relationshipStore = null;
+    private EntityDiscoveryService entityDiscoveryService = null;
+
+    enum AtlasDeleteOption { SOFT , HARD }
+
+    private AtlasDeleteOption atlasDeleteConfiguration;
+
+    private boolean useRegistry = true;
+
+    // EventMapper will be set by the event mapper itself calling the metadataCollection once the mapper is started.
+    private AtlasOMRSRepositoryEventMapper eventMapper = null;
+
+
+
+    // package private
+    LocalAtlasOMRSMetadataCollection(LocalAtlasOMRSRepositoryConnector parentConnector,
+                                     String                            repositoryName,
+                                     OMRSRepositoryHelper              repositoryHelper,
+                                     OMRSRepositoryValidator           repositoryValidator,
+                                     String                            metadataCollectionId)
+    {
+
+        /*
+         * The metadata collection Id is the unique Id for the metadata collection.  It is managed by the super class.
+         */
+        super(parentConnector, repositoryName, metadataCollectionId, repositoryHelper, repositoryValidator);
+
+        /*
+         *  Initialize the Atlas stores
+         */
+        this.typeRegistry = SpringBridge.services().getTypeRegistry();
+        this.typeDefStore = SpringBridge.services().getTypeDefStore();
+        this.entityStore = SpringBridge.services().getEntityStore();
+        this.relationshipStore = SpringBridge.services().getRelationshipStore();
+        this.entityDiscoveryService = SpringBridge.services().getEntityDiscoveryService();
+
+        /*
+         * Read the Atlas Configuration to initialize the recorded delete configuration of the repository.
+         * The following approach ensures that you get a class - because the getDeleteHandlerV1Impl method
+         * adopts the default class if no property has been set. This is preferable to looking directly
+         * for the property and (if not set) deciding here what default to adopt - this should come from Atlas.
+         */
+
+        LOG.debug("LocalAtlasOMRSMetadataCollection: Find which Atlas deleteHandler is configured");
+        Class<? extends DeleteHandlerV1>  deleteHandlerClass = AtlasRepositoryConfiguration.getDeleteHandlerV1Impl();
+        if (deleteHandlerClass != null) {
+            LOG.debug("LocalAtlasOMRSMetadataCollection: delete handler is {}", deleteHandlerClass.getName());
+            atlasDeleteConfiguration =
+                    deleteHandlerClass.getName().equals("SoftDeleteHandlerV1") ? AtlasDeleteOption.SOFT : AtlasDeleteOption.HARD;
+        }
+        else {
+            // Cannot access configuration so will not know how to handle deletes. Give it up.
+            LOG.error("LocalAtlasOMRSMetadataCollection: delete handler configuration not found!");
+
+            String actionDescription = "LocalAtlasOMRSMetadataCollection Constructor";
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ATLAS_CONFIGURATION;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(repositoryName);
+
+            throw new OMRSLogicErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    actionDescription,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+    }
+
+
+    /*
+     * Helper method for event mapper
+     */
+    public boolean isAtlasConfiguredForHardDelete() {
+
+        if (atlasDeleteConfiguration == AtlasDeleteOption.HARD) {
+            LOG.debug("isAtlasConfiguredForHardDelete: Repository is configured for hard deletes");
+            return true;
+        }
+        return false;
+    }
+
+
+
+    /* ======================================================================
+     * Group 1: Confirm the identity of the metadata repository being called.
+     */
+
+    /**
+     * Returns the identifier of the metadata repository.  This is the identifier used to register the
+     * metadata repository with the metadata repository cohort.  It is also the identifier used to
+     * identify the home repository of a metadata instance.
+     *
+     * @return String - metadata collection id.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     */
+    public String      getMetadataCollectionId()
+        throws
+            RepositoryErrorException
+    {
+
+        final String methodName = "getMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        /*
+         * Perform operation
+         */
+        return super.metadataCollectionId;
+    }
+
+
+
+    /* ==============================
+     * Group 2: Working with typedefs
+     */
+
+    /**
+     * Returns the list of different types of TypeDefs organized by TypeDef Category.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @return TypeDefs - List of different categories of TypeDefs.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDefGallery getAllTypes(String userId)
+            throws
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+
+
+        final String                       methodName = "getAllTypes";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> {} (userId={})", methodName, userId);
+        }
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * The MDC will request the TypeDefs from Atlas. It then parses each of the lists in the TypesDef and
+         * behaves as follows:
+         * For entities, relationships and classifications it will parse each TypeDef and will produce a
+         * corresponding OM type def - which will be of concrete type (e.g. EntityDef). It can only do this for Atlas defs
+         * that can be modelled in OM - some things are not possible, in which case no OM def is produced for that Atlas def.
+         * It will validate that the generated OM type is valid - i.e. that all mandatory fields are present, that no constraints are
+         * violated, etc - Note that this validation step is not very explicit yet - it will be refined/extended later.
+         * The MDC must then check whether the generated OM type is known in the RCM. It uses the RepoHelper and Validator
+         * classes for this - it can new up a RepoHelper and this will have a static link to the RCM. It should then issue
+         * a get by name of the typedef against the RCM. I think this might use isKnownType().
+         * If the type is found within the RCM, then we know that it already exists and we must then perform a deep
+         * compare of the known type and the newly generated type. If they are the same then we can safely use the
+         * known type; we adopt it's GUID and add the typedef to the TDG. If they do not match exactly then we issue
+         * an audit log entry and ignore the generated type (it will not be added to the TDG). If the type is NOT found in the
+         * RCM then we are dealing with a newly discovered type and we can generate a GUID (using the usual means). The generated
+         * typedef is added to the TDG.
+         * In addition to looking in the RCM we need to look at any types we already added to the TDG (in this pass) because each
+         * type only appears once in the TDG. This can be a compare by name only and does not need a compare of content (which is needed
+         * vs a type found in the RCM by name) because the type namespace in Atlas means that two references by the same name must by
+         * definition be references to the same type.
+         * The above processing is similar for EntityDef, RelationshipDef and ClassificationDef typedefs. The MDC is either referring to
+         * known types or generating newly discovered types for those types not found in the RCM.
+         *
+         * The above types can (and probably will) contain attribute defs. For each attribute the MDC needs to decide what type
+         * the attribute has. It will either be an Enum, a Prim or a Coll of Prim, or it may be a type reference or coll of type reference.
+         * In the last two cases (involving type refs) the enclosing typedef will be skipped (not added to the TypeDefGallery). This is
+         * because type references are specific to older Atlas types and in OM the types should use first-class relationships.
+         * The older Atlas types are therefore not pulled into OM.
+         *
+         *  Whenever an enclosing typedef (EntityDef, RelationshipDef or ClassificationDef) is added to the TypeDefGallery it will have a
+         * propertiesDef which is a list of TDA, each having the attribute name and an AttributeTypeDef which is on the TypeDefGallery's
+         * attributeTypeDefs list.
+         * This is similar to how one TypDef refers to another TypeDef (as opposed to a property/attribute): when a TypeDef refers to another
+         * TypeDef a similar linkage is established through a TypeDefLink that refers to a TypeDef on the TypeDefGallery's typeDefs list.
+         * For attribute types that are either consistent and known or valid and new we add them to the TypeDefGallery's list of attributeTypeDefs.
+         * Where multiple 'top-level' typedefs contain attributes of the same type - e.g. EntityDef1 has an int called 'retention' and
+         * EntityDef2 has an int called 'count' - then they will both refer to the same single entry for the int primitive attr type in the
+         * TypeDefGallery. References to types in the TypeDefGallery are by TypeDefLink (which needs a cat, name and guid).
+         *
+         * So the attribute types to be processed are:
+         * Prim - for each of these the MDC will match the Atlas typename (a string) against the known PrimDefCats and construct a PrimDef with
+         * the appropriate PrimDefCat. Look in the RCM and if a Prim with the same string typename exists then adopt its GUID.
+         * [ There is a shortcut here I think as the RCM will have used the same GUID as the PrimDefCat so you can find the
+         * GUID directly. ] I think it is very unlikely that there will be new Primitives discovered. In fact I think that is impossible.
+         * Collection - a Collection can be either an ARRAY<Primitive> or a MAP<Primitive,Primitive>. In both cases we can create a consistent
+         * name for the collection type by using the pattern found in CollectionDef[Cat]. The MDC uses that collection type name to
+         * check whether the collection type is already known in the RCM (again this is a get by name, since we do not have a GUID).
+         * If the collection is a known type then we will use the GUID from the RCM and add it to the √. It is likely that the RCM
+         * will already know about a small number of collections - eg. Map<String,String> - so for these the MDC will reuse the
+         * existing attributeDef - it will still add the coll def to the √ and will refer to it using a TDL with the cat, name and guid.
+         * Any further coll defs will be generated and given a new GUID.
+         * Enum - An Enum Def is an easier beast to convert than a Prim or a Coll because in Atlas it is a real type and has a guid. Processing for an
+         * enum will be more like that for EntityDef, etc. and will require validation (of possible values, default value, etc) and an existence
+         * check in the RCM. If known we will do a deep compare and on match will use the existing def, on mismatch generate audit log entry and
+         * skip not just the enum but also any type that contains it. If it does not exist in the RCM we will generate a new EnumDef with a new GUID.
+         *
+         * Unit Testing
+         * ------------
+         * 3 phases of elaboration.
+         * 1. Just assume (assert?) that each type does not exist in the RCM and hence we will project it into the generated √. This is a good way
+         * to see and verify the generation of types by the MDC. The generator and comparator should be able to generate/compare √.
+         * 2. Mock up the RCM so that we can control what it 'already knows'. This will allow us to test the existence match behaviour of MDC and
+         * the apparent-match-but-different-content logic and audit log entry generation.
+         * 3. Like UT1 (assume that everything is new) but have all the OM types loaded into Atlas. This will allow us to test whether the integration
+         * with Atlas is working and whether the types are coming through OK. This is actually an integration test I think.
+         *
+         */
+
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        /*
+         * This method is a thin wrapper around loadAtlasTypeDefs which will clear and reload the cache
+         * and will construct it's result in typeDefsForAPI and save it into the typeDefsCache.
+         * The loadAtlasTypeDefs method can be used at other times when we need to cache the known TypeDefs
+         * - e.g. for verify calls.
+         */
+
+
+        try {
+            loadAtlasTypeDefs(userId);
+        } catch (RepositoryErrorException e) {
+            LOG.error("getAllTypes: caught exception from Atlas {}", e);
+            throw e;
+        }
+
+        /*
+         * typeDefsForAPI will have been loaded with all discovered TypeDefs. It can be converted into a TypeDefGallery
+         * and can be reset on the next API to be called.
+         */
+
+
+        // Convert the typeDefsForAPI to a gallery
+        TypeDefGallery typeDefGallery = typeDefsForAPI.convertTypeDefsToGallery();
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== {} typeDefGallery={}", methodName, typeDefGallery);
+        }
+        return typeDefGallery;
+    }
+
+    /**
+     * Returns a list of type definitions that have the specified name.  Type names should be unique.  This
+     * method allows wildcard character to be included in the name.  These are * (asterisk) for an
+     * arbitrary string of characters and ampersand for an arbitrary character.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param name - name of the TypeDefs to return (including wildcard characters).
+     * @return TypeDefGallery - List of different categories of type definitions.
+     * @throws InvalidParameterException - the name of the TypeDef is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDefGallery findTypesByName(String  userId,
+                                          String  name)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        /*
+         * Retrieve the typedefs from Atlas, and return a TypeDefGallery that contains two lists, each sorted by category
+         * as follows:
+         * TypeDefGallery.attributeTypeDefs contains:
+         * 1. PrimitiveDefs
+         * 2. CollectionDefs
+         * 3. EnumDefs
+         * TypeDefGallery.newTypeDefs contains:
+         * 1. EntityDefs
+         * 2. RelationshipDefs
+         * 3. ClassificationDefs
+         */
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findTypesByName(userId={}, name={})", userId, name);
+        }
+
+        final String   methodName        = "findTypesByName";
+        final String   sourceName        = metadataCollectionId;
+        final String   nameParameterName = "name";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeName(repositoryName, nameParameterName, name, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        // Strategy: use searchTypesDef with a SearchFilter with name parameter
+        SearchFilter searchFilter = new SearchFilter();
+        searchFilter.setParam(SearchFilter.PARAM_NAME, name);
+        AtlasTypesDef atd;
+        try {
+            atd = typeDefStore.searchTypesDef(searchFilter);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("findTypesByName: caught exception from Atlas type def store {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NAME_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(name, nameParameterName, methodName, sourceName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+
+        }
+
+        /*
+         * Parse the Atlas TypesDef
+         * Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+         * and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+         * is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+         * supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+         * things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+         * anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+         * contains anything other than primitives).
+         */
+
+        // This method will populate the typeDefsForAPI object.
+        if (atd != null) {
+            convertAtlasTypeDefs(userId, atd);
+        }
+
+        // Convert the typeDefsForAPI to a gallery
+        TypeDefGallery typeDefGallery = typeDefsForAPI.convertTypeDefsToGallery();
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findTypesByName(userId={}, name={}): typeDefGallery={}", userId, name, typeDefGallery);
+        }
+        return typeDefGallery;
+    }
+
+
+    /**
+     * Returns all of the TypeDefs for a specific category.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param category - enum value for the category of TypeDef to return.
+     * @return TypeDefs list.
+     * @throws InvalidParameterException - the TypeDefCategory is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<TypeDef> findTypeDefsByCategory(String          userId,
+                                                TypeDefCategory category)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        // Use Atlas typedefstore search API and then post-filter by type category
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findTypeDefsByCategory(userId={}, category={})", userId, category);
+        }
+
+        final String methodName            = "findTypeDefsByCategory";
+        final String categoryParameterName = "category";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefCategory(repositoryName, categoryParameterName, category, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        List<TypeDef> retList;
+        try {
+            retList = _findTypeDefsByCategory(userId, category);
+        }
+        catch (Exception e) {
+            LOG.debug("findTypeDefsByCategory: re-throwing exception from _findTypeDefsByCategory ");
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findTypeDefsByCategory : retList={}", retList);
+        }
+        return retList;
+    }
+
+    private List<TypeDef> _findTypeDefsByCategory(String          userId,
+                                                  TypeDefCategory category)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName = "_findTypeDefsByCategory";
+        final String sourceName = metadataCollectionId;
+        final String categoryParameterName = "category";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _findTypeDefsByCategory(userId={}, category={})", userId, category);
+        }
+
+        // Strategy: use searchTypesDef with a SearchFilter with type parameter set according to category
+        String typeForSearchParameter;
+        switch (category) {
+            case ENTITY_DEF:
+                typeForSearchParameter = "ENTITY";
+                break;
+            case RELATIONSHIP_DEF:
+                typeForSearchParameter = "RELATIONSHIP";
+                break;
+            case CLASSIFICATION_DEF:
+                typeForSearchParameter = "CLASSIFICATION";
+                break;
+            default:
+                LOG.error("_findTypeDefsByCategory: unsupported category {}", category);
+                return null;
+        }
+        SearchFilter searchFilter = new SearchFilter();
+        searchFilter.setParam(SearchFilter.PARAM_TYPE, typeForSearchParameter);
+        AtlasTypesDef atd;
+        try {
+
+            atd = typeDefStore.searchTypesDef(searchFilter);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("_findTypeDefsByCategory: caught exception from Atlas type def store {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NAME_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("category", categoryParameterName, methodName, sourceName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+           }
+
+        /*
+         * Parse the Atlas TypesDef
+         * Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+         * and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+         * is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+         * supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+         * things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+         * anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+         * contains anything other than primitives).
+         */
+
+
+        // This method will populate the typeDefsForAPI object.
+        if (atd != null) {
+            convertAtlasTypeDefs(userId, atd);
+        }
+
+        // Retrieve the list of typedefs from the appropriate list in the typeDefsForAPI
+        List<TypeDef> ret;
+        switch (category) {
+            case ENTITY_DEF:
+                ret = typeDefsForAPI.getEntityDefs();
+                break;
+            case RELATIONSHIP_DEF:
+                ret = typeDefsForAPI.getRelationshipDefs();
+                break;
+            case CLASSIFICATION_DEF:
+                ret = typeDefsForAPI.getClassificationDefs();
+                break;
+            default:
+                LOG.error("_findTypeDefsByCategory: unsupported category {}", category);
+                return null;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _findTypeDefsByCategory: ret={}", userId, category, ret);
+        }
+        return ret;
+    }
+
+
+    /**
+     * Returns all of the AttributeTypeDefs for a specific category.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param category - enum value for the category of an AttributeTypeDef to return.
+     * @return AttributeTypeDefs list.
+     * @throws InvalidParameterException - the TypeDefCategory is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<AttributeTypeDef> findAttributeTypeDefsByCategory(String                   userId,
+                                                                  AttributeTypeDefCategory category)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException {
+
+        final String methodName            = "findAttributeTypeDefsByCategory";
+        final String categoryParameterName = "category";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findAttributeTypeDefsByCategory(userId={}, category={})", userId, category);
+        }
+
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAttributeTypeDefCategory(repositoryName, categoryParameterName, category, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        List<AttributeTypeDef> retList;
+        try {
+            retList = _findAttributeTypeDefsByCategory(userId, category);
+        }
+        catch (Exception e) {
+            LOG.debug("findAttributeTypeDefsByCategory: re-throwing exception from _findAttributeTypeDefsByCategory ");
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findAttributeTypeDefsByCategory : retList={}", retList);
+        }
+        return retList;
+
+    }
+
+    private List<AttributeTypeDef> _findAttributeTypeDefsByCategory(String                   userId,
+                                                                    AttributeTypeDefCategory category)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName            = "_findAttributeTypeDefsByCategory";
+        final String categoryParameterName = "category";
+        final String sourceName            = metadataCollectionId;
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _findAttributeTypeDefsByCategory(userId={}, category={})", userId, category);
+        }
+        /*
+         * Strategy:
+         * Atlas handles Enum defs as types - whereas in OM they are attribute type defs, so for enums (only) use a search
+         * like above for findTypeDefByCategory
+         * For all other categories we need to do a different search - see below...
+         */
+
+
+        List<AttributeTypeDef> ret;
+
+
+        // If category is ENUM_DEF use searchTypesDef with a SearchFilter with type parameter set according to category
+        if (category == ENUM_DEF) {
+            String typeForSearchParameter = "ENUM";
+            SearchFilter searchFilter = new SearchFilter();
+            searchFilter.setParam(SearchFilter.PARAM_TYPE, typeForSearchParameter);
+            AtlasTypesDef atd;
+            try {
+
+                atd = typeDefStore.searchTypesDef(searchFilter);
+
+            } catch (AtlasBaseException e) {
+
+                LOG.error("_findAttributeTypeDefsByCategory: caught exception from Atlas type def store {}", e);
+
+                OMRSErrorCode errorCode = OMRSErrorCode.ATTRIBUTE_TYPEDEF_NAME_NOT_KNOWN;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("category", categoryParameterName, methodName, sourceName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            /*
+             * Parse the Atlas TypesDef
+             * Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+             * and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+             * is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+             * supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+             * things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+             * anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+             * contains anything other than primitives).
+             */
+
+
+            // This method will populate the typeDefsForAPI object.
+            if (atd != null) {
+                convertAtlasTypeDefs(userId, atd);
+            }
+
+            // Retrieve the list of typedefs from the appropriate list in the typeDefsForAPI
+
+            ret = typeDefsForAPI.getEnumDefs();
+        }
+
+        else {
+
+            /*
+             * Category is not ENUM - it should be PRIMITIVE or COLLECTION - or could be UNKNOWN_DEF or invalid.
+             * In the case where we are looking for all attribute type defs by category PRIMITIVE or COLLECTION,
+             * the best way may be to get all types and then return the appropriate section of the TDBC...
+             * ... expensive operation but cannot currently see another way to achieve it.
+             */
+
+            try {
+                loadAtlasTypeDefs(userId);
+            } catch (RepositoryErrorException e) {
+                LOG.error("getAllTypes: caught exception from Atlas {}", e);
+                throw e;
+            }
+
+            switch (category) {
+                case PRIMITIVE:
+                    ret = typeDefsForAPI.getPrimitiveDefs();
+                    break;
+                case COLLECTION:
+                    ret = typeDefsForAPI.getCollectionDefs();
+                    break;
+                default:
+                    LOG.error("findAttributeTypeDefsByCategory: unsupported category {}", category);
+                    ret = null;
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findAttributeTypeDefsByCategory: ret={}", ret);
+        }
+        return ret;
+    }
+
+
+    /**
+     * Return the TypeDefs that have the properties matching the supplied match criteria.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param matchCriteria - TypeDefProperties - a list of property names.
+     * @return TypeDefs list.
+     * @throws InvalidParameterException - the matchCriteria is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<TypeDef> findTypeDefsByProperty(String             userId,
+                                                TypeDefProperties  matchCriteria)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName                 = "findTypeDefsByProperty";
+        final String  matchCriteriaParameterName = "matchCriteria";
+        final String  sourceName                 = metadataCollectionId;
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _findTypeDefsByProperty(userId={}, matchCriteria={})", userId, matchCriteria);
+        }
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateMatchCriteria(repositoryName, matchCriteriaParameterName, matchCriteria, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * Implementation: perform a search of the Atlas type defs and convert each into
+         * corresponding OM TypeDef, filtering the results by properties in the matchCriteria
+         * Return is a List<TypeDef>
+         * AttributeTypeDefs are not included, so the list just contains
+         *  1. EntityDefs
+         *  2. RelationshipDefs
+         *  3. ClassificationDefs
+         */
+
+
+        // The result of the load is constructed in typeDefsForAPI, so clear that first.
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        // Strategy: use searchTypesDef with a null (default) SearchFilter.
+        SearchFilter emptySearchFilter = new SearchFilter();
+        AtlasTypesDef atd;
+        try {
+
+            atd = typeDefStore.searchTypesDef(emptySearchFilter);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("findTypeDefsByProperty: caught exception from Atlas type def store {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NAME_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("category", matchCriteriaParameterName, methodName, sourceName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Parse the Atlas TypesDef
+         * Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+         * and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+         * is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+         * supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+         * things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+         * anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+         * contains anything other than primitives).
+         */
+
+
+        /*
+         * This method will populate the typeDefsForAPI object.
+         * This is also converting the ATDs which appears wasteful but does allow any problems
+         * to be handled, resulting in the skipping of the problematic TypeDef.
+         */
+        if (atd != null) {
+            convertAtlasTypeDefs(userId, atd);
+        }
+
+
+        // For the Entity, Relationship and Classification type defs, filter them through matchCriteria
+        //List<String> matchPropertyNames = matchCriteria.getTypeDefProperties();
+        Map<String,Object> matchProperties = matchCriteria.getTypeDefProperties();
+        List<String> matchPropertyNames = new ArrayList(matchProperties.keySet());
+
+
+        List<TypeDef> returnableTypeDefs = new ArrayList<>();
+
+        // Filter EntityDefs
+        List<TypeDef> entityDefs = typeDefsForAPI.getEntityDefs();
+        if (entityDefs != null) {
+            for (TypeDef typeDef : entityDefs) {
+                // Get the property names for this TypeDef
+                List<String> currentTypePropNames = getPropertyNames(userId, typeDef);
+                if (propertiesContainAllMatchNames(currentTypePropNames,matchPropertyNames)) {
+                    // Amalgamate each survivor into the returnable list...
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+        // Filter RelationshipDefs
+        List<TypeDef> relationshipDefs = typeDefsForAPI.getRelationshipDefs();
+        if (relationshipDefs != null) {
+            for (TypeDef typeDef : relationshipDefs) {
+                // Get the property names for this TypeDef
+                List<String> currentTypePropNames = getPropertyNames(userId, typeDef);
+                if (propertiesContainAllMatchNames(currentTypePropNames,matchPropertyNames)) {
+                    // Amalgamate each survivor into the returnable list...
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+        // Filter ClassificationDefs
+        List<TypeDef> classificationDefs = typeDefsForAPI.getClassificationDefs();
+        if (classificationDefs != null) {
+            for (TypeDef typeDef : classificationDefs) {
+                // Get the property names for this TypeDef
+                List<String> currentTypePropNames = getPropertyNames(userId, typeDef);
+                if (propertiesContainAllMatchNames(currentTypePropNames,matchPropertyNames)) {
+                    // Amalgamate each survivor into the returnable list...
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+
+        List<TypeDef> returnValue = returnableTypeDefs.isEmpty() ? null : returnableTypeDefs;
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _findTypeDefsByProperty: return={})",returnValue);
+        }
+        return returnValue;
+    }
+
+    /*
+     * Utility method to recursively gather property names from a TypeDef
+     */
+    private List<String> getPropertyNames(String userId, TypeDef typeDef)
+            throws
+            RepositoryErrorException
+    {
+        List<String> discoveredPropNames = new ArrayList<>();
+        List<TypeDefAttribute> typeDefAttributeList = typeDef.getPropertiesDefinition();
+        if (typeDefAttributeList != null) {
+            for (TypeDefAttribute tda : typeDefAttributeList) {
+                String attrName = tda.getAttributeName();
+                discoveredPropNames.add(attrName);
+            }
+        }
+        TypeDefLink superTypeLink = typeDef.getSuperType();
+        if (superTypeLink != null) {
+            // Retrieve the supertype - the TDL gives us its GUID and name
+            if (superTypeLink.getName() != null) {
+                TypeDef superTypeDef;
+                try {
+                    superTypeDef = this._getTypeDefByName(userId, superTypeLink.getName());
+
+                } catch (Exception e) {
+                    LOG.error("getPropertyNames: caught exception from getTypeDefByName {}", e);
+                    OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("name", "getPropertyNames", metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "getPropertyNames",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+                if (superTypeDef != null) {
+                    List<String> superTypesPropNames = getPropertyNames(userId, superTypeDef);
+                    if (superTypesPropNames != null) {
+                        discoveredPropNames.addAll(superTypesPropNames);
+                    }
+                }
+            }
+        }
+        if (discoveredPropNames.isEmpty())
+            discoveredPropNames = null;
+        return discoveredPropNames;
+    }
+
+    /*
+     * Utility method to check whether all match names are contained in a list of property names
+     */
+    private boolean propertiesContainAllMatchNames(List<String> propNames, List<String> matchNames) {
+
+        // Check the currentTypePropNames contains ALL the names in matchCriteria
+        if (matchNames == null) {
+            // There are no matchCriteria - the list of property names implicitly passes the filter test
+            return true;
+        }
+        else {
+            // There are matchCriteria - inspect the list of property names
+            if (propNames == null) {
+                // The prop list has no properties - instant match failure
+                return false;
+            }
+            // It has been established that both currentTypePropNames and matchPropertyNames are not null
+            boolean allMatchPropsFound = true;
+            for (String matchName : matchNames) {
+                boolean thisMatchPropFound = false;
+                for (String propName : propNames) {
+                    if (propName.equals(matchName)) {
+                        thisMatchPropFound = true;
+                        break;
+                    }
+                }
+                if (!thisMatchPropFound) {
+                    allMatchPropsFound = false;
+                    break;
+                }
+            }
+            return allMatchPropsFound;
+
+        }
+    }
+
+    /**
+     * Return the types that are linked to the elements from the specified standard.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param standard - name of the standard - null means any, but either standard or organization must be specified
+     * @param organization - name of the organization - null means any, but either standard or organization must be specified.
+     * @param identifier - identifier of the element in the standard - must be specified (cannot be null)
+     * @return TypeDefs list - each entry in the list contains a TypeDef.  This is a structure
+     * describing the TypeDef's category and properties.
+     * @throws InvalidParameterException - all attributes of the external id are null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<TypeDef>  findTypesByExternalID(String userId,
+                                                String standard,
+                                                String organization,
+                                                String identifier)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName = "findTypesByExternalID";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findTypesByExternalID(userId={},standard={},organization={},identifier={})",
+                    userId, standard, organization, identifier);
+        }
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateExternalId(repositoryName, standard, organization, identifier, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        List<TypeDef> returnValue = null;
+
+        // Pack the filter criteria into an ExternalStandardMapping
+        ExternalStandardMapping filterCriteria = new ExternalStandardMapping();
+        filterCriteria.setStandardName(standard);
+        filterCriteria.setStandardOrganization(organization);
+        filterCriteria.setStandardTypeName(identifier);
+
+        /*
+         * There is no point asking Atlas for type defs and then filtering on External Standards information,
+         * because that information only exists in the RepositoryContentManager. So instead, ask the Repository
+         * Helper, and then filter.
+         */
+        TypeDefGallery knownTypes = repositoryHelper.getKnownTypeDefGallery();
+        List<TypeDef> knownTypeDefs = knownTypes.getTypeDefs();
+        if (knownTypeDefs != null) {
+
+            List<TypeDef> returnableTypeDefs = new ArrayList<>();
+
+            /*
+             * Look through the knownTypeDefs checking for the three strings we need to match...
+             * According to the validator we are expecting at least one of standard OR organization to be non-null AND
+             * for identifier to be non-null. So identifier must be present AND either standard OR organization must
+             * be present.
+             * This has been asserted by calling the validator's validateExternalId method.
+             * For a TypeDef to match it must possess the specified standard mapping within its list of ESMs.
+             */
+            for (TypeDef typeDef : knownTypeDefs) {
+                // Get the external standards fields for this TypeDef
+                List<ExternalStandardMapping> typeDefExternalMappings = typeDef.getExternalStandardMappings();
+
+                if (externalStandardsSatisfyCriteria(typeDefExternalMappings,filterCriteria)) {
+                    // Amalgamate each survivor into the returnable list...
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+
+            if (!(returnableTypeDefs.isEmpty())) {
+                returnValue = returnableTypeDefs;
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findTypesByExternalID: return={})",returnValue);
+        }
+        return returnValue;
+
+    }
+
+    /*
+     * Utility method to compare a list of external standards mappings with a set of filter criteria.
+     * If the list contains at least one member that satisfies the criteria, the method returns true.
+     * This method is based on the assumption that at least one of the filterCriteria is non null, as
+     * established by the validator, in the caller.
+     */
+    private boolean externalStandardsSatisfyCriteria(List<ExternalStandardMapping> typeDefExternalMappings, ExternalStandardMapping filterCriteria) {
+
+        String standardCriterion = filterCriteria.getStandardName();
+        String organizationCriterion = filterCriteria.getStandardOrganization();
+        String identifierCriterion = filterCriteria.getStandardTypeName();
+        /*
+         * In case the caller does not establish that there is at least one non-null filter criterion, take care of that here
+         * If there are no criteria then the list will pass
+         */
+        if (standardCriterion == null && organizationCriterion == null && identifierCriterion == null ) {
+            // Degenerate filterCriteria, test automatically passes
+            return true;
+        }
+
+        /*
+         * For each ESM in the list, check whether it satisfies the criteria in the filterCriteria.
+         * If any ESM in the list matches then the list passes.
+         * Return a boolean for the list.
+         * When a filter criterion is null it means 'anything goes', so it is only the specific value(s)
+         * that need to match.
+         * If there is no filterCriteria.standard or there is and it matches the ESM passes
+         * If there is no filterCriteria.organization or there is and it matches the ESM passes
+         * If there is no filterCriteria.identifier or there is and it matches the ESM passes
+         */
+        if (typeDefExternalMappings == null) {
+            // It has already been established that at least one of the filterCriteria is not null.
+            // If that is the case and there are no ESMs in the list, then the list fails.
+            return false;
+        }
+        else {
+            boolean listOK = false;
+
+            for (ExternalStandardMapping currentESM : typeDefExternalMappings ) {
+
+                boolean standardSatisfied = ( standardCriterion == null || currentESM.getStandardName().equals(standardCriterion) );
+                boolean organizationSatisfied = ( organizationCriterion == null || currentESM.getStandardOrganization().equals(organizationCriterion) );
+                boolean identifierSatisfied = ( identifierCriterion == null || currentESM.getStandardTypeName().equals(identifierCriterion) );
+
+                if (standardSatisfied && organizationSatisfied && identifierSatisfied ) {
+                    // This ESM matches the criteria so the whole list passes...
+                    listOK = true;
+                    break;
+                }
+                // This ESM does not match the criteria but continue with the remainder of the list...
+            }
+
+            return listOK;
+        }
+    }
+
+
+    /**
+     * Return the TypeDefs that match the search criteria.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param searchCriteria - String - search criteria.
+     * @return TypeDefs list - each entry in the list contains a TypeDef.  This is is a structure
+     * describing the TypeDef's category and properties.
+     * @throws InvalidParameterException - the searchCriteria is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<TypeDef> searchForTypeDefs(String userId,
+                                           String searchCriteria)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName                  = "searchForTypeDefs";
+        final String searchCriteriaParameterName = "searchCriteria";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> searchForTypeDefs(userId={},searchCriteria={})", userId, searchCriteria);
+        }
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateSearchCriteria(repositoryName, searchCriteriaParameterName, searchCriteria, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * The searchCriteria is interpreted as a String to be used in a wildcard comparison with the name of the TypeDef.
+         * It is only the name of the TypeDef that is compared.
+         *
+         */
+
+        /*
+         * Implementation: perform a search of the Atlas type defs and convert each into
+         * corresponding OM TypeDef, filtering the results by testing whether the searchCriteria
+         * string is contained in (or equal to) the name of each TypeDef.
+         * Return is a List<TypeDef>
+         * AttributeTypeDefs are not included, so the list just contains
+         *  1. EntityDefs
+         *  2. RelationshipDefs
+         *  3. ClassificationDefs
+         */
+
+
+        // The result of the load is constructed in typeDefsForAPI, so clear that first.
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        // Strategy: use searchTypesDef with a null (default) SearchFilter.
+        SearchFilter emptySearchFilter = new SearchFilter();
+        AtlasTypesDef atd;
+        try {
+
+            atd = typeDefStore.searchTypesDef(emptySearchFilter);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("searchForTypeDefs:caught exception from attempt to retrieve all TypeDefs from Atlas repository", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(searchCriteria, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        /*
+         * Parse the Atlas TypesDef
+         * Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+         * and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+         *  is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+         *  supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+         *  things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+         *  anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+         *  contains anything other than primitives).
+         *
+         * This method will populate the typeDefsForAPI object.
+         * This is also converting the ATDs which appears wasteful but does allow any problems
+         * to be handled, resulting in the skipping of the problematic TypeDef.
+         */
+        if (atd != null) {
+            convertAtlasTypeDefs(userId, atd);
+        }
+
+
+        // For the Entity, Relationship and Classification type defs, filter them through matchCriteria
+
+        List<TypeDef> returnableTypeDefs = new ArrayList<>();
+
+        // Filter EntityDefs
+        List<TypeDef> entityDefs = typeDefsForAPI.getEntityDefs();
+        if (entityDefs != null) {
+            for (TypeDef typeDef : entityDefs) {
+                if (typeDef.getName().matches(searchCriteria)) {
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+        // Filter RelationshipDefs
+        List<TypeDef> relationshipDefs = typeDefsForAPI.getEntityDefs();
+        if (relationshipDefs != null) {
+            for (TypeDef typeDef : relationshipDefs) {
+                if (typeDef.getName().matches(searchCriteria)) {
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+        // Filter ClassificationDefs
+        List<TypeDef> classificationDefs = typeDefsForAPI.getEntityDefs();
+        if (classificationDefs != null) {
+            for (TypeDef typeDef : classificationDefs) {
+                if (typeDef.getName().matches(searchCriteria)) {
+                    returnableTypeDefs.add(typeDef);
+                }
+            }
+        }
+
+
+        List<TypeDef> returnValue = null;
+        if (!(returnableTypeDefs.isEmpty())) {
+            returnValue =  returnableTypeDefs;
+        }
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== searchForTypeDefs: return={})", returnValue);
+        }
+        return returnValue;
+
+    }
+
+
+    /**
+     * Return the TypeDef identified by the GUID.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid - String unique id of the TypeDef
+     * @return TypeDef structure describing its category and properties.
+     * @throws InvalidParameterException - the guid is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                  the metadata collection is stored.
+     * @throws TypeDefNotKnownException - The requested TypeDef is not known in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDef getTypeDefByGUID(String userId,
+                                    String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getTypeDefByGUID(userId={}, guid={})", userId, guid);
+        }
+
+        final String methodName        = "getTypeDefByGUID";
+        final String guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Perform operation
+         */
+
+
+        // Initialisation
+
+        // Clear the transient type defs
+        this.typeDefsForAPI = new TypeDefsByCategory();
+
+
+        // Invoke internal helper method
+        TypeDef ret;
+        try {
+            // The underlying method handles Famous Five conversions.
+            ret = _getTypeDefByGUID(userId, guid);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            LOG.error("getTypeDefByGUID: re-throwing exception from internal method", e);
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getTypeDefByGUID: ret={}", ret);
+        }
+        return ret;
+    }
+
+
+    /*
+     * Internal implementation of getTypeDefByGUID()
+     * This is separated so that other methods can use it without resetting the typeDefsForAPI object
+     */
+    private TypeDef _getTypeDefByGUID(String userId,
+                                      String guid)
+            throws
+            RepositoryErrorException,
+            TypeDefNotKnownException {
+        // Strategy:
+        // Check guid is not null. null => return null
+        // Use Atlas typedef store getByName()
+        // If you get back a typedef of a category that can be converted to OM typedef then convert it and return the type def.
+        // If Atlas type is not of a category that can be converted to an OM TypeDef then return throw TypeDefNotKnownException.
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getTypeDefByGUID(userId={}, guid={})", userId, guid);
+        }
+
+        // This is an internal helper method so should never get null guid; but if so return null.
+        if (guid == null)
+            return null;
+
+
+        // Retrieve the AtlasBaseTypeDef
+        AtlasBaseTypeDef abtd;
+
+        try {
+
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByGuid(guid);
+            }
+            else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByGuid(guid);
+            }
+
+        } catch (AtlasBaseException e) {
+
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_GUID_NOT_FOUND) {
+                LOG.error("_getTypeDefByGUID: Atlas does not have the type with guid {} ", guid, e);
+                // The AttributeTypeDef was not found - return null
+                abtd = null;
+            } else {
+
+                LOG.debug("_getTypeDefByGUID: caught exception from Atlas getByGuid using guid {}", guid);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("guid", "_getTypeDefByGuid", metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getTypeDefByGUID",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+
+        if (abtd == null) {
+            LOG.debug("_getTypeDefByGUID: Atlas does not have the type with guid {} ", guid);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("guid", "_getTypeDefByGuid",metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Underlying method handles Famous Five conversions
+        TypeDef ret;
+        try {
+            ret = convertAtlasTypeDefToOMTypeDef(userId, abtd);
+        }
+        catch (TypeErrorException e) {
+            LOG.error("_getTypeDefByGUID: Failed to convert the Atlas type {} to an OM TypeDef", abtd.getName(), e);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("guid", "_getTypeDefByGuid",metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _getTypeDefByGUID: ret={}", ret);
+        }
+        return ret;
+
+    }
+
+
+
+    /**
+     * Return the AttributeTypeDef identified by the GUID
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String name of the AttributeTypeDef.
+     * @return TypeDef structure describing its category and properties.
+     * @throws InvalidParameterException  - the name is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested AttributeTypeDef is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public AttributeTypeDef getAttributeTypeDefByGUID(String userId,
+                                                      String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getAttributeTypeDefByGUID(userId={}, guid={})", userId, guid);
+        }
+
+        final String methodName        = "getAttributeTypeDefByGUID";
+        final String guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Initialisation
+
+        // Clear the transient type defs
+        this.typeDefsForAPI = new TypeDefsByCategory();
+
+        // Return object
+        AttributeTypeDef ret;
+        try {
+            ret = _getAttributeTypeDefByGUID(userId, guid);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            LOG.error("getAttributeTypeDefByGUID: re-throwing exception from internal method", e);
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getAttributeTypeDefByGUID): ret={}", userId, guid, ret);
+        }
+        return ret;
+    }
+
+    /*
+     * Internal implementation of getAttributeTypeDefByGUID
+     * This is separated so that other methods can use it without resetting the typeDefsForAPI object
+     */
+    private AttributeTypeDef _getAttributeTypeDefByGUID(String userId,
+                                                        String guid)
+        throws
+            RepositoryErrorException,
+            TypeDefNotKnownException {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getAttributeTypeDefByGUID(userId={}, guid={})", userId, guid);
+        }
+
+        // Strategy:
+        // Check guid is not null. null => return null (it should already have been checked)
+        // Use Atlas typedef store getByName()
+        // If you get back a AttributeTypeDef of a category that can be converted to OM AttributeTypeDef
+        // then convert it and return the AttributeTypeDef.
+        // If Atlas type is not of a category that can be converted to an OM AttributeTypeDef then return throw TypeDefNotKnownException.
+
+        if (guid == null) {
+            LOG.error("_getAttributeTypeDefByGUID: guid is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Look in the Atlas type def store
+        AtlasBaseTypeDef abtd;
+        try {
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByGuid(guid);
+            } else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByGuid(guid);
+            }
+
+        } catch (AtlasBaseException e) {
+
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_GUID_NOT_FOUND) {
+                LOG.debug("_getAttributeTypeDefByGUID: Atlas does not have the type with guid {} ", guid, e);
+                // The AttributeTypeDef was not found - return null
+                abtd = null;
+            } else {
+                LOG.error("_getAttributeTypeDefByGUID: caught exception trying to retrieve type with guid {}", guid, e);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByGUID",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        if (abtd == null) {
+            LOG.debug("_getAttributeTypeDefByGUID: Atlas does not have the type with guid {} ", guid);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("guid", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // abtd is known to be good
+
+        AttributeTypeDef ret;
+
+        // Generate a candidate OM TypeDef
+        AttributeTypeDef candidateAttributeTypeDef;
+
+        // Find the category of the Atlas typedef and invoke the relevant conversion method.
+        // The only Atlas type categories that we can convert to OM AttributeTypeDef are:
+        // PRIMITIVE: ENUM: ARRAY: MAP:
+        // Anything else we will bounce and return null.
+        // This will populate TDBC - you then need to retrieve the TD and return it.
+        TypeCategory atlasCat = abtd.getCategory();
+        switch (atlasCat) {
+
+            case PRIMITIVE:
+            case ENUM:
+            case ARRAY:
+            case MAP:
+                // For any of these categories get a candidate ATD
+                //candidateAttributeTypeDef = convertAtlasBaseTypeDefToAttributeTypeDef(abtd);
+                AtlasBaseTypeDefMapper abtdMapper = new AtlasBaseTypeDefMapper(abtd);
+                candidateAttributeTypeDef = abtdMapper.toAttributeTypeDef();
+                break;
+
+            case ENTITY:
+            case RELATIONSHIP:
+            case CLASSIFICATION:
+            case STRUCT:
+            case OBJECT_ID_TYPE:
+            default:
+                LOG.error("_getAttributeTypeDefByGUID: Atlas type has category cannot be converted to OM AttributeTypeDef, category {} ", atlasCat);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+                throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByGUID",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+
+
+        if (candidateAttributeTypeDef == null) {
+            LOG.error("_getAttributeTypeDefByGUID: candidateAttributeTypeDef is null");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByGUID",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        } else {
+            // Finally, check if the converted attributeTypeDef is known by the repos helper and whether it matches exactly.
+            // If it doesn't exist in RH, return the copy we got from the TDBC.
+            // If it does exist in RH then perform a deep compare; exact match => return the ATD from the RH
+            // If it does exist in RH but is not an exact match => audit log and return null;
+
+            // Ask RepositoryContentManager whether there is an AttributeTypeDef with supplied name
+            String source = metadataCollectionId;
+            AttributeTypeDef existingAttributeTypeDef;
+            String name = candidateAttributeTypeDef.getName();
+            try {
+                existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(source, name);
+            } catch (OMRSLogicErrorException e) {
+                LOG.error("_getAttributeTypeDefByGUID: Caught exception from repository helper for attribute type def with name {}", name, e);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+                throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByGUID",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            if (existingAttributeTypeDef == null) {
+                // The RH does not have a typedef by the supplied name - use the candidateTypeDef
+                LOG.debug("_getAttributeTypeDefByGUID: repository content manager returned name not found - use the candidate AttributeTypeDef");
+                candidateAttributeTypeDef.setDescriptionGUID(null);
+                // candidateAttributeTypeDef will be returned at end of method
+                ret = candidateAttributeTypeDef;
+            } else {
+                // RH returned an AttributeTypeDef; cast it by category and compare against candidate
+                // If match we will use RH TD; if not match we will generate audit log entry
+                LOG.debug("_getAttributeTypeDefByGUID: RepositoryHelper returned a TypeDef with name {} : {}", name, existingAttributeTypeDef);
+                LOG.debug("_getAttributeTypeDefByGUID: RepositoryHelper TypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                boolean typematch;
+                Comparator comp = new Comparator();
+                switch (existingAttributeTypeDef.getCategory()) {
+
+                    case PRIMITIVE:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        PrimitiveDef existingPrimitiveDef = (PrimitiveDef) existingAttributeTypeDef;
+                        PrimitiveDef newPrimitiveDef = (PrimitiveDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingPrimitiveDef, newPrimitiveDef);
+                        break;
+
+                    case COLLECTION:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        CollectionDef existingCollectionDef = (CollectionDef) existingAttributeTypeDef;
+                        CollectionDef newCollectionDef = (CollectionDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingCollectionDef, newCollectionDef);
+                        break;
+
+                    case ENUM_DEF:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        EnumDef existingEnumDef = (EnumDef) existingAttributeTypeDef;
+                        EnumDef newEnumDef = (EnumDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingEnumDef, newEnumDef);
+                        break;
+
+                    default:
+                        LOG.error("_getAttributeTypeDefByGUID: repository content manager found TypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                        OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+                        throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "_getAttributeTypeDefByGUID",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                }
+
+                // If compare matches use the known type
+                if (typematch) {
+                    // We will add the attributeTypeDef to the TypeDefGallery
+                    LOG.debug("_getAttributeTypeDefByGUID: return the repository content manager TypeDef with name {}", name);
+                    candidateAttributeTypeDef = existingAttributeTypeDef;
+                    ret = candidateAttributeTypeDef;
+
+                } else {
+                    // If compare failed generate AUDIT log entry and abandon
+                    LOG.error("_getAttributeTypeDefByGUID: repository content manager found clashing def with name {}", name);
+                    OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("atlasEntityDef", "_getAttributeTypeDefByGUID", metadataCollectionId);
+
+                    throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "_getAttributeTypeDefByGUID",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _getAttributeTypeDefByGUID: ret={}", userId, guid, ret);
+        }
+        return ret;
+    }
+
+
+    /**
+     * Return the TypeDef identified by the unique name.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param name   - String name of the TypeDef.
+     * @return TypeDef structure describing its category and properties.
+     * @throws InvalidParameterException  - the name is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested TypeDef is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDef getTypeDefByName(String userId,
+                                    String name)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getTypeDefByName(userId={}, name={}", userId, name);
+        }
+
+        final String  methodName = "getTypeDefByName";
+        final String  nameParameterName = "name";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeName(repositoryName, nameParameterName, name, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Clear the transient type defs
+        this.typeDefsForAPI = new TypeDefsByCategory();
+
+        TypeDef ret;
+        try {
+            ret = _getTypeDefByName(userId, name);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            LOG.error("getTypeDefByName: re-throwing exception from internal method", e);
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getTypeDefByName: ret={}", ret);
+        }
+        return ret;
+    }
+
+
+
+    /**
+     * Internal implementation of getTypeDefByName()
+     * @param userId     - unique identifier for requesting user.
+     * @param omTypeName - String name of the TypeDef.
+     * @return TypeDef structure describing its category and properties.
+     */
+    // package private
+    TypeDef _getTypeDefByName(String userId,
+                              String omTypeName)
+        throws
+            RepositoryErrorException,
+            TypeDefNotKnownException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getTypeDefByName(userId={}, omTypeName={})", userId, omTypeName);
+        }
+        // Strategy:
+        // Check name is not null. null => throw
+        // Use Atlas typedef store getByName()
+        // If you get back a typedef of a category that can be converted to OM typedef then convert it and return the type def.
+        // If Atlas type is not of a category that can be converted to an OM TypeDef then return throw TypeDefNotKnownException.
+
+
+        // Look in the Atlas type def store
+
+        // If the OM typeName is in famous five then you need to look for the corresponding Atlas name
+        String atlasTypeName = omTypeName;
+        if (FamousFive.omTypeRequiresSubstitution(omTypeName)) {
+            // The type to be looked up is in the famous five.
+            // We do not have the OM GUID but all we need at the moment is the Atlas type name to look up so GUID can be null
+            atlasTypeName = FamousFive.getAtlasTypeName(omTypeName, null);
+        }
+
+        AtlasBaseTypeDef abtd;
+        try {
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByName(atlasTypeName);
+            }
+            else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByName(atlasTypeName);
+            }
+
+        } catch (AtlasBaseException e) {
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                LOG.debug("_getTypeDefByName: Atlas does not have the type with name {} ", atlasTypeName);
+                // The AttributeTypeDef was not found - ensure abtd is null, exception to be handled below
+                abtd = null;
+            }
+            else {
+                LOG.error("_getTypeDefByName: Caught exception trying to retrieve Atlas type with name {} ", atlasTypeName, e);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        // Separate null check ensures we have covered both cases (registry and store)
+        if (abtd == null) {
+
+            LOG.debug("_getTypeDefByName: received null return from Atlas getByName using name {}", atlasTypeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(atlasTypeName, "unknown", "name", "_getTypeDefByName", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // From here on we know that abtd is not null
+
+
+        // Underlying method handles Famous Five conversions
+        TypeDef ret;
+        try {
+            ret = convertAtlasTypeDefToOMTypeDef(userId, abtd);
+        }
+        catch (TypeErrorException e) {
+            LOG.error("_getTypeDefByName: Failed to convert the Atlas type {} to an OM TypeDef", abtd.getName(), e);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("atlasEntityDef", "getTypeDefByGuid",metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _getTypeDefByName: ret={}", ret);
+        }
+
+        return ret;
+
+    }
+
+
+    /**
+     * Return the AttributeTypeDef identified by the unique name.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param name   - String name of the AttributeTypeDef.
+     * @return TypeDef structure describing its category and properties.
+     * @throws InvalidParameterException  - the name is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested AttributeTypeDef is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public AttributeTypeDef getAttributeTypeDefByName(String userId,
+                                                      String name)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getAttributeTypeDefByName(userId={}, name={})", userId, name);
+        }
+
+        final String  methodName = "getAttributeTypeDefByName";
+        final String  nameParameterName = "name";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeName(repositoryName, nameParameterName, name, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Initialisation
+
+        // Clear the transient type defs
+        this.typeDefsForAPI = new TypeDefsByCategory();
+
+
+        // Return object
+        AttributeTypeDef ret;
+        try {
+            ret = _getAttributeTypeDefByName(userId, name);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            LOG.error("getAttributeTypeDefByName: re-throwing exception from internal method", e);
+            throw e;
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getAttributeTypeDefByName: ret={}", ret);
+        }
+        return ret;
+    }
+
+    /*
+     * Internal implementation of getAttributeTypeDefByName
+     */
+    private AttributeTypeDef _getAttributeTypeDefByName(String userId,
+                                                        String name)
+            throws
+            RepositoryErrorException,
+            TypeDefNotKnownException
+
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getAttributeTypeDefByName(userId={}, name={})", userId, name);
+        }
+
+        // Strategy:
+        // Check name is not null. null => throw exception
+        // Use Atlas typedef store getByName()
+        // If you get an AttributeTypeDef of a category that can be converted to OM AttributeTypeDef
+        // then convert it and return the AttributeTypeDef.
+        // If Atlas type is not of a category that can be converted to an OM AttributeTypeDef then return throw TypeDefNotKnownException.
+
+       if (name == null) {
+           LOG.error("_getAttributeTypeDefByName: Cannot get Atlas type with null name");
+           OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+           String errorMessage = errorCode.getErrorMessageId()
+                   + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+           throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                   this.getClass().getName(),
+                   "_getAttributeTypeDefByName",
+                   errorMessage,
+                   errorCode.getSystemAction(),
+                   errorCode.getUserAction());
+       }
+
+
+        // Look in the Atlas type def store or registry.
+        // Note that on typedef not exists, the registry will return null, whereas the store will throw an exception
+        AtlasBaseTypeDef abtd;
+        try {
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByName(name);
+            }
+            else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByName(name);
+            }
+
+        } catch (AtlasBaseException e) {
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                LOG.debug("_getAttributeTypeDefByName: Atlas does not have the type with name {} ", name);
+                // The AttributeTypeDef was not found - ensure abtd is null, exception to be handled below
+                abtd = null;
+            }
+            else {
+                LOG.error("_getAttributeTypeDefByName: Caught exception trying to retrieve Atlas type with name {} ", name, e);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        // Separate null check ensures we have covered both cases (registry and store)
+        if (abtd == null) {
+
+            LOG.debug("_getAttributeTypeDefByName: received null return from Atlas getByName using name {}", name);
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(name, "unknown", "name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // From this point, we know that abtd is non-null
+
+        AttributeTypeDef ret;
+
+        // Generate a candidate OM TypeDef
+        AttributeTypeDef candidateAttributeTypeDef;
+
+        // Find the category of the Atlas typedef and invoke the relevant conversion method.
+        // The only Atlas type categories that we can convert to OM AttributeTypeDef are:
+        // PRIMITIVE: ENUM: ARRAY: MAP:
+        // Anything else we will bounce and return null.
+        // This will populate TDBC - you then need to retrieve the TD and return it.
+        TypeCategory atlasCat = abtd.getCategory();
+        switch (atlasCat) {
+            case PRIMITIVE:
+            case ENUM:
+            case ARRAY:
+            case MAP:
+                // For any of these categories get a candidate ATD
+                //candidateAttributeTypeDef = convertAtlasBaseTypeDefToAttributeTypeDef(abtd);
+                AtlasBaseTypeDefMapper abtdMapper = new AtlasBaseTypeDefMapper(abtd);
+                candidateAttributeTypeDef = abtdMapper.toAttributeTypeDef();
+                break;
+            case ENTITY:
+            case RELATIONSHIP:
+            case CLASSIFICATION:
+            case STRUCT:
+            case OBJECT_ID_TYPE:
+            default:
+                LOG.debug("_getAttributeTypeDefByName: Atlas type has category cannot be converted to OM AttributeTypeDef, category {} ", atlasCat);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+
+        if (candidateAttributeTypeDef == null) {
+            LOG.debug("_getAttributeTypeDefByName: received null return from attempt to convert AtlasBaseTypeDef to AttributeTypeDef");
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        } else {
+            // Finally, check if the converted attributeTypeDef is known by the repos helper and whether it matches exactly.
+            // If it doesn't exist in RH, return the copy we got from the TDBC.
+            // If it does exist in RH then perform a deep compare; exact match => return the ATD from the RH
+            // If it does exist in RH but is not an exact match => audit log and return null;
+
+            // Ask RepositoryContentManager whether there is an AttributeTypeDef with supplied name
+            String source = metadataCollectionId;
+            AttributeTypeDef existingAttributeTypeDef;
+            try {
+                existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(source, name);
+            } catch (OMRSLogicErrorException e) {
+                LOG.error("_getAttributeTypeDefByName: caught exception from repository helper for type name {}", name, e);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            if (existingAttributeTypeDef == null) {
+                // The RH does not have a typedef by the supplied name - use the candidateTypeDef
+                LOG.debug("_getAttributeTypeDefByName: repository content manager returned name not found - use the candidate AttributeTypeDef");
+                candidateAttributeTypeDef.setDescriptionGUID(null);
+                // candidateAttributeTypeDef will be returned at end of method
+                ret = candidateAttributeTypeDef;
+            } else {
+                // RH returned an AttributeTypeDef; cast it by category and compare against candidate
+                // If match we will use RH TD; if not match we will generate audit log entry
+                LOG.debug("_getAttributeTypeDefByName: RepositoryHelper returned a TypeDef with name {} : {}", name, existingAttributeTypeDef);
+                boolean typematch;
+                Comparator comp = new Comparator();
+                switch (existingAttributeTypeDef.getCategory()) {
+                    case PRIMITIVE:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        PrimitiveDef existingPrimitiveDef = (PrimitiveDef) existingAttributeTypeDef;
+                        PrimitiveDef newPrimitiveDef = (PrimitiveDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingPrimitiveDef, newPrimitiveDef);
+                        break;
+                    case COLLECTION:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        CollectionDef existingCollectionDef = (CollectionDef) existingAttributeTypeDef;
+                        CollectionDef newCollectionDef = (CollectionDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingCollectionDef, newCollectionDef);
+                        break;
+                    case ENUM_DEF:
+                        // Perform a deep compare of the known type and new type
+                        //Comparator comp = new Comparator();
+                        EnumDef existingEnumDef = (EnumDef) existingAttributeTypeDef;
+                        EnumDef newEnumDef = (EnumDef) candidateAttributeTypeDef;
+                        typematch = comp.compare(true, existingEnumDef, newEnumDef);
+                        break;
+                    default:
+                        LOG.debug("_getAttributeTypeDefByName: repository content manager found TypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                        OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+                        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "_getAttributeTypeDefByName",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                }
+
+                // If compare matches use the known type
+                if (typematch) {
+                    // We will add the attributeTypeDef to the TypeDefGallery
+                    LOG.debug("_getAttributeTypeDefByName: return the repository content manager TypeDef with name {}", name);
+                    candidateAttributeTypeDef = existingAttributeTypeDef;
+                    ret = candidateAttributeTypeDef;
+                } else {
+                    // If compare failed generate AUDIT log entry and abandon
+                    LOG.debug("_getAttributeTypeDefByName: repository content manager found clashing def with name {}", name);
+                    OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "_getAttributeTypeDefByName",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== _getAttributeTypeDefByName: ret={}", ret);
+        }
+        return ret;
+    }
+
+
+    /**
+     * Create a collection of related types.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param newTypes - TypeDefGalleryResponse structure describing the new AttributeTypeDefs and TypeDefs.
+     * @throws InvalidParameterException - the new TypeDef is null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                  the metadata collection is stored.
+     * @throws TypeDefNotSupportedException - the repository is not able to support this TypeDef.
+     * @throws TypeDefKnownException - the TypeDef is already stored in the repository.
+     * @throws TypeDefConflictException - the new TypeDef conflicts with an existing TypeDef.
+     * @throws InvalidTypeDefException - the new TypeDef has invalid contents
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void addTypeDefGallery(String         userId,
+                                  TypeDefGallery newTypes)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotSupportedException,
+            TypeDefKnownException,
+            TypeDefConflictException,
+            InvalidTypeDefException,
+            UserNotAuthorizedException
+
+    {
+
+        final String  methodName = "addTypeDefGallery";
+        final String  galleryParameterName = "newTypes";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> addTypeDefGallery(userId={}, newTypes={})", userId, newTypes);
+        }
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefGallery(repositoryName, galleryParameterName, newTypes, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * Parse the TypeDefGallery and for each category of TypeDef and AttributeTypeDef perform the
+         * corresponding add operation.
+         * AttributeTypeDefs and handled first, then TypeDefs.
+         *
+         * All exceptions thrown by the called methods match the signature of this method, so let them
+         * throw through.
+         */
+
+        List<AttributeTypeDef> attributeTypeDefs = newTypes.getAttributeTypeDefs();
+        if (attributeTypeDefs != null) {
+            for (AttributeTypeDef attributeTypeDef : attributeTypeDefs) {
+                 addAttributeTypeDef(userId,attributeTypeDef);
+            }
+        }
+
+        List<TypeDef> typeDefs = newTypes.getTypeDefs();
+        if (typeDefs != null) {
+            for (TypeDef typeDef : typeDefs) {
+                addTypeDef(userId,typeDef);
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== addTypeDefGallery");
+        }
+    }
+
+
+
+    /**
+     * Create a definition of a new TypeDef.
+     *
+     * @param userId     - unique identifier for requesting user.
+     * @param newTypeDef - TypeDef structure describing the new TypeDef.
+     * @throws InvalidParameterException    - the new TypeDef is null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws TypeDefNotSupportedException - the repository is not able to support this TypeDef.
+     * @throws TypeDefKnownException        - the TypeDef is already stored in the repository.
+     * @throws TypeDefConflictException     - the new TypeDef conflicts with an existing TypeDef.
+     * @throws InvalidTypeDefException      - the new TypeDef has invalid contents.
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public void addTypeDef(String  userId,
+                           TypeDef newTypeDef)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotSupportedException,
+            TypeDefKnownException,
+            TypeDefConflictException,
+            InvalidTypeDefException,
+            UserNotAuthorizedException {
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> addTypeDef(userId={}, newTypeDef={})", userId, newTypeDef);
+        }
+
+        final String methodName = "addTypeDef";
+        final String typeDefParameterName = "newTypeDef";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDef(repositoryName, typeDefParameterName, newTypeDef, methodName);
+        repositoryValidator.validateUnknownTypeDef(repositoryName, typeDefParameterName, newTypeDef, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * Validate the status fields in the passed TypeDef
+         */
+        boolean statusFieldsValid = validateStatusFields(newTypeDef);
+        if (!statusFieldsValid) {
+            // We cannot accept this typedef because it contains status fields that cannot be modelled by Atlas
+            LOG.error("addTypeDef: The TypeDef with name {}, initialStatus {} and validInstanceStatusList {} could not be modelled in Atlas", newTypeDef, newTypeDef.getInitialStatus(), newTypeDef.getValidInstanceStatusList());
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(newTypeDef.getName(), newTypeDef.getGUID(), typeDefParameterName, methodName, repositoryName, newTypeDef.toString());
+            throw new TypeDefNotSupportedException(
+                    errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Given an OM TypeDef - convert it to corresponding Atlas type def, store it, then read it back and convert
+         * it back to OM. The write-through and read-back is so that we pick up any Atlas initializations, e.g. of
+         * fields like createdBy, description (if originally null), etc.
+         */
+
+
+        /*
+         *  To do this we need to put the Atlas type definition into an AtlasTypesDef
+         *  Create an empty AtlasTypesDef container for type to be converted below
+         */
+        AtlasTypesDef atlasTypesDef = new AtlasTypesDef();
+
+        /*
+         *  Get category of OM TypeDef, then depending on category instantiate the corresponding Atlas typedef, which will
+         * be one of AtlasEntityDef, AtlasRelationshipDef or AtlasClassificationDef
+         */
+        String newTypeName = newTypeDef.getName();
+        TypeDefCategory category = newTypeDef.getCategory();
+        LOG.debug("addTypeDef: was passed an OM TypeDef with name {} and category {}", newTypeName, category);
+        switch (category) {
+
+            case ENTITY_DEF:
+                // The following method will detect a Famous Five type and convert accordingly.
+                AtlasEntityDef atlasEntityDef = convertOMEntityDefToAtlasEntityDef((EntityDef) newTypeDef);
+                if (atlasEntityDef != null) {
+                    atlasTypesDef.getEntityDefs().add(atlasEntityDef);
+                }
+                break;
+
+            case RELATIONSHIP_DEF:
+                try {
+                    AtlasRelationshipDef atlasRelationshipDef = convertOMRelationshipDefToAtlasRelationshipDef((RelationshipDef) newTypeDef);
+                    if (atlasRelationshipDef != null) {
+                        atlasTypesDef.getRelationshipDefs().add(atlasRelationshipDef);
+                    }
+
+                } catch (RepositoryErrorException | TypeErrorException e) {
+                    // Log the error and re-throw
+                    LOG.debug("addTypeDef: caught exception from attempt to convert OM RelationshipDef to Atlas, name {}", newTypeDef.getName());
+                    OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("TypeDef", "retrieval", metadataCollectionId);
+
+                    throw new InvalidTypeDefException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "addTypeDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+                break;
+
+            case CLASSIFICATION_DEF:
+                AtlasClassificationDef atlasClassificationDef = convertOMClassificationDefToAtlasClassificationDef((ClassificationDef) newTypeDef);
+                if (atlasClassificationDef != null) {
+                    atlasTypesDef.getClassificationDefs().add(atlasClassificationDef);
+                }
+                break;
+
+            case UNKNOWN_DEF:
+                LOG.debug("addTypeDef: cannot convert an OM TypeDef with category {}", category);
+                break;
+        }
+
+
+        AtlasBaseTypeDef retrievedAtlasTypeDef;
+
+        try {
+            /*
+             * Add the AtlasTypesDef to the typeDefStore.
+             */
+            LOG.debug("addTypeDef: add AtlasTypesDef {} to store", atlasTypesDef);
+            typeDefStore.createTypesDef(atlasTypesDef);
+            /*
+             * Read the AtlasTypeDef back and convert it back into an OM TypeDef.
+             */
+            retrievedAtlasTypeDef = typeDefStore.getByName(newTypeName);
+            LOG.debug("addTypeDef: retrieved created type from store {}", atlasTypesDef);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("addTypeDef: exception from store and retrieve AtlasTypesDef {}", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("TypeDef", "retrieval", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "addTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Formulate the return value - the retrieved Atlas Type is converted into an OM TypeDef
+         */
+        TypeDef returnableTypeDef = null;
+        boolean fatalError = false;
+        switch (retrievedAtlasTypeDef.getCategory()) {
+
+            case ENTITY:
+                AtlasEntityDef retrievedAtlasEntityDef = (AtlasEntityDef) retrievedAtlasTypeDef;
+                EntityDef returnableEntityDef;
+                try {
+                    AtlasEntityDefMapper atlasEntityDefMapper = new AtlasEntityDefMapper(this, userId, retrievedAtlasEntityDef);
+                    returnableEntityDef = atlasEntityDefMapper.toOMEntityDef();
+                    returnableTypeDef = returnableEntityDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            case RELATIONSHIP:
+                AtlasRelationshipDef retrievedAtlasRelationshipDef = (AtlasRelationshipDef) retrievedAtlasTypeDef;
+                RelationshipDef returnableRelationshipDef;
+                try {
+                    AtlasRelationshipDefMapper atlasRelationshipDefMapper = new AtlasRelationshipDefMapper(this, userId, retrievedAtlasRelationshipDef);
+                    returnableRelationshipDef = atlasRelationshipDefMapper.toOMRelationshipDef();
+                    returnableTypeDef = returnableRelationshipDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            case CLASSIFICATION:
+                AtlasClassificationDef retrievedAtlasClassificationDef = (AtlasClassificationDef) retrievedAtlasTypeDef;
+                ClassificationDef returnableClassificationDef;
+                try {
+                    AtlasClassificationDefMapper atlasClassificationDefMapper = new AtlasClassificationDefMapper(this, userId, retrievedAtlasClassificationDef);
+                    returnableClassificationDef = atlasClassificationDefMapper.toOMClassificationDef();
+                    returnableTypeDef = returnableClassificationDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            default:
+                LOG.debug("addTypeDef: cannot convert an OM TypeDef with category {}", category);
+                fatalError = true;
+        }
+
+        if (fatalError || returnableTypeDef == null) {
+
+            LOG.error("addTypeDef: could not initialise mapper or convert retrieved AtlasBaseTypeDef {} to OM TypeDef", newTypeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("TypeDef", "addTypeDef", metadataCollectionId);
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "addTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== addTypeDef(userId={}, newTypeDef={})", userId, returnableTypeDef);
+        }
+
+    }
+
+
+    /**
+     * Create a definition of a new AttributeTypeDef.
+     *
+     * @param userId              - unique identifier for requesting user.
+     * @param newAttributeTypeDef - TypeDef structure describing the new TypeDef.
+     * @throws InvalidParameterException    - the new TypeDef is null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws TypeDefNotSupportedException - the repository is not able to support this TypeDef.
+     * @throws TypeDefKnownException        - the TypeDef is already stored in the repository.
+     * @throws TypeDefConflictException     - the new TypeDef conflicts with an existing TypeDef.
+     * @throws InvalidTypeDefException      - the new TypeDef has invalid contents.
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public void addAttributeTypeDef(String           userId,
+                                    AttributeTypeDef newAttributeTypeDef)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotSupportedException,
+            TypeDefKnownException,
+            TypeDefConflictException,
+            InvalidTypeDefException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> addAttributeTypeDef(userId={}, newAttributeTypeDef={})", userId, newAttributeTypeDef);
+        }
+
+        final String  methodName           = "addAttributeTypeDef";
+        final String  typeDefParameterName = "newAttributeTypeDef";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAttributeTypeDef(repositoryName, typeDefParameterName, newAttributeTypeDef, methodName);
+        repositoryValidator.validateUnknownAttributeTypeDef(repositoryName, typeDefParameterName, newAttributeTypeDef, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         *  Given an OM AttributeTypeDef - convert it to corresponding AtlasAttributeDef
+         *
+         *  If asked to create a Primitive or Collection there is not really a corresponding Atlas type, so
+         *  need to detect whether we are creating an Enum... otherwise no action.
+         *
+         * Approach:
+         * Get the category of OM AttributeTypeDef, then depending on category instantiate the corresponding
+         * AtlasAttributeDef
+         *
+         *  AttributeTypeDefCategory category        --> switch between Atlas cases and CTOR will set Atlas category
+         *  The category is one of: UNKNOWN_DEF, PRIMITIVE, COLLECTION, ENUM_DEF
+         *   String                   guid            --> IGNORED
+         *   String                   name            --> Atlas name
+         *   String                   description     --> Atlas description
+         *   String                   descriptionGUID --> IGNORED (these are always set to null for now)
+         *
+         */
+
+
+        // Create an empty AtlasTypesDef container for whatever we convert below..
+        AtlasTypesDef atlasTypesDef = new AtlasTypesDef();
+
+        AttributeTypeDefCategory category = newAttributeTypeDef.getCategory();
+
+        if (category == ENUM_DEF) {
+            EnumDef omEnumDef = (EnumDef) newAttributeTypeDef;
+            // Building an AtlasEnumDef we need all the fields of the AtlasBaseTypeDef plus the
+            // AtlasEnumDef specific extensions, i.e.
+            // TypeCategory category; --> set by CTOR
+            // String  guid           --> set from OM guid
+            // String  createdBy      --> set to user
+            // String  updatedBy      --> set to user
+            // Date    createTime     --> set to NOW
+            // Date    updateTime     --> set to NOW
+            // Long    version        --> set to 1     - this is the initial create
+            // String  name;          --> set from OM name
+            // String  description;   --> set from OM description
+            // String  typeVersion;   --> set to "1"
+            // Map<String, String> options;  --> set to null
+            // List<AtlasEnumElementDef> elementDefs;  --> set from OM elementDefs
+            // String                    defaultValue;  --> set from OM defaultValue
+            //
+            // The OM EnumDef provides
+            // AttributeTypeDefCategory category
+            // String                   guid
+            // String                   name
+            // String                   description
+            // String                   descriptionGUID --> IGNORED
+            // ArrayList<EnumElementDef> elementDefs
+            // EnumElementDef            defaultValue
+            //
+
+            AtlasEnumDef atlasEnumDef = new AtlasEnumDef();
+            atlasEnumDef.setGuid(omEnumDef.getGUID());
+            atlasEnumDef.setCreatedBy(userId);
+            atlasEnumDef.setUpdatedBy(userId);
+            Date now = new Date();
+            atlasEnumDef.setCreateTime(now);
+            atlasEnumDef.setUpdateTime(now);
+            atlasEnumDef.setVersion(1L);
+            atlasEnumDef.setName(omEnumDef.getName());
+            atlasEnumDef.setDescription(omEnumDef.getDescription());
+            atlasEnumDef.setTypeVersion("1");
+            atlasEnumDef.setOptions(null);
+            // EnumElements
+            List<AtlasEnumDef.AtlasEnumElementDef> atlasElemDefs = null;
+            List<EnumElementDef> omEnumElems = omEnumDef.getElementDefs();
+            if (omEnumElems != null && !(omEnumElems.isEmpty())) {
+                atlasElemDefs = new ArrayList<>();
+                for (EnumElementDef omElemDef : omEnumDef.getElementDefs()) {
+                    AtlasEnumDef.AtlasEnumElementDef atlasElemDef = new AtlasEnumDef.AtlasEnumElementDef();
+                    atlasElemDef.setValue(omElemDef.getValue());
+                    atlasElemDef.setDescription(omElemDef.getDescription());
+                    atlasElemDef.setOrdinal(omElemDef.getOrdinal());
+                    atlasElemDefs.add(atlasElemDef);
+                }
+            }
+            atlasEnumDef.setElementDefs(atlasElemDefs);
+            // Default value
+            EnumElementDef omDefaultValue = omEnumDef.getDefaultValue();
+            LOG.debug("addAttributeTypeDef: omDefaultValue {}",omDefaultValue);
+            if (omDefaultValue != null) {
+                atlasEnumDef.setDefaultValue(omDefaultValue.getValue());
+                LOG.debug("addAttributeTypeDef: Atlas default value set to {}",atlasEnumDef.getDefaultValue());
+            }
+
+            LOG.debug("addAttributeTypeDef: create AtlasEnumDef {}",atlasEnumDef);
+
+            // Add the AtlasEnumDef to the AtlasTypesDef so it can be added to the TypeDefStore...
+            atlasTypesDef.getEnumDefs().add(atlasEnumDef);
+
+            // Add the AtlasTypesDef to the typeDefStore.
+            // To do this we need to put the EntityDef into an AtlasTypesDef
+            LOG.debug("addAttributeTypeDef: create Atlas types {}",atlasTypesDef);
+            try {
+                typeDefStore.createTypesDef(atlasTypesDef);
+
+            } catch (AtlasBaseException e) {
+
+                LOG.error("addAttributeTypeDef: caught exception from Atlas, error code {}",e);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_TYPEDEF_CREATE_FAILED;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasEnumDef.toString(), methodName, repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());}
+        }
+        else {
+            LOG.debug("addAttributeTypeDef: category is {}, so no action needed", category);
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== addAttributeTypeDef(userId={}, newAttributeTypeDef={})", userId, newAttributeTypeDef);
+        }
+
+    }
+
+    /**
+     * Verify whether a definition of a TypeDef is known. The method tests whether a type with the
+     * specified name is known and whether that type matches the presented type, in which case the
+     * it is verified and returns true.
+     * If the type (name) is not known the method returns false.
+     * If the type name is one of the Famous Five then convert the name to extended form. If the
+     * extended type does not exist return false, to promote an addTypeDef(). During the add
+     * the name is again converted so that the extended type is added.
+     * If the type is not valid or conflicts with an existing type (of the same name) then the
+     * method throws the relevant exception.
+     *
+     * @param userId  - unique identifier for requesting user.
+     * @param typeDef - TypeDef structure describing the TypeDef to test.
+     * @return boolean - true means the TypeDef matches the local definition - false means the TypeDef is not known.
+     * @throws InvalidParameterException    - the TypeDef is null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws TypeDefNotSupportedException - the repository is not able to support this TypeDef.
+     * @throws TypeDefConflictException     - the new TypeDef conflicts with an existing TypeDef.
+     * @throws InvalidTypeDefException      - the new TypeDef has invalid contents.
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public boolean verifyTypeDef(String   userId,
+                                 TypeDef  typeDef)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotSupportedException,
+            TypeDefConflictException,
+            InvalidTypeDefException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> verifyTypeDef(userId={}, typeDef={})", userId, typeDef);
+        }
+
+        final String  methodName           = "verifyTypeDef";
+        final String  typeDefParameterName = "typeDef";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDef(repositoryName, typeDefParameterName, typeDef, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        String typeName = typeDef.getName();
+
+        /*
+         * Validate the status fields in the passed TypeDef
+         */
+        boolean statusFieldsValid = validateStatusFields(typeDef);
+        if (!statusFieldsValid) {
+            // We cannot accept this typedef because it contains status fields that cannot be modelled by Atlas
+            LOG.error("verifyTypeDef: The TypeDef with name {}, initialStatus {} and validInstanceStatusList {} could not be modelled in Atlas", typeName, typeDef.getInitialStatus(), typeDef.getValidInstanceStatusList());
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, typeDef.getGUID(), typeDefParameterName, methodName, repositoryName, typeDef.toString());
+            throw new TypeDefNotSupportedException(
+                    errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+
+        boolean ret = false;
+        boolean conflict = false;
+        TypeDef existingTypeDef;
+
+        // Verify whether the supplied TypeDef is known in the cache.
+
+        TypeDefCategory tdCat = typeDef.getCategory();
+        switch (tdCat) {
+
+            case ENTITY_DEF:
+                /*
+                 * If the type name matches one of the Famous Five then convert the name to extended form.
+                 * It is the extended type that we must look for in the repo. If the extended type does not
+                 * exist then return false. This will provoke an addTypeDef (of the same type) which will
+                 * allow us to create an extended type in Atlas.
+                 * If the extended type does exist then convert it back prior to the compare.
+                 *
+                 */
+
+                String typeNameToLookFor = typeName;
+                if (FamousFive.omTypeRequiresSubstitution(typeName)) {
+                    LOG.debug("verifyTypeDef: type name {} requires substitution - returning false", typeName);
+                    typeNameToLookFor = FamousFive.getAtlasTypeName(typeName, typeDef.getGUID());
+                }
+
+                // Ask Atlas...
+                try {
+                    existingTypeDef = _getTypeDefByName(userId, typeNameToLookFor);
+                }
+                catch (TypeDefNotKnownException e) {
+                    // Handle below
+                    existingTypeDef = null;
+                }
+                if (existingTypeDef == null) {
+                    // Log using both the original typeName and extended name where different
+                    if (typeNameToLookFor.equals(typeName))
+                        LOG.debug("verifyTypeDef: no existing TypeDef with name {}", typeName);
+                    else
+                        LOG.debug("verifyTypeDef: requested TypeDef name {} mapped to name {} which is not in the repo, ", typeName, typeNameToLookFor);
+                    ret = false;
+                }
+                else if (existingTypeDef.getCategory() == ENTITY_DEF) {
+                    EntityDef existingEntityDef = (EntityDef) existingTypeDef;
+                    LOG.debug("verifyTypeDef: existing EntityDef: {}", existingEntityDef);
+
+                    // The definition is not new - compare the existing def with the one passed
+                    // A compare will be too strict - instead use an equivalence check...
+                    Comparator comp = new Comparator();
+                    EntityDef passedEntityDef = (EntityDef) typeDef;
+                    LOG.debug("verifyTypeDef: new typedef: {}", passedEntityDef);
+                    boolean match = comp.equivalent(existingEntityDef, passedEntityDef);
+                    LOG.debug("verifyTypeDef: equivalence result {}", match);
+                    if (match) {
+                        // The definition is known and matches - return true
+                        ret = true;
+                    }
+                    else {
+                        conflict = true;
+                    }
+                }
+                else {
+                    conflict = true;
+                }
+                break;
+
+            case RELATIONSHIP_DEF:
+                // Ask Atlas...
+                try {
+                    existingTypeDef = _getTypeDefByName(userId, typeName);
+                }
+                catch (TypeDefNotKnownException e) {
+                    // Handle below
+                    existingTypeDef = null;
+                }
+                if (existingTypeDef == null) {
+                    LOG.debug("verifyTypeDef: no existing TypeDef with name {}", typeName);
+                    ret = false;
+                }
+                else if (existingTypeDef.getCategory() == RELATIONSHIP_DEF) {
+                    RelationshipDef existingRelationshipDef = (RelationshipDef) existingTypeDef;
+                    LOG.debug("verifyTypeDef: existing RelationshipDef: {}", existingRelationshipDef);
+
+                    // The definition is not new - compare the existing def with the one passed
+                    // A compare will be too strict - instead use an equivalence check...
+                    Comparator comp = new Comparator();
+                    RelationshipDef passedRelationshipDef = (RelationshipDef) typeDef;
+                    LOG.debug("verifyTypeDef: new typedef: {}", passedRelationshipDef);
+                    boolean match = comp.equivalent(existingRelationshipDef, passedRelationshipDef);
+                    LOG.debug("verifyTypeDef: equivalence result {}", match);
+                    if (match) {
+                        // The definition is known and matches - return true
+                        ret = true;
+                    }
+                    else {
+                        conflict = true;
+                    }
+                }
+                else {
+                    conflict = true;
+                }
+                break;
+
+            case CLASSIFICATION_DEF:
+                // Ask Atlas...
+                try {
+                    existingTypeDef = _getTypeDefByName(userId, typeName);
+                }
+                catch (TypeDefNotKnownException e) {
+                    // Handle below
+                    existingTypeDef = null;
+                }
+                if (existingTypeDef == null) {
+                    LOG.debug("verifyTypeDef: no existing TypeDef with name {}", typeName);
+                    ret = false;
+                }
+                else if (existingTypeDef.getCategory() == CLASSIFICATION_DEF) {
+                    ClassificationDef existingClassificationDef = (ClassificationDef) existingTypeDef;
+                    LOG.debug("verifyTypeDef: existing ClassificationDef: {}", existingClassificationDef);
+
+                    // The definition is not new - compare the existing def with the one passed
+                    // A compare will be too strict - instead use an equivalence check...
+                    Comparator comp = new Comparator();
+                    ClassificationDef passedClassificationDef = (ClassificationDef) typeDef;
+                    LOG.debug("verifyTypeDef: new typedef: {}", passedClassificationDef);
+                    boolean match = comp.equivalent(existingClassificationDef, passedClassificationDef);
+                    LOG.debug("verifyTypeDef: equivalence result {}", match);
+                    if (match) {
+                        // The definition is known and matches - return true
+                        ret = true;
+                    }
+                    else {
+                        conflict = true;
+                    }
+                }
+                else {
+                    conflict = true;
+                }
+                break;
+
+            default:
+                // The typedef category is not supported - raise an exception
+                LOG.error("verifyTypeDef: The supplied TypeDef with name {} has an unsupported category {}",typeName, tdCat);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_TYPEDEF_CATEGORY;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(tdCat.toString(), typeDef.toString(), methodName, repositoryName);
+
+                throw new TypeDefNotSupportedException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+
+
+        if (conflict) {
+            // The definition is known but conflicts - raise an exception
+            // The typeDef was known but conflicted in some way with the existing type - raise an exception
+            LOG.error("verifyTypeDef: The TypeDef with name {} conflicts with an existing type {}", typeName, existingTypeDef);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, typeDef.getGUID(), typeDefParameterName, methodName, repositoryName, typeDef.toString());
+            throw new TypeDefConflictException(
+                    errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== verifyTypeDef(userId={}, typeDef={}): ret={}", userId, typeDef, ret);
+        }
+        return ret;
+    }
+
+    /**
+     * Verify whether a definition of an AttributeTypeDef is known. The method tests whether a type with the
+     * specified name is known and whether that type matches the presented type, in which case the
+     * it is verified and returns true.
+     * If the type (name) is not known the method returns false.
+     * If the type name is one of the Famous Five then return false, to provoke an addTypeDef().
+     * If the type is not valid or conflicts with an existing type (of the same name) then the
+     * method throws the relevant exception.
+     *
+     * @param userId           - unique identifier for requesting user.
+     * @param attributeTypeDef - TypeDef structure describing the TypeDef to test.
+     * @return boolean - true means the TypeDef matches the local definition - false means the TypeDef is not known.
+     * @throws InvalidParameterException    - the TypeDef is null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws TypeDefNotSupportedException - the repository is not able to support this TypeDef.
+     * @throws TypeDefConflictException     - the new TypeDef conflicts with an existing TypeDef.
+     * @throws InvalidTypeDefException      - the new TypeDef has invalid contents.
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public boolean verifyAttributeTypeDef(String           userId,
+                                          AttributeTypeDef attributeTypeDef)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotSupportedException,
+            TypeDefConflictException,
+            InvalidTypeDefException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> verifyAttributeTypeDef(userId={}, typeDef={})", userId, attributeTypeDef);
+        }
+
+        final String  methodName           = "verifyAttributeTypeDef";
+        final String  typeDefParameterName = "attributeTypeDef";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAttributeTypeDef(repositoryName, typeDefParameterName, attributeTypeDef, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Clear the per-API records of TypeDefs
+        typeDefsForAPI = new TypeDefsByCategory();
+
+        /*
+         * If a PRIMITIVE or COLLECTION (MAP or ARRAY) then return false to trigger an immediate
+         * addAttributeTypeDef(). We will then add the ATD with the specified GUID.
+         * The benefit of this is that the LocalConnector then populates the RCM with the OM types
+         * instead of the AtlasConnector fabricating them.
+         * If we are dealing with an ENUM then we need to do more work. Note that in Atlas an
+         * ENUM is a Type whereas in OM it is an Attribute Type.
+         */
+        boolean ret = false;
+        String atdName = attributeTypeDef.getName();
+        AttributeTypeDefCategory atdCat = attributeTypeDef.getCategory();
+        switch (atdCat) {
+
+            case PRIMITIVE:
+                LOG.debug("verifyAttributeTypeDef: supplied AttributeTypeDef has category PRIMITIVE - returning false");
+                ret = false;
+                break;
+
+            case COLLECTION:
+                LOG.debug("verifyAttributeTypeDef: supplied AttributeTypeDef has category COLLECTION - returning false");
+                ret = false;
+                break;
+
+            case ENUM_DEF:
+                boolean conflict = false;
+                LOG.debug("verifyAttributeTypeDef: supplied AttributeTypeDef has category ENUM_DEF - checking for existence");
+                // Look in Atlas to see whether we have an ENUM of this name and if so
+                // perform a comparison.
+                AttributeTypeDef existingATD;
+                try {
+                    existingATD = _getAttributeTypeDefByName(userId, atdName);
+                }
+                catch (TypeDefNotKnownException e) {
+                    // handle below
+                    existingATD = null;
+                }
+                if (existingATD == null) {
+                    LOG.debug("verifyAttributeTypeDef: no existing enum def with the name {}", atdName);
+                    ret = false;
+                }
+                else if (existingATD.getCategory() == ENUM_DEF) {
+                    EnumDef existingEnumDef = (EnumDef) existingATD;
+                    LOG.debug("verifyAttributeTypeDef: existing enum def: {}", existingEnumDef);
+
+                    // The definition is not new - compare the existing def with the one passed
+                    // A compare will be too strict - instead use an equivalence check...
+                    Comparator comp = new Comparator();
+                    EnumDef passedEnumDef = (EnumDef) attributeTypeDef;
+                    LOG.debug("verifyAttributeTypeDef: new enum def: {}", passedEnumDef);
+                    boolean match = comp.equivalent(existingEnumDef, passedEnumDef);
+                    LOG.debug("verifyAttributeTypeDef: equivalence result: {}", match);
+                    if (match) {
+                        // The definition is known and matches - return true
+                        ret = true;
+                    }
+                    else {
+                        conflict = true;
+                    }
+                }
+                else {
+                    conflict = true;
+                }
+                if (conflict) {
+                    // The typeDef was known but conflicted in some way with the existing type - raise an exception
+                    LOG.error("verifyAttributeTypeDef: The supplied AttributeTypeDef conflicts with an existing type with name {}", atdName);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("typeDef", methodName, repositoryName);
+
+                    throw new TypeDefConflictException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+
+                break;
+
+            case UNKNOWN_DEF:
+                LOG.error("verifyAttributeTypeDef: The supplied AttributeTypeDef {} has unsupported category {}", atdName, atdCat);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ATTRIBUTE_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("typeDef", methodName, repositoryName);
+
+                throw new TypeDefConflictException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== verifyAttributeTypeDef(userId={}, typeDef={}): ret={}", userId, attributeTypeDef, ret);
+        }
+        return ret;
+
+    }
+
+    /**
+     * Update one or more properties of the TypeDef.  The TypeDefPatch controls what types of updates
+     * are safe to make to the TypeDef.
+     *
+     * @param userId       - unique identifier for requesting user.
+     * @param typeDefPatch - TypeDef patch describing change to TypeDef.
+     * @return updated TypeDef
+     * @throws InvalidParameterException  - the TypeDefPatch is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested TypeDef is not found in the metadata collection.
+     * @throws PatchErrorException        - the TypeDef can not be updated because the supplied patch is incompatible
+     *                                    with the stored TypeDef.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDef updateTypeDef(String       userId,
+                                 TypeDefPatch typeDefPatch)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            PatchErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName           = "updateTypeDef";
+        final String  typeDefParameterName = "typeDefPatch";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefPatch(repositoryName, typeDefPatch, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        /*
+         * A TypeDefPatch describes a change (patch) to a typeDef's properties, options, external
+         * standards mappings or list of valid instance statuses.
+         * A patch can be applied to an EntityDef, RelationshipDef or ClassificationDef.
+         * Changes to a TypeDef's category or superclasses requires a new type definition.
+         * In addition it is not possible to delete an attribute through a patch.
+         *
+         * The TypeDefPatch contains:
+         *
+         *   TypeDefPatchAction                 action
+         *   String                             typeDefGUID
+         *   String                             typeName
+         *   long                               applyToVersion
+         *   long                               updateToVersion
+         *   String                             newVersionName
+         *   String                             description
+         *   String                             descriptionGUID
+         *   ArrayList<TypeDefAttribute>        typeDefAttributes
+         *   Map<String, String>                typeDefOptions
+         *   ArrayList<ExternalStandardMapping> externalStandardMappings
+         *   ArrayList<InstanceStatus>          validInstanceStatusList    - note that no action is defined for this
+         *
+         * The validateTypeDefPatch above merely checks the patch is not null. Within the patch itself
+         * some fields are always mandatory and the presence of others depend on the action being performed.
+         * Mandatory fields: action, typeDefGUID, typeName, applyToVersion, updateToVersion, newVersionName
+         * Remaining fields are optional, subject to action (e.g. if add_options then options are needed)
+         *
+         * The TypeDefPatchAction can be one of:
+         *  ADD_ATTRIBUTES                    ==> typeDefAttributes must be supplied
+         *  ADD_OPTIONS                       ==> typeDefOptions must be supplied
+         *  UPDATE_OPTIONS                    ==> typeDefOptions must be supplied
+         *  DELETE_OPTIONS                    ==> typeDefOptions must be supplied
+         *  ADD_EXTERNAL_STANDARDS            ==> externalStandardMappings must be supplied
+         *  UPDATE_EXTERNAL_STANDARDS         ==> externalStandardMappings must be supplied
+         *  DELETE_EXTERNAL_STANDARDS         ==> externalStandardMappings must be supplied
+         *  UPDATE_DESCRIPTIONS               ==> description must be supplied; descriptionGUID is optional
+         */
+
+        /*
+         * Versions
+         *
+         * The applyToVersion field in the TypeDefPatch is optional.
+         * The Atlas Connector can only retrieve the TypeDef by GUID or name, not by version.
+         * The returned TypeDef is assumed to be the current/active version and if applyToVersion
+         * is specified (!= 0L) the connector will check that it matches the retrieved TypeDef
+         * and throw an exception if it does not match.
+         * If applyToVersion is not specified (== 0L) then the patch will be applied to the
+         * current (retrieved) TypeDef.
+         *
+         * The updateToVersion and newVersionName fields in the TypeDefPatch are optional.
+         * If updateToVersion and/or newVersionName are not supplied the connector can generate
+         * values for them (in the updated TypeDef) because the updated TypeDef is returned to
+         * the caller (i.e. LocalOMRSMetadataCollection) which then updates the RepositoryContentManager
+         * (RCM). The new version information generated by the connector will therefore be reflected in
+         * the RCM.
+         */
+
+        /*
+         * Identification
+         * This method can tolerate either typeDefGUID OR typeName being absent, but not both.
+         */
+        String typeDefGUID   = typeDefPatch.getTypeDefGUID();
+        String typeName      = typeDefPatch.getTypeName();
+        if ( typeDefGUID == null && typeName == null )  {
+
+            LOG.error("updateTypeDef: At least one of typeDefGUID and typeName must be supplied");
+
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeDefParameterName, methodName, repositoryName);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        /*
+         * Find the TypeDef - as described above this will only get the 'current' version.
+         * Check the retrieved version matches the applyToVersion, if specified.
+         * Perform the requested action.
+         */
+        AtlasBaseTypeDef atlasPreTypeDef;
+        try {
+            // Find the TypeDef
+            if (typeDefGUID != null) {
+                if (!useRegistry) {
+                    // Look in the Atlas type def store
+                    atlasPreTypeDef = typeDefStore.getByGuid(typeDefGUID);
+                }
+                else {
+                    // Using registry
+                    atlasPreTypeDef = typeRegistry.getTypeDefByGuid(typeDefGUID);
+                }
+            }
+            else { // we know that typeName != null
+
+                if (!useRegistry) {
+                    // Look in the Atlas type def store
+                    atlasPreTypeDef = typeDefStore.getByName(typeName);
+                }
+                else {
+                    // Using registry
+                    atlasPreTypeDef = typeRegistry.getTypeDefByName(typeName);
+                }
+            }
+
+        } catch (AtlasBaseException e) {
+
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                LOG.debug("_getAttributeTypeDefByName: Atlas does not have the type with name {} ", typeName);
+                // The TypeDef was not found - ensure atlasPreTypeDef is null, exception to be handled below
+                atlasPreTypeDef = null;
+
+            } else {
+
+                LOG.error("_getAttributeTypeDefByName: Caught exception trying to retrieve Atlas type with name {} ", typeName, e);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getAttributeTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        // Separate null check ensures we have covered both cases (registry and store)
+        if (atlasPreTypeDef == null) {
+
+            LOG.error("_getAttributeTypeDefByName: received null return from Atlas getByName using name {}", typeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, "unknown", "name", "_getAttributeTypeDefByName", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getAttributeTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // From here on we know that atlasPreTypeDef is not null
+
+        // Check the version
+        Long applyToVersion = typeDefPatch.getApplyToVersion();
+        Long preTypeDefVersion = atlasPreTypeDef.getVersion();
+        if (applyToVersion != 0L && !applyToVersion.equals(preTypeDefVersion) ) {
+
+            LOG.error("updateTypeDef: Retrieved TypeDef version {} does not match version {} specified in patch", preTypeDefVersion, applyToVersion);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeName, typeDefGUID, typeDefParameterName, methodName, repositoryName, typeDefPatch.toString());
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Convert the Atlas TypeDef to an OM TypeDef
+        // We are only concerned with EntityDef, RelationshipDef and ClassificationDef TypeDefs
+        TypeDef omPreTypeDef = null;
+        boolean fatalError = false;
+        TypeCategory atlasCategory = atlasPreTypeDef.getCategory();
+        switch (atlasCategory) {
+
+            case ENTITY:
+                AtlasEntityDef retrievedAtlasEntityDef = (AtlasEntityDef) atlasPreTypeDef;
+                AtlasEntityDefMapper atlasEntityDefMapper;
+                EntityDef returnableEntityDef;
+                try {
+                    atlasEntityDefMapper = new AtlasEntityDefMapper(this, userId, retrievedAtlasEntityDef);
+                    returnableEntityDef = atlasEntityDefMapper.toOMEntityDef();
+                    omPreTypeDef = returnableEntityDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            case RELATIONSHIP:
+                AtlasRelationshipDef retrievedAtlasRelationshipDef = (AtlasRelationshipDef) atlasPreTypeDef;
+                AtlasRelationshipDefMapper atlasRelationshipDefMapper;
+                RelationshipDef returnableRelationshipDef;
+                try {
+                    atlasRelationshipDefMapper = new AtlasRelationshipDefMapper(this, userId, retrievedAtlasRelationshipDef);
+                    returnableRelationshipDef = atlasRelationshipDefMapper.toOMRelationshipDef();
+                    omPreTypeDef = returnableRelationshipDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            case CLASSIFICATION:
+                AtlasClassificationDef retrievedAtlasClassificationDef = (AtlasClassificationDef) atlasPreTypeDef;
+                AtlasClassificationDefMapper atlasClassificationDefMapper;
+                ClassificationDef returnableClassificationDef;
+                try {
+                    atlasClassificationDefMapper = new AtlasClassificationDefMapper(this, userId, retrievedAtlasClassificationDef);
+                    returnableClassificationDef = atlasClassificationDefMapper.toOMClassificationDef();
+                    omPreTypeDef = returnableClassificationDef;
+                } catch (Exception e) {
+                    fatalError = true;
+                }
+                break;
+
+            default:
+                LOG.debug("updateTypeDef: cannot convert an OM TypeDef with category {}", atlasCategory);
+                fatalError = true;
+        }
+
+        if (fatalError || omPreTypeDef == null) {
+
+            LOG.error("updateTypeDef: could not initialise mapper or convert retrieved AtlasBaseTypeDef {} to OM TypeDef", atlasPreTypeDef.getName());
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("TypeDef", "updateTypeDef", metadataCollectionId);
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "updateTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Now have established an omPreTypeDef to which action can be performed...
+        LOG.debug("updateTypeDef: AtlasEntityDef mapped to OM TypeDef {}", omPreTypeDef);
+
+
+        // Perform the requested action
+        TypeDef omPostTypeDef;
+        switch (typeDefPatch.getAction()) {
+            case ADD_OPTIONS:
+                omPostTypeDef = updateTypeDefAddOptions(omPreTypeDef, typeDefPatch.getTypeDefOptions());
+                break;
+            case DELETE_OPTIONS:
+                omPostTypeDef = updateTypeDefDeleteOptions(omPreTypeDef, typeDefPatch.getTypeDefOptions());
+                break;
+            case UPDATE_OPTIONS:
+                omPostTypeDef = updateTypeDefUpdateOptions(omPreTypeDef, typeDefPatch.getTypeDefOptions());
+                break;
+            case ADD_ATTRIBUTES:
+                omPostTypeDef = updateTypeDefAddAttributes(omPreTypeDef, typeDefPatch.getTypeDefAttributes());
+                break;
+            case UPDATE_DESCRIPTIONS:
+                omPostTypeDef = updateTypeDefUpdateDescriptions(omPreTypeDef, typeDefPatch.getDescription(), typeDefPatch.getDescriptionGUID());
+                break;
+            case ADD_EXTERNAL_STANDARDS:
+                omPostTypeDef = updateTypeDefAddExternalStandards(omPreTypeDef, typeDefPatch.getExternalStandardMappings());
+                break;
+            case DELETE_EXTERNAL_STANDARDS:
+                omPostTypeDef = updateTypeDefDeleteExternalStandards(omPreTypeDef, typeDefPatch.getExternalStandardMappings());
+                break;
+            case UPDATE_EXTERNAL_STANDARDS:
+                omPostTypeDef = updateTypeDefUpdateExternalStandards(omPreTypeDef, typeDefPatch.getExternalStandardMappings());
+                break;
+            // There maybe should be instance status actions too, but these are not yet defined (see TypeDefPatchAction)
+            default:
+                LOG.error("updateTypeDef: TypeDefPatch action {} is not recognised", typeDefPatch.getAction());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, typeDefGUID, typeDefParameterName, methodName, repositoryName, typeDefPatch.toString());
+
+                throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+
+        LOG.error("updateTypeDef: omPostTypeDef {} ", omPostTypeDef);
+
+        /*
+         * Convert the updated OM TypeDef to Atlas TypeDef and update in Atlas, read it back and convert to OM.
+         * The write-through and read-back is so that we pick up any Atlas initializations, e.g. of
+         * fields like createdBy, description (if originally null), etc.
+         */
+
+
+        /*
+         * Depending on OM TypeDef category, perform the corresponding Atlas update, which will be for one of
+         * AtlasEntityDef, AtlasRelationshipDef or AtlasClassificationDef
+         */
+
+        AtlasBaseTypeDef retrievedAtlasTypeDef = null;
+        try {
+
+            TypeDefCategory category = omPostTypeDef.getCategory();
+            LOG.debug("updateTypeDef: convert and store updated OM TypeDef with guid {} and category {}", typeDefGUID, category);
+            switch (category) {
+
+                case ENTITY_DEF:
+                    // convertOMEntityDefToAtlasEntityDef will detect a Famous Five type and convert accordingly.
+                    AtlasEntityDef atlasEntityDef = convertOMEntityDefToAtlasEntityDef((EntityDef) omPostTypeDef);
+                    if (atlasEntityDef != null) {
+                        LOG.debug("updateTypeDef: Call Atlas updateEntityDefByGuid with guid {} entity {}", typeDefGUID, atlasEntityDef);
+                        retrievedAtlasTypeDef = typeDefStore.updateEntityDefByGuid(typeDefGUID, atlasEntityDef);
+                        if (retrievedAtlasTypeDef == null)
+                            throw new AtlasBaseException();
+                    }
+                    break;
+
+                case RELATIONSHIP_DEF:
+                    try {
+                        AtlasRelationshipDef atlasRelationshipDef = convertOMRelationshipDefToAtlasRelationshipDef((RelationshipDef) omPostTypeDef);
+                        if (atlasRelationshipDef != null) {
+                            LOG.debug("updateTypeDef: Call Atlas updateEntityDefByGuid with guid {} entity {}", typeDefGUID, atlasRelationshipDef);
+                            retrievedAtlasTypeDef = typeDefStore.updateRelationshipDefByGuid(typeDefGUID, atlasRelationshipDef);
+                            if (retrievedAtlasTypeDef == null)
+                                throw new AtlasBaseException();
+                        }
+                    }
+                    catch (RepositoryErrorException | TypeErrorException e) {
+                        // Log the error and re-throw
+                        LOG.debug("updateTypeDef: caught exception from attempt to convert OM RelationshipDef to Atlas, name {}", omPostTypeDef.getName());
+                        OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage("TypeDef", "updateTypeDef", metadataCollectionId);
+
+                        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "updateTypeDef",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+                    break;
+
+                case CLASSIFICATION_DEF:
+                    AtlasClassificationDef atlasClassificationDef = convertOMClassificationDefToAtlasClassificationDef((ClassificationDef) omPostTypeDef);
+                    if (atlasClassificationDef != null) {
+                        LOG.debug("updateTypeDef: Call Atlas updateClassificationDefByGuid with guid {} entity {}", typeDefGUID, atlasClassificationDef);
+                        retrievedAtlasTypeDef = typeDefStore.updateClassificationDefByGuid(typeDefGUID, atlasClassificationDef);
+                        if (retrievedAtlasTypeDef == null)
+                            throw new AtlasBaseException();
+                    }
+                    break;
+
+                case UNKNOWN_DEF:
+                    LOG.error("updateTypeDef: cannot convert and update an OM TypeDef with category {}", category);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(typeName, typeDefGUID, typeDefParameterName, methodName, repositoryName, typeDefPatch.toString());
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "updateTypeDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+            }
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("updateTypeDef: exception from store and retrieve AtlasTypesDef {}", e);
+
+            // I'm not sure how to differentiate between the different causes of AtlasBaseException
+            // e.g. if there were an authorization exception it is not clear how to tell that
+            // in order to throw the correct type of exception. I think that for now if we get an
+            // AtlasBaseException we will always throw RepositoryErrorException
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("TypeDef", "updateTypeDef", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "updateTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Convert the retrieved Atlas Type into an OM TypeDef to be returned
+         */
+        TypeDef returnableTypeDef = null;
+        if (retrievedAtlasTypeDef != null) {
+            fatalError = false;
+            TypeCategory category = retrievedAtlasTypeDef.getCategory();
+            switch (category) {
+
+                case ENTITY:
+                    AtlasEntityDef retrievedAtlasEntityDef = (AtlasEntityDef) retrievedAtlasTypeDef;
+                    EntityDef returnableEntityDef;
+                    try {
+                        AtlasEntityDefMapper atlasEntityDefMapper = new AtlasEntityDefMapper(this, userId, retrievedAtlasEntityDef);
+                        returnableEntityDef = atlasEntityDefMapper.toOMEntityDef();
+                        returnableTypeDef = returnableEntityDef;
+                    } catch (Exception e) {
+                        fatalError = true;
+                    }
+                    break;
+
+                case RELATIONSHIP:
+                    AtlasRelationshipDef retrievedAtlasRelationshipDef = (AtlasRelationshipDef) retrievedAtlasTypeDef;
+                    RelationshipDef returnableRelationshipDef;
+                    try {
+                        AtlasRelationshipDefMapper atlasRelationshipDefMapper = new AtlasRelationshipDefMapper(this, userId, retrievedAtlasRelationshipDef);
+                        returnableRelationshipDef = atlasRelationshipDefMapper.toOMRelationshipDef();
+                        returnableTypeDef = returnableRelationshipDef;
+                    } catch (Exception e) {
+                        fatalError = true;
+                    }
+                    break;
+
+                case CLASSIFICATION:
+                    AtlasClassificationDef retrievedAtlasClassificationDef = (AtlasClassificationDef) retrievedAtlasTypeDef;
+                    ClassificationDef returnableClassificationDef;
+                    try {
+                        AtlasClassificationDefMapper atlasClassificationDefMapper = new AtlasClassificationDefMapper(this, userId, retrievedAtlasClassificationDef);
+                        returnableClassificationDef = atlasClassificationDefMapper.toOMClassificationDef();
+                        returnableTypeDef = returnableClassificationDef;
+                    } catch (Exception e) {
+                        fatalError = true;
+                    }
+                    break;
+
+                default:
+                    LOG.debug("updateTypeDef: cannot convert an OM TypeDef with category {}", category);
+                    fatalError = true;
+            }
+        }
+
+        if (fatalError || returnableTypeDef == null) {
+
+            LOG.error("updateTypeDef: could not initialise mapper or convert retrieved AtlasBaseTypeDef {} to OM TypeDef", typeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("TypeDef", "updateTypeDef", metadataCollectionId);
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "updateTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Finally return the retrieved, updated TypeDef
+        LOG.debug("updateTypeDef: Updated OM TypeDef {}", returnableTypeDef);
+        return returnableTypeDef;
+
+    }
+
+    /*
+     * Utility methods to update TypeDefs
+     */
+    private TypeDef updateTypeDefAddOptions(TypeDef typeDefToModify, Map<String, String> typeDefOptions) {
+        Map<String,String> updatedOptions = typeDefToModify.getOptions();
+        if (typeDefOptions != null) {
+            updatedOptions.putAll(typeDefOptions);
+        }
+        typeDefToModify.setOptions(updatedOptions);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefDeleteOptions(TypeDef typeDefToModify, Map<String, String> typeDefOptions) {
+        Map<String,String> updatedOptions = typeDefToModify.getOptions();
+        if (typeDefOptions != null) {
+            for (String s : typeDefOptions.keySet()) {
+                updatedOptions.remove(s);
+            }
+        }
+        typeDefToModify.setOptions(updatedOptions);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefUpdateOptions(TypeDef typeDefToModify, Map<String, String> typeDefOptions) {
+        typeDefToModify.setOptions(typeDefOptions);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefAddAttributes(TypeDef typeDefToModify, List<TypeDefAttribute> typeDefAttributes)
+        throws
+            PatchErrorException
+    {
+        final String methodName = "updateTypeDefAddAttributes";
+
+        List<TypeDefAttribute> updatedAttributes = typeDefToModify.getPropertiesDefinition();
+        // This operation must be additive only - check each attribute to be added does not already exist
+        if (typeDefAttributes != null) {
+            if (updatedAttributes == null) {
+                updatedAttributes = typeDefAttributes;
+            } else {
+                for (TypeDefAttribute tda : typeDefAttributes) {
+                    String newAttrName = tda.getAttributeName();
+                    boolean nameClash = false;
+                    for (TypeDefAttribute existingAttr : updatedAttributes ) {
+                        if (existingAttr.getAttributeName().equals(newAttrName)) {
+                            // There is a name clash - error
+                            nameClash = true;
+                            break;
+                        }
+                    }
+                    if (!nameClash) {
+                        // add the new attribute
+                        updatedAttributes.add(tda);
+                    }
+                    else {
+                        // exception
+                        LOG.error("updateTypeDef: Cannot add attribute {} because it already exists", newAttrName);
+                        OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(typeDefToModify.getName(), typeDefToModify.getGUID(), "typeDefToModify", methodName, repositoryName, typeDefToModify.toString());
+
+                        throw new PatchErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                "updateTypeDefAddAttributes",
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+
+                    }
+                }
+            }
+        }
+        typeDefToModify.setPropertiesDefinition(updatedAttributes);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefUpdateDescriptions(TypeDef typeDefToModify, String description, String descriptionGUID) {
+        typeDefToModify.setDescription(description);
+        typeDefToModify.setDescriptionGUID(descriptionGUID);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefAddExternalStandards(TypeDef typeDefToModify, List<ExternalStandardMapping> externalStandardMappings) {
+        List<ExternalStandardMapping> updatedExternalStandardMappings = typeDefToModify.getExternalStandardMappings();
+        if (externalStandardMappings != null) {
+            updatedExternalStandardMappings.addAll(externalStandardMappings);
+        }
+        typeDefToModify.setExternalStandardMappings(updatedExternalStandardMappings);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefDeleteExternalStandards(TypeDef typeDefToModify, List<ExternalStandardMapping> externalStandardMappings)
+        throws
+            PatchErrorException
+    {
+        final String methodName = "updateTypeDefDeleteExternalStandards";
+
+        List<ExternalStandardMapping> updatedExternalStandardMappings = typeDefToModify.getExternalStandardMappings();
+        if (externalStandardMappings != null) {
+            if (updatedExternalStandardMappings == null) {
+                // there are no existing mappings - exception
+                LOG.error("updateTypeDef: Cannot delete external standard mappings because none exist");
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeDefToModify.getName(), typeDefToModify.getGUID(), "typeDefToModify", methodName, repositoryName, typeDefToModify.toString());
+
+
+                throw new PatchErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "updateTypeDefAddAttributes",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+            else {
+                /*
+                 * There are existing mappings - find each mapping to be deleted and remove it from the list
+                 * Our definition of equality is that all 3 components of the ExternalStandardMapping must
+                 * match - the optional fields must be present and match or not be present in both objects,
+                 * so we just test equality including equality of null == null. Meanwhile, the mandatory field
+                 * must match. The test is therefore actually quite simple.
+                 */
+
+                // This loop is tolerant i.e it does not raise an error - if it does not find the mapping to delete
+                for (ExternalStandardMapping esm : externalStandardMappings) {
+                    // Find the corresponding member of the existing list
+                    for (ExternalStandardMapping existingESM : updatedExternalStandardMappings) {
+                        if (    existingESM.getStandardTypeName().equals(esm.getStandardTypeName()) &&
+                                existingESM.getStandardOrganization().equals(esm.getStandardOrganization()) &&
+                                existingESM.getStandardName().equals(esm.getStandardName()) ) {
+                            // matching entry found - remove the entry from the list
+                            updatedExternalStandardMappings.remove(existingESM);
+                            // no break - if there are multiple matching entries delete them all
+                        }
+                    }
+                }
+            }
+        }
+        typeDefToModify.setExternalStandardMappings(updatedExternalStandardMappings);
+        return typeDefToModify;
+    }
+
+    private TypeDef updateTypeDefUpdateExternalStandards(TypeDef typeDefToModify, List<ExternalStandardMapping> externalStandardMappings) {
+        typeDefToModify.setExternalStandardMappings(externalStandardMappings);
+        return typeDefToModify;
+    }
+
+
+
+
+    /**
+     * Delete the TypeDef.  This is only possible if the TypeDef has never been used to create instances or any
+     * instances of this TypeDef have been purged from the metadata collection.
+     *
+     * @param userId              - unique identifier for requesting user.
+     * @param obsoleteTypeDefGUID - String unique identifier for the TypeDef.
+     * @param obsoleteTypeDefName - String unique name for the TypeDef.
+     * @throws InvalidParameterException  - the one of TypeDef identifiers is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested TypeDef is not found in the metadata collection.
+     * @throws TypeDefInUseException      - the TypeDef can not be deleted because there are instances of this type in the
+     *                                    the metadata collection.  These instances need to be purged before the
+     *                                    TypeDef can be deleted.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void deleteTypeDef(String userId,
+                              String obsoleteTypeDefGUID,
+                              String obsoleteTypeDefName)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            TypeDefInUseException,
+            UserNotAuthorizedException
+    {
+        final String    methodName        = "deleteTypeDef";
+        final String    guidParameterName = "obsoleteTypeDefGUID";
+        final String    nameParameterName = "obsoleteTypeDefName";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                obsoleteTypeDefGUID,
+                obsoleteTypeDefName,
+                methodName);
+
+        /*
+         * Perform operation
+         */
+
+        TypeDef omTypeDefToDelete = null;
+        try {
+            /*
+             * Find the obsolete type def so that we know its category
+             *
+             */
+            omTypeDefToDelete = _getTypeDefByGUID(userId, obsoleteTypeDefGUID);
+
+            if (omTypeDefToDelete == null) {
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(guidParameterName,
+                        methodName,
+                        repositoryName);
+
+                throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            TypeDefCategory typeDefCategory = omTypeDefToDelete.getCategory();
+
+
+        /*
+         * Construct an AtlasTypesDef containing an Atlas converted copy of the OM TypeDef to be deleted then call the TypeDefStore
+         *
+         */
+            AtlasTypesDef atlasTypesDef = new AtlasTypesDef();
+            switch (typeDefCategory) {
+                case CLASSIFICATION_DEF:
+                    ClassificationDef classificationDefToDelete = (ClassificationDef) omTypeDefToDelete;
+                    AtlasClassificationDef atlasClassificationDef = convertOMClassificationDefToAtlasClassificationDef(classificationDefToDelete);
+                    List<AtlasClassificationDef> atlasClassificationDefs = atlasTypesDef.getClassificationDefs();
+                    atlasClassificationDefs.add(atlasClassificationDef);
+                    break;
+
+                case RELATIONSHIP_DEF:
+                    RelationshipDef relationshipDefToDelete = (RelationshipDef) omTypeDefToDelete;
+                    AtlasRelationshipDef atlasRelationshipDef = convertOMRelationshipDefToAtlasRelationshipDef(relationshipDefToDelete);
+                    List<AtlasRelationshipDef> atlasRelationshipDefs = atlasTypesDef.getRelationshipDefs();
+                    atlasRelationshipDefs.add(atlasRelationshipDef);
+                    break;
+
+                case ENTITY_DEF:
+                    EntityDef entityDefToDelete = (EntityDef) omTypeDefToDelete;
+                    AtlasEntityDef atlasEntityDef = convertOMEntityDefToAtlasEntityDef(entityDefToDelete);
+                    List<AtlasEntityDef> atlasEntityDefs = atlasTypesDef.getEntityDefs();
+                    atlasEntityDefs.add(atlasEntityDef);
+                    break;
+
+                default:
+                    LOG.error("deleteTypeDef: invalid typedef category {}", typeDefCategory);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(obsoleteTypeDefName, obsoleteTypeDefGUID, guidParameterName, methodName, repositoryName, omTypeDefToDelete.toString());
+
+                    throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+            }
+
+            /*
+             * Ask Atlas to perform the delete operation
+             */
+            typeDefStore.deleteTypesDef(atlasTypesDef);
+
+        }
+        catch (TypeErrorException  e) {
+            LOG.error("The retrieved TypeDef could not be converted to Atlas format", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteTypeDefName, obsoleteTypeDefGUID, guidParameterName, methodName, repositoryName, omTypeDefToDelete.toString());
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        catch (AtlasBaseException  e) {
+            LOG.error("The Atlas repository could not delete the TypeDef", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteTypeDefName, obsoleteTypeDefGUID, guidParameterName, methodName, repositoryName, omTypeDefToDelete.toString());
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Delete an AttributeTypeDef.  This is only possible if the AttributeTypeDef has never been used to create
+     * instances or any instances of this AttributeTypeDef have been purged from the metadata collection.
+     *
+     * @param userId              - unique identifier for requesting user.
+     * @param obsoleteTypeDefGUID - String unique identifier for the AttributeTypeDef.
+     * @param obsoleteTypeDefName - String unique name for the AttributeTypeDef.
+     * @throws InvalidParameterException  - the one of AttributeTypeDef identifiers is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the requested AttributeTypeDef is not found in the metadata collection.
+     * @throws TypeDefInUseException      - the AttributeTypeDef can not be deleted because there are instances of this type in the
+     *                                    the metadata collection.  These instances need to be purged before the
+     *                                    AttributeTypeDef can be deleted.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void deleteAttributeTypeDef(String userId,
+                                       String obsoleteTypeDefGUID,
+                                       String obsoleteTypeDefName)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            TypeDefInUseException,
+            UserNotAuthorizedException {
+        final String methodName = "deleteAttributeTypeDef";
+        final String guidParameterName = "obsoleteTypeDefGUID";
+        final String nameParameterName = "obsoleteTypeDefName";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAttributeTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                obsoleteTypeDefGUID,
+                obsoleteTypeDefName,
+                methodName);
+
+        /*
+         * Perform operation
+         */
+        AtlasBaseTypeDef abtd;
+
+        /*
+         * Look in the Atlas type def store for the obsolete attribute type def so that we know its category
+         */
+        try {
+
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByGuid(obsoleteTypeDefGUID);
+            } else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByGuid(obsoleteTypeDefGUID);
+            }
+
+        } catch (AtlasBaseException e) {
+
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                LOG.debug("deleteAttributeTypeDef: Atlas does not have the type with GUID {} ", obsoleteTypeDefGUID);
+                // The TypeDef was not found - ensure atlasPreTypeDef is null, exception to be handled below
+                abtd = null;
+
+            } else {
+
+                LOG.error("deleteAttributeTypeDef: Caught exception trying to retrieve Atlas type with GUID {} ", obsoleteTypeDefGUID, e);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "deleteAttributeTypeDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        // Separate null check ensures we have covered both cases (registry and store)
+        if (abtd == null) {
+
+            LOG.debug("deleteAttributeTypeDef: received null return from Atlas getByName using GUID {}", obsoleteTypeDefGUID);
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteTypeDefGUID, "unknown", "obsoleteTypeDefGUID", "deleteAttributeTypeDef", metadataCollectionId);
+
+            throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "deleteAttributeTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // From here on we know that atlasPreTypeDef is not null
+
+
+        // We have an AtlasBaseTypeDef
+        TypeCategory atlasTypeCategory = abtd.getCategory();
+
+        AtlasTypesDef atlasTypesDef = new AtlasTypesDef();
+
+        try {
+            switch (atlasTypeCategory) {
+
+                case ENUM:
+                    AtlasEnumDef atlasEnumDef = (AtlasEnumDef) abtd;
+                    List<AtlasEnumDef> atlasEnumDefs = atlasTypesDef.getEnumDefs();
+                    atlasEnumDefs.add(atlasEnumDef);
+                    break;
+
+                case PRIMITIVE:
+                case ARRAY:
+                case MAP:
+                    LOG.debug("There is nothing to do when the AttributeTypeDef is a primitive or collection");
+                    return;
+
+                default:
+                    LOG.error("deleteAttributeTypeDef: unsupported attribute type def category {}", atlasTypeCategory);
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(obsoleteTypeDefName, obsoleteTypeDefGUID, guidParameterName, methodName, repositoryName, abtd.toString());
+
+                    throw new TypeDefNotKnownException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+            }
+
+            /*
+             * Ask Atlas to perform the delete operation
+             */
+            typeDefStore.deleteTypesDef(atlasTypesDef);
+
+        }
+        catch (AtlasBaseException  e) {
+            LOG.error("The Atlas repository could not delete the AttributeTypeDef", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteTypeDefName, obsoleteTypeDefGUID, guidParameterName, methodName, repositoryName, abtd.toString());
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Change the guid or name of an existing TypeDef to a new value.  This is used if two different
+     * TypeDefs are discovered to have the same guid.  This is extremely unlikely but not impossible so
+     * the open metadata protocol has provision for this.
+     *
+     * @param userId              - unique identifier for requesting user.
+     * @param originalTypeDefGUID - the original guid of the TypeDef.
+     * @param originalTypeDefName - the original name of the TypeDef.
+     * @param newTypeDefGUID      - the new identifier for the TypeDef.
+     * @param newTypeDefName      - new name for this TypeDef.
+     * @return typeDef - new values for this TypeDef, including the new guid/name.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the TypeDef identified by the original guid/name is not found
+     *                                    in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public TypeDef reIdentifyTypeDef(String userId,
+                                     String originalTypeDefGUID,
+                                     String originalTypeDefName,
+                                     String newTypeDefGUID,
+                                     String newTypeDefName)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+        final String    methodName                = "reIdentifyTypeDef";
+        final String    originalGUIDParameterName = "originalTypeDefGUID";
+        final String    originalNameParameterName = "originalTypeDefName";
+        final String    newGUIDParameterName      = "newTypeDefGUID";
+        final String    newNameParameterName      = "newTypeDefName";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                originalGUIDParameterName,
+                originalNameParameterName,
+                originalTypeDefGUID,
+                originalTypeDefName,
+                methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                newGUIDParameterName,
+                newNameParameterName,
+                newTypeDefGUID,
+                newTypeDefName,
+                methodName);
+
+        /*
+         * Perform operation
+         */
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName, this.getClass().getName(), repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    /**
+     * Change the guid or name of an existing TypeDef to a new value.  This is used if two different
+     * TypeDefs are discovered to have the same guid.  This is extremely unlikely but not impossible so
+     * the open metadata protocol has provision for this.
+     *
+     * @param userId                       - unique identifier for requesting user.
+     * @param originalAttributeTypeDefGUID - the original guid of the AttributeTypeDef.
+     * @param originalAttributeTypeDefName - the original name of the AttributeTypeDef.
+     * @param newAttributeTypeDefGUID      - the new identifier for the AttributeTypeDef.
+     * @param newAttributeTypeDefName      - new name for this AttributeTypeDef.
+     * @return attributeTypeDef - new values for this AttributeTypeDef, including the new guid/name.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeDefNotKnownException   - the AttributeTypeDef identified by the original guid/name is not
+     *                                    found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public AttributeTypeDef reIdentifyAttributeTypeDef(String userId,
+                                                       String originalAttributeTypeDefGUID,
+                                                       String originalAttributeTypeDefName,
+                                                       String newAttributeTypeDefGUID,
+                                                       String newAttributeTypeDefName)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeDefNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String    methodName                = "reIdentifyAttributeTypeDef";
+        final String    originalGUIDParameterName = "originalAttributeTypeDefGUID";
+        final String    originalNameParameterName = "originalAttributeTypeDefName";
+        final String    newGUIDParameterName      = "newAttributeTypeDefGUID";
+        final String    newNameParameterName      = "newAttributeTypeDefName";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                originalGUIDParameterName,
+                originalNameParameterName,
+                originalAttributeTypeDefGUID,
+                originalAttributeTypeDefName,
+                methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                newGUIDParameterName,
+                newNameParameterName,
+                newAttributeTypeDefGUID,
+                newAttributeTypeDefName,
+                methodName);
+
+        /*
+         * Perform operation
+         */
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName, this.getClass().getName(), repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    // ==========================================================================================================================
+
+    // Group 3 methods
+
+    /**
+     * Returns a boolean indicating if the entity is stored in the metadata collection.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String unique identifier for the entity.
+     * @return entity details if the entity is found in the metadata collection; otherwise return null.
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail isEntityKnown(String userId,
+                                      String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> isEntityKnown(userId={}, guid={})", userId, guid);
+        }
+
+        final String  methodName = "isEntityKnown";
+        final String  guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        EntityDetail entityDetail;
+        try {
+            entityDetail = getEntityDetail(userId, guid);
+        } catch (EntityNotKnownException e) {
+            LOG.error("isEntityKnown: caught EntityNotKnownException exception from getEntityDetail - exception swallowed, returning null", e);
+            return null;
+        } catch (RepositoryErrorException e) {
+            LOG.error("isEntityKnown: caught RepositoryErrorException exception from getEntityDetail - rethrowing", e);
+            throw e;
+        } catch (UserNotAuthorizedException e) {
+            LOG.error("isEntityKnown: caught UserNotAuthorizedException exception from getEntityDetail - rethrowing", e);
+            throw e;
+        }
+
+        LOG.debug("isEntityKnown: retrieved EntityDetail {}", entityDetail);
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== isEntityKnown(userId={}, guid={}: entityDetail={})", userId, guid, entityDetail);
+        }
+        return entityDetail;
+    }
+
+    public boolean isEntityProxy(String guid) throws EntityNotKnownException {
+        // Using the supplied guid look up the entity.
+        final String methodName = "isEntityProxy";
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+            atlasEntityWithExt = entityStore.getById(guid);
+        } catch (AtlasBaseException e) {
+            LOG.error("isEntityProxy: caught exception from to get entity from Atlas repository, guid {}", guid, e);
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+        LOG.debug("isEntityProxy: AtlasEntity proxy {}",atlasEntity.isProxy());
+        return atlasEntity.isProxy();
+    }
+
+    public boolean isEntityLocal(String guid) throws EntityNotKnownException {
+        // Using the supplied guid look up the entity.
+        final String methodName = "isEntityLocal";
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+            atlasEntityWithExt = entityStore.getById(guid);
+        } catch (AtlasBaseException e) {
+            LOG.error("isEntityLocal: caught exception from to get entity from Atlas repository, guid {}", guid, e);
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+        LOG.debug("isEntityLocal: AtlasEntity local {}", atlasEntity.getHomeId() == null);
+        return atlasEntity.getHomeId() == null;
+    }
+
+    /**
+     * Return the header and classifications for a specific entity.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String unique identifier for the entity.
+     * @return EntitySummary structure
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the requested entity instance is not known in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntitySummary getEntitySummary(String userId,
+                                          String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getEntitySummary(userId={}, guid={})", userId, guid);
+        }
+
+        final String  methodName        = "getEntitySummary";
+        final String  guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Using the supplied guid look up the entity.
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+            atlasEntityWithExt = entityStore.getById(guid);
+        } catch (AtlasBaseException e) {
+            LOG.error("getEntitySummary: caught exception from to get entity from Atlas repository, guid {}", guid, e);
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+
+        // Project the AtlasEntity as an EntitySummary
+
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            EntitySummary omEntitySummary = atlasEntityMapper.toEntitySummary();
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("<== getEntitySummary(userId={}, guid={}: entitySummary={})", userId, guid, omEntitySummary);
+            }
+            return omEntitySummary;
+        }
+        catch (Exception e) {
+            LOG.error("getEntitySummary: caught exception {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+    }
+
+
+    /**
+     * Return the header, classifications and properties of a specific entity.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String unique identifier for the entity.
+     * @return EntityDetail structure.
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the requested entity instance is not known in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail getEntityDetail(String userId,
+                                        String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getEntityDetail(userId={}, guid={})", userId, guid);
+        }
+
+        final String  methodName        = "getEntityDetail";
+        final String  guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Perform operation
+         */
+
+
+        // Using the supplied guid look up the entity.
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+            atlasEntityWithExt = entityStore.getById(guid);
+        } catch (AtlasBaseException e) {
+
+            LOG.error("getEntityDetail: caught exception from get entity by guid {}, {}",guid, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("getEntityDetail: atlasEntityWithExt is {}", atlasEntityWithExt);
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+
+        // Project the AtlasEntity as an EntityDetail
+
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("<== getEntityDetail(userId={}, guid={}: entityDetail={})", userId, guid, omEntityDetail);
+            }
+            return omEntityDetail;
+
+        } catch (TypeErrorException | InvalidEntityException e) {
+            LOG.error("getEntityDetail: caught exception from attempt to convert Atlas entity to OM {}, {}", atlasEntity, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+    }
+
+
+    /**
+     * Return a historical versionName of an entity - includes the header, classifications and properties of the entity.
+     *
+     * @param userId     - unique identifier for requesting user.
+     * @param guid       - String unique identifier for the entity.
+     * @param asOfTime   - the time used to determine which versionName of the entity that is desired.
+     * @return EntityDetail structure.
+     * @throws InvalidParameterException     - the guid or date is null or date is for future time
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws EntityNotKnownException       - the requested entity instance is not known in the metadata collection
+     *                                         at the time requested.
+     * @throws EntityProxyOnlyException      - the requested entity instance is only a proxy in the metadata collection.
+     * @throws FunctionNotSupportedException - the repository does not support satOfTime parameter.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail getEntityDetail(String  userId,
+                                        String  guid,
+                                        Date    asOfTime)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            EntityProxyOnlyException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName        = "getEntityDetail";
+        final String  guidParameterName = "guid";
+        final String  asOfTimeParameter = "asOfTime";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // This method requires a historic query which is not supported
+        LOG.debug("getEntityDetail: Does not support asOfTime historic retrieval");
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        String errorMessage = errorCode.getErrorMessageId()
+                + errorCode.getFormattedErrorMessage(guid, methodName, metadataCollectionId);
+
+        throw new FunctionNotSupportedException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+
+    }
+
+
+
+
+    /**
+     * Return the relationships for a specific entity.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entityGUID - String unique identifier for the entity.
+     * @param relationshipTypeGUID - String GUID of the the type of relationship required (null for all).
+     * @param fromRelationshipElement - the starting element number of the relationships to return.
+     *                                This is used when retrieving elements
+     *                                beyond the first page of results. Zero means start from the first element.
+     * @param limitResultsByStatus - By default, relationships in all statuses are returned.  However, it is possible
+     *                             to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                             status values.
+     * @param asOfTime - Requests a historical query of the relationships for the entity.  Null means return the
+     *                 present values.
+     * @param sequencingProperty - String name of the property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize -- the maximum number of result classifications that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return Relationships list.  Null means no relationships associated with the entity.
+     * @throws InvalidParameterException a parameter is invalid or null.
+     * @throws TypeErrorException the type guid passed on the request is not known by the metadata collection.
+     * @throws RepositoryErrorException there is a problem communicating with the metadata repository where
+     *                                  the metadata collection is stored.
+     * @throws EntityNotKnownException the requested entity instance is not known in the metadata collection.
+     * @throws PropertyErrorException the sequencing property is not valid for the attached classifications.
+     * @throws PagingErrorException the paging/sequencing parameters are set up incorrectly.
+     * @throws FunctionNotSupportedException the repository does not support the asOfTime parameter.
+     * @throws UserNotAuthorizedException the userId is not permitted to perform this operation.
+     */
+    public List<Relationship> getRelationshipsForEntity(String                     userId,
+                                                        String                     entityGUID,
+                                                        String                     relationshipTypeGUID,
+                                                        int                        fromRelationshipElement,
+                                                        List<InstanceStatus>       limitResultsByStatus,
+                                                        Date                       asOfTime,
+                                                        String                     sequencingProperty,
+                                                        SequencingOrder            sequencingOrder,
+                                                        int                        pageSize)
+        throws
+            InvalidParameterException,
+            TypeErrorException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            PagingErrorException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getRelationshipsForEntity(userId={}, entityGUID={}, relationshipTypeGUID={}, fromRelationshipElement={}, limitResultsByStatus={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={})", userId, entityGUID, relationshipTypeGUID, fromRelationshipElement, limitResultsByStatus, asOfTime, sequencingProperty, sequencingOrder, pageSize);
+        }
+        final String methodName = "getRelationshipsForEntity";
+        final String guidParameterName = "entityGUID";
+        final String typeGUIDParameterName = "relationshipTypeGUID";
+        final String asOfTimeParameter = "asOfTime";
+        final String pageSizeParameter = "pageSize";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, entityGUID, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, typeGUIDParameterName, relationshipTypeGUID, methodName);
+        }
+        catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage( "unknown", relationshipTypeGUID, typeGUIDParameterName, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        /*
+         * Perform operation
+         */
+
+        // Historical queries are not yet supported.
+        if (asOfTime != null) {
+            LOG.debug("getRelationshipsForEntity: Request to find relationships as they were at time {} is not supported", asOfTime);
+            OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Sequenced queries are not yet supported. TODO commented block to be removed when tested
+        //if (!StringUtil.isBlank(sequencingProperty)) {
+        //    LOG.debug("getRelationshipsForEntity: Request to find relationships sequenced by {} is not supported", sequencingProperty);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Paged queries are not yet supported. TODO commented block to be removed when tested
+        //if (pageSize != 0) {
+        //    LOG.debug("getRelationshipsForEntity: Request to page relationships using pageSize {}", pageSize);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Result offset is not yet supported. TODO commented block to be removed when tested
+        //if (fromRelationshipElement != 0) {
+        //    LOG.debug("getRelationshipsForEntity: Request to offset relationships is not supported");
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+
+            atlasEntityWithExt = entityStore.getById(entityGUID);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("getRelationshipsForEntity: caught exception from attempt to get Atlas entity by GUID {}", entityGUID, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+        List<Relationship> matchingRelationships = null;
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            EntityUniverse entityUniverse = atlasEntityMapper.toEntityUniverse();
+            List<Relationship> allRelationships = entityUniverse.getEntityRelationships();
+            if (allRelationships != null && !allRelationships.isEmpty() ) {
+                for (Relationship r : allRelationships) {
+                    /*  If there is no type filtering, or if the relationship type matches then
+                     *  consider including it in the result.
+                     */
+                    if (relationshipTypeGUID == null || r.getType().getTypeDefGUID().equals(relationshipTypeGUID)) {
+
+                        /*  If there is no status filter specified, or if the relationship satisfies the status filter,
+                         *  include the relationship in the result, otherwise skip the relationship
+                         */
+                        if (limitResultsByStatus != null) {
+                            // Need to check that the relationship status is in the list of allowed status values
+                            InstanceStatus relStatus = r.getStatus();
+                            boolean match = false;
+                            for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                                if (relStatus == allowedStatus) {
+                                    match = true;
+                                    break;
+                                }
+                            }
+                            if (!match) {
+                                continue;  // skip this relationship and process the next, if any remain
+                            }
+                        }
+
+                        // Need to add the relationship to the result
+                        if (matchingRelationships == null)
+                            matchingRelationships = new ArrayList<>();
+                        matchingRelationships.add(r);
+                    }
+                }
+            }
+        }
+        catch (TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+            LOG.error("getRelationshipsForEntity: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getRelationshipsForEntity(userId={}, entityGUID={}, relationshipTypeGUID={}, fromRelationshipElement={}, limitResultsByStatus={}, " +
+                            "asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={}: matchingRelationships={})",
+                    userId, entityGUID, relationshipTypeGUID, fromRelationshipElement, limitResultsByStatus,
+                    asOfTime, sequencingProperty, sequencingOrder, pageSize, matchingRelationships);
+        }
+
+
+        return formatRelationshipResults(matchingRelationships, fromRelationshipElement, sequencingProperty, sequencingOrder, pageSize);
+
+    }
+
+    /**
+     * Return a list of entities that match the supplied properties according to the match criteria.  The results
+     * can be returned over many pages.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entityTypeGUID - String unique identifier for the entity type of interest (null means any entity type).
+     * @param matchProperties - List of entity properties to match to (null means match on entityTypeGUID only).
+     * @param matchCriteria - Enum defining how the properties should be matched to the entities in the repository.
+     * @param fromEntityElement - the starting element number of the entities to return.
+     *                                This is used when retrieving elements
+     *                                beyond the first page of results. Zero means start from the first element.
+     * @param limitResultsByStatus - By default, entities in all statuses are returned.  However, it is possible
+     *                             to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                             status values.
+     * @param limitResultsByClassification - List of classifications that must be present on all returned entities.
+     * @param asOfTime - Requests a historical query of the entity.  Null means return the present values.
+     * @param sequencingProperty - String name of the entity property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result entities that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return a list of entities matching the supplied criteria - null means no matching entities in the metadata
+     * collection.
+     * @throws InvalidParameterException - a parameter is invalid or null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException - the type guid passed on the request is not known by the
+     *                              metadata collection.
+     * @throws PropertyErrorException - the properties specified are not valid for any of the requested types of
+     *                                  entity.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     * @throws FunctionNotSupportedException - the repository does not support the asOfTime parameter.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public  List<EntityDetail> findEntitiesByProperty(String                    userId,
+                                                      String                    entityTypeGUID,
+                                                      InstanceProperties        matchProperties,
+                                                      MatchCriteria             matchCriteria,
+                                                      int                       fromEntityElement,
+                                                      List<InstanceStatus>      limitResultsByStatus,
+                                                      List<String>              limitResultsByClassification,
+                                                      Date                      asOfTime,
+                                                      String                    sequencingProperty,
+                                                      SequencingOrder           sequencingOrder,
+                                                      int                       pageSize)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            PagingErrorException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByProperty(userId={}, entityTypeGUID={}, matchProperties={}, matchCriteria={}, fromEntityElement={}, limitResultsByStatus={}, limitResultsByClassification={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={})",
+                    userId,entityTypeGUID,matchProperties,matchCriteria,fromEntityElement,limitResultsByStatus,limitResultsByClassification,asOfTime,sequencingProperty,sequencingOrder,pageSize );
+        }
+
+        final String  methodName                   = "findEntitiesByProperty";
+        final String  matchCriteriaParameterName   = "matchCriteria";
+        final String  matchPropertiesParameterName = "matchProperties";
+        final String  guidParameterName            = "entityTypeGUID";
+        final String  asOfTimeParameter            = "asOfTime";
+        final String  pageSizeParameter            = "pageSize";
+        final String  offsetParameter              = "fromEntityElement";
+        final String  sequencingOrderParameter     = "sequencingOrder";
+        final String  sequencingPropertyParameter  = "sequencingProperty";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+        repositoryValidator.validateMatchCriteria(repositoryName,
+                matchCriteriaParameterName,
+                matchPropertiesParameterName,
+                matchCriteria,
+                matchProperties,
+                methodName);
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, guidParameterName, entityTypeGUID, methodName);
+
+        } catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage( "unknown", entityTypeGUID, guidParameterName, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Perform operation
+         */
+
+
+        /*
+         *  This method behaves as follows:
+         *  * The optional entityTypeGuid restricts the find to entities of the given type - null will span all types.
+         *
+         *  * The optional InstanceProperties object contains a list of property filters - each property filter specifies
+         *    the type, name and value of a property that a matching entity must possess. Only the named properties are
+         *    compared; properties that are not named in the InstanceProperties object are ignored. Where a named property
+         *    is of type String, the property will match if the specified value is contained in the value of the named
+         *    property - i.e. it does not have be an exact match. For all other types of property - i.e. non-String
+         *    properties - the value comparison is an exact match.
+         *
+         *  * The property filters can be combined using the matchCriteria of ALL, ANY or NONE. If null, this will default to ALL
+         *
+         *  * The results can be narrowed by optionally specifying one or more instance status values - the results
+         *    will only contain entities that have one of the specified status values
+         *
+         *  * The results can be narrowed by optionally specifying one or more classifications - the results will
+         *    only contain entities that have all of the specified classifications
+         *
+         *  All of the above filters are optional - if none of them are supplied - i.e. no entityTypeGUID, matchProperties,
+         *  status values or classifications - then ALL entities will be returned. This will perform very badly.
+         *
+         *
+         *  IMPORTANT NOTE
+         *  --------------
+         *  It is difficult to see how to implement the combination of NONE and string searchCriteria - there is no
+         *  NOT operator in DSL nor in SearchWithParameters, and the only solution I can currently think of is a
+         *  negated regex which seems unduly complex. Short of performing two searches and subtracting one from the
+         *  other - which would not perform well - I am currently stuck for a solution. This might require direct manipulation
+         *  of the gremlin - which would make for an untidy solution alongside Atlas's other query methods; or we would
+         *  need to introduce negation operators into Atlas, which will take longer to implement but is probably the nicest
+         *  option. So for now this method is not supporting matchCriteria NONE.
+         *
+         */
+
+        if (matchCriteria == MatchCriteria.NONE) {
+            LOG.debug("findEntitiesByProperty: Request to find entities using matchCriteria NONE is not supported");
+            OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(matchCriteriaParameterName, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Historical queries are not yet supported.
+        if (asOfTime != null) {
+            LOG.debug("findEntitiesByProperty: Request to find entities as they were at time {} is not supported", asOfTime);
+            OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Sequenced queries are not yet supported. TODO commented block to be removed when tested
+        //if (!StringUtil.isBlank(sequencingProperty)) {
+        //    LOG.debug("findEntitiesByProperty: Request to find entities sequenced by {} is not supported", sequencingProperty);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(sequencingOrderParameter+" or "+sequencingPropertyParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Paged queries are not yet supported. TODO commented block to be removed when tested
+        //if (pageSize != 0) {
+        //    LOG.debug("findEntitiesByProperty: Request to page entities using pageSize {}", pageSize);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(pageSizeParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Result offset is not yet supported. TODO commented block to be removed when tested
+        //if (fromEntityElement != 0) {
+        //    LOG.debug("findEntitiesByProperty: Request to offset entities is not supported");
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(offsetParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Because there is not post-filtering by this method, pass the offset and pageSize through to the underlying methods
+
+        List<EntityDetail> returnList;
+        if (entityTypeGUID != null) {   // Use DSL
+            try {
+                returnList = findEntitiesByPropertyUsingDSL(userId, entityTypeGUID, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification, fromEntityElement, pageSize);
+            }
+            catch (TypeErrorException | RepositoryErrorException | PropertyErrorException e) {
+                // Log and re-throw
+                LOG.debug("findEntitiesByProperty: Caught exception from findEntitiesByPropertyUsingDSL");
+                throw e;
+            }
+
+        } else {
+
+            // entityTypeGUID == null means type is not specified, use searchWithParameters
+            returnList = findEntitiesByPropertyUsingSearchParameters(userId, matchProperties, matchCriteria,  limitResultsByStatus, limitResultsByClassification, fromEntityElement, pageSize);
+
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByProperty(userId={}, entityTypeGUID={}, matchProperties={}, matchCriteria={}, fromEntityElement={}, limitResultsByStatus={}, limitResultsByClassification={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={}): returnList={}",
+                    userId,entityTypeGUID,matchProperties,matchCriteria,fromEntityElement,limitResultsByStatus,limitResultsByClassification,asOfTime,sequencingProperty,sequencingOrder,pageSize,returnList );
+        }
+
+        // Have already applied offset and pageSize - do not apply offset again, hence fromELement set to 0
+        return formatEntityResults(returnList, 0, sequencingProperty, sequencingOrder, pageSize);
+
+    }
+
+
+
+    /**
+     * Return a list of entities that have the requested type of classification attached.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entityTypeGUID - unique identifier for the type of entity requested.  Null mans any type of entity.
+     * @param classificationName - name of the classification - a null is not valid.
+     * @param matchClassificationProperties - list of classification properties used to narrow the search.
+     * @param matchCriteria - Enum defining how the properties should be matched to the classifications in the repository.
+     * @param fromEntityElement - the starting element number of the entities to return.
+     *                                This is used when retrieving elements
+     *                                beyond the first page of results. Zero means start from the first element.
+     * @param limitResultsByStatus - By default, entities in all statuses are returned.  However, it is possible
+     *                             to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                             status values.
+     * @param asOfTime - Requests a historical query of the entity.  Null means return the present values.
+     * @param sequencingProperty - String name of the entity property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result entities that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return a list of entities matching the supplied criteria - null means no matching entities in the metadata
+     * collection.
+     * @throws InvalidParameterException - a parameter is invalid or null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException - the type guid passed on the request is not known by the
+     *                              metadata collection.
+     * @throws ClassificationErrorException - the classification request is not known to the metadata collection.
+     * @throws PropertyErrorException - the properties specified are not valid for the requested type of
+     *                                  classification.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     * @throws FunctionNotSupportedException - the repository does not support the asOfTime parameter.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<EntityDetail> findEntitiesByClassification(String                    userId,
+                                                           String                    entityTypeGUID,
+                                                           String                    classificationName,
+                                                           InstanceProperties        matchClassificationProperties,
+                                                           MatchCriteria             matchCriteria,
+                                                           int                       fromEntityElement,
+                                                           List<InstanceStatus>      limitResultsByStatus,
+                                                           Date                      asOfTime,
+                                                           String                    sequencingProperty,
+                                                           SequencingOrder           sequencingOrder,
+                                                           int                       pageSize)
+
+            throws
+                InvalidParameterException,
+                RepositoryErrorException,
+                TypeErrorException,
+                ClassificationErrorException,
+                PropertyErrorException,
+                PagingErrorException,
+                FunctionNotSupportedException,
+                UserNotAuthorizedException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByClassification(userId={}, entityTypeGUID={}, classificationName={}, matchClassificationProperties={}, matchCriteria={}, fromEntityElement={}, limitResultsByStatus={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={})",
+                    userId,entityTypeGUID,classificationName,matchClassificationProperties,matchCriteria,fromEntityElement,limitResultsByStatus,asOfTime,sequencingProperty,sequencingOrder,pageSize );
+        }
+
+        final String  methodName                   = "findEntitiesByClassification";
+        final String  classificationParameterName  = "classificationName";
+        final String  entityTypeGUIDParameterName  = "entityTypeGUID";
+
+        final String  matchCriteriaParameterName   = "matchCriteria";
+        final String  matchPropertiesParameterName = "matchClassificationProperties";
+        final String  asOfTimeParameter            = "asOfTime";
+        final String  pageSizeParameter            = "pageSize";
+        final String  sequencingParameter          = "sequencingOrder";
+        final String  offsetParameter              = "fromEntityElement";
+
+
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, entityTypeGUIDParameterName, entityTypeGUID, methodName);
+        } catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("unknown", entityTypeGUID, entityTypeGUIDParameterName, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validate TypeDef
+         */
+        if (entityTypeGUID != null)
+        {
+            TypeDef entityTypeDef;
+            try {
+                entityTypeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+            }
+            catch (TypeDefNotKnownException e) {
+                // handle below
+                LOG.error("findEntitiesByClassification: caught exception from _getTypeDefByGUID {}", e);
+                entityTypeDef = null;
+            }
+            if (entityTypeDef == null || entityTypeDef.getCategory() != ENTITY_DEF) {
+
+                OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage( "unknown", entityTypeGUID, entityTypeGUIDParameterName, methodName, repositoryName, "unknown");
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            repositoryValidator.validateTypeDefForInstance(repositoryName,
+                    entityTypeGUIDParameterName,
+                    entityTypeDef,
+                    methodName);
+
+            repositoryValidator.validateClassification(repositoryName,
+                    classificationParameterName,
+                    classificationName,
+                    entityTypeDef.getName(),
+                    methodName);
+        }
+        else
+        {
+            repositoryValidator.validateClassification(repositoryName,
+                    classificationParameterName,
+                    classificationName,
+                    null,
+                    methodName);
+        }
+
+        repositoryValidator.validateMatchCriteria(repositoryName,
+                matchCriteriaParameterName,
+                matchPropertiesParameterName,
+                matchCriteria,
+                matchClassificationProperties,
+                methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // Historical queries are not yet supported.
+        if (asOfTime != null) {
+            LOG.debug("findEntitiesByClassification: Request to find entities as they were at time {} is not supported", asOfTime);
+            OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Sequencing of results is not yet supported. TODO commented block to be removed when tested
+        //if (!StringUtil.isBlank(sequencingProperty)) {
+        //    LOG.debug("findEntitiesByClassification: Request to sequence entities is not supported");
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(sequencingParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Paging of results is not yet supported. TODO commented block to be removed when tested
+        //if (pageSize != 0) {
+        //    LOG.debug("findEntitiesByClassification: Request to page entities is not supported");
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(pageSizeParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Result offset is not yet supported. TODO commented block to be removed when tested
+        //if (fromEntityElement != 0) {
+        //    LOG.debug("findEntitiesByClassification: Request to offset entities is not supported");
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(offsetParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+
+        if (classificationName == null) {
+            LOG.error("findEntitiesByClassification: Classification name must not be null; please specify a classification name");
+            OMRSErrorCode errorCode = OMRSErrorCode.NULL_CLASSIFICATION_NAME;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(offsetParameter, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // There is no post-filtering by this method, so pass offset and pageSize through to underlying methods
+
+        List<EntityDetail> returnList;
+        // If we have a guid use DSL
+        if (entityTypeGUID != null) {
+            // Use DSL
+            returnList = findEntitiesByClassificationUsingDSL(userId, entityTypeGUID, classificationName, matchClassificationProperties, matchCriteria,  limitResultsByStatus, fromEntityElement, pageSize);
+
+        } else {
+            // Type is not specified so use searchWithParameters
+            returnList = findEntitiesByClassificationUsingSearchParameters(userId, classificationName, matchClassificationProperties, matchCriteria,  limitResultsByStatus, fromEntityElement, pageSize);
+        }
+
+        // Offset and pageSize are handled in the queries above - more efficient at the server. So do not apply them again here.
+        // Hence fromElement is set to 0; pageSize can be left as specified by caller.
+        return formatEntityResults(returnList, 0, sequencingProperty, sequencingOrder, pageSize);
+
+
+    }
+
+
+
+    /**
+     * Return a list of entities whose string based property values match the search criteria.  The
+     * search criteria may include regex style wild cards.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entityTypeGUID - GUID of the type of entity to search for. Null means all types will
+     *                       be searched (could be slow so not recommended).
+     * @param searchCriteria - String expression contained in any of the property values within the entities
+     *                       of the supplied type.
+     * @param fromEntityElement - the starting element number of the entities to return.
+     *                                This is used when retrieving elements
+     *                                beyond the first page of results. Zero means start from the first element.
+     * @param limitResultsByStatus - By default, entities in all statuses are returned.  However, it is possible
+     *                             to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                             status values.
+     * @param limitResultsByClassification - List of classifications that must be present on all returned entities.
+     * @param asOfTime - Requests a historical query of the entity.  Null means return the present values.
+     * @param sequencingProperty - String name of the property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result entities that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return a list of entities matching the supplied criteria - null means no matching entities in the metadata
+     * collection.
+     * @throws InvalidParameterException - a parameter is invalid or null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws PropertyErrorException - the sequencing property specified is not valid for any of the requested types of
+     *                                  entity.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     * @throws FunctionNotSupportedException - the repository does not support the asOfTime parameter.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<EntityDetail> findEntitiesByPropertyValue(String                userId,
+                                                          String                entityTypeGUID,
+                                                          String                searchCriteria,
+                                                          int                   fromEntityElement,
+                                                          List<InstanceStatus>  limitResultsByStatus,
+                                                          List<String>          limitResultsByClassification,
+                                                          Date                  asOfTime,
+                                                          String                sequencingProperty,
+                                                          SequencingOrder       sequencingOrder,
+                                                          int                   pageSize)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            PropertyErrorException,
+            PagingErrorException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+
+    {
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyValue(userId={}, entityTypeGUID={}, searchCriteria={}, fromEntityElement={}, limitResultsByStatus={}, limitResultsByClassification={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={})",
+                    userId,entityTypeGUID,searchCriteria,fromEntityElement,limitResultsByStatus,limitResultsByClassification, asOfTime,sequencingProperty,sequencingOrder,pageSize );
+        }
+
+        final String  methodName = "findEntitiesByPropertyValue";
+        final String  searchCriteriaParameterName = "searchCriteria";
+        final String  asOfTimeParameter = "asOfTime";
+        final String  typeGUIDParameter = "entityTypeGUID";
+        final String  pageSizeParameter = "pageSize";
+        final String  offsetParameter   = "fromEntityElement";
+        final String  sequencingParameter = "sequencingOrder";
+
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateSearchCriteria(repositoryName, searchCriteriaParameterName, searchCriteria, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, typeGUIDParameter, entityTypeGUID, methodName);
+        } catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("unknown", entityTypeGUID, typeGUIDParameter, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Process operation
+         */
+
+        // The nature of this find/search is that it will match an entity that has ANY matching property
+        // i.e. any string property containing the searchCriteria string. It only operates on string
+        // properties (other property types are ignored) and it implicitly uses matchCriteria.ANY.
+
+        // Historical queries are not yet supported.
+        if (!StringUtil.isBlank(sequencingProperty)) {
+            LOG.debug("findEntitiesByPropertyValue: Request to find sequenced entities using {} is not supported", sequencingProperty);
+            OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(sequencingParameter, methodName, metadataCollectionId);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Sequenced queries are not yet supported. TODO commented block to be removed when tested
+        //if (asOfTime != null) {
+        //    LOG.debug("findEntitiesByPropertyValue: Request to find entities as they were at time {} is not supported", asOfTime);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+        // Paging of results not yet supported. TODO commented block to be removed when tested
+        //if (pageSize != 0) {
+        //    LOG.debug("findEntitiesByPropertyValue: Request to page entities, page size {} is not supported", pageSize);
+        //    OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        //    String errorMessage = errorCode.getErrorMessageId()
+        //            + errorCode.getFormattedErrorMessage(pageSizeParameter, methodName, metadataCollectionId);
+        //
+        //    throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+        //            this.getClass().getName(),
+        //            methodName,
+        //            errorMessage,
+        //            errorCode.getSystemAction(),
+        //            errorCode.getUserAction());
+        //}
+
+
+        // There is no post-processing performed by this method, so it is safe to delegate offset to the underlying methods...
+
+        List<EntityDetail> returnList;
+        if (entityTypeGUID != null) {
+            // Type specified so use DSL
+            try {
+                returnList = findEntitiesByPropertyUsingDSL(userId, entityTypeGUID, searchCriteria, limitResultsByStatus, limitResultsByClassification, fromEntityElement, pageSize);
+            }
+            catch (TypeErrorException | RepositoryErrorException | PropertyErrorException e) {
+                LOG.error("findEntitiesByPropertyValue: Caught exception from findEntitiesByPropertyUsingDSL", e);
+                OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("findEntitiesByProperty", methodName, metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());            }
+        } else {
+            // Since entityTypeGUID is null it means type is not specified, so use searchWithParameters
+            // Prepare the matchProperties as we should be matching string properties only...
+            returnList = findEntitiesByPropertyUsingSearchParameters(userId, searchCriteria, limitResultsByStatus, limitResultsByClassification, fromEntityElement, pageSize);
+
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByPropertyValue(userId={}, entityTypeGUID={}, searchCriteria={}, fromEntityElement={}, limitResultsByStatus={}, limitResultsByClassification={}, asOfTime={}, sequencingProperty={}, sequencingOrder={}, pageSize={}): returnList={}",
+                    userId,entityTypeGUID,searchCriteria,fromEntityElement,limitResultsByStatus,limitResultsByClassification, asOfTime,sequencingProperty,sequencingOrder,pageSize,returnList );
+        }
+
+        // Already applied offset and pageSize so do not offset again - set fomrElement to 0
+        return formatEntityResults(returnList, 0, sequencingProperty, sequencingOrder, pageSize);
+
+    }
+
+
+    /**
+     * Returns a boolean indicating if the relationship is stored in the metadata collection.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String unique identifier for the relationship.
+     * @return relationship details if the relationship is found in the metadata collection; otherwise return null.
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public Relationship isRelationshipKnown(String userId,
+                                            String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            UserNotAuthorizedException {
+
+        final String methodName = "isRelationshipKnown";
+        final String guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Process operation
+         */
+
+        try {
+            return getRelationship(userId, guid);
+        }
+        catch (RelationshipNotKnownException e) {
+            return null;
+        }
+
+    }
+
+
+    /**
+     * Return a requested relationship.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param guid   - String unique identifier for the relationship.
+     * @return a relationship structure.
+     * @throws InvalidParameterException     - the guid is null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the metadata collection does not have a relationship with
+     *                                       the requested GUID stored.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship getRelationship(String userId,
+                                        String guid)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+    {
+        final String  methodName = "getRelationship";
+        final String  guidParameterName = "guid";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+
+        /*
+         * Process operation
+         */
+        AtlasRelationship atlasRelationship;
+        try {
+            atlasRelationship = relationshipStore.getById(guid);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("getRelationship: Caught exception from Atlas {}", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("findEntitiesByProperty", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("getRelationship: Read from atlas relationship store; relationship {}", atlasRelationship);
+        Relationship omRelationship;
+
+        try {
+            AtlasRelationshipMapper atlasRelationshipMapper = new AtlasRelationshipMapper(
+                    this,
+                    userId,
+                    atlasRelationship,
+                    entityStore);
+
+            omRelationship = atlasRelationshipMapper.toOMRelationship();
+            LOG.debug("getRelationship: om relationship {}", omRelationship);
+
+        }
+        catch (Exception e) {
+            LOG.debug("getRelationship: caught exception from mapper "+e.getMessage());
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_RELATIONSHIP_FROM_STORE;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guidParameterName,
+                    methodName,
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        LOG.debug("getRelationship: returning relationship {}", omRelationship);
+        return omRelationship;
+    }
+
+
+    /**
+     * Return a historical versionName of a relationship.
+     *
+     * @param userId   - unique identifier for requesting user.
+     * @param guid     - String unique identifier for the relationship.
+     * @param asOfTime - the time used to determine which versionName of the entity that is desired.
+     * @return EntityDetail structure.
+     * @throws InvalidParameterException     - the guid or date is null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the requested entity instance is not known in the metadata collection
+     *                                         at the time requested
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship getRelationship(String userId,
+                                        String guid,
+                                        Date asOfTime)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "getRelationship";
+        final String  guidParameterName = "guid";
+        final String  asOfTimeParameter = "asOfTime";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, guid, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // This method requires a historic query which is not supported
+        LOG.debug("getRelationship: Does not support asOfTime historic retrieval");
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        String errorMessage = errorCode.getErrorMessageId()
+                + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+
+        throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Return a list of relationships that match the requested properties by the matching criteria.   The results
+     * can be broken into pages.
+     *
+     * @param userId                  - unique identifier for requesting user
+     * @param relationshipTypeGUID    - unique identifier (guid) for the new relationship's type.
+     * @param matchProperties         - list of  properties used to narrow the search.
+     * @param matchCriteria           - Enum defining how the properties should be matched to the relationships in the repository.
+     * @param fromEntityDetailElement - the starting element number of the entities to return.
+     *                                This is used when retrieving elements
+     *                                beyond the first page of results. Zero means start from the first element.
+     * @param limitResultsByStatus    - By default, relationships in all statuses are returned.  However, it is possible
+     *                                to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                                status values.
+     * @param asOfTime                - Requests a historical query of the relationships for the entity.  Null means return the
+     *                                present values.
+     * @param sequencingProperty      - String name of the property that is to be used to sequence the results.
+     *                                Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder         - Enum defining how the results should be ordered.
+     * @param pageSize                - the maximum number of result relationships that can be returned on this request.  Zero means
+     *                                unrestricted return results size.
+     * @return a list of relationships.  Null means no matching relationships.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException         - the type guid passed on the request is not known by the
+     *                                    metadata collection.
+     * @throws PropertyErrorException     - the properties specified are not valid for any of the requested types of
+     *                                    relationships.
+     * @throws PagingErrorException       - the paging/sequencing parameters are set up incorrectly.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<Relationship> findRelationshipsByProperty(String userId,
+                                                          String relationshipTypeGUID,
+                                                          InstanceProperties matchProperties,
+                                                          MatchCriteria matchCriteria,
+                                                          int fromEntityDetailElement,
+                                                          List<InstanceStatus> limitResultsByStatus,
+                                                          Date asOfTime,
+                                                          String sequencingProperty,
+                                                          SequencingOrder sequencingOrder,
+                                                          int pageSize)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            PagingErrorException,
+            UserNotAuthorizedException
+
+    {
+        final String  methodName = "findRelationshipsByProperty";
+        final String  matchCriteriaParameterName = "matchCriteria";
+        final String  matchPropertiesParameterName = "matchProperties";
+        final String  guidParameterName = "relationshipTypeGUID";
+        final String  asOfTimeParameter = "asOfTime";
+        final String  pageSizeParameter = "pageSize";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+        repositoryValidator.validateMatchCriteria(repositoryName,
+                matchCriteriaParameterName,
+                matchPropertiesParameterName,
+                matchCriteria,
+                matchProperties,
+                methodName);
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, guidParameterName, relationshipTypeGUID, methodName);
+        } catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("unknown", relationshipTypeGUID, guidParameterName, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Perform operation
+         */
+        // This method requires a historic query which is not supported
+        LOG.debug("findRelationshipsByProperty: Does not support asOfTime historic retrieval");
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        String errorMessage = errorCode.getErrorMessageId()
+                + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+
+        throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+    /**
+     * Return a list of relationships whose string based property values match the search criteria.  The
+     * search criteria may include regex style wild cards.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param relationshipTypeGUID - GUID of the type of entity to search for. Null means all types will
+     *                       be searched (could be slow so not recommended).
+     * @param searchCriteria - String expression contained in any of the property values within the entities
+     *                       of the supplied type.
+     * @param fromRelationshipElement - Element number of the results to skip to when building the results list
+     *                                to return.  Zero means begin at the start of the results.  This is used
+     *                                to retrieve the results over a number of pages.
+     * @param limitResultsByStatus - By default, relationships in all statuses are returned.  However, it is possible
+     *                             to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                             status values.
+     * @param asOfTime - Requests a historical query of the relationships for the entity.  Null means return the
+     *                 present values.
+     * @param sequencingProperty - String name of the property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result relationships that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return a list of relationships.  Null means no matching relationships.
+     * @throws InvalidParameterException - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                  the metadata collection is stored.
+     * @throws PropertyErrorException - there is a problem with one of the other parameters.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     * @throws FunctionNotSupportedException - the repository does not support the asOfTime parameter.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<Relationship> findRelationshipsByPropertyValue(String                    userId,
+                                                               String                    relationshipTypeGUID,
+                                                               String                    searchCriteria,
+                                                               int                       fromRelationshipElement,
+                                                               List<InstanceStatus>      limitResultsByStatus,
+                                                               Date                      asOfTime,
+                                                               String                    sequencingProperty,
+                                                               SequencingOrder           sequencingOrder,
+                                                               int                       pageSize)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            PropertyErrorException,
+            PagingErrorException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+        final String  methodName = "findRelationshipsByPropertyValue";
+        final String  asOfTimeParameter = "asOfTime";
+        final String  pageSizeParameter = "pageSize";
+        final String  typeGUIDParameter = "relationshipTypeGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+
+
+        try {
+            this.validateTypeGUID(userId, repositoryName, typeGUIDParameter, relationshipTypeGUID, methodName);
+        } catch (TypeErrorException e) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage( "unknown", relationshipTypeGUID, typeGUIDParameter, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Perform operation
+         */
+        // This method requires a historic query which is not supported
+        LOG.debug("findRelationshipsByPropertyValue: Does not support asOfTime historic retrieval");
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+        String errorMessage = errorCode.getErrorMessageId()
+                + errorCode.getFormattedErrorMessage(asOfTimeParameter, methodName, metadataCollectionId);
+
+        throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Return all of the relationships and intermediate entities that connect the startEntity with the endEntity.
+     *
+     * @param userId               - unique identifier for requesting user.
+     * @param startEntityGUID      - The entity that is used to anchor the query.
+     * @param endEntityGUID        - the other entity that defines the scope of the query.
+     * @param limitResultsByStatus - By default, relationships in all statuses are returned.  However, it is possible
+     *                               to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                               status values.
+     * @param asOfTime             - Requests a historical query of the relationships for the entity.  Null means return the
+     *                               present values.
+     * @return InstanceGraph - the sub-graph that represents the returned linked entities and their relationships.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by either the startEntityGUID or the endEntityGUID
+     *                                      is not found in the metadata collection.
+     * @throws PropertyErrorException     - there is a problem with one of the other parameters.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public InstanceGraph getLinkingEntities(String               userId,
+                                            String               startEntityGUID,
+                                            String               endEntityGUID,
+                                            List<InstanceStatus> limitResultsByStatus,
+                                            Date                 asOfTime)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName                   = "getLinkingEntities";
+        final String startEntityGUIDParameterName = "startEntityGUID";
+        final String endEntityGUIDParameterName   = "entityGUID";
+        final String asOfTimeParameter            = "asOfTime";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, startEntityGUIDParameterName, startEntityGUID, methodName);
+        repositoryValidator.validateGUID(repositoryName, endEntityGUIDParameterName, endEntityGUID, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+
+        /*
+         * Perform operation
+         */
+
+        // TODO!! Need to investigate how to implement this method in Atlas
+        // To do this efficiently requires a gremlin traversal - it may be possible to do this in Atlas (internally).
+        // To achieve this by other means would be inefficient.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName, this.getClass().getName(), repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Return the entities and relationships that radiate out from the supplied entity GUID.
+     * The results are scoped both the instance type guids and the level.
+     *
+     * @param userId                       - unique identifier for requesting user.
+     * @param entityGUID                   - the starting point of the query.
+     * @param entityTypeGUIDs              - list of entity types to include in the query results.  Null means include
+     *                                     all entities found, irrespective of their type.
+     * @param relationshipTypeGUIDs        - list of relationship types to include in the query results.  Null means include
+     *                                     all relationships found, irrespective of their type.
+     * @param limitResultsByStatus         - By default, relationships in all statuses are returned.  However, it is possible
+     *                                     to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                                     status values.
+     * @param limitResultsByClassification - List of classifications that must be present on all returned entities.
+     * @param asOfTime                     - Requests a historical query of the relationships for the entity.  Null means return the
+     *                                     present values.
+     * @param level                        - the number of the relationships out from the starting entity that the query will traverse to
+     *                                     gather results.
+     * @return InstanceGraph - the sub-graph that represents the returned linked entities and their relationships.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException         - one or more of the type guids passed on the request is not known by the
+     *                                    metadata collection.
+     * @throws EntityNotKnownException    - the entity identified by the entityGUID is not found in the metadata collection.
+     * @throws PropertyErrorException     - there is a problem with one of the other parameters.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public InstanceGraph getEntityNeighborhood(String               userId,
+                                               String               entityGUID,
+                                               List<String>         entityTypeGUIDs,
+                                               List<String>         relationshipTypeGUIDs,
+                                               List<InstanceStatus> limitResultsByStatus,
+                                               List<String>         limitResultsByClassification,
+                                               Date                 asOfTime,
+                                               int                  level)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName                                  = "getEntityNeighborhood";
+        final String entityGUIDParameterName                     = "entityGUID";
+        final String entityTypeGUIDParameterName                 = "entityTypeGUIDs";
+        final String relationshipTypeGUIDParameterName           = "relationshipTypeGUIDs";
+        final String limitedResultsByClassificationParameterName = "limitResultsByClassification";
+        final String asOfTimeParameter                           = "asOfTime";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+
+        if (entityTypeGUIDs != null)
+        {
+            for (String guid : entityTypeGUIDs)
+            {
+                this.validateTypeGUID(userId, repositoryName, entityTypeGUIDParameterName, guid, methodName);
+            }
+        }
+
+        if (relationshipTypeGUIDs != null)
+        {
+            for (String guid : relationshipTypeGUIDs)
+            {
+                this.validateTypeGUID(userId, repositoryName, relationshipTypeGUIDParameterName, guid, methodName);
+            }
+        }
+
+        if (limitResultsByClassification != null)
+        {
+            for (String classificationName : limitResultsByClassification)
+            {
+                repositoryValidator.validateClassificationName(repositoryName,
+                        limitedResultsByClassificationParameterName,
+                        classificationName,
+                        methodName);
+            }
+        }
+
+        /*
+         * Perform operation
+         */
+        // TODO - Need to investigate how to implement this method in Atlas
+        // This should be implemented by a gremlin traversal internally within Atlas.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName, this.getClass().getName(), repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Return the list of entities that are of the types listed in instanceTypes and are connected, either directly or
+     * indirectly to the entity identified by startEntityGUID.
+     *
+     * @param userId                       - unique identifier for requesting user.
+     * @param startEntityGUID              - unique identifier of the starting entity.
+     * @param instanceTypes                - list of types to search for.  Null means an type.
+     * @param fromEntityElement            - starting element for results list.  Used in paging.  Zero means first element.
+     * @param limitResultsByStatus         - By default, relationships in all statuses are returned.  However, it is possible
+     *                                     to specify a list of statuses (eg ACTIVE) to restrict the results to.  Null means all
+     *                                     status values.
+     * @param limitResultsByClassification - List of classifications that must be present on all returned entities.
+     * @param asOfTime                     - Requests a historical query of the relationships for the entity.  Null means return the
+     *                                     present values.
+     * @param sequencingProperty           - String name of the property that is to be used to sequence the results.
+     *                                     Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder              - Enum defining how the results should be ordered.
+     * @param pageSize                     - the maximum number of result entities that can be returned on this request.  Zero means
+     *                                     unrestricted return results size.
+     * @return list of entities either directly or indirectly connected to the start entity
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException         - the requested type is not known, or not supported in the metadata repository
+     *                                    hosting the metadata collection.
+     * @throws EntityNotKnownException    - the entity identified by the startEntityGUID
+     *                                    is not found in the metadata collection.
+     * @throws PropertyErrorException     - the sequencing property specified is not valid for any of the requested types of
+     *                                    entity.
+     * @throws PagingErrorException       - the paging/sequencing parameters are set up incorrectly.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public List<EntityDetail> getRelatedEntities(String               userId,
+                                                 String               startEntityGUID,
+                                                 List<String>         instanceTypes,
+                                                 int                  fromEntityElement,
+                                                 List<InstanceStatus> limitResultsByStatus,
+                                                 List<String>         limitResultsByClassification,
+                                                 Date                 asOfTime,
+                                                 String               sequencingProperty,
+                                                 SequencingOrder      sequencingOrder,
+                                                 int                  pageSize)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            PagingErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "getRelatedEntities";
+        final String  entityGUIDParameterName  = "startEntityGUID";
+        final String  instanceTypesParameter = "instanceTypes";
+        final String  asOfTimeParameter = "asOfTime";
+        final String  pageSizeParameter = "pageSize";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, startEntityGUID, methodName);
+        repositoryValidator.validateAsOfTime(repositoryName, asOfTimeParameter, asOfTime, methodName);
+        repositoryValidator.validatePageSize(repositoryName, pageSizeParameter, pageSize, methodName);
+
+        if (instanceTypes != null)
+        {
+            for (String guid : instanceTypes)
+            {
+                this.validateTypeGUID(userId, repositoryName, instanceTypesParameter, guid, methodName);
+            }
+        }
+
+        /*
+         * Perform operation
+         */
+        // TODO - Need to investigate how to implement this method in Atlas
+        // This should be implemented by a gremlin traversal within Atlas
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName, this.getClass().getName(), repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    // ==========================================================================================================================
+
+    // Group 4 methods
+
+    /**
+     * Create a new entity and put it in the requested state.  The new entity is returned.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entityTypeGUID - unique identifier (guid) for the new entity's type.
+     * @param initialProperties - initial list of properties for the new entity - null means no properties.
+     * @param initialClassifications - initial list of classifications for the new entity - null means no classifications.
+     * @param initialStatus - initial status - typically DRAFT, PREPARED or ACTIVE.
+     * @return EntityDetail showing the new header plus the requested properties and classifications.  The entity will
+     * not have any relationships at this stage.
+     * @throws InvalidParameterException - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException - the requested type is not known, or not supported in the metadata repository
+     *                              hosting the metadata collection.
+     * @throws PropertyErrorException - one or more of the requested properties are not defined, or have different
+     *                                  characteristics in the TypeDef for this entity's type.
+     * @throws ClassificationErrorException - one or more of the requested classifications are either not known or
+     *                                           not defined for this entity type.
+     * @throws StatusNotSupportedException - the metadata repository hosting the metadata collection does not support
+     *                                       the requested status.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail addEntity(String                     userId,
+                                  String                     entityTypeGUID,
+                                  InstanceProperties         initialProperties,
+                                  List<Classification>       initialClassifications,
+                                  InstanceStatus             initialStatus)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            ClassificationErrorException,
+            StatusNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+
+
+        final String methodName = "addEntity";
+        final String sourceName = metadataCollectionId;
+        final String entityGUIDParameterName = "entityTypeGUID";
+        final String propertiesParameterName = "initialProperties";
+        final String classificationsParameterName = "initialClassifications";
+        final String initialStatusParameterName = "initialStatus";
+
+        if (LOG.isDebugEnabled())
+            LOG.debug("==> {}: userId {} entityTypeGUID {} initialProperties {} initialClassifications {} initialStatus {} ",
+                    methodName,userId,entityTypeGUID , initialProperties , initialClassifications, initialStatus );
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeGUID(repositoryName, entityGUIDParameterName, entityTypeGUID, methodName);
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+            if (typeDef != null) {
+                repositoryValidator.validateTypeDefForInstance(repositoryName, entityGUIDParameterName, typeDef, methodName);
+                repositoryValidator.validateClassificationList(repositoryName,
+                        classificationsParameterName,
+                        initialClassifications,
+                        typeDef.getName(),
+                        methodName);
+
+                repositoryValidator.validatePropertiesForType(repositoryName,
+                        propertiesParameterName,
+                        typeDef,
+                        initialProperties,
+                        methodName);
+
+                repositoryValidator.validateInstanceStatus(repositoryName,
+                        initialStatusParameterName,
+                        initialStatus,
+                        typeDef,
+                        methodName);
+            }
+        } catch (TypeDefNotKnownException e) {
+            // Swallow and throw TypeErrorException below
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Validation complete - ok to create new instance
+         */
+
+        // Perform validation checks on type specified by guid.
+        // Create an instance of the Entity, setting the createdBy to userId, createdTime to now, etc.
+        // Then set the properties and initialStatus.
+        // Create the entity in the Atlas repository.
+        // Set the classifications
+
+        // Note: There are two obvious ways to implement this method -
+        // i) retrieve the typedef from Atlas into OM form, perform logic, construct Atlas objects and send to Atlas
+        // ii) retrieve typedef from Atlas and use it directly to instantiate the entity.
+        // This method uses the former approach, as it may result in common code with other methods.
+
+
+        if (typeDef.getCategory() != ENTITY_DEF) {
+            LOG.error("addEntity: Found typedef with guid {} but it is not an EntityDef", entityTypeGUID);
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("unknown", entityTypeGUID, entityGUIDParameterName, methodName, repositoryName, "unknown");
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        EntityDef entityDef = (EntityDef) typeDef;
+
+        // Retrieve the classification def for each of the initial classifications, and check they list the entity type as valid.
+        if (initialClassifications != null) {
+            for (Classification classification :  initialClassifications ) {
+                // Retrieve the classification def and check it contains the entity type
+                ClassificationDef classificationDef;
+                try {
+                    classificationDef = (ClassificationDef)_getTypeDefByName(userId, classification.getName());
+                }
+                catch (Exception e) {
+                    LOG.error("addEntity: Could not find classification def with name {}", classification.getName(), e);
+
+                    OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+                    String        errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(classification.getName(), "unknown", classificationsParameterName, methodName, repositoryName, "unknown");
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+                List<TypeDefLink> validEntityDefs = classificationDef.getValidEntityDefs();
+                if (validEntityDefs != null) {
+                    // This assumes that if validEntityDefs is null then the classification can be attached (to anything).
+                    boolean match = false;
+                    for (TypeDefLink tDL : validEntityDefs) {
+                        // compare the tDL with the entityTDL
+                        if (entityDef.getGUID().equals(tDL.getGUID()) && entityDef.getName().equals(tDL.getName())) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if (!match) {
+                        LOG.error("addEntity: Cannot classify entity type with classification {}", classification.getName());
+
+                        OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_CLASSIFICATION_FOR_ENTITY;
+                        String        errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(classification.getName(), classificationsParameterName, methodName, repositoryName);
+
+                        throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                methodName,
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+
+                    }
+                }
+            }
+        }
+
+
+        // Collate the valid instance properties
+        EntityDefMapper entityDefMapper = new EntityDefMapper(this, userId, entityDef);
+        ArrayList<String> validInstanceProperties = entityDefMapper.getValidPropertyNames();
+
+        // Create an instance type
+        // An OM EntityDef only has one superType - so retrieve it and wrap into a list of length one...
+        ArrayList<TypeDefLink> listSuperTypes = new ArrayList<>();
+        listSuperTypes.add(entityDef.getSuperType());
+        InstanceType instanceType = new InstanceType(entityDef.getCategory(),
+                                                     entityTypeGUID,
+                                                     entityDef.getName(),
+                                                     entityDef.getVersion(),
+                                                     entityDef.getDescription(),
+                                                     entityDef.getDescriptionGUID(),
+                                                     listSuperTypes,
+                                                     entityDef.getValidInstanceStatusList(),
+                                                     validInstanceProperties);
+
+        // Construct an EntityDetail object
+        Date now = new Date();
+        EntityDetail entityDetail = new EntityDetail();
+        // Set fields from InstanceAuditHeader
+        entityDetail.setType(instanceType);
+        entityDetail.setCreatedBy(userId);
+        entityDetail.setCreateTime(now);
+        entityDetail.setUpdatedBy(userId);
+        entityDetail.setUpdateTime(now);
+        entityDetail.setVersion(1L);
+        entityDetail.setStatus(InstanceStatus.ACTIVE);
+        // Set fields from InstanceHeader
+        entityDetail.setMetadataCollectionId(metadataCollectionId);
+        // GUID is not set till after the create by Atlas
+        entityDetail.setGUID(null);
+        entityDetail.setInstanceURL(null);
+        // Set fields from EntitySummary
+        // Set the classifications
+        entityDetail.setClassifications(initialClassifications);
+        // Set fields from EntityDetail
+        // Set the properties
+        entityDetail.setProperties(initialProperties);
+
+        // Add the Entity to the AtlasEntityStore...
+
+        /*
+         * Construct an AtlasEntity
+         * Let the AtlasEntity constructor set the GUID - it will be initialized
+         * to nextInternalId and Atlas will generate
+         */
+        AtlasEntity atlasEntity = new AtlasEntity();
+        atlasEntity.setTypeName(typeDef.getName());
+
+        atlasEntity.setStatus(AtlasEntity.Status.ACTIVE);
+        atlasEntity.setCreatedBy(entityDetail.getCreatedBy());
+        atlasEntity.setUpdatedBy(entityDetail.getUpdatedBy());
+        atlasEntity.setCreateTime(entityDetail.getCreateTime());
+        atlasEntity.setUpdateTime(entityDetail.getUpdateTime());
+        atlasEntity.setVersion(entityDetail.getVersion());
+
+        // Cannot set classifications yet - need to do that post-create to get the entity GUID
+
+        // Map attributes from OM EntityDetail to AtlasEntity
+        InstanceProperties instanceProperties = entityDetail.getProperties();
+        Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(instanceProperties);
+        atlasEntity.setAttributes(atlasAttrs);
+
+        // AtlasEntity should have been fully constructed by this point
+        LOG.debug("addEntity: atlasEntity to create is {}", atlasEntity);
+
+        String newEntityGuid;
+        // Construct an AtlasEntityStream and call the repository
+        //
+        // Because we want to retain the value of the isProxy  flag and other system attributes, we need to
+        // use an EntityImportStream.
+        // The CTOR for this takes an AtlasEntityWithExtInfo entityWithExtInfo & an EntityStream entityStream
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWEI = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+        AtlasEntityStreamForImport eis = new AtlasEntityStreamForImport(atlasEntityWEI, null);
+        EntityMutationResponse emr;
+        try {
+            emr = entityStore.createOrUpdateForImport(eis);
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("addEntity: Caught exception from Atlas {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("entity", "entity parameters", methodName, sourceName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Interpret the EMR (EntityMutationResponse) and fill in any extra detail in EntityDetail - e.g. sys attrs
+        // The EMR provides the following:
+        //  Map<EntityOperation, List<AtlasEntityHeader>> mutatedEntities;
+        //  Map<String, String>                           guidAssignments;
+        // Check that our Entity is in the createdEntities
+        if (emr != null) {
+            List<AtlasEntityHeader> atlasEntityHeaders = emr.getCreatedEntities();
+            if (atlasEntityHeaders == null || atlasEntityHeaders.size() != 1) {
+                int numReturned = 0;
+                if (atlasEntityHeaders == null) {
+                    LOG.error("addEntity: Expected Atlas to return exactly one created entity, but returned null");
+                } else {
+                    numReturned = atlasEntityHeaders.size();
+                    LOG.error("addEntity: Expected Atlas to return exactly one created entity, but returned {}", numReturned);
+                }
+                // We have more or less entities than we expected
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("entity", "entity createOrUpdate", methodName, sourceName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            } else {
+                // Verify that the AEH contains what we would expect..
+                // String                    guid                => should be set to allocated GUID - we will copy this to EntityDetail
+                // AtlasEntity.Status        status              => check set to AtlasEntity.Status.ACTIVE;
+                // String                    displayText         => ignored
+                // List<String>              classificationNames => ignored - classifications are set below
+                // List<AtlasClassification> classifications     => ignored - classifications are set below
+                AtlasEntityHeader aeh = atlasEntityHeaders.get(0);
+                if (aeh.getStatus() != AtlasEntity.Status.ACTIVE) {
+                    LOG.error("addEntity: Atlas created entity, but status set to {}", aeh.getStatus());
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage("entity", "entity createOrUpdate", methodName, sourceName);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                } else {
+                    // Note the newly allocated entity GUID - we will need it in multiple places below
+                    newEntityGuid = aeh.getGuid();
+                    LOG.debug("newEntityGuid = {}", newEntityGuid);
+                    entityDetail.setGUID(newEntityGuid);
+                }
+            }
+        } else {
+            LOG.error("addEntity: Atlas create of entity returned null");
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("null", "entityMutationResponse", methodName, sourceName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        /*
+         * Call Atlas to set classifications..
+         *
+         *  You can't set the classifications on the AtlasEntity until after it has been
+         *  created, as each AtlasClassification needs the entity GUID. So add the classifications post-create.
+         *  AtlasEntity needs a List<AtlasClassification> so we need to do some translation
+         *
+         *  OM Classification has:
+         *  String               classificationName
+         *  InstanceProperties   classificationProperties
+         *  ClassificationOrigin classificationOrigin
+         *  String               classificationOriginGUID
+         *
+         *  AtlasClassification has:
+         *  String              entityGuid
+         *  boolean             propagate
+         *  List<TimeBoundary>  validityPeriods
+         *  String              typeName
+         *  Map<String, Object> attributes
+         */
+
+
+        if (entityDetail.getClassifications() != null && entityDetail.getClassifications().size() > 0) {
+            ArrayList<AtlasClassification> atlasClassifications = new ArrayList<>();
+            for (Classification omClassification : entityDetail.getClassifications()) {
+                AtlasClassification atlasClassification = new AtlasClassification(omClassification.getName());
+                /*
+                 * For this OM classification build an Atlas equivalent...
+                 * For now we are always setting propagatable to true and AtlasClassification has propagate=true by default.
+                 * Instead this could traverse to the Classification.InstanceType.typeDefGUID and retrieve the ClassificationDef
+                 * to find the value of propagatable on the def.
+                 */
+                atlasClassification.setTypeName(omClassification.getType().getTypeDefName());
+                atlasClassification.setEntityGuid(newEntityGuid);
+
+                /* OM Classification has InstanceProperties of form Map<String, InstancePropertyValue>  instanceProperties
+                 */
+                InstanceProperties classificationProperties = omClassification.getProperties();
+                Map<String, Object> atlasClassificationAttrs = convertOMPropertiesToAtlasAttributes(classificationProperties);
+                atlasClassification.setAttributes(atlasClassificationAttrs);
+
+                atlasClassifications.add(atlasClassification);
+            }
+            /* We do not need to augment the AtlasEntity we created earlier - we can just use the
+             * atlasClassifications directly with the following repository call...
+             */
+            try {
+
+                entityStore.addClassifications(newEntityGuid, atlasClassifications);
+
+            } catch (AtlasBaseException e) {
+
+                // Failed to add classifications to the entity
+                LOG.error("addEntity: Atlas created entity, but we could not add classifications to it, guid {}", newEntityGuid);
+
+                OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_CLASSIFIED;
+
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        if (LOG.isDebugEnabled())
+            LOG.debug("<== {}: entityDetail {} ", methodName, entityDetail);
+
+        return entityDetail;
+    }
+
+
+    /**
+     * Create an entity proxy in the metadata collection.  This is used to store relationships that span metadata
+     * repositories.
+     *
+     * @param userId                         - unique identifier for requesting user.
+     * @param entityProxy                    - details of entity to add.
+     * @throws InvalidParameterException     - the entity proxy is null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws FunctionNotSupportedException - the repository does not support entity proxies as first class elements.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public void addEntityProxy(String      userId,
+                               EntityProxy entityProxy)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+        final String  methodName         = "addEntityProxy";
+        final String  proxyParameterName = "entityProxy";
+
+
+        if (LOG.isDebugEnabled())
+            LOG.debug("==> {}: userId {} entityProxy {} ", methodName, userId, entityProxy );
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+
+        repositoryValidator.validateEntityProxy(repositoryName,
+                metadataCollectionId,
+                proxyParameterName,
+                entityProxy,
+                methodName);
+
+        /*
+         * Also validate that the proxy contains a metadataCollectionId (i.e. it is not null)
+         */
+        if (entityProxy.getMetadataCollectionId() == null) {
+            LOG.error("addEntityProxy: Must contain a non-null metadataCollectionId identifying the home repository");
+
+            OMRSErrorCode errorCode = OMRSErrorCode.LOCAL_ENTITY_PROXY;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(
+                    metadataCollectionId,
+                    proxyParameterName,
+                    methodName);
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validation complete
+         */
+
+        /*
+         * An EntityProxy is stored in Atlas as a normal AtlasEntity but with a reduced
+         * level of detail (the other fields of EntityDetail are not available). In order
+         * to identify that the created AtlasEntity is a proxy, the isProxy system attribute
+         * is set.
+         */
+
+        /*
+         * Check that the EntityProxy contains everything we expect...
+         */
+        Date now = new Date();
+        entityProxy.setCreatedBy(userId);
+        entityProxy.setCreateTime(now);
+        entityProxy.setUpdatedBy(userId);
+        entityProxy.setUpdateTime(now);
+        entityProxy.setVersion(1L);
+        entityProxy.setStatus(InstanceStatus.ACTIVE);
+
+
+        // Add the EntityProxy to the AtlasEntityStore...
+
+
+        /*
+         * Construct an AtlasEntity
+         * The AtlasEntity constructor will set the GUID - but overwrite it with the GUID from the proxy
+         * Also set the homeId and the isProxy flag.
+         */
+        AtlasEntity atlasEntity = new AtlasEntity();
+        atlasEntity.setIsProxy(true);
+        atlasEntity.setGuid(entityProxy.getGUID());
+        atlasEntity.setHomeId(entityProxy.getMetadataCollectionId());
+
+        atlasEntity.setTypeName(entityProxy.getType().getTypeDefName());
+
+        atlasEntity.setStatus(AtlasEntity.Status.ACTIVE);
+        atlasEntity.setCreatedBy(entityProxy.getCreatedBy());
+        atlasEntity.setUpdatedBy(entityProxy.getUpdatedBy());
+        atlasEntity.setCreateTime(entityProxy.getCreateTime());
+        atlasEntity.setUpdateTime(entityProxy.getUpdateTime());
+        atlasEntity.setVersion(entityProxy.getVersion());
+
+        // Cannot set classifications yet - need to do that post-create to get the entity GUID
+
+        // Map attributes from OM EntityProxy to AtlasEntity
+        InstanceProperties instanceProperties = entityProxy.getUniqueProperties();
+        Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(instanceProperties);
+        atlasEntity.setAttributes(atlasAttrs);
+
+        // AtlasEntity should have been fully constructed by this point
+        LOG.debug("addEntityProxy: atlasEntity to create is {}", atlasEntity);
+
+        // Construct an AtlasEntityStream and call the repository
+        // Because we want to impose the GUID (e.g. RID) that has been supplied in the EntityProxy, we
+        // need to ask Atlas to accept the entity with existing GUID. Therefore we must use an EntityImportStream.
+        // The CTOR for this takes an AtlasEntityWithExtInfo entityWithExtInfo & an EntityStream entityStream
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWEI = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+        AtlasEntityStreamForImport eis = new AtlasEntityStreamForImport(atlasEntityWEI, null);
+        EntityMutationResponse emr;
+        try {
+            emr = entityStore.createOrUpdateForImport(eis);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("addEntityProxy: Caught exception trying to create entity proxy, {} ", e);
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ENTITY_NOT_CREATED;
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(
+                    atlasEntity.toString(), methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        LOG.debug("addEntityProxy: response from entityStore {}", emr);
+
+        /*
+         * Call Atlas to set classifications..
+         *
+         *  You can't set the classifications on the AtlasEntity until after it has been
+         *  created, as each AtlasClassification needs the entity GUID. So add the classifications post-create.
+         *  AtlasEntity needs a List<AtlasClassification> so we need to do some translation
+         *
+         *  OM Classification has:
+         *  String               classificationName
+         *  InstanceProperties   classificationProperties
+         *  ClassificationOrigin classificationOrigin
+         *  String               classificationOriginGUID
+         *
+         *  AtlasClassification has:
+         *  String              entityGuid
+         *  boolean             propagate
+         *  List<TimeBoundary>  validityPeriods
+         *  String              typeName
+         *  Map<String, Object> attributes
+         */
+
+
+        if (entityProxy.getClassifications() != null && entityProxy.getClassifications().size() > 0) {
+            ArrayList<AtlasClassification> atlasClassifications = new ArrayList<>();
+            for (Classification omClassification : entityProxy.getClassifications()) {
+                AtlasClassification atlasClassification = new AtlasClassification(omClassification.getName());
+                /*
+                 * For this OM classification build an Atlas equivalent...
+                 * For now we are always setting propagatable to true and AtlasClassification has propagate=true by default.
+                 * Instead this could traverse to the Classification.InstanceType.typeDefGUID and retrieve the ClassificationDef
+                 * to find the value of propagatable on the def.
+                 */
+                atlasClassification.setTypeName(omClassification.getType().getTypeDefName());
+                atlasClassification.setEntityGuid(entityProxy.getGUID());
+
+                /* OM Classification has InstanceProperties of form Map<String, InstancePropertyValue>  instanceProperties
+                 */
+                InstanceProperties classificationProperties = omClassification.getProperties();
+                Map<String, Object> atlasClassificationAttrs = convertOMPropertiesToAtlasAttributes(classificationProperties);
+                atlasClassification.setAttributes(atlasClassificationAttrs);
+
+                atlasClassifications.add(atlasClassification);
+            }
+            /* We do not need to augment the AtlasEntity we created earlier - we can just use the
+             * atlasClassifications directly with the following repository call...
+             */
+            try {
+
+                entityStore.addClassifications(entityProxy.getGUID(), atlasClassifications);
+
+            } catch (AtlasBaseException e) {
+
+                // Failed to add classifications to the entity
+                LOG.error("addEntityProxy: Atlas created entity, but we could not add classifications to it, guid {}", entityProxy.getGUID(), e);
+
+                OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_CLASSIFIED;
+
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+
+        if (LOG.isDebugEnabled())
+            LOG.debug("<== {}: entityProxy {} ", methodName, entityProxy);
+
+    }
+
+
+    /**
+     * Update the status for a specific entity.
+     *
+     * @param userId     - unique identifier for requesting user.
+     * @param entityGUID - unique identifier (guid) for the requested entity.
+     * @param newStatus  - new InstanceStatus for the entity.
+     * @return EntityDetail showing the current entity header, properties and classifications.
+     * @throws InvalidParameterException   - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException    - there is a problem communicating with the metadata repository where
+     *                                     the metadata collection is stored.
+     * @throws EntityNotKnownException     - the entity identified by the guid is not found in the metadata collection.
+     * @throws StatusNotSupportedException - the metadata repository hosting the metadata collection does not support
+     *                                     the requested status.
+     * @throws UserNotAuthorizedException  - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail updateEntityStatus(String         userId,
+                                           String         entityGUID,
+                                           InstanceStatus newStatus)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            StatusNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName               = "updateEntityStatus";
+        final String  entityGUIDParameterName  = "entityGUID";
+        final String  statusParameterName      = "newStatus";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        repositoryValidator.validateInstanceType(repositoryName, entity);
+
+        String entityTypeGUID = entity.getType().getTypeDefGUID();
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+
+            if (typeDef != null) {
+                repositoryValidator.validateNewStatus(repositoryName, statusParameterName, newStatus, typeDef, methodName);
+            }
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        /*
+         * The above validation has already retrieved the entity from Atlas, by GUID and
+         * converted it to an EntityDetail.
+         */
+
+        /*
+         * Set the status to the requested value.
+         */
+        entity.setStatus(newStatus);
+
+        /*
+         * Convert to Atlas and store, retrieve and convert to returnable EntityDetail
+         */
+        try {
+            AtlasEntity atlasEntity = convertOMEntityDetailToAtlasEntity(userId, entity);
+            LOG.debug("updateEntityStatus: atlasEntity to update is {}", atlasEntity);
+
+            // Construct an AtlasEntityWithExtInfo and call the repository
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityToUpdate = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+
+            entityStore.createOrUpdate(new AtlasEntityStream(atlasEntityToUpdate),true);
+
+            // Retrieve the AtlasEntity - rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+            if (atlasEntWithExt == null) {
+                LOG.error("updateEntityStatus: Could not find entity with guid {} ", entityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntWithExt.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            return returnEntityDetail;
+
+        }
+        catch (TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("updateEntityStatus: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("updateEntityStatus: Caught exception from Atlas {}", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Update selected properties in an entity.
+     *
+     * @param userId     - unique identifier for requesting user.
+     * @param entityGUID - String unique identifier (guid) for the entity.
+     * @param properties - a list of properties to change.
+     * @return EntityDetail showing the resulting entity header, properties and classifications.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection
+     * @throws PropertyErrorException     - one or more of the requested properties are not defined, or have different
+     *                                      characteristics in the TypeDef for this entity's type
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail updateEntityProperties(String             userId,
+                                               String             entityGUID,
+                                               InstanceProperties properties)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "updateEntityProperties";
+        final String  entityGUIDParameterName  = "entityGUID";
+        final String  propertiesParameterName  = "properties";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        repositoryValidator.validateInstanceType(repositoryName, entity);
+
+        String entityTypeGUID = entity.getType().getTypeDefGUID();
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+
+            if (typeDef != null) {
+                repositoryValidator.validateNewPropertiesForType(repositoryName,
+                        propertiesParameterName,
+                        typeDef,
+                        properties,
+                        methodName);
+            }
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        /*
+         * The above validation has already retrieved the entity from Atlas, by GUID and
+         * converted it to an EntityDetail.
+         */
+
+        /*
+         * Update the properties that need changing.
+         */
+        InstanceProperties currentProps = entity.getProperties();
+        Iterator<String> newPropNames = properties == null ? null : properties.getPropertyNames();
+        if (newPropNames != null) {
+            while (newPropNames.hasNext()) {
+                String name = newPropNames.next();
+                InstancePropertyValue value = properties.getPropertyValue(name);
+                currentProps.setProperty(name,value);
+            }
+        }
+        entity.setProperties(currentProps);
+
+        /*
+         * Convert to Atlas and store, retrieve and convert to returnable EntityDetail
+         */
+        try {
+            AtlasEntity atlasEntity = convertOMEntityDetailToAtlasEntity(userId, entity);
+            LOG.debug("updateEntityStatus: atlasEntity to update is {}", atlasEntity);
+
+            // Construct an AtlasEntityWithExtInfo and call the repository
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityToUpdate = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+            entityStore.createOrUpdate(new AtlasEntityStream(atlasEntityToUpdate),true);
+
+            // Retrieve the AtlasEntity. Rather than parsing the EMR returned by the store, just get the entity directly
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+            if (atlasEntWithExt == null) {
+                LOG.error("updateEntityStatus: Could not find entity with guid {} ", entityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntWithExt.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            return returnEntityDetail;
+
+        }
+        catch (StatusNotSupportedException | TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("updateEntityStatus: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("updateEntityStatus: Caught exception from Atlas {}", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Undo the last update to an entity and return the previous content.
+     *
+     * @param userId                      - unique identifier for requesting user.
+     * @param entityGUID                  - String unique identifier (guid) for the entity.
+     * @return EntityDetail showing the resulting entity header, properties and classifications.
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail undoEntityUpdate(String userId,
+                                         String entityGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "undoEntityUpdate";
+        final String  entityGUIDParameterName  = "entityGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+
+        /*
+         * Validation complete - ok to restore entity
+         */
+
+        // In the Atlas connector the previous update is not persisted.
+
+        // I do not known of a way in Atlas to retrieve an earlier previous version.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Delete an entity.  The entity is soft deleted.  This means it is still in the graph but it is no longer returned
+     * on queries.  All relationships to the entity are also soft-deleted and will no longer be usable.
+     * To completely eliminate the entity from the graph requires a call to the purgeEntity() method after the delete call.
+     * The restoreEntity() method will switch an entity back to Active status to restore the entity to normal use.
+     *
+     * @param userId                         - unique identifier for requesting user.
+     * @param typeDefGUID                    - unique identifier of the type of the entity to delete.
+     * @param typeDefName                    - unique name of the type of the entity to delete.
+     * @param obsoleteEntityGUID             - String unique identifier (guid) for the entity.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws EntityNotKnownException       - the entity identified by the guid is not found in the metadata collection.
+     * @throws FunctionNotSupportedException - the metadata repository hosting the metadata collection does not support
+     *                                         soft-deletes - use purgeEntity() to remove the entity permanently.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail deleteEntity(String userId,
+                                     String typeDefGUID,
+                                     String typeDefName,
+                                     String obsoleteEntityGUID)
+
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        // TODO - need to find a way to determine whether soft deletes are supported.
+
+        final String  methodName               = "deleteEntity";
+        final String  typeDefGUIDParameterName = "typeDefGUID";
+        final String  typeDefNameParameterName = "typeDefName";
+        final String  entityGUIDParameterName  = "obsoleteEntityGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                typeDefGUIDParameterName,
+                typeDefNameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, obsoleteEntityGUID, methodName);
+
+        /*
+         * Locate Entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, obsoleteEntityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, obsoleteEntityGUID, entity, methodName);
+
+        repositoryValidator.validateTypeForInstanceDelete(repositoryName,
+                typeDefGUID,
+                typeDefName,
+                entity,
+                methodName);
+
+        repositoryValidator.validateInstanceStatusForDelete(repositoryName, entity, methodName);
+
+        /*
+         * Complete the request
+         */
+
+        // One final piece of validation - if deletes are configured as HARD then throw not supported exception
+        if (atlasDeleteConfiguration == AtlasDeleteOption.HARD) {
+            LOG.error("deleteEntity: Repository is configured for hard deletes, cannot soft delete entity with guid {}",
+                    obsoleteEntityGUID);
+            LocalAtlasOMRSErrorCode errorCode    = LocalAtlasOMRSErrorCode.ATLAS_CONFIGURATION_HARD;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteEntityGUID, methodName, repositoryName);
+
+            throw new FunctionNotSupportedException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /* From here on, this method is performing a SOFT delete.
+         * The deleted entity is read back to read the updated the system attributes
+         * so they can be set in the returned EntityDetail
+         */
+
+        try {
+            entityStore.deleteById(obsoleteEntityGUID);
+
+            /*
+             * Read the entity back from the store - this should work if it was a soft delete.
+             * By reading back, the status should reflect that it's been deleted and it should
+             * have updated system attributes.
+             *
+             * Retrieve the AtlasEntity - rather than parsing the EMR just get the entity directly
+             */
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+
+            atlasEntWithExt = entityStore.getById(obsoleteEntityGUID);
+
+            if (atlasEntWithExt == null) {
+                LOG.error("deleteEntity: Could not find entity with guid {} ", obsoleteEntityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(obsoleteEntityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntWithExt.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            return returnEntityDetail;
+
+        }
+        catch (TypeErrorException | InvalidEntityException e) {
+
+            LOG.error("updateEntityStatus: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        catch (AtlasBaseException e) {
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Permanently removes a deleted entity from the metadata collection.  This request can not be undone.
+     *
+     * @param userId            - unique identifier for requesting user.
+     * @param typeDefGUID       - unique identifier of the type of the entity to purge.
+     * @param typeDefName       - unique name of the type of the entity to purge.
+     * @param deletedEntityGUID - String unique identifier (guid) for the entity.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection
+     * @throws EntityNotDeletedException  - the entity is not in DELETED status and so can not be purged
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void purgeEntity(String userId,
+                            String typeDefGUID,
+                            String typeDefName,
+                            String deletedEntityGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            EntityNotDeletedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName               = "purgeEntity";
+        final String  typeDefGUIDParameterName = "typeDefGUID";
+        final String  typeDefNameParameterName = "typeDefName";
+        final String  entityGUIDParameterName  = "deletedEntityGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                typeDefGUIDParameterName,
+                typeDefNameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, deletedEntityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, deletedEntityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, deletedEntityGUID, entity, methodName);
+
+        repositoryValidator.validateTypeForInstanceDelete(repositoryName,
+                typeDefGUID,
+                typeDefName,
+                entity,
+                methodName);
+
+
+        /* Atlas has two configuration settings for its DeleteHandler - soft deletes or hard deletes.
+         * If Atlas is configured for hard deletes, this purge method will remove the entity.
+         * If Atlas is configured for soft deletes, the entity must have been (soft-)deleted prior to
+         * this purgeEntity call. In this case, check that the entity is in DELETED state.
+         *
+         * This method does not use the repository's deleteById method - instead it uses the purgeById
+         * method - which guarantees a permanent removal independent of how the repository is configured.
+         */
+
+        /*
+         * If soft delete is enabled in the repository, check that the entity has been deleted.
+         */
+        if (atlasDeleteConfiguration == AtlasDeleteOption.SOFT) {
+            LOG.debug("purgeEntity: Soft-delete is configured, check that entity to be purged is in DELETED state");
+            repositoryValidator.validateEntityIsDeleted(repositoryName, entity, methodName);
+        }
+
+
+        /*
+         * Validation is complete - ok to remove the entity
+         */
+
+        /*
+         * From here on, this method performs a HARD delete.
+         */
+
+        try {
+
+            LOG.debug("TODO!! add purgeById to entity store!!");
+            //entityStore.purgeById(deletedEntityGUID); // TODO - waiting for ATLAS-2774
+
+        }
+        //catch (AtlasBaseException e) { // TODO - catch appropriate exceptions when ATLAS-2774 is available
+        catch (Exception e) {
+            LOG.error("purgeEntity: Caught exception from Atlas entityStore trying to purge entity {}", deletedEntityGUID, e);
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ENTITY_NOT_DELETED;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(deletedEntityGUID, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Restore the requested entity to the state it was before it was deleted.
+     *
+     * @param userId            - unique identifier for requesting user.
+     * @param deletedEntityGUID - String unique identifier (guid) for the entity.
+     * @return EntityDetail showing the restored entity header, properties and classifications.
+     * @throws InvalidParameterException  - the guid is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection
+     * @throws EntityNotDeletedException  - the entity is currently not in DELETED status and so it can not be restored
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail restoreEntity(String userId,
+                                      String deletedEntityGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            EntityNotDeletedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName              = "restoreEntity";
+        final String  entityGUIDParameterName = "deletedEntityGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, deletedEntityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, deletedEntityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, deletedEntityGUID, entity, methodName);
+
+        repositoryValidator.validateEntityIsDeleted(repositoryName, entity, methodName);
+
+        /*
+         * Validation is complete.  It is ok to restore the entity.
+         */
+        // Atlas has two configuration settings for its DeleteHandler - all soft deletes or all hard deletes.
+        // We would require that soft deletes are in force and even then it is not clear how to implement
+        // a restore from an earlier soft delete. There is no entity store operation for this.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    /**
+     * Add the requested classification to a specific entity.
+     *
+     * @param userId                   - unique identifier for requesting user.
+     * @param entityGUID               - String unique identifier (guid) for the entity.
+     * @param classificationName       - String name for the classification.
+     * @param classificationProperties - list of properties to set in the classification.
+     * @return EntityDetail showing the resulting entity header, properties and classifications.
+     * @throws InvalidParameterException    - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException      - the entity identified by the guid is not found in the metadata collection
+     * @throws ClassificationErrorException - the requested classification is either not known or not valid
+     *                                      for the entity.
+     * @throws PropertyErrorException       - one or more of the requested properties are not defined, or have different
+     *                                      characteristics in the TypeDef for this classification type
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail classifyEntity(String             userId,
+                                       String             entityGUID,
+                                       String             classificationName,
+                                       InstanceProperties classificationProperties)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            ClassificationErrorException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName                  = "classifyEntity";
+        final String  entityGUIDParameterName     = "entityGUID";
+        final String  classificationParameterName = "classificationName";
+        final String  propertiesParameterName     = "classificationProperties";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity  = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        repositoryValidator.validateInstanceType(repositoryName, entity);
+
+        InstanceType entityType = entity.getType();
+
+        repositoryValidator.validateClassification(repositoryName,
+                classificationParameterName,
+                classificationName,
+                entityType.getTypeDefName(),
+                methodName);
+
+        Classification newClassification;
+        try
+        {
+            repositoryValidator.validateClassificationProperties(repositoryName,
+                    classificationName,
+                    propertiesParameterName,
+                    classificationProperties,
+                    methodName);
+
+            /*
+             * Validation complete - build the new classification
+             */
+            newClassification = repositoryHelper.getNewClassification(repositoryName,
+                    userId,
+                    classificationName,
+                    entityType.getTypeDefName(),
+                    ClassificationOrigin.ASSIGNED,
+                    null,
+                    classificationProperties);
+        }
+        catch (Throwable   error)
+        {
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_CLASSIFICATION_FOR_ENTITY;
+
+            throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    error.getMessage(),
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validation complete - ok to update entity
+         */
+
+
+        /*
+         * The classificationName parameter is actually the name of the ClassificationDef for the type of classification.
+         * Locate the ClassificationDef (by name). Fail if not found.
+         * Locate the AtlasEntity (by GUID).  Fail if not found.
+         * Project the AtlasEntity to an OM Entity - classification eligibility is tested in terms of OM defs.
+         * Check that the ClassificationDef lists the EntityDef as a validEntityDef. Fail if not.
+         * Create an AtlasClassification.
+         * Update the AtlasEntity with the AtlasClassification.
+         * Store in the repo.
+         * Retrieve the classified entity from the repo and convert to/return as an EntityDetail showing the new classification.
+         */
+
+        LOG.debug("classifyEntity: newClassification is {}", newClassification);
+
+        // Use the classificationName to locate the ClassificationDef.
+        // The parameter validation above performs some of this already, but we need to classify the Atlas entity
+        // with an Atlas classification
+        TypeDef typeDef;
+        try {
+
+            typeDef = _getTypeDefByName(userId, classificationName);
+
+        } catch (TypeDefNotKnownException e) {
+            // Handle below
+            typeDef = null;
+        }
+        if (typeDef == null || typeDef.getCategory() != CLASSIFICATION_DEF) {
+            LOG.error("classifyEntity: Could not find a classification def with name {}", classificationName);
+            OMRSErrorCode errorCode    = OMRSErrorCode.NO_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(classificationName, "classificationName", methodName, repositoryName);
+
+            throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        ClassificationDef classificationDef = (ClassificationDef) typeDef;
+
+
+        // Retrieve the AtlasEntity
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+        try {
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+        } catch (AtlasBaseException e) {
+            // handle below
+            atlasEntWithExt = null;
+        }
+        if (atlasEntWithExt == null) {
+            LOG.error("classifyEntity: Could not find entity with guid {} ", entityGUID);
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, "entityGUID", methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+        // Extract the entity
+        AtlasEntity atlasEntity = atlasEntWithExt.getEntity();
+
+        LOG.debug("classifyEntity: atlasEntity retrieved with classifications {}", atlasEntity.getClassifications());
+
+        // Project AtlasEntity as an EntityDetail.
+        EntityDetail entityDetail;
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            entityDetail = atlasEntityMapper.toEntityDetail();
+        }
+        catch (TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("classifyEntity: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, "entityGUID", methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Check that the entity type is listed in the VEDs for the classificationDef
+        entityType = entityDetail.getType();
+        String entityTypeName = entityType.getTypeDefName();
+        List<TypeDefLink> validEntityDefs = classificationDef.getValidEntityDefs();
+        LOG.debug("classifyEntity: classification def has validEntityDefs {}", validEntityDefs);
+        if (validEntityDefs != null) {
+            boolean match = false;
+            for (TypeDefLink vED : validEntityDefs) {
+                // check whether this validEntityDef matches the entity type or any of its supertypes...
+                if ( vED.getName().equals(entityTypeName) ) {
+                    match = true;
+                    break;
+                }
+                // If not an immediate match check the supertypes
+                for ( TypeDefLink superType : entityType.getTypeDefSuperTypes() ) {
+                    if ( vED.getName().equals(superType.getName()) ) {
+                        match = true;
+                        break;
+                    }
+                }
+            }
+            if (!match) {
+                // Entity is not of a type that is eligible for the classification...reject
+                LOG.error("classifyEntity: Classification cannot be applied to entity of type {}", entityTypeName);
+                OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_CLASSIFICATION_FOR_ENTITY;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityTypeName, "entityTypeName", methodName, repositoryName);
+
+                throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        // Create an AtlasClassification.
+        AtlasClassification atlasClassification = new AtlasClassification();
+        atlasClassification.setEntityGuid(entityGUID);
+        atlasClassification.setTypeName(classificationName);
+
+        // Map classification properties to classification attributes
+        if (classificationProperties != null) {
+            Map<String, Object> atlasClassificationAttrs = convertOMPropertiesToAtlasAttributes(classificationProperties);
+            atlasClassification.setAttributes(atlasClassificationAttrs);
+        }
+
+        // Add the AtlasClassification to the AtlasEntity
+
+        try {
+            // method accepts a list of entity GUIDS
+            List<String> entityGUIDList = new ArrayList<>();
+            entityGUIDList.add(entityGUID);
+            entityStore.addClassification(entityGUIDList, atlasClassification);
+
+            /* Retrieve the AtlasEntity back from store to pick up any Atlas modifications.
+             * Rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+             */
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityExtRetrieved;
+
+            atlasEntityExtRetrieved = entityStore.getById(entityGUID);
+
+            if (atlasEntityExtRetrieved == null) {
+                LOG.error("classifyEntity: Could not find entity with guid {} ", entityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntityRetrieved contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntityExtRetrieved.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            // Return OM EntityDetail which should now have the new classification.
+            LOG.debug("classifyEntity: om entity {}", returnEntityDetail);
+            return returnEntityDetail;
+
+        } catch (Exception e) {
+            LOG.error("classifyEntity: caught exception {}", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Remove a specific classification from an entity.
+     *
+     * @param userId             - unique identifier for requesting user.
+     * @param entityGUID         - String unique identifier (guid) for the entity.
+     * @param classificationName - String name for the classification.
+     * @return EntityDetail showing the resulting entity header, properties and classifications.
+     * @throws InvalidParameterException    - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException      - the entity identified by the guid is not found in the metadata collection
+     * @throws ClassificationErrorException - the requested classification is not set on the entity.
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail declassifyEntity(String userId,
+                                         String entityGUID,
+                                         String classificationName)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            ClassificationErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName                  = "declassifyEntity";
+        final String  entityGUIDParameterName     = "entityGUID";
+        final String  classificationParameterName = "classificationName";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+        repositoryValidator.validateClassificationName(repositoryName,
+                classificationParameterName,
+                classificationName,
+                methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        /*
+         * Process the request
+         */
+
+
+        /*
+         * The classificationName parameter is actually the name of the ClassificationDef for the type of classification.
+         * Locate the ClassificationDef (by name). Fail if not found.
+         * Retrieve the AtlasEntity (by GUID).  Fail if not found.
+         * Update the AtlasEntity by removing the AtlasClassification.
+         * Store in the repo.
+         * Retrieve the de-classified entity from the repository.
+         * Convert to/return an EntityDetail showing the revised classifications.
+         */
+
+        // Retrieve the AtlasEntity
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+        try {
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("declassifyEntity: Caught exception from Atlas {}", e);
+            // handle below
+            atlasEntWithExt = null;
+        }
+
+        if (atlasEntWithExt == null) {
+
+            LOG.error("declassifyEntity: Could not find entity with guid {} ", entityGUID);
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // atlasEntWithExt contains an AtlasEntity (entity)
+        // Extract the entity
+        AtlasEntity atlasEntity = atlasEntWithExt.getEntity();
+
+        LOG.debug("declassifyEntity: atlasEntity retrieved with classifications {}", atlasEntity.getClassifications());
+
+        // Remove the AtlasClassification from the AtlasEntity
+
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityExtRetrieved;
+
+        try {
+
+            // entityStore.createOrUpdate(new AtlasEntityStream(atlasEntityWEI), false, true);
+
+            entityStore.deleteClassification(entityGUID, classificationName);
+
+            /* Retrieve the AtlasEntity back from store to pick up any Atlas modifications.
+             * Rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+             */
+
+            atlasEntityExtRetrieved = entityStore.getById(entityGUID);
+
+        }
+        catch (AtlasBaseException e) {
+            LOG.error("declassifyEntity: Caught exception from Atlas {}", e);
+            // handle below
+            atlasEntityExtRetrieved = null;
+
+        }
+
+        if (atlasEntityExtRetrieved == null) {
+
+            LOG.error("declassifyEntity: Could not update or find entity with guid {} ", entityGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // atlasEntityRetrieved contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+        // Extract the entity
+        AtlasEntity atlasEntityRetrieved = atlasEntityExtRetrieved.getEntity();
+
+        // Convert AtlasEntity to OM EntityDetail.
+        EntityDetail returnEntityDetail;
+
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+        }
+        catch (TypeErrorException | InvalidEntityException e) {
+
+            LOG.error("declassifyEntity: Could not convert Atlas entity with guid {} ", entityGUID, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Return OM EntityDetail which should now have the new classification.
+        LOG.debug("declassifyEntity: om entity {}", returnEntityDetail);
+        return returnEntityDetail;
+
+
+
+    }
+
+
+    /**
+     * Update one or more properties in one of an entity's classifications.
+     *
+     * @param userId             - unique identifier for requesting user.
+     * @param entityGUID         - String unique identifier (guid) for the entity.
+     * @param classificationName - String name for the classification.
+     * @param properties         - list of properties for the classification.
+     * @return EntityDetail showing the resulting entity header, properties and classifications.
+     * @throws InvalidParameterException    - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException     - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException      - the entity identified by the guid is not found in the metadata collection
+     * @throws ClassificationErrorException - the requested classification is not attached to the classification.
+     * @throws PropertyErrorException       - one or more of the requested properties are not defined, or have different
+     *                                      characteristics in the TypeDef for this classification type
+     * @throws UserNotAuthorizedException   - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail updateEntityClassification(String             userId,
+                                                   String             entityGUID,
+                                                   String             classificationName,
+                                                   InstanceProperties properties)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            ClassificationErrorException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "updateEntityClassification";
+        final String  sourceName = metadataCollectionId;
+        final String  entityGUIDParameterName     = "entityGUID";
+        final String  classificationParameterName = "classificationName";
+        final String  propertiesParameterName = "properties";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityGUIDParameterName, entityGUID, methodName);
+        repositoryValidator.validateClassificationName(repositoryName, classificationParameterName, classificationName, methodName);
+
+
+        try
+        {
+            repositoryValidator.validateClassificationProperties(repositoryName,
+                    classificationName,
+                    propertiesParameterName,
+                    properties,
+                    methodName);
+        }
+        catch (PropertyErrorException  error)
+        {
+            throw error;
+        }
+        catch (Throwable   error)
+        {
+            OMRSErrorCode errorCode = OMRSErrorCode.UNKNOWN_CLASSIFICATION;
+
+            throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    error.getMessage(),
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Locate entity
+         */
+        EntityDetail entity = getEntityDetail(userId,entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+
+        /*
+         * Process the request
+         */
+
+        /*
+         * The classificationName parameter is the name of the ClassificationDef for the type of classification.
+         * This has already been validated above.
+         * Retrieve the AtlasEntity (by GUID).  Fail if not found.
+         * Retrieve the classifications, locate the one to update and update its properties
+         * Store in the repo.
+         * Retrieve the de-classified entity from the repository.
+         * Convert to/return an EntityDetail showing the revised classifications.
+         */
+
+
+        // Retrieve the AtlasEntity
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+        try {
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("updateEntityClassification: Caught exception from Atlas {}", e);
+            // handle below
+            atlasEntWithExt = null;
+        }
+
+        if (atlasEntWithExt == null) {
+
+            LOG.error("updateEntityClassification: Could not find entity with guid {} ", entityGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // atlasEntWithExt contains an AtlasEntity (entity). Extract the entity
+        AtlasEntity atlasEntity = atlasEntWithExt.getEntity();
+
+        LOG.debug("updateEntityClassification: atlasEntity retrieved with classifications {}", atlasEntity.getClassifications());
+
+        // Project AtlasEntity as an EntityDetail.
+        EntityDetail entityDetail;
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            entityDetail = atlasEntityMapper.toEntityDetail();
+        }
+        catch (TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("updateEntityClassification: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, sourceName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        // Update the entityDetail's classifications
+
+        // Locate the Classification to update
+        List<Classification> preClassifications = entityDetail.getClassifications();
+        // Find the classification to remove...
+        if (preClassifications == null) {
+
+            LOG.error("updateEntityClassification: Entity with guid {} has no classifications", entityGUID);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_CLASSIFIED;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new ClassificationErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Allow loop to match multiple entries, just in case duplicates exist
+        for (Classification preClassification : preClassifications){
+            if (preClassification.getName().equals(classificationName)) {
+                // Found the classification to update
+                LOG.debug("updateEntityClassification: classification {} previously had properties {}", classificationName, preClassification.getProperties());
+                // Replace all of the classification's properties with the new InstanceProperties
+                preClassification.setProperties(properties);
+                LOG.debug("updateEntityClassification: classification {} now has properties {}", classificationName, preClassification.getProperties());
+            }
+        }
+
+        entityDetail.setClassifications(preClassifications);
+
+
+        // Construct an atlasClassifications list - based on the revised OM classifications above - that we can pass to the Atlas EntityStore.
+        // There is no public Atlas method to update the props of one classification, so this code replaces them all.
+        ArrayList<AtlasClassification> atlasClassifications = new ArrayList<>();
+
+        // For each classification in the entity detail create an Atlas classification and add it to the list...
+        for (Classification c : entityDetail.getClassifications() ) {
+            // Create an AtlasClassification.
+            AtlasClassification atlasClassification = new AtlasClassification();
+            atlasClassification.setEntityGuid(entityGUID);
+            atlasClassification.setTypeName(c.getName());
+            // Map classification properties to classification attributes
+            if (c.getProperties() != null) {
+                Map<String, Object> atlasClassificationAttrs = convertOMPropertiesToAtlasAttributes(c.getProperties());
+                atlasClassification.setAttributes(atlasClassificationAttrs);
+            }
+            atlasClassifications.add(atlasClassification);
+        }
+
+
+        LOG.debug("updateEntityClassification: atlasEntity to be updated with classifications {}", atlasEntity.getClassifications());
+
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityExtRetrieved;
+        try {
+
+            // entityStore.createOrUpdate(new AtlasEntityStream(atlasEntityWEI), false, true);
+            entityStore.updateClassifications(entityGUID, atlasClassifications);
+
+            /* Retrieve the AtlasEntity back from store to pick up any Atlas modifications.
+             * Rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+             */
+
+            atlasEntityExtRetrieved = entityStore.getById(entityGUID);
+        }
+        catch (AtlasBaseException e) {
+            LOG.error("updateEntityClassification: Caught exception from Atlas {}", e);
+            // handle below
+            atlasEntityExtRetrieved = null;
+        }
+
+        if (atlasEntityExtRetrieved == null) {
+
+            LOG.error("updateEntityClassification: Could not find entity with guid {} ", entityGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // atlasEntityRetrieved contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+        // Extract the entity
+        AtlasEntity atlasEntityRetrieved = atlasEntityExtRetrieved.getEntity();
+
+        // Convert AtlasEntity to OM EntityDetail.
+        EntityDetail returnEntityDetail;
+
+        try {
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+        }
+        catch (TypeErrorException | InvalidEntityException e) {
+
+            LOG.error("updateEntityClassification: Caught exception from AtlasEntityMapper, entity guid {}, {} ", entityGUID, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityGUIDParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Return OM EntityDetail which should now have the new classification.
+        LOG.debug("updateEntityClassification: om entity {}", returnEntityDetail);
+        return returnEntityDetail;
+
+    }
+
+
+    /**
+     * Add a new relationship between two entities to the metadata collection.
+     *
+     * @param userId               - unique identifier for requesting user.
+     * @param relationshipTypeGUID - unique identifier (guid) for the new relationship's type.
+     * @param initialProperties    - initial list of properties for the new entity - null means no properties.
+     * @param entityOneGUID        - the unique identifier of one of the entities that the relationship is connecting together.
+     * @param entityTwoGUID        - the unique identifier of the other entity that the relationship is connecting together.
+     * @param initialStatus        - initial status - typically DRAFT, PREPARED or ACTIVE.
+     * @return Relationship structure with the new header, requested entities and properties.
+     * @throws InvalidParameterException   - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException    - there is a problem communicating with the metadata repository where
+     *                                     the metadata collection is stored.
+     * @throws TypeErrorException          - the requested type is not known, or not supported in the metadata repository
+     *                                     hosting the metadata collection.
+     * @throws PropertyErrorException      - one or more of the requested properties are not defined, or have different
+     *                                     characteristics in the TypeDef for this relationship's type.
+     * @throws EntityNotKnownException     - one of the requested entities is not known in the metadata collection.
+     * @throws StatusNotSupportedException - the metadata repository hosting the metadata collection does not support
+     *                                     the requested status.
+     * @throws UserNotAuthorizedException  - the userId is not permitted to perform this operation.
+     */
+    public Relationship addRelationship(String             userId,
+                                        String             relationshipTypeGUID,
+                                        InstanceProperties initialProperties,
+                                        String             entityOneGUID,
+                                        String             entityTwoGUID,
+                                        InstanceStatus     initialStatus)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            EntityNotKnownException,
+            StatusNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "addRelationship";
+        final String  guidParameterName = "relationshipTypeGUID";
+        final String  propertiesParameterName       = "initialProperties";
+        final String  initialStatusParameterName    = "initialStatus";
+        final String  entityOneGUIDParameterName    = "entityOneGUID";
+        final String  entityTwoGUIDParameterName    = "entityTwoGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateTypeGUID(repositoryName, guidParameterName, relationshipTypeGUID, methodName);
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, relationshipTypeGUID);
+            if (typeDef != null) {
+                repositoryValidator.validateTypeDefForInstance(repositoryName, guidParameterName, typeDef, methodName);
+
+
+                repositoryValidator.validatePropertiesForType(repositoryName,
+                        propertiesParameterName,
+                        typeDef,
+                        initialProperties,
+                        methodName);
+
+                repositoryValidator.validateInstanceStatus(repositoryName,
+                        initialStatusParameterName,
+                        initialStatus,
+                        typeDef,
+                        methodName);
+
+            }
+        } catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeGUID, guidParameterName, methodName, repositoryName);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validation complete - ok to create new instance
+         */
+
+        //=================================================================================================================
+        // Perform validation checks on type specified by guid.
+        // Retrieve both entities by guid from the repository
+        // Create an instance of the Relationship, setting the createdBy to userId, createdTime to now, etc.
+        // Then set the properties and initialStatus.
+        // Create the relationship in the Atlas repository.
+        //
+
+        RelationshipDef relationshipDef = (RelationshipDef) typeDef;
+
+        // Collate the valid instance properties - no supertypes to traverse for a relationship def
+        ArrayList<String> validInstanceProperties = null;
+        List<TypeDefAttribute> typeDefAttributes = relationshipDef.getPropertiesDefinition();
+        if (typeDefAttributes != null) {
+            validInstanceProperties = new ArrayList<>();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                String attrName = typeDefAttribute.getAttributeName();
+                validInstanceProperties.add(attrName);
+            }
+        }
+
+
+        /* Create a Relationship object
+         * InstanceAuditHeader fields
+         * InstanceType              type = null;
+         * String                    createdBy
+         * String                    updatedBy
+         * Date                      createTime
+         * Date                      updateTime
+         * Long                      version
+         * InstanceStatus            currentStatus
+         * InstanceStatus            statusOnDelete
+         * Instance Header fields
+         * InstanceProvenanceType    instanceProvenanceType
+         * String                    metadataCollectionId
+         * String                    guid
+         * String                    instanceURL
+         * Relationship fields
+         *   InstanceProperties    relationshipProperties
+         *   String                entityOnePropertyName    // Retrieve this from the RelDef.RelEndDef for end1
+         *   EntityProxy           entityOneProxy
+         *   String                entityTwoPropertyName    // Retrieve this from the RelDef.RelEndDef for end2
+         *   EntityProxy           entityTwoProxy
+         */
+
+        // An OM RelationshipDef has no superType - so we just set that to null
+        InstanceType instanceType = new InstanceType(
+                relationshipDef.getCategory(),
+                relationshipTypeGUID,
+                relationshipDef.getName(),
+                relationshipDef.getVersion(),
+                relationshipDef.getDescription(),
+                relationshipDef.getDescriptionGUID(),
+                null,
+                relationshipDef.getValidInstanceStatusList(),
+                validInstanceProperties);
+
+        // Construct a Relationship object
+        Date now = new Date();
+        Relationship omRelationship = new Relationship();
+        // Set fields from InstanceAuditHeader
+        omRelationship.setType(instanceType);
+        omRelationship.setCreatedBy(userId);
+        omRelationship.setCreateTime(now);
+        omRelationship.setUpdatedBy(userId);
+        omRelationship.setUpdateTime(now);
+        omRelationship.setVersion(1L);
+        omRelationship.setStatus(InstanceStatus.ACTIVE);
+        // Set fields from InstanceHeader
+        omRelationship.setMetadataCollectionId(metadataCollectionId);
+        omRelationship.setGUID(null);                                    // GUID will not be set until after the create in Atlas
+        omRelationship.setInstanceURL(null);
+        // Set fields from Relationship
+        omRelationship.setProperties(initialProperties);
+        //   String                entityOnePropertyName
+        //   EntityProxy           entityOneProxy
+        //   String                entityTwoPropertyName
+        //   EntityProxy           entityTwoProxy
+
+        RelationshipEndDef relEndDef1 = relationshipDef.getEndDef1();
+        if (relEndDef1 != null) {
+            String endDef1AttributeName = relEndDef1.getAttributeName();
+            omRelationship.setEntityOnePropertyName(endDef1AttributeName);
+        } else {
+            LOG.error("addRelationship: Missing relationship end def in relationship def {} ", relationshipDef.getName());
+            return null;
+        }
+        RelationshipEndDef relEndDef2 = relationshipDef.getEndDef2();
+        if (relEndDef2 != null) {
+            String endDef2AttributeName = relEndDef2.getAttributeName();
+            omRelationship.setEntityTwoPropertyName(endDef2AttributeName);
+        } else {
+            LOG.error("addRelationship: Missing relationship end def in relationship def {} ", relationshipDef.getName());
+            return null;
+        }
+
+        // Need to retrieve the entities from the repository and create an EntityProxy object for each...
+        // ENT1 : We have the parameter entityOneGUID
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt1;
+        try {
+            atlasEntWithExt1 = entityStore.getById(entityOneGUID);
+        } catch (AtlasBaseException e) {
+            LOG.error("addRelationship: Caught exception from Atlas {}", e);
+            // Handle below
+            atlasEntWithExt1 = null;
+        }
+        if (atlasEntWithExt1 == null) {
+            LOG.error("addRelationship: Could not find entity with guid {} ", entityOneGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityOneGUID, entityOneGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Extract the entity
+        AtlasEntity atlasEnt1 = atlasEntWithExt1.getEntity();
+
+        // Convert the AtlasEntity into an OM EntityProxy
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEnt1);
+            EntityProxy end1Proxy = atlasEntityMapper.toEntityProxy();
+            LOG.debug("addRelationship: om entity {}", end1Proxy);
+            omRelationship.setEntityOneProxy(end1Proxy);
+
+        } catch (TypeErrorException | InvalidEntityException e) {
+
+            LOG.error("addRelationship: caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityOneGUID, entityOneGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Repeat the above for ent2
+
+        // ENT2 : We have the parameter entityTwoGUID
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt2;
+        try {
+            atlasEntWithExt2 = entityStore.getById(entityTwoGUID);
+        } catch (AtlasBaseException e) {
+            LOG.error("addRelationship: Caught exception from Atlas {}", e);
+            // Handle below
+            atlasEntWithExt2 = null;
+        }
+        if (atlasEntWithExt2 == null) {
+            LOG.error("addRelationship: Could not find entity with guid {} ", entityTwoGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTwoGUID, entityTwoGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Extract the entity
+        AtlasEntity atlasEnt2 = atlasEntWithExt2.getEntity();
+
+        // Convert the AtlasEntity into an OM EntityProxy
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEnt2);
+            EntityProxy end2Proxy = atlasEntityMapper.toEntityProxy();
+            LOG.debug("addRelationship: om entity {}", end2Proxy);
+            omRelationship.setEntityTwoProxy(end2Proxy);
+
+        } catch (Exception e) {
+
+            LOG.error("addRelationship: caught exception {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTwoGUID, entityTwoGUIDParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // omRelationship should be complete apart from GUID - which is to be assigned by repo.
+
+        // Convert the OM Relationship to an AtlasRelationship. Because this is a new Relationship we want
+        // Atlas to generate the GUID, so useExistingGUID must be set to false.
+        AtlasRelationship atlasRelationship = convertOMRelationshipToAtlasRelationship(omRelationship, false, relationshipDef);
+
+        // Add the Relationship to the AtlasRelationshipStore...
+        AtlasRelationship returnedAtlasRelationship;
+        try {
+
+            returnedAtlasRelationship = relationshipStore.create(atlasRelationship);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("addRelationship: caught exception from relationship store create method {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        // Verify the returnedAtlasRelationship and fill in any extra detail in omRelationship - e.g. sys attrs
+
+        if (returnedAtlasRelationship.getStatus() != ACTIVE) {
+
+            LOG.error("addRelationship: Atlas created relationship, but status set to {}", returnedAtlasRelationship.getStatus());
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Note the newly allocated relationship GUID
+        String newRelationshipGuid = returnedAtlasRelationship.getGuid();
+        omRelationship.setGUID(newRelationshipGuid);
+
+        return omRelationship;
+
+    }
+
+    /*
+     * Utility method to convert a Relationship to an AtlasRelationship.
+     * Needs the RelationshipDef to find the propagation rule
+     */
+    private AtlasRelationship convertOMRelationshipToAtlasRelationship(Relationship omRelationship,
+                                                                       boolean useExistingGUID,
+                                                                       RelationshipDef relationshipDef)
+        throws
+            StatusNotSupportedException,
+            TypeErrorException
+
+    {
+
+
+        final String methodName = "convertOMRelationshipToAtlasRelationship";
+
+        /* Construct an AtlasRelationship
+         * An AtlasRelationship has:
+         * String              typeName
+         * Map<String, Object> attributes
+         * String              guid
+         * AtlasObjectID       end1
+         * AtlasObjectID       end2
+         * String              label
+         * PropagateTags       propagateTags
+         * Status              status
+         * String              createdBy
+         * String              updatedBy
+         * Date                createTime
+         * Date                updateTime
+         * Long                version
+         */
+
+        AtlasRelationship atlasRelationship = new AtlasRelationship();
+        atlasRelationship.setTypeName(omRelationship.getType().getTypeDefName());
+        /* GUID is set by Atlas to nextInternalID - you must leave it for a new AtlasRelationship,
+         * unless you really want to reuse a particular GUID in which case the useGUID parameter will
+         * have been set to true and the GUID to use will have been set in the OM Relationship...
+         */
+        if (useExistingGUID)
+           atlasRelationship.setGuid(omRelationship.getGUID());
+
+        InstanceStatus omStatus = omRelationship.getStatus();
+        AtlasRelationship.Status atlasRelationshipStatus;
+        switch (omStatus) {
+            // AtlasEntity.Status can only be either { ACTIVE | DELETED }
+            case DELETED:
+                atlasRelationshipStatus = AtlasRelationship.Status.DELETED;
+                break;
+            case ACTIVE:
+                atlasRelationshipStatus = AtlasRelationship.Status.ACTIVE;
+                break;
+            default:
+                // unsupportable status
+                LOG.error("convertOMRelationshipToAtlasRelationship: Atlas does not support relationship status {}", omStatus);
+                OMRSErrorCode errorCode = OMRSErrorCode.BAD_INSTANCE_STATUS;
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+                throw new StatusNotSupportedException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+        atlasRelationship.setStatus(atlasRelationshipStatus);
+
+        atlasRelationship.setCreatedBy(omRelationship.getCreatedBy());
+        atlasRelationship.setUpdatedBy(omRelationship.getUpdatedBy());
+        atlasRelationship.setCreateTime(omRelationship.getCreateTime());
+        atlasRelationship.setUpdateTime(omRelationship.getUpdateTime());
+        atlasRelationship.setVersion(omRelationship.getVersion());
+        // Set end1
+        AtlasObjectId end1 = new AtlasObjectId();
+        end1.setGuid(omRelationship.getEntityOneProxy().getGUID());                       // entityOneGUID
+        end1.setTypeName(omRelationship.getEntityOneProxy().getType().getTypeDefName());  //relationshipDef.getEndDef1().getEntityType().getName());
+        atlasRelationship.setEnd1(end1);
+        // Set end2
+        AtlasObjectId end2 = new AtlasObjectId();
+        end2.setGuid(omRelationship.getEntityTwoProxy().getGUID());                      // entityTwoGUID
+        end2.setTypeName(omRelationship.getEntityTwoProxy().getType().getTypeDefName()); // relationshipDef.getEndDef2().getEntityType().getName());
+        atlasRelationship.setEnd2(end2);
+        atlasRelationship.setLabel(omRelationship.getType().getTypeDefName());           // Set the label to the type name of the relationship.
+        // Set propagateTags
+        ClassificationPropagationRule omPropRule = relationshipDef.getPropagationRule();
+        AtlasRelationshipDef.PropagateTags atlasPropTags = convertOMPropagationRuleToAtlasPropagateTags(omPropRule);
+        atlasRelationship.setPropagateTags(atlasPropTags);
+
+        // Set attributes on AtlasRelationship
+        // Map attributes from OM Relationship to AtlasRelationship
+        InstanceProperties instanceProperties = omRelationship.getProperties();
+        Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(instanceProperties);
+        atlasRelationship.setAttributes(atlasAttrs);
+
+        // AtlasRelationship should have been fully constructed by this point
+
+        return atlasRelationship;
+    }
+
+    /**
+     * Update the status of a specific relationship.
+     *
+     * @param userId           - unique identifier for requesting user.
+     * @param relationshipGUID - String unique identifier (guid) for the relationship.
+     * @param newStatus        - new InstanceStatus for the relationship.
+     * @return Resulting relationship structure with the new status set.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the requested relationship is not known in the metadata collection.
+     * @throws StatusNotSupportedException   - the metadata repository hosting the metadata collection does not support
+     *                                       the requested status.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship updateRelationshipStatus(String         userId,
+                                                 String         relationshipGUID,
+                                                 InstanceStatus newStatus)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            StatusNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName          = "updateRelationshipStatus";
+        final String  guidParameterName   = "relationshipGUID";
+        final String  statusParameterName = "newStatus";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, relationshipGUID, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship = this.getRelationship(userId, relationshipGUID);
+
+        repositoryValidator.validateInstanceType(repositoryName, relationship);
+
+        String relationshipTypeGUID = relationship.getType().getTypeDefGUID();
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, relationshipTypeGUID);
+            if (typeDef != null) {
+                repositoryValidator.validateNewStatus(repositoryName,
+                        statusParameterName,
+                        newStatus,
+                        typeDef,
+                        methodName);
+            }
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        Relationship   updatedRelationship = new Relationship(relationship);
+
+        updatedRelationship.setStatus(newStatus);
+
+        updatedRelationship = repositoryHelper.incrementVersion(userId, relationship, updatedRelationship);
+
+        /*
+         * Store the updatedRelationship into Atlas
+         *
+         * To do this, retrieve the AtlasRelationship but do not map it (as we did above) to an OM Relationship.
+         * Update the status of the Atlas relationship then write it back to the store
+         */
+        AtlasRelationship atlasRelationship;
+        try {
+            atlasRelationship = relationshipStore.getById(relationshipGUID);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("updateRelationshipStatus: Caught exception from Atlas {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("updateRelationshipStatus: Read from atlas relationship store; relationship {}", atlasRelationship);
+
+        // Atlas status field has type Status
+        AtlasRelationship.Status atlasStatus;
+        switch (newStatus) {
+            case ACTIVE:
+                atlasStatus = ACTIVE;
+                break;
+            case DELETED:
+                atlasStatus = DELETED;
+                break;
+            default:
+                // Atlas can only accept ACTIVE | DELETED
+                LOG.error("updateRelationshipStatus: Atlas cannot accept status value of {}", newStatus);
+
+                OMRSErrorCode errorCode    = OMRSErrorCode.BAD_INSTANCE_STATUS;
+
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(relationshipGUID,
+                        methodName,
+                        repositoryName);
+
+                throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+
+        atlasRelationship.setStatus(atlasStatus);
+
+        // Save the relationship to Atlas
+        AtlasRelationship returnedAtlasRelationship;
+        try {
+
+            returnedAtlasRelationship = relationshipStore.update(atlasRelationship);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("updateRelationshipStatus: Caught exception from Atlas relationship store update method {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID,
+                    methodName,
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Refresh the system attributes of the returned OM Relationship
+        updatedRelationship.setUpdatedBy(returnedAtlasRelationship.getUpdatedBy());
+        updatedRelationship.setUpdateTime(returnedAtlasRelationship.getUpdateTime());
+
+        return updatedRelationship;
+
+    }
+
+
+    /**
+     * Update the properties of a specific relationship.
+     *
+     * @param userId           - unique identifier for requesting user.
+     * @param relationshipGUID - String unique identifier (guid) for the relationship.
+     * @param properties       - list of the properties to update.
+     * @return Resulting relationship structure with the new properties set.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the requested relationship is not known in the metadata collection.
+     * @throws PropertyErrorException        - one or more of the requested properties are not defined, or have different
+     *                                       characteristics in the TypeDef for this relationship's type.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship updateRelationshipProperties(String             userId,
+                                                     String             relationshipGUID,
+                                                     InstanceProperties properties)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            PropertyErrorException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "updateRelationshipProperties";
+        final String  guidParameterName = "relationshipGUID";
+        final String  propertiesParameterName = "properties";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, relationshipGUID, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship = this.getRelationship(userId, relationshipGUID);
+
+        repositoryValidator.validateInstanceType(repositoryName, relationship);
+
+        String relationshipTypeGUID = relationship.getType().getTypeDefGUID();
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, relationshipTypeGUID);
+            if (typeDef != null) {
+                repositoryValidator.validateNewPropertiesForType(repositoryName,
+                        propertiesParameterName,
+                        typeDef,
+                        properties,
+                        methodName);
+            }
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipTypeGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        Relationship   updatedRelationship = new Relationship(relationship);
+
+        updatedRelationship.setProperties(repositoryHelper.mergeInstanceProperties(repositoryName,
+                relationship.getProperties(),
+                properties));
+        updatedRelationship = repositoryHelper.incrementVersion(userId, relationship, updatedRelationship);
+
+        /*
+         * Store the updatedRelationship into Atlas
+         *
+         * To do this, retrieve the AtlasRelationship but do not map it (as we did above) to an OM Relationship.
+         * Update the properties of the Atlas relationship then write it back to the store
+         */
+        AtlasRelationship atlasRelationship;
+        try {
+
+            atlasRelationship = relationshipStore.getById(relationshipGUID);
+            LOG.debug("updateRelationshipProperties: Read from atlas relationship store; relationship {}", atlasRelationship);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("updateRelationshipProperties: Caught exception from Atlas {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, guidParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // The properties were merged above, retrieve the merged set from the updatedRelationship
+        // and use it to replace the Atlas properties
+        InstanceProperties mergedProperties = updatedRelationship.getProperties();
+        Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(mergedProperties);
+        atlasRelationship.setAttributes(atlasAttrs);
+
+        // Save the relationship to Atlas
+        AtlasRelationship returnedAtlasRelationship;
+        try {
+
+            returnedAtlasRelationship = relationshipStore.create(atlasRelationship);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("updateRelationshipProperties: Caught exception from Atlas relationship store create method, {}", e);
+            // handle below
+            returnedAtlasRelationship = null;
+        }
+
+        if (returnedAtlasRelationship == null) {
+
+            LOG.error("updateRelationshipProperties: Atlas relationship store create method did not return a relationship");
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_RELATIONSHIP_FROM_STORE;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Convert the returnedAtlasRelationship to OM for return, instead of updatedRelationship
+
+        Relationship returnRelationship;
+
+        try {
+            AtlasRelationshipMapper atlasRelationshipMapper = new AtlasRelationshipMapper(
+                    this,
+                    userId,
+                    returnedAtlasRelationship,
+                    entityStore);
+
+            returnRelationship = atlasRelationshipMapper.toOMRelationship();
+            LOG.debug("updateRelationshipProperties: om relationship {}", returnRelationship);
+
+        }
+        catch (Exception e) {
+            LOG.debug("updateRelationshipProperties: caught exception from mapper "+e.getMessage());
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_RELATIONSHIP_FROM_STORE;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(guidParameterName,
+                    methodName,
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        return returnRelationship;
+    }
+
+
+    /**
+     * Undo the latest change to a relationship (either a change of properties or status).
+     *
+     * @param userId           - unique identifier for requesting user.
+     * @param relationshipGUID - String unique identifier (guid) for the relationship.
+     * @return Relationship structure with the new current header, requested entities and properties.
+     * @throws InvalidParameterException     - the guid is null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the requested relationship is not known in the metadata collection.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship undoRelationshipUpdate(String userId,
+                                               String relationshipGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "undoRelationshipUpdate";
+        final String  guidParameterName = "relationshipGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, relationshipGUID, methodName);
+
+        // I do not known of a way in Atlas to retrieve an earlier previous version.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * Delete a specific relationship.  This is a soft-delete which means the relationship's status is updated to
+     * DELETED and it is no longer available for queries.  To remove the relationship permanently from the
+     * metadata collection, use purgeRelationship().
+     *
+     * @param userId                          - unique identifier for requesting user.
+     * @param typeDefGUID                     - unique identifier of the type of the relationship to delete.
+     * @param typeDefName                     - unique name of the type of the relationship to delete.
+     * @param obsoleteRelationshipGUID        - String unique identifier (guid) for the relationship.
+     * @throws InvalidParameterException      - one of the parameters is null.
+     * @throws RepositoryErrorException       - there is a problem communicating with the metadata repository where
+     *                                          the metadata collection is stored.
+     * @throws RelationshipNotKnownException  - the requested relationship is not known in the metadata collection.
+     * @throws FunctionNotSupportedException  - the metadata repository hosting the metadata collection does not support
+     *                                          soft-deletes.
+     * @throws UserNotAuthorizedException     - the userId is not permitted to perform this operation.
+     */
+    public Relationship deleteRelationship(String userId,
+                                           String typeDefGUID,
+                                           String typeDefName,
+                                           String obsoleteRelationshipGUID)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            FunctionNotSupportedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "deleteRelationship";
+        final String  guidParameterName = "typeDefGUID";
+        final String  nameParameterName = "typeDefName";
+        final String  relationshipParameterName = "obsoleteRelationshipGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, obsoleteRelationshipGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, obsoleteRelationshipGUID);
+
+        repositoryValidator.validateTypeForInstanceDelete(repositoryName,
+                typeDefGUID,
+                typeDefName,
+                relationship,
+                methodName);
+
+
+        /*
+         * Process the request
+         */
+
+        // One final piece of validation - if deletes are configured as HARD then throw not supported exception
+        if (atlasDeleteConfiguration == AtlasDeleteOption.HARD) {
+            LOG.error("deleteRelationship: Repository is configured for hard deletes, cannot soft delete relationship with guid {}",
+                    obsoleteRelationshipGUID);
+            LocalAtlasOMRSErrorCode errorCode    = LocalAtlasOMRSErrorCode.ATLAS_CONFIGURATION_HARD;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(obsoleteRelationshipGUID, methodName, repositoryName);
+
+            throw new FunctionNotSupportedException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /* From here on, this method is performing a SOFT delete.
+         * The method returns the deleted Relationship, which should reflect
+         * the change in state in the AtlasRelationship's system attributes.
+         */
+
+        try {
+            relationshipStore.deleteById(obsoleteRelationshipGUID);
+
+            /*
+             * Read the relationship back from the store - this should work if it was a soft delete.
+             * By reading back, the status should reflect that it's been deleted and it should
+             * have updated system attributes.
+             *
+             * Retrieve the AtlasRelationship
+             */
+            AtlasRelationship atlasRelationship;
+
+            atlasRelationship = relationshipStore.getById(obsoleteRelationshipGUID);
+
+            if (atlasRelationship == null) {
+                LOG.error("deleteRelationship: Could not find relationship with guid {} ", obsoleteRelationshipGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(obsoleteRelationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+                throw new RelationshipNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+
+            AtlasRelationshipMapper atlasRelationshipMapper =
+                    new AtlasRelationshipMapper(this,
+                                                 userId,
+                                                 atlasRelationship,
+                                                 entityStore);
+
+            Relationship returnRelationship = atlasRelationshipMapper.toOMRelationship();
+
+            LOG.debug("deleteRelationship: deleted relationship {}", returnRelationship);
+
+            return returnRelationship;
+
+        }
+        catch (TypeErrorException | AtlasBaseException | InvalidEntityException | InvalidRelationshipException | EntityNotKnownException e) {
+            OMRSErrorCode errorCode = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RelationshipNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+    }
+
+
+    /**
+     * Permanently delete the relationship from the repository.  There is no means to undo this request.
+     *
+     * @param userId                  - unique identifier for requesting user.
+     * @param typeDefGUID             - unique identifier of the type of the relationship to purge.
+     * @param typeDefName             - unique name of the type of the relationship to purge.
+     * @param deletedRelationshipGUID - String unique identifier (guid) for the relationship.
+     * @throws InvalidParameterException       - one of the parameters is null.
+     * @throws RepositoryErrorException        - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws RelationshipNotKnownException   - the requested relationship is not known in the metadata collection.
+     * @throws RelationshipNotDeletedException - the requested relationship is not in DELETED status.
+     * @throws UserNotAuthorizedException      - the userId is not permitted to perform this operation.
+     */
+    public void purgeRelationship(String userId,
+                                  String typeDefGUID,
+                                  String typeDefName,
+                                  String deletedRelationshipGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            RelationshipNotDeletedException,
+            UserNotAuthorizedException
+    {
+        final String  methodName = "purgeRelationship";
+        final String  guidParameterName = "typeDefGUID";
+        final String  nameParameterName = "typeDefName";
+        final String  relationshipParameterName = "deletedRelationshipGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, deletedRelationshipGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, deletedRelationshipGUID);
+
+        repositoryValidator.validateTypeForInstanceDelete(repositoryName,
+                typeDefGUID,
+                typeDefName,
+                relationship,
+                methodName);
+
+
+        /* Atlas has two configuration settings for its DeleteHandler - soft deletes or hard deletes.
+         * If Atlas is configured for hard deletes, this purge method will remove the relationship.
+         * If Atlas is configured for soft deletes, the relationship must have been (soft-)deleted prior to
+         * this purgeEntity call. In this case, check that the relationship is in DELETED state.
+         *
+         * This method does not use the repository's deleteById method - instead it uses the purgeById
+         * method - which guarantees a permanent removal independent of how the repository is configured.
+         */
+
+        /*
+         * If soft delete is enabled in the repository, check that the relationship has been deleted.
+         */
+        if (atlasDeleteConfiguration == AtlasDeleteOption.SOFT) {
+            LOG.debug("purgeRelationship: Soft-delete is configured, check that relationship to be purged is in DELETED state");
+            repositoryValidator.validateRelationshipIsDeleted(repositoryName, relationship, methodName);
+        }
+
+
+        /*
+         * Validation is complete - ok to remove the entity
+         */
+
+        /*
+         * From here on, this method performs a HARD delete.
+         */
+
+        try {
+
+            LOG.debug("purgeRelationship: TODO!! add purgeById to relationship store!!");
+            //entityStore.purgeById(deletedEntityGUID); // TODO - waiting for ATLAS-2774
+
+        }
+        //catch (AtlasBaseException e) { // TODO - catch appropriate exceptions when ATLAS-2774 is available
+        catch (Exception e) {
+            LOG.error("purgeRelationship: Caught exception from Atlas relationshipStore trying to purge relationship {}", deletedRelationshipGUID, e);
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.RELATIONSHIP_NOT_DELETED;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(deletedRelationshipGUID, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Restore a deleted relationship into the metadata collection.  The new status will be ACTIVE and the
+     * restored details of the relationship are returned to the caller.
+     *
+     * @param userId                  - unique identifier for requesting user.
+     * @param deletedRelationshipGUID - String unique identifier (guid) for the relationship.
+     * @return Relationship structure with the restored header, requested entities and properties.
+     * @throws InvalidParameterException       - the guid is null.
+     * @throws RepositoryErrorException        - there is a problem communicating with the metadata repository where
+     *                                         the metadata collection is stored.
+     * @throws RelationshipNotKnownException   - the requested relationship is not known in the metadata collection.
+     * @throws RelationshipNotDeletedException - the requested relationship is not in DELETED status.
+     * @throws UserNotAuthorizedException      - the userId is not permitted to perform this operation.
+     */
+    public Relationship restoreRelationship(String userId,
+                                            String deletedRelationshipGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            RelationshipNotDeletedException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "restoreRelationship";
+        final String  guidParameterName = "deletedRelationshipGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, guidParameterName, deletedRelationshipGUID, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, deletedRelationshipGUID);
+
+        repositoryValidator.validateRelationshipIsDeleted(repositoryName, relationship, methodName);
+
+        /*
+         * Validation is complete.  It is ok to restore the relationship.
+         */
+        // Atlas has two configuration settings for its DeleteHandler - all soft deletes or all hard deletes.
+        // We would require that soft deletes are in force and even then it is not clear how to implement
+        // a restore from an earlier soft delete. There is no entity store operation for this.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    // =========================================================================================================
+
+    // Group 5 methods
+
+    /**
+     * Change the guid of an existing entity to a new value.  This is used if two different
+     * entities are discovered to have the same guid.  This is extremely unlikely but not impossible so
+     * the open metadata protocol has provision for this.
+     *
+     * @param userId        - unique identifier for requesting user.
+     * @param typeDefGUID   - the guid of the TypeDef for the entity - used to verify the entity identity.
+     * @param typeDefName   - the name of the TypeDef for the entity - used to verify the entity identity.
+     * @param entityGUID    - the existing identifier for the entity.
+     * @param newEntityGUID - new unique identifier for the entity.
+     * @return entity - new values for this entity, including the new guid.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail reIdentifyEntity(String userId,
+                                         String typeDefGUID,
+                                         String typeDefName,
+                                         String entityGUID,
+                                         String newEntityGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "reIdentifyEntity";
+        final String  guidParameterName = "typeDefGUID";
+        final String  nameParameterName = "typeDefName";
+        final String  instanceParameterName = "deletedRelationshipGUID";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        parentConnector.validateRepositoryIsActive(methodName);
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, instanceParameterName, newEntityGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail  entity  = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        /* In Atlas the GUID is the id of the vertex, so it is not possible to change it in situ.
+         * It may be possible to implement this method by deleting the existing Atlas entity
+         * and creating a new one. If soft deletes are in force then the previous entity would
+         * still exist, in soft-deleted state. This may lead to complexity compared to the
+         * more desirable situation of having exactly one GUID that relates to the entity.
+         */
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    /**
+     * Change the type of an existing entity.  Typically this action is taken to move an entity's
+     * type to either a super type (so the subtype can be deleted) or a new subtype (so additional properties can be
+     * added.)  However, the type can be changed to any compatible type and the properties adjusted.
+     *
+     * @param userId                - unique identifier for requesting user.
+     * @param entityGUID            - the unique identifier for the entity to change.
+     * @param currentTypeDefSummary - the current details of the TypeDef for the entity - used to verify the entity identity
+     * @param newTypeDefSummary     - details of this entity's new TypeDef.
+     * @return entity - new values for this entity, including the new type information.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException         - the requested type is not known, or not supported in the metadata repository
+     *                                    hosting the metadata collection.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.     *
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail reTypeEntity(String         userId,
+                                     String         entityGUID,
+                                     TypeDefSummary currentTypeDefSummary,
+                                     TypeDefSummary newTypeDefSummary)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            ClassificationErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+
+    {
+        final String  methodName = "reTypeEntity";
+        final String  entityParameterName = "entityGUID";
+        final String  currentTypeDefParameterName = "currentTypeDefSummary";
+        final String  newTypeDefParameterName = "newTypeDefSummary";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityParameterName, entityGUID, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail  entity  = getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+        repositoryValidator.validateInstanceType(repositoryName,
+                entity,
+                currentTypeDefParameterName,
+                currentTypeDefParameterName,
+                currentTypeDefSummary.getGUID(),
+                currentTypeDefSummary.getName());
+
+        repositoryValidator.validatePropertiesForType(repositoryName,
+                newTypeDefParameterName,
+                newTypeDefSummary,
+                entity.getProperties(),
+                methodName);
+
+        repositoryValidator.validateClassificationList(repositoryName,
+                entityParameterName,
+                entity.getClassifications(),
+                newTypeDefSummary.getName(),
+                methodName);
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+
+        /* In Atlas the entity type is stored in the AtlasEntity typeName field.
+         * If you want to update an entity then you essentially pass the modified AtlasEntity
+         * to the entity store's updateEntity method - this accepts an AtlasEntity.
+         * That in turn will call the entity store's createOrUpdate.
+         * This calls the store's preCreateOrUpdate...
+         * preCreateOrUpdate calls validateAndNormalizeForUpdate
+         *  ... that gets the type using the typeName in the updated entity
+         *  ... and then calls validateValueForUpdate
+         *  ... and getNormalizedValueForUpdate
+         *  ... which validates that the attributes are valid values
+         * createOrUpdate then...
+         * ... compares the attributes & classifications of the updated entity
+         * ... and then asks the EntityGraphMapper to alter attributes and classifications
+         * ... this will get the type by referring to the typename in the (updated) entity....
+         *
+         * All in all I think it is possible to change the entity type
+         *
+         */
+
+        /*
+         * Alter the retrieved EntityDetail so that it's InstanceType reflects the new type
+         * Then convert it to an AtlasEntity and call updateEntity.
+         */
+
+
+        // Retrieve the TypeDef for the new type
+        String newTypeGUID = newTypeDefSummary.getGUID();
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, newTypeGUID);
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null || typeDef.getCategory() != ENTITY_DEF) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(newTypeGUID, newTypeDefParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Create a new InstanceType
+        InstanceType newInstanceType = new InstanceType();
+        newInstanceType.setTypeDefName(typeDef.getName());
+        newInstanceType.setTypeDefCategory(typeDef.getCategory());
+        List<TypeDefLink> superTypes = new ArrayList<>();
+        superTypes.add(typeDef.getSuperType());
+        newInstanceType.setTypeDefSuperTypes(superTypes);
+        List<TypeDefAttribute> typeDefAttributes = typeDef.getPropertiesDefinition();
+        List<String> validPropertyNames = null;
+        if (typeDefAttributes != null) {
+            validPropertyNames = new ArrayList<>();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                validPropertyNames.add(typeDefAttribute.getAttributeName());
+            }
+        }
+        newInstanceType.setValidInstanceProperties(validPropertyNames);
+        newInstanceType.setTypeDefGUID(newTypeGUID);
+        newInstanceType.setTypeDefVersion(typeDef.getVersion());
+        newInstanceType.setValidStatusList(typeDef.getValidInstanceStatusList());
+        newInstanceType.setTypeDefDescription(typeDef.getDescription());
+        newInstanceType.setTypeDefDescriptionGUID(typeDef.getDescriptionGUID());
+
+        // Set the new instance type into the entity
+        entity.setType(newInstanceType);
+
+        // Convert and store the re-typed entity to Atlas
+        try {
+            AtlasEntity atlasEntity = convertOMEntityDetailToAtlasEntity(userId, entity);
+            LOG.debug("updateEntityStatus: atlasEntity to update is {}", atlasEntity);
+
+            // Construct an AtlasEntityWithExtInfo and call the repository
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityToUpdate = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+            AtlasObjectId atlasObjectId = AtlasTypeUtil.getAtlasObjectId(atlasEntity);
+
+            entityStore.updateEntity(atlasObjectId, atlasEntityToUpdate,true);
+
+            // Retrieve the AtlasEntity - rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+            if (atlasEntWithExt == null) {
+                LOG.error("updateEntityStatus: Could not find entity with guid {} ", entityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntWithExt.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            return returnEntityDetail;
+
+        }
+        catch (StatusNotSupportedException | TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("retypeEntity: Caught OMRS exception {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("retypeEntity: Caught exception from Atlas {}", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+    }
+
+
+    /**
+     * Change the home of an existing entity.  This action is taken for example, if the original home repository
+     * becomes permanently unavailable, or if the user community updating this entity move to working
+     * from a different repository in the open metadata repository cohort.
+     *
+     * @param userId                      - unique identifier for requesting user.
+     * @param entityGUID                  - the unique identifier for the entity to change.
+     * @param typeDefGUID                 - the guid of the TypeDef for the entity - used to verify the entity identity.
+     * @param typeDefName                 - the name of the TypeDef for the entity - used to verify the entity identity.
+     * @param homeMetadataCollectionId    - the existing identifier for this entity's home.
+     * @param newHomeMetadataCollectionId - unique identifier for the new home metadata collection/repository.
+     * @return entity - new values for this entity, including the new home information.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public EntityDetail reHomeEntity(String userId,
+                                     String entityGUID,
+                                     String typeDefGUID,
+                                     String typeDefName,
+                                     String homeMetadataCollectionId,
+                                     String newHomeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName                = "reHomeEntity";
+        final String guidParameterName         = "typeDefGUID";
+        final String nameParameterName         = "typeDefName";
+        final String entityParameterName       = "entityGUID";
+        final String homeParameterName         = "homeMetadataCollectionId";
+        final String newHomeParameterName      = "newHomeMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, entityParameterName, entityGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, homeParameterName, homeMetadataCollectionId, methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, newHomeParameterName, newHomeMetadataCollectionId, methodName);
+
+        /*
+         * Locate entity
+         */
+        EntityDetail  entity  =  getEntityDetail(userId, entityGUID);
+
+        repositoryValidator.validateEntityFromStore(repositoryName, entityGUID, entity, methodName);
+
+
+        /*
+         * Validation complete - ok to make changes
+         */
+        // Set the new instance type into the entity
+        entity.setMetadataCollectionId(newHomeMetadataCollectionId);
+
+        // Convert and store the re-typed entity to Atlas
+        try {
+            AtlasEntity atlasEntity = convertOMEntityDetailToAtlasEntity(userId, entity);
+            LOG.debug("updateEntityStatus: atlasEntity to update is {}", atlasEntity);
+
+            // Construct an AtlasEntityWithExtInfo and call the repository
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityToUpdate = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+            AtlasObjectId atlasObjectId = AtlasTypeUtil.getAtlasObjectId(atlasEntity);
+            entityStore.updateEntity(atlasObjectId, atlasEntityToUpdate,true);
+
+            // Retrieve the AtlasEntity - rather than parsing the EMR since it only has AtlasEntityHeaders. So get the entity directly
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntWithExt;
+
+            atlasEntWithExt = entityStore.getById(entityGUID);
+
+            if (atlasEntWithExt == null) {
+                LOG.error("updateEntityStatus: Could not find entity with guid {} ", entityGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+                throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+            // atlasEntWithExt contains an AtlasEntity (entity) plus a Map<String, AtlasEntity> (referredEntities)
+            // Extract the entity
+            AtlasEntity atlasEntityRetrieved = atlasEntWithExt.getEntity();
+
+            // Convert AtlasEntity to OM EntityDetail.
+            EntityDetail returnEntityDetail;
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntityRetrieved);
+            returnEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            return returnEntityDetail;
+
+        }
+        catch (StatusNotSupportedException | TypeErrorException | RepositoryErrorException | InvalidEntityException e) {
+
+            LOG.error("retypeEntity: Caught exception from AtlasEntityMapper {}", e);
+
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+            throw new EntityNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("retypeEntity: Caught exception from Atlas {}", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, entityParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Change the guid of an existing relationship.  This is used if two different
+     * relationships are discovered to have the same guid.  This is extremely unlikely but not impossible so
+     * the open metadata protocol has provision for this.
+     *
+     * @param userId              - unique identifier for requesting user.
+     * @param typeDefGUID         - the guid of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param typeDefName         - the name of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param relationshipGUID    - the existing identifier for the relationship.
+     * @param newRelationshipGUID - the new unique identifier for the relationship.
+     * @return relationship - new values for this relationship, including the new guid.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the relationship identified by the guid is not found in the
+     *                                       metadata collection.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship reIdentifyRelationship(String userId,
+                                               String typeDefGUID,
+                                               String typeDefName,
+                                               String relationshipGUID,
+                                               String newRelationshipGUID)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName                   = "reIdentifyRelationship";
+        final String guidParameterName            = "typeDefGUID";
+        final String nameParameterName            = "typeDefName";
+        final String relationshipParameterName    = "relationshipGUID";
+        final String newRelationshipParameterName = "newHomeMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, relationshipGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateGUID(repositoryName, newRelationshipParameterName, newRelationshipGUID, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, relationshipGUID);
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        LOG.debug("reIdentifyRelationship: relationship is {}", relationship);
+
+        /* In Atlas the GUID is the id of the vertex, so it is not possible to change it in situ.
+         * It may be possible to implement this method by deleting the existing Atlas entity
+         * and creating a new one. If soft deletes are in force then the previous entity would
+         * still exist, in soft-deleted state. This may lead to complexity compared to the
+         * more desirable situation of having exactly one GUID that relates to the entity.
+         */
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    /**
+     * Change the type of an existing relationship.  Typically this action is taken to move a relationship's
+     * type to either a super type (so the subtype can be deleted) or a new subtype (so additional properties can be
+     * added.)  However, the type can be changed to any compatible type.
+     *
+     * @param userId                - unique identifier for requesting user.
+     * @param relationshipGUID      - the unique identifier for the relationship.
+     * @param currentTypeDefSummary - the details of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param newTypeDefSummary     - details of this relationship's new TypeDef.
+     * @return relationship - new values for this relationship, including the new type information.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws TypeErrorException            - the requested type is not known, or not supported in the metadata repository
+     *                                       hosting the metadata collection.
+     * @throws RelationshipNotKnownException - the relationship identified by the guid is not found in the
+     *                                       metadata collection.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship reTypeRelationship(String         userId,
+                                           String         relationshipGUID,
+                                           TypeDefSummary currentTypeDefSummary,
+                                           TypeDefSummary newTypeDefSummary)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+
+    {
+
+        final String methodName = "reTypeRelationship";
+        final String relationshipParameterName = "relationshipGUID";
+        final String currentTypeDefParameterName = "currentTypeDefSummary";
+        final String newTypeDefParameterName = "newTypeDefSummary";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, relationshipGUID, methodName);
+        repositoryValidator.validateType(repositoryName, currentTypeDefParameterName, currentTypeDefSummary, TypeDefCategory.RELATIONSHIP_DEF, methodName);
+        repositoryValidator.validateType(repositoryName, currentTypeDefParameterName, newTypeDefSummary, TypeDefCategory.RELATIONSHIP_DEF, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, relationshipGUID);
+
+        repositoryValidator.validateInstanceType(repositoryName,
+                relationship,
+                currentTypeDefParameterName,
+                currentTypeDefParameterName,
+                currentTypeDefSummary.getGUID(),
+                currentTypeDefSummary.getName());
+
+
+        repositoryValidator.validatePropertiesForType(repositoryName,
+                newTypeDefParameterName,
+                newTypeDefSummary,
+                relationship.getProperties(),
+                methodName);
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        /* In Atlas the relationship type is stored in the AtlasRelationship typeName field.
+         * If you want to update an relationship then you essentially pass the modified AtlasRelationship
+         * to the relationship store's update() method - this accepts an AtlasRelationship.
+         */
+
+        /*
+         * Alter the retrieved Relationship so that it's InstanceType reflects the new type
+         * Then convert it to an AtlasRelationship and call the update method.
+         */
+
+
+        // Retrieve the TypeDef for the new type
+        String newTypeGUID = newTypeDefSummary.getGUID();
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, newTypeGUID);
+        }
+        catch (TypeDefNotKnownException e) {
+            typeDef = null;
+        }
+
+        if (typeDef == null || typeDef.getCategory() != RELATIONSHIP_DEF) {
+            OMRSErrorCode errorCode    = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(newTypeGUID, newTypeDefParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        RelationshipDef relationshipDef = (RelationshipDef)typeDef;
+
+        // Create a new InstanceType
+        InstanceType newInstanceType = new InstanceType();
+        newInstanceType.setTypeDefName(typeDef.getName());
+        newInstanceType.setTypeDefCategory(typeDef.getCategory());
+        // supertypes not relevant to Relationship
+        newInstanceType.setTypeDefSuperTypes(null);
+        List<TypeDefAttribute> typeDefAttributes = typeDef.getPropertiesDefinition();
+        List<String> validPropertyNames = null;
+        if (typeDefAttributes != null) {
+            validPropertyNames = new ArrayList<>();
+            for (TypeDefAttribute typeDefAttribute : typeDefAttributes) {
+                validPropertyNames.add(typeDefAttribute.getAttributeName());
+            }
+        }
+        newInstanceType.setValidInstanceProperties(validPropertyNames);
+        newInstanceType.setTypeDefGUID(newTypeGUID);
+        newInstanceType.setTypeDefVersion(typeDef.getVersion());
+        newInstanceType.setValidStatusList(typeDef.getValidInstanceStatusList());
+        newInstanceType.setTypeDefDescription(typeDef.getDescription());
+        newInstanceType.setTypeDefDescriptionGUID(typeDef.getDescriptionGUID());
+
+        // Set the new instance type into the relationship
+        relationship.setType(newInstanceType);
+
+
+        try {
+
+            // Convert and store the re-typed relationship to Atlas. Because this is a retype of an existing
+            // Relationship, reuse the same GUID, so useExistingGUID must be set to true.
+            AtlasRelationship atlasRelationship = convertOMRelationshipToAtlasRelationship(relationship, true, relationshipDef);
+
+            LOG.debug("reTypeRelationship: atlasRelationship to update is {}", atlasRelationship);
+
+            // Save the retyped AtlasRelationship to the repository
+            AtlasRelationship atlasRelationshipRetrieved = relationshipStore.update(atlasRelationship);
+
+            // Convert and return the retrieved AtlasRelationship
+            if (atlasRelationshipRetrieved == null) {
+                LOG.error("reTypeRelationship: Could not update relationship with guid {} ", relationshipGUID);
+                OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+                String        errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(relationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+                throw new RelationshipNotKnownException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+
+
+            // Convert AtlasRelationship to OM Relationship.
+            Relationship returnRelationship;
+
+            AtlasRelationshipMapper atlasRelationshipMapper = new AtlasRelationshipMapper(
+                    this,
+                    userId,
+                    atlasRelationshipRetrieved,
+                    entityStore);
+
+            returnRelationship = atlasRelationshipMapper.toOMRelationship();
+            LOG.debug("reTypeRelationship: retrieved Relationship {}", returnRelationship);
+
+            return returnRelationship;
+
+        }
+        catch (StatusNotSupportedException | TypeErrorException | RepositoryErrorException | EntityNotKnownException | InvalidRelationshipException | InvalidEntityException e) {
+            LOG.error("reTypeRelationship: Caught OMRS exception", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+            throw new RelationshipNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("reTypeRelationship: Caught exception from Atlas", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    /**
+     * Change the home of an existing relationship.  This action is taken for example, if the original home repository
+     * becomes permanently unavailable, or if the user community updating this relationship move to working
+     * from a different repository in the open metadata repository cohort.
+     *
+     * @param userId                      - unique identifier for requesting user.
+     * @param relationshipGUID            - the unique identifier for the relationship.
+     * @param typeDefGUID                 - the guid of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param typeDefName                 - the name of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param homeMetadataCollectionId    - the existing identifier for this relationship's home.
+     * @param newHomeMetadataCollectionId - unique identifier for the new home metadata collection/repository.
+     * @return relationship - new values for this relationship, including the new home information.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the relationship identified by the guid is not found in the
+     *                                       metadata collection.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public Relationship reHomeRelationship(String userId,
+                                           String relationshipGUID,
+                                           String typeDefGUID,
+                                           String typeDefName,
+                                           String homeMetadataCollectionId,
+                                           String newHomeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName               = "reHomeRelationship";
+        final String guidParameterName         = "typeDefGUID";
+        final String nameParameterName         = "typeDefName";
+        final String relationshipParameterName = "relationshipGUID";
+        final String homeParameterName         = "homeMetadataCollectionId";
+        final String newHomeParameterName      = "newHomeMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateUserId(repositoryName, userId, methodName);
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, relationshipGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, homeParameterName, homeMetadataCollectionId, methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, newHomeParameterName, newHomeMetadataCollectionId, methodName);
+
+        /*
+         * Locate relationship
+         */
+        Relationship  relationship  = this.getRelationship(userId, relationshipGUID);
+
+        /*
+         * Validation complete - ok to make changes
+         */
+
+        // Will need the RelationshipDef
+        RelationshipDef relationshipDef;
+        TypeDef relTypeDef;
+        try {
+            relTypeDef = _getTypeDefByName(userId, typeDefName);
+        }
+        catch (TypeDefNotKnownException e) {
+            // Handle below
+            relTypeDef = null;
+        }
+        if (relTypeDef == null || relTypeDef.getCategory() != RELATIONSHIP_DEF) {
+            LOG.debug("reHomeRelationship: no existing relationship_def with name {}", typeDefName);
+            OMRSErrorCode errorCode    = OMRSErrorCode.INVALID_TYPEDEF;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(typeDefName, typeDefGUID, nameParameterName, methodName, repositoryName, "unknown");
+
+            throw new InvalidParameterException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        relationshipDef = (RelationshipDef) relTypeDef;
+        LOG.debug("reHomeRelationship: existing RelationshipDef: {}", relationshipDef);
+
+
+        // Set the new metadataCollectionId in the relationship
+        relationship.setMetadataCollectionId(newHomeMetadataCollectionId);
+
+        // Convert and store the re-typed entity to Atlas
+        try {
+            // Construct an AtlasRelationship and call the repository
+            AtlasRelationship atlasRelationship = convertOMRelationshipToAtlasRelationship(relationship, true, relationshipDef);
+            LOG.debug("reHomeRelationship: atlasRelationship to update is {}", atlasRelationship);
+
+            AtlasRelationship atlasReturnedRelationship = relationshipStore.update(atlasRelationship);
+
+            // Convert AtlasRelationship to OM Relationship.
+            Relationship returnRelationship;
+
+            AtlasRelationshipMapper atlasRelationshipMapper = new AtlasRelationshipMapper(
+                    this,
+                    userId,
+                    atlasReturnedRelationship,
+                    entityStore);
+
+            returnRelationship = atlasRelationshipMapper.toOMRelationship();
+            LOG.debug("reHomeRelationship: returning Relationship {}", returnRelationship);
+
+            return returnRelationship;
+
+        }
+        catch (StatusNotSupportedException | TypeErrorException | RepositoryErrorException | InvalidRelationshipException | EntityNotKnownException | InvalidEntityException e) {
+            LOG.error("reTypeRelationship: Caught OMRS exception", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+            throw new RelationshipNotKnownException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("reTypeRelationship: Caught exception from Atlas", e);
+            OMRSErrorCode errorCode    = OMRSErrorCode.RELATIONSHIP_NOT_KNOWN;
+            String        errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(relationshipGUID, relationshipParameterName, methodName, repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+    }
+
+
+    // =========================================================================================================
+
+    // Group 6 methods
+
+    /**
+     * Save the entity as a reference copy.  The id of the home metadata collection is already set up in the
+     * entity.
+     *
+     * @param userId - unique identifier for requesting user.
+     * @param entity - details of the entity to save.
+     * @throws InvalidParameterException  - the entity is null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws TypeErrorException         - the requested type is not known, or not supported in the metadata repository
+     *                                    hosting the metadata collection.
+     * @throws PropertyErrorException     - one or more of the requested properties are not defined, or have different
+     *                                    characteristics in the TypeDef for this entity's type.
+     * @throws HomeEntityException        - the entity belongs to the local repository so creating a reference
+     *                                    copy would be invalid.
+     * @throws EntityConflictException    - the new entity conflicts with an existing entity.
+     * @throws InvalidEntityException     - the new entity has invalid contents.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void saveEntityReferenceCopy(String          userId,
+                                        EntityDetail    entity)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            PropertyErrorException,
+            HomeEntityException,
+            EntityConflictException,
+            InvalidEntityException,
+            UserNotAuthorizedException
+    {
+
+        final String  methodName = "saveEntityReferenceCopy";
+        final String  instanceParameterName = "entity";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+        repositoryValidator.validateReferenceInstanceHeader(repositoryName,
+                metadataCollectionId,
+                instanceParameterName,
+                entity,
+                methodName);
+
+
+        // Convert the EntityDetail to an AtlasEntity and store it.
+
+
+        if (entity == null) {
+            LOG.debug("saveEntityReferenceCopy: the EntityDetail entity is null");
+            return;
+        }
+
+        AtlasEntity atlasEntity;
+        try {
+            atlasEntity = convertOMEntityDetailToAtlasEntity(userId, entity);
+        }
+        catch (StatusNotSupportedException e) {
+            LOG.error("saveEntityReferenceCopy: Could not set entity status for entity with GUID {} ", entity.getGUID(), e);
+            OMRSErrorCode errorCode = OMRSErrorCode.BAD_INSTANCE_STATUS;
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+            throw new InvalidEntityException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        LOG.debug("saveEntityReferenceCopy: atlasEntity (minus any classifications) to create is {}", atlasEntity);
+
+        // Store the entity
+
+        // Construct an AtlasEntityStream and call the repository
+        // Because we want to impose the GUID (e.g. RID) that has been supplied in the EntityDetail, we
+        // need to ask Atlas to accept the entity with existing GUID. Therefore we must use an EntityImportStream.
+        // The CTOR for this takes an AtlasEntityWithExtInfo entityWithExtInfo & an EntityStream entityStream
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWEI = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity);
+        AtlasEntityStreamForImport eis = new AtlasEntityStreamForImport(atlasEntityWEI, null);
+        EntityMutationResponse emr;
+        try {
+            emr = entityStore.createOrUpdateForImport(eis);
+
+        } catch (AtlasBaseException e) {
+            LOG.error("saveEntityReferenceCopy: Caught exception trying to create entity", e);
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        LOG.debug("saveEntityReferenceCopy: emr is {}", emr);
+
+        /* If there were classifications on the supplied EntityDetail, call Atlas to set classifications
+         *
+         * AtlasEntity needs a List<AtlasClassification> so we need to do some translation
+         * OM Classification has:
+         * String                 classificationName
+         * InstanceProperties     classificationProperties
+         * ClassificationOrigin   classificationOrigin
+         * String                 classificationOriginGUID
+         *
+         * AtlasClassification has:
+         * String                 entityGuid
+         * boolean                propagate
+         * List<TimeBoundary>     validityPeriods
+         * String                 typeName;
+         * Map<String, Object>    attributes;
+         */
+        if (entity.getClassifications() != null && entity.getClassifications().size() > 0) {
+            ArrayList<AtlasClassification> atlasClassifications = new ArrayList<>();
+            for (Classification omClassification : entity.getClassifications()) {
+                AtlasClassification atlasClassification = new AtlasClassification(omClassification.getName());
+                // For this OM classification build an Atlas equivalent...
+
+                /* For now we are always setting propagatable to true and AtlasClassification has propagate=true by default.
+                 * Instead this could traverse to the Classification.InstanceType.typeDefGUID and retrieve the ClassificationDef
+                 * to find the value of propagatable on the def.
+                 */
+                atlasClassification.setTypeName(omClassification.getType().getTypeDefName());
+                atlasClassification.setEntityGuid(entity.getGUID());
+
+                // Map attributes from OM Classification to AtlasEntity
+                InstanceProperties classificationProperties = omClassification.getProperties();
+                Map<String, Object> atlasClassificationAttrs = convertOMPropertiesToAtlasAttributes(classificationProperties);
+                atlasClassification.setAttributes(atlasClassificationAttrs);
+
+                LOG.debug("saveEntityReferenceCopy: adding classification {}", atlasClassification);
+                atlasClassifications.add(atlasClassification);
+            }
+            // We do not need to augment the AtlasEntity we created earlier - we can just use the
+            // atlasClassifications directly with the following repository call...
+            try {
+                LOG.debug("saveEntityReferenceCopy: adding classifications {}", atlasClassifications);
+                entityStore.addClassifications(entity.getGUID(), atlasClassifications);
+
+            } catch (AtlasBaseException e) {
+                // Could not add classifications to the entity
+                LOG.error("saveEntityReferenceCopy: Atlas saved entity, but could not add classifications to it, guid {}", entity.getGUID(), e);
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_CLASSIFICATION_FOR_ENTITY;
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+        LOG.debug("saveEntityReferenceCopy: completed");
+
+
+    }
+
+
+    /**
+     * Utility method to convert an OM EntityDetail to an AtlasEntity
+     * @param userId - the security context of the operation
+     * @param entityDetail - the OM EntityDetail object to convert
+     * @return atlasEntity that corresponds to supplied entityDetail
+     * @throws TypeErrorException          - general type error
+     * @throws RepositoryErrorException    - unknown error afflicting repository
+     * @throws StatusNotSupportedException - status value is not supported
+     */
+    private AtlasEntity convertOMEntityDetailToAtlasEntity(String       userId,
+                                                           EntityDetail entityDetail)
+        throws
+            TypeErrorException,
+            RepositoryErrorException,
+            StatusNotSupportedException
+    {
+
+        final String methodName = "convertOMEntityDetailToAtlasEntity";
+
+
+        // Find the entity type
+        String entityTypeName = entityDetail.getType().getTypeDefName();
+
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByName(userId, entityTypeName);
+            if (typeDef == null || typeDef.getCategory() != ENTITY_DEF) {
+                LOG.error("convertOMEntityDetailToAtlasEntity: Could not find entity def with name {} ", entityTypeName);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+            AtlasEntity atlasEntity = new AtlasEntity();
+            atlasEntity.setTypeName(typeDef.getName());
+
+            /* The AtlasEntity constructor sets an unassigned GUID (initialized to nextInternalId),
+             * because normally Atlas would generate a new GUID.
+             *
+             * However, in this particular API we want to accept a supplied identifier (could be a
+             * RID from IGC for example) and use that as the GUID.
+             *
+             * The Atlas connector will need to later be able to identify the home repo that this
+             * object came from - as well as reconstitute that repo's identifier for the object -
+             * which could be an IGC rid for example. The GUID is set as supplied and the homeId
+             * is set to the metadataCollectionId of the home repository.
+             *
+             */
+
+            atlasEntity.setGuid(entityDetail.getGUID());
+            atlasEntity.setHomeId(entityDetail.getMetadataCollectionId());
+
+
+            InstanceStatus omStatus = entityDetail.getStatus();
+            AtlasEntity.Status atlasEntityStatus;
+            switch (omStatus) {
+                // AtlasEntity.Status can only be either { ACTIVE | DELETED }
+                case DELETED:
+                    atlasEntityStatus = AtlasEntity.Status.DELETED;
+                    break;
+                case ACTIVE:
+                    atlasEntityStatus = AtlasEntity.Status.ACTIVE;
+                    break;
+                default:
+                    // unsupportable status
+                    LOG.error("convertOMEntityDetailToAtlasEntity: Atlas does not support entity status {}", omStatus);
+                    OMRSErrorCode errorCode = OMRSErrorCode.BAD_INSTANCE_STATUS;
+                    String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                            this.getClass().getName(),
+                            repositoryName);
+                    throw new StatusNotSupportedException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+            }
+            atlasEntity.setStatus(atlasEntityStatus);
+
+
+            atlasEntity.setCreatedBy(entityDetail.getCreatedBy());
+            atlasEntity.setUpdatedBy(entityDetail.getUpdatedBy());
+            atlasEntity.setCreateTime(entityDetail.getCreateTime());
+            atlasEntity.setUpdateTime(entityDetail.getUpdateTime());
+            atlasEntity.setVersion(entityDetail.getVersion());
+            // Cannot set classifications yet - need to do that post-create to get the entity GUID
+
+            // Map attributes from OM EntityDetail to AtlasEntity
+            InstanceProperties instanceProperties = entityDetail.getProperties();
+            Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(instanceProperties);
+            atlasEntity.setAttributes(atlasAttrs);
+
+            // AtlasEntity has been fully constructed
+
+            return atlasEntity;
+
+        }
+        catch (TypeDefNotKnownException e) {
+
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+    }
+
+    /**
+     * Remove a reference copy of the the entity from the local repository.  This method can be used to
+     * remove reference copies from the local cohort, repositories that have left the cohort,
+     * or entities that have come from open metadata archives.
+     *
+     * @param userId                   - unique identifier for requesting user.
+     * @param entityGUID               - the unique identifier for the entity.
+     * @param typeDefGUID              - the guid of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param typeDefName              - the name of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param homeMetadataCollectionId - unique identifier for the new home repository.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                    the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.
+     * @throws HomeEntityException        - the entity belongs to the local repository so creating a reference
+     *                                    copy would be invalid.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void purgeEntityReferenceCopy(String userId,
+                                         String entityGUID,
+                                         String typeDefGUID,
+                                         String typeDefName,
+                                         String homeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            HomeEntityException,
+            UserNotAuthorizedException
+    {
+        final String methodName                = "purgeEntityReferenceCopy";
+        final String guidParameterName         = "typeDefGUID";
+        final String nameParameterName         = "typeDefName";
+        final String entityParameterName       = "entityGUID";
+        final String homeParameterName         = "homeMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateGUID(repositoryName, entityParameterName, entityGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName, guidParameterName, nameParameterName, typeDefGUID, typeDefName, methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, homeParameterName, homeMetadataCollectionId, methodName);
+
+        // Atlas has two configuration settings for its DeleteHandler - all soft deletes or all hard deletes.
+        // It is not clear how to implement this method other than when hard deletes are configured.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    /**
+     * The local repository has requested that the repository that hosts the home metadata collection for the
+     * specified entity sends out the details of this entity so the local repository can create a reference copy.
+     *
+     * @param userId                   - unique identifier for requesting user.
+     * @param entityGUID               - unique identifier of requested entity.
+     * @param typeDefGUID              - unique identifier of requested entity's TypeDef.
+     * @param typeDefName              - unique name of requested entity's TypeDef.
+     * @param homeMetadataCollectionId - identifier of the metadata collection that is the home to this entity.
+     * @throws InvalidParameterException  - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException   - there is a problem communicating with the metadata repository where
+     *                                      the metadata collection is stored.
+     * @throws EntityNotKnownException    - the entity identified by the guid is not found in the metadata collection.
+     * @throws HomeEntityException        - the entity belongs to the local repository so creating a reference
+     *                                      copy would be invalid.
+     * @throws UserNotAuthorizedException - the userId is not permitted to perform this operation.
+     */
+    public void refreshEntityReferenceCopy(String userId,
+                                           String entityGUID,
+                                           String typeDefGUID,
+                                           String typeDefName,
+                                           String homeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            EntityNotKnownException,
+            HomeEntityException,
+            UserNotAuthorizedException
+    {
+
+        final String methodName = "refreshEntityReferenceCopy";
+
+        /*
+         * This method needs to check whether this is the metadataCollection indicated in the homeMetadataCollectionId
+         * parameter. If it is not, it will ignore the request. If it is the specified metadataCollection, then it needs
+         * to retrieve the entity (by GUID) from Atlas and pass it to the EventMapper which will handle it (formulate the
+         * appropriate call to the repository event processor).
+         */
+
+        if (!homeMetadataCollectionId.equals(this.metadataCollectionId)) {
+            LOG.debug("refreshEntityReferenceCopy: ignoring request because not intended for this metadataCollection");
+            return;
+        }
+
+        if (this.eventMapper == null) {
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.EVENT_MAPPER_NOT_INITIALIZED;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /* This is the correct metadataCollection and it has a valid event mapper.
+         * Retrieve the entity and call the event mapper
+         */
+
+        // Using the supplied guid look up the entity.
+
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+        try {
+            atlasEntityWithExt = entityStore.getById(entityGUID);
+        } catch (AtlasBaseException e) {
+
+            LOG.error("getEntityDetail: caught exception from get entity by guid {}, {}", entityGUID, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+        LOG.debug("getEntityDetail: atlasEntityWithExt is {}", atlasEntityWithExt);
+        AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+
+        // Project the AtlasEntity as an EntityDetail and invoke the mapper
+
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+            EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("<== getEntityDetail(userId={}, guid={}: entityDetail={})", userId, entityGUID, omEntityDetail);
+            }
+            this.eventMapper.processRefreshEvent(omEntityDetail);
+
+        } catch (TypeErrorException | InvalidEntityException e) {
+            LOG.error("getEntityDetail: caught exception from attempt to convert Atlas entity to OM {}, {}", atlasEntity, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityGUID, methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+    }
+
+    /**
+     * Save the relationship as a reference copy.  The id of the home metadata collection is already set up in the
+     * relationship.
+     *
+     * @param userId       - unique identifier for requesting user.
+     * @param relationship - relationship to save.
+     * @throws InvalidParameterException     - the relationship is null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws TypeErrorException            - the requested type is not known, or not supported in the metadata repository
+     *                                       hosting the metadata collection.
+     * @throws EntityNotKnownException       - one of the entities identified by the relationship is not found in the
+     *                                       metadata collection.
+     * @throws PropertyErrorException        - one or more of the requested properties are not defined, or have different
+     *                                       characteristics in the TypeDef for this relationship's type.
+     * @throws HomeRelationshipException     - the relationship belongs to the local repository so creating a reference
+     *                                       copy would be invalid.
+     * @throws RelationshipConflictException - the new relationship conflicts with an existing relationship.
+     * @throws InvalidRelationshipException  - the new relationship has invalid contents.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public void saveRelationshipReferenceCopy(String       userId,
+                                              Relationship relationship)
+        throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            TypeErrorException,
+            EntityNotKnownException,
+            PropertyErrorException,
+            HomeRelationshipException,
+            RelationshipConflictException,
+            InvalidRelationshipException,
+            UserNotAuthorizedException
+    {
+        final String  methodName = "saveRelationshipReferenceCopy";
+        final String  instanceParameterName = "relationship";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateReferenceInstanceHeader(repositoryName, metadataCollectionId, instanceParameterName, relationship, methodName);
+
+        // Need to access the relationship def to find the OM propagation rule.
+        // Use the typeName from the relationship to locate the RelationshipDef typedef for the relationship.
+
+        // Note that relationship end def attributeNames are reversed between OM and Atlas.... see the converter methods.
+
+
+        // Find the relationship type
+        String relationshipTypeName = relationship.getType().getTypeDefName();
+        TypeDef typeDef;
+        try {
+
+            typeDef = _getTypeDefByName(userId, relationshipTypeName);
+
+        }
+        catch (TypeDefNotKnownException e) {
+            LOG.debug("saveRelationshipReferenceCopy: Caught exception attempting to get relationship type from _getTypeDefByName {}", e.getMessage());
+            // Handle below
+            typeDef = null;
+        }
+        // Validate it
+        if (typeDef == null || typeDef.getCategory() != RELATIONSHIP_DEF) {
+            LOG.error("saveRelationshipReferenceCopy: Could not find a RelationshipDef with name {} ", relationshipTypeName);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        RelationshipDef relationshipDef = (RelationshipDef) typeDef;
+
+
+        // Find the GUIDs and the type names of the entities
+        String entityOneGUID = null;
+        String entityOneTypeName = null;
+        EntityProxy entityOneProxy = relationship.getEntityOneProxy();
+        if (entityOneProxy != null) {
+            entityOneGUID = entityOneProxy.getGUID();
+            if (entityOneProxy.getType() != null) {
+                entityOneTypeName = entityOneProxy.getType().getTypeDefName();
+            }
+        }
+
+        // Test whether we have the entity (by GUID). If so that's cool; if not we must create a proxy
+        // Using the supplied guid look up the entity
+        try {
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+            atlasEntityWithExt = entityStore.getById(entityOneGUID);
+            LOG.debug("saveRelationshipReferenceCopy: entity one exists in repository; {}", atlasEntityWithExt);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.debug("saveRelationshipReferenceCopy: exception from get entity by guid {}, {}",entityOneGUID, e.getMessage());
+            // The entity does not already exist, so create as proxy
+            try {
+                addEntityProxy(userId,entityOneProxy);
+            }
+            catch (InvalidParameterException | RepositoryErrorException |
+                   FunctionNotSupportedException | UserNotAuthorizedException exc) {
+                LOG.error("saveRelationshipReferenceCopy: caught exception from addEntityProxy", exc );
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ENTITY_NOT_CREATED;
+
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(
+                        entityOneProxy.toString(), methodName, repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+        }
+
+
+        String entityTwoGUID = null;
+        String entityTwoTypeName = null;
+        EntityProxy entityTwoProxy = relationship.getEntityTwoProxy();
+        if (entityTwoProxy != null) {
+            entityTwoGUID = entityTwoProxy.getGUID();
+            if (entityTwoProxy.getType() != null) {
+                entityTwoTypeName = entityTwoProxy.getType().getTypeDefName();
+            }
+        }
+
+        // Test whether we have the entity (by GUID). If so that's cool; if not we must create a proxy
+        // Using the supplied guid look up the entity
+        try {
+            AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+            atlasEntityWithExt = entityStore.getById(entityTwoGUID);
+            LOG.debug("saveRelationshipReferenceCopy: entity two exists in repository; {}", atlasEntityWithExt);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.debug("saveRelationshipReferenceCopy: exception from get entity by guid {}, {}",entityTwoGUID, e.getMessage());
+            // The entity does not already exist, so create as proxy
+            try {
+                addEntityProxy(userId,entityTwoProxy);
+            }
+            catch (InvalidParameterException | RepositoryErrorException |
+                    FunctionNotSupportedException | UserNotAuthorizedException exc) {
+                LOG.error("saveRelationshipReferenceCopy: caught exception from addEntityProxy", exc );
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.ENTITY_NOT_CREATED;
+
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(
+                        entityTwoProxy.toString(), methodName, repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+        }
+
+        /* Create or Update the AtlasRelationship
+         * If the relationship already exists - i.e. we have a relationship with the same GUID - then
+         * perform an update. Otherwise we will create the relationship.
+         */
+
+        AtlasRelationship atlasRelationship = new AtlasRelationship();
+
+        /* GUID is set by Atlas CTOR (called above) to nextInternalID. Because we are saving a ref copy we overwrite with
+         * the provided GUID if one has been supplied. In some cases, the caller may not have a GUID to use, in which case
+         * leave the GUID as generated by Atlas.
+         */
+        String suppliedGUID = relationship.getGUID();
+        if (suppliedGUID != null) {
+            atlasRelationship.setGuid(suppliedGUID);
+        }
+        // The atlasRelationship now has either the supplied GUID or has generated its own GUID
+
+
+        /* The Atlas connector will need to later be able to identify the home repo that this object came from - as well as reconstitute that
+         * repo's identifier for the object - which could be an IGC rid for example. The GUID is stored as supplied and the homeId is set to the
+         * metadataCollectionId of the home repository.
+         */
+        atlasRelationship.setHomeId(relationship.getMetadataCollectionId());
+
+        atlasRelationship.setTypeName(relationshipTypeName);
+        atlasRelationship.setStatus(ACTIVE);
+        atlasRelationship.setCreatedBy(relationship.getCreatedBy());
+        atlasRelationship.setUpdatedBy(relationship.getUpdatedBy());
+        atlasRelationship.setCreateTime(relationship.getCreateTime());
+        atlasRelationship.setUpdateTime(relationship.getUpdateTime());
+        atlasRelationship.setVersion(relationship.getVersion());
+        // Set end1
+        AtlasObjectId end1 = new AtlasObjectId();
+        end1.setGuid(entityOneGUID);
+        end1.setTypeName(entityOneTypeName);
+        atlasRelationship.setEnd1(end1);
+        // Set end2
+        AtlasObjectId end2 = new AtlasObjectId();
+        end2.setGuid(entityTwoGUID);
+        end2.setTypeName(entityTwoTypeName);
+        atlasRelationship.setEnd2(end2);
+        atlasRelationship.setLabel(relationshipTypeName);    // Set the label to the type name of the relationship def.
+        // Set propagateTags
+        ClassificationPropagationRule omPropRule = relationshipDef.getPropagationRule();
+        AtlasRelationshipDef.PropagateTags atlasPropTags = convertOMPropagationRuleToAtlasPropagateTags(omPropRule);
+        atlasRelationship.setPropagateTags(atlasPropTags);
+
+        // Set attributes on AtlasRelationship
+        // Get the relationshipProperties from the OM Relationship, and create Atlas attributes...
+
+        // Map attributes from OM Relationship to AtlasRelationship
+        InstanceProperties instanceProperties = relationship.getProperties();
+        Map<String, Object> atlasAttrs = convertOMPropertiesToAtlasAttributes(instanceProperties);
+        atlasRelationship.setAttributes(atlasAttrs);
+
+        // AtlasRelationship should have been fully constructed by this point
+
+        // Call the repository
+        // If the relationship does not exist we will call create(). If already exists then we must call update().
+        // So we need to find out whether it exists or not... the getById will throw an exception if the id does
+        // not yet exist.
+
+        boolean relationshipExists;
+        try {
+            AtlasRelationship existingRelationship = relationshipStore.getById(atlasRelationship.getGuid());
+            LOG.debug("Relationship with GUID {} already exists - so will be updated", atlasRelationship.getGuid() );
+            relationshipExists = true;
+        }
+        catch (AtlasBaseException e) {
+            if (e.getAtlasErrorCode() == AtlasErrorCode.RELATIONSHIP_GUID_NOT_FOUND) {
+                LOG.debug("Relationship with GUID {} does not exist - so will be created", atlasRelationship.getGuid());
+                relationshipExists = false;
+            }
+            else {
+                // Trouble at mill...
+                LOG.debug("saveRelationshipReferenceCopy: Caught exception from Atlas relationship store getById method {}", e.getMessage());
+
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+
+                String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                        this.getClass().getName(),
+                        repositoryName);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+
+        AtlasRelationship returnedAtlasRelationship;
+
+        try {
+            if (relationshipExists) {
+                LOG.debug("Updating existing relationship wih GUID {}", atlasRelationship.getGuid());
+                returnedAtlasRelationship = relationshipStore.update(atlasRelationship);
+            } else {
+                LOG.debug("Creating new relationship wih GUID {}", atlasRelationship.getGuid());
+                returnedAtlasRelationship = relationshipStore.create(atlasRelationship);
+            }
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.debug("saveRelationshipReferenceCopy: Caught exception from Atlas relationship store create/update method {}", e.getMessage());
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.REPOSITORY_ERROR;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        // Verify the returnedAtlasRelationship and fill in any extra detail in relationship - e.g. sys attrs
+
+        if (returnedAtlasRelationship.getStatus() != ACTIVE) {
+            LOG.error("saveRelationshipReferenceCopy: Atlas created relationship, but status set to {}", returnedAtlasRelationship.getStatus());
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_RELATIONSHIP_FROM_STORE;
+
+            String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                    this.getClass().getName(),
+                    repositoryName);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        LOG.debug("saveRelationshipReferenceCopy: Save to Atlas returned relationship {}", returnedAtlasRelationship);
+
+    }
+
+
+    /**
+     * Remove the reference copy of the relationship from the local repository. This method can be used to
+     * remove reference copies from the local cohort, repositories that have left the cohort,
+     * or relationships that have come from open metadata archives.
+     *
+     * @param userId                   - unique identifier for requesting user.
+     * @param relationshipGUID         - the unique identifier for the relationship.
+     * @param typeDefGUID              - the guid of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param typeDefName              - the name of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param homeMetadataCollectionId - unique identifier for the home repository for this relationship.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the relationship identifier is not recognized.
+     * @throws HomeRelationshipException     - the relationship belongs to the local repository so creating a reference
+     *                                       copy would be invalid.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public void purgeRelationshipReferenceCopy(String userId,
+                                               String relationshipGUID,
+                                               String typeDefGUID,
+                                               String typeDefName,
+                                               String homeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            HomeRelationshipException,
+            UserNotAuthorizedException
+    {
+        final String methodName                = "purgeRelationshipReferenceCopy";
+        final String guidParameterName         = "typeDefGUID";
+        final String nameParameterName         = "typeDefName";
+        final String relationshipParameterName = "relationshipGUID";
+        final String homeParameterName         = "homeMetadataCollectionId";
+
+        /*
+         * Validate parameters
+         */
+        this.validateRepositoryConnector(methodName);
+        parentConnector.validateRepositoryIsActive(methodName);
+
+        repositoryValidator.validateGUID(repositoryName, relationshipParameterName, relationshipGUID, methodName);
+        repositoryValidator.validateTypeDefIds(repositoryName,
+                guidParameterName,
+                nameParameterName,
+                typeDefGUID,
+                typeDefName,
+                methodName);
+        repositoryValidator.validateHomeMetadataGUID(repositoryName, homeParameterName, homeMetadataCollectionId, methodName);
+
+        /*
+         * Process the request
+         */
+
+        // Atlas has two configuration settings for its DeleteHandler - all soft deletes or all hard deletes.
+        // It is not clear how to implement this method other than when hard deletes are configured.
+
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+    }
+
+
+    /**
+     * The local repository has requested that the repository that hosts the home metadata collection for the
+     * specified relationship sends out the details of this relationship so the local repository can create a
+     * reference copy.
+     *
+     * @param userId                   - unique identifier for requesting user.
+     * @param relationshipGUID         - unique identifier of the relationship.
+     * @param typeDefGUID              - the guid of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param typeDefName              - the name of the TypeDef for the relationship - used to verify the relationship identity.
+     * @param homeMetadataCollectionId - unique identifier for the home repository for this relationship.
+     * @throws InvalidParameterException     - one of the parameters is invalid or null.
+     * @throws RepositoryErrorException      - there is a problem communicating with the metadata repository where
+     *                                       the metadata collection is stored.
+     * @throws RelationshipNotKnownException - the relationship identifier is not recognized.
+     * @throws HomeRelationshipException     - the relationship belongs to the local repository so creating a reference
+     *                                       copy would be invalid.
+     * @throws UserNotAuthorizedException    - the userId is not permitted to perform this operation.
+     */
+    public void refreshRelationshipReferenceCopy(String userId,
+                                                 String relationshipGUID,
+                                                 String typeDefGUID,
+                                                 String typeDefName,
+                                                 String homeMetadataCollectionId)
+            throws
+            InvalidParameterException,
+            RepositoryErrorException,
+            RelationshipNotKnownException,
+            HomeRelationshipException,
+            UserNotAuthorizedException
+    {
+        final String methodName                = "refreshRelationshipReferenceCopy";
+
+        /*
+         *  TODO!! Need to work out how to implement this method in conjunction with EventMapper
+         */
+        OMRSErrorCode errorCode = OMRSErrorCode.METHOD_NOT_IMPLEMENTED;
+
+        String errorMessage = errorCode.getErrorMessageId() + errorCode.getFormattedErrorMessage(methodName,
+                this.getClass().getName(),
+                repositoryName);
+
+        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                this.getClass().getName(),
+                methodName,
+                errorMessage,
+                errorCode.getSystemAction(),
+                errorCode.getUserAction());
+
+    }
+
+
+    // ==============================================================================================================
+    //
+    // INTERNAL METHODS AND HELPER CLASSSES
+    //
+
+    /*
+     * Parse the OM EntityDef and create an AtlasEntityDef
+     */
+    private AtlasEntityDef convertOMEntityDefToAtlasEntityDef(EntityDef omEntityDef) {
+
+        LOG.debug("convertOMEntityDef: OM EntityDef {}", omEntityDef);
+
+        if (omEntityDef == null) {
+            return null;
+        }
+
+        String omTypeName = omEntityDef.getName();
+        String atlasTypeName = omTypeName;
+
+        // Detect whether the OM Type is one of the Famous Five
+        boolean famousFive = false;
+        if (FamousFive.omTypeRequiresSubstitution(omTypeName)) {
+            famousFive = true;
+            // Prefix the type name
+            atlasTypeName = FamousFive.getAtlasTypeName(omTypeName,omEntityDef.getGUID());
+        }
+
+        // Convert OM type into a valid Atlas type
+
+        // Allocate AtlasEntityDef, which will set TypeCategory automatically
+        AtlasEntityDef atlasEntityDef = new AtlasEntityDef();
+
+        // Set common fields
+        atlasEntityDef.setGuid(omEntityDef.getGUID());
+        atlasEntityDef.setName(atlasTypeName);
+        atlasEntityDef.setDescription(omEntityDef.getDescription());
+        atlasEntityDef.setVersion(omEntityDef.getVersion());
+        atlasEntityDef.setTypeVersion(omEntityDef.getVersionName());
+        atlasEntityDef.setCreatedBy(omEntityDef.getCreatedBy());
+        atlasEntityDef.setUpdatedBy(omEntityDef.getUpdatedBy());
+        atlasEntityDef.setCreateTime(omEntityDef.getCreateTime());
+        atlasEntityDef.setUpdateTime(omEntityDef.getUpdateTime());
+        atlasEntityDef.setOptions(omEntityDef.getOptions());
+
+        // Handle fields that require conversion - i.e. supertypes, attributeDefs
+        // subtypes are deliberately ignored
+
+        // Convert OMRS List<TypeDefLink> to an Atlas Set<String> of Atlas type names
+        // If famousFive then modify the superType hierarchy
+        if (!famousFive) {
+            TypeDefLink omSuperType = omEntityDef.getSuperType();
+            if (omSuperType == null) {
+                // If there is no superType defined in OM EntityDef then set atlasEntityDef.superTypes to null
+                atlasEntityDef.setSuperTypes(null);
+            } else {
+                // OM type has supertype...add that plus original OM type as supertypes in Atlas.
+                // If the OM supertype is itself in Famous Five, convert it...
+                String omSuperTypeName = omSuperType.getName();
+                String omSuperTypeGUID = omSuperType.getGUID();
+                if (FamousFive.omTypeRequiresSubstitution(omSuperTypeName)) {
+                    // Prefix the supertype name
+                    String atlasSuperTypeName = FamousFive.getAtlasTypeName(omSuperTypeName, omSuperTypeGUID);
+                    Set<String> atlasSuperTypes = new HashSet<>();
+                    atlasSuperTypes.add(atlasSuperTypeName);
+                    atlasEntityDef.setSuperTypes(atlasSuperTypes);
+                }
+                else {
+                    Set<String> atlasSuperTypes = new HashSet<>();
+                    atlasSuperTypes.add(omSuperTypeName);
+                    atlasEntityDef.setSuperTypes(atlasSuperTypes);
+                }
+            }
+        }
+        else { // famousFive
+            TypeDefLink omSuperType = omEntityDef.getSuperType();
+            if (omSuperType == null) {
+                // If there is no superType defined in OM set atlasEntityDef.superTypes to original OM type
+                Set<String> atlasSuperTypes = new HashSet<>();
+                atlasSuperTypes.add(omTypeName);
+                atlasEntityDef.setSuperTypes(atlasSuperTypes);
+            } else {
+                // OM type has supertype...add that plus original OM type as supertypes in Atlas.
+                // If the OM supertype is itself in Famous Five, convert it...
+                String omSuperTypeName = omSuperType.getName();
+                String omSuperTypeGUID = omSuperType.getGUID();
+                if (FamousFive.omTypeRequiresSubstitution(omSuperTypeName)) {
+                    // Prefix the supertype name
+                    String atlasSuperTypeName = FamousFive.getAtlasTypeName(omSuperTypeName, omSuperTypeGUID);
+                    Set<String> atlasSuperTypes = new HashSet<>();
+                    atlasSuperTypes.add(atlasSuperTypeName);
+                    atlasSuperTypes.add(omTypeName);
+                    atlasEntityDef.setSuperTypes(atlasSuperTypes);
+                }
+                else {
+                    Set<String> atlasSuperTypes = new HashSet<>();
+                    atlasSuperTypes.add(omSuperTypeName);
+                    atlasSuperTypes.add(omTypeName);
+                    atlasEntityDef.setSuperTypes(atlasSuperTypes);
+                }
+            }
+        }
+
+        // Set Atlas Attribute defs
+        // OMRS ArrayList<TypeDefAttribute> --> Atlas List<AtlasAttributeDef>
+        // Retrieve the OM EntityDef attributes:
+        List<TypeDefAttribute> omAttrs = omEntityDef.getPropertiesDefinition();
+        ArrayList<AtlasStructDef.AtlasAttributeDef> atlasAttrs = convertOMAttributeDefs(omAttrs);
+        atlasEntityDef.setAttributeDefs(atlasAttrs);
+
+        // Return the AtlasEntityDef
+        return atlasEntityDef;
+    }
+
+
+    /*
+     * Parse the OM RelationshipDef and create an AtlasRelationshipDef
+     */
+    private AtlasRelationshipDef convertOMRelationshipDefToAtlasRelationshipDef(RelationshipDef omRelationshipDef)
+            throws
+            RepositoryErrorException,
+            TypeErrorException
+    {
+
+
+        final String methodName = "convertOMRelationshipDefToAtlasRelationshipDef";
+
+        LOG.debug("convertOMRelationshipDef: OM RelationshipDef {}", omRelationshipDef);
+
+        if (omRelationshipDef == null) {
+            return null;
+        }
+
+        /*
+         * Convert OM type into a valid Atlas type:
+         *
+         *  [OM RelationshipDef]                                         ->  [AtlasRelationshipDef]
+         *  RelationshipCategory               relationshipCategory      ->  RelationshipCategory    relationshipCategory; REMOVED
+         *  RelationshipContainerEnd           relationshipContainerEnd  ->  sets aspects of EndDef that is the ctr end    REMOVED
+         *  ClassificationPropagationRule      propagationRule           ->  PropagateTags           propagateTags;
+         *  RelationshipEndDef                 endDef1                   ->  AtlasRelationshipEndDef endDef1;
+         *  RelationshipEndDef                 endDef2                   ->  AtlasRelationshipEndDef endDef2;
+         *  TypeDefLink                        superType                 ->  IGNORED
+         *  String                             description               ->  description
+         *  String                             descriptionGUID           ->  IGNORED
+         *  String                             origin                    ->  IGNORED
+         *  String                             createdBy                 ->  createdBy
+         *  String                             updatedBy                 ->  updatedBy
+         *  Date                               createTime                ->  createTime
+         *  Date                               updateTime                ->  updateTime
+         *  Map<String, String>                options                   ->  options
+         *  ArrayList<ExternalStandardMapping> externalStandardMappings  ->  IGNORED
+         *  ArrayList<InstanceStatus>          validInstanceStatusList   ->  IGNORED
+         *  InstanceStatus                     initialStatus             ->  IGNORED
+         *  ArrayList<TypeDefAttribute>        propertiesDefinition      ->  attributeDefs
+         *  Long                               version                   ->  atlas version
+         *  String                             versionName               ->  typeVersion
+         *  TypeDefCategory                    category                  ->  NOT NEEDED Atlas Cat set by CTOR
+         *  String                             guid                      ->  atlas guid
+         *  String                             name                      ->  atlas name
+         */
+
+
+        // Allocate AtlasRelationshipDef, which will set TypeCategory automatically
+        AtlasRelationshipDef atlasRelationshipDef;
+        try {
+            atlasRelationshipDef = new AtlasRelationshipDef();
+
+        } catch (AtlasBaseException e) {
+            LOG.error("convertOMRelationshipDef: could not create an AtlasRelationshipDef for type {}", omRelationshipDef.getName(), e);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("RelationshipDef", "convert", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "convertOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // Set common fields
+        atlasRelationshipDef.setGuid(omRelationshipDef.getGUID());
+        atlasRelationshipDef.setName(omRelationshipDef.getName());
+        atlasRelationshipDef.setDescription(omRelationshipDef.getDescription());
+        atlasRelationshipDef.setVersion(omRelationshipDef.getVersion());
+        atlasRelationshipDef.setTypeVersion(omRelationshipDef.getVersionName());
+        atlasRelationshipDef.setCreatedBy(omRelationshipDef.getCreatedBy());
+        atlasRelationshipDef.setUpdatedBy(omRelationshipDef.getUpdatedBy());
+        atlasRelationshipDef.setCreateTime(omRelationshipDef.getCreateTime());
+        atlasRelationshipDef.setUpdateTime(omRelationshipDef.getUpdateTime());
+        atlasRelationshipDef.setOptions(omRelationshipDef.getOptions());
+
+        /*
+         * Remaining fields require conversion - supertypes and subtypes are deliberately ignored
+         */
+
+        /* If in future OM RelationshipDef supports different categories of Relationship, convert accordingly:
+         *
+         * RelationshipCategory omRelCat = omRelationshipDef.getRelationshipCategory();
+         * AtlasRelationshipDef.RelationshipCategory atlasRelCat = convertOMRelationshipCategoryToAtlasRelationshipCategory(omRelCat);
+         * atlasRelationshipDef.setRelationshipCategory(atlasRelCat);
+         *
+         * For now though:
+         * OM relationship defs are always ASSOCIATIONS. Atlas supports COMPOSITION and AGGREGATION too, but OM only uses ASSOCIATION
+         */
+        atlasRelationshipDef.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+
+        // Convert propagationRule to propagateTags
+        ClassificationPropagationRule omPropRule = omRelationshipDef.getPropagationRule();
+
+        AtlasRelationshipDef.PropagateTags atlasPropTags = convertOMPropagationRuleToAtlasPropagateTags(omPropRule);
+
+        atlasRelationshipDef.setPropagateTags(atlasPropTags);
+
+        /* RelationshipEndDef needs to be converted to AtlasRelationshipEndDef
+         *
+         * OM RelationshipEndDef contains:
+         * TypeDefLink  entityType   which contains name and guid     -> set Atlas type
+         * String       attributeName                                 -> set Atlas name
+         * String       attributeDescription                          -> set Atlas description
+         * String       attributeDescriptionGUID                      -> IGNORED
+         * AttributeCardinality attributeCardinality                  -> set Atlas cardinality
+         * In Atlas RED we need the following fields - which are set as above, unless noted differently:
+         *
+         * Note that the attribute naming is transposed between the OM and Atlas models, so we swap the
+         * names - i.e. the attrName of OM end1 will be used for the attribute name of Atlas end2 and v.v.
+         * This is because Atlas stores the relationship ends as literal objects - i.e. the object will contain
+         * the attributeName that will be used to refer to the other (relationship) end. - e.g. the RelationshipEndDef
+         * for a Glossary that has a TermAnchor relationship to a Term will be stored as type="Glossary";attributeName="terms".
+         * This is the opposite to OM which defines the RelEndDef for Glossary as type="Glossary"; attributeName="anchor" - ie.
+         * the name by which the Glossary will be 'known' (referred to) from a Term. Therefore when converting between
+         * OM and Atlas we must switch the attributeNames between ends 1 and 2.
+         *
+         * String type;
+         * String name;
+         * boolean isContainer;        <--will be set from OM RCE after both ends have been established
+         * Cardinality cardinality;
+         * boolean isLegacyAttribute;  <-- will always be set to false.
+         * String description;
+         *
+         * The connector take the various parts of the RelationshipDef in good faith and does not perform existence
+         * checking or comparison - e.g. that the entity defs exist. That is delegated to Atlas since it has that
+         * checking already.
+         */
+
+        // Get both the OM end defs and validate them. We also need both their types up front - so we can swap them over.
+
+
+        // END1
+        //RelationshipEndDef            endDef1                   ->  AtlasRelationshipEndDef endDef1;
+        RelationshipEndDef omEndDef1 = omRelationshipDef.getEndDef1();
+        // An OM end def must have a type and an attributeName, otherwise it will fail to register in Atlas
+        TypeDefLink omTDL1 = omEndDef1.getEntityType();
+        String attributeName1 = omEndDef1.getAttributeName();
+        String attributeDescription1 = omEndDef1.getAttributeDescription();
+        if (attributeName1 == null || omTDL1.getName() == null || omTDL1.getGUID() == null) {
+            // There is not enough information to create the relationship end - and hence the relationship def
+            LOG.error("convertOMRelationshipDef: Failed to convert OM RelationshipDef {} - end1 partially defined; name {}, type {}",
+                    omRelationshipDef.getName(), attributeName1, omTDL1.getName());
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(omRelationshipDef.getName(), omRelationshipDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omRelationshipDef.toString());
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "convertOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        // END2
+        RelationshipEndDef omEndDef2 = omRelationshipDef.getEndDef2();
+        TypeDefLink omTDL2 = omEndDef2.getEntityType();
+        String attributeName2 = omEndDef2.getAttributeName();
+        String attributeDescription2 = omEndDef2.getAttributeDescription();
+        if (attributeName2 == null || omTDL2.getName() == null || omTDL2.getGUID() == null) {
+            // There is not enough information to create the relationship end - and hence the relationship def
+            LOG.error("convertOMRelationshipDef: Failed to convert OM RelationshipDef {} - end2 partially defined; name {}, type {}",
+                    omRelationshipDef.getName(), attributeName2, omTDL2.getName());
+            OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(omRelationshipDef.getName(), omRelationshipDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omRelationshipDef.toString());
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "convertOMRelationshipDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        /* Process END1
+         * Note that hen converting from Atlas to OM or vice versa, the attribute name and cardinality needs to be switched
+         * from one end to the other.
+         */
+        AtlasRelationshipEndDef atlasEndDef1 = new AtlasRelationshipEndDef();
+        atlasEndDef1.setName(omEndDef2.getAttributeName());   // attribute names are deliberately transposed as commented above
+        atlasEndDef1.setDescription(attributeDescription2);   // attribute descriptions are deliberately transposed as above
+        // Ends with entity types in famous five need to be converted...
+        String omTypeName1 = omTDL1.getName();
+        String omTypeGUID1 = omTDL1.getGUID();
+        String atlasTypeName1 = omTypeName1;
+        if (FamousFive.omTypeRequiresSubstitution(omTypeName1)) {
+            atlasTypeName1 = FamousFive.getAtlasTypeName(omTypeName1, omTypeGUID1);
+        }
+        atlasEndDef1.setType(atlasTypeName1);
+        LOG.debug("Atlas end1 is {}", atlasEndDef1);
+
+
+        atlasEndDef1.setIsLegacyAttribute(false);
+
+        /* Cardinality
+         * Cardinality is mapped from OM to Atlas Cardinality { SINGLE, LIST, SET }.
+         * An OM relationship end def has cardinality always interpreted in the 'optional' sense, so that
+         * the relationship ends are 0..1 or 0..* - allowing us to create a relationship instance between a pair of entity
+         * instances as a one-to-many, many-to-one, many-to-many.
+         */
+        RelationshipEndCardinality omEndDef1Card = omEndDef2.getAttributeCardinality(); // attribute cardinality deliberately transposed as commented above
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasEndDef1Card;
+        switch (omEndDef1Card) {
+
+            case AT_MOST_ONE:
+                atlasEndDef1Card = SINGLE;
+                break;
+
+            case ANY_NUMBER:
+                atlasEndDef1Card = SET;
+                break;
+
+            default:
+                /* Any other cardinality is unexpected - all OM RelationshipDefs are associations with optional, unordered ends.
+                 * There is no sensible way to proceed here.
+                 */
+                 LOG.error("convertOMRelationshipDef: OM cardinality {} not valid for relationship end def 1 in relationship def {}", omEndDef1Card, omRelationshipDef.getName());
+
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(omRelationshipDef.getName(), omRelationshipDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omRelationshipDef.toString());
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "convertOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+        atlasEndDef1.setCardinality(atlasEndDef1Card);
+        atlasRelationshipDef.setEndDef1(atlasEndDef1);
+
+        /* Process END2
+         * Note that hen converting from Atlas to OM or vice versa, the attribute name and cardinality needs to be switched
+         * from one end to the other.
+         */
+
+        AtlasRelationshipEndDef atlasEndDef2 = new AtlasRelationshipEndDef();
+        atlasEndDef2.setName(omEndDef1.getAttributeName());     // attribute names are deliberately transposed as commented above
+        atlasEndDef2.setDescription(attributeDescription1);     // attribute descriptions are deliberately transposed as above
+        // Ends with entity types in famous five need to be converted...
+        String omTypeName2 = omTDL2.getName();
+        String omTypeGUID2 = omTDL2.getGUID();
+        String atlasTypeName2 = omTypeName2;
+        if (FamousFive.omTypeRequiresSubstitution(omTypeName2)) {
+            atlasTypeName2 = FamousFive.getAtlasTypeName(omTypeName2, omTypeGUID2);
+        }
+        atlasEndDef2.setType(atlasTypeName2);
+        atlasEndDef2.setDescription(omEndDef2.getAttributeDescription());
+        atlasEndDef2.setIsLegacyAttribute(false);
+
+        /* Cardinality
+         * Cardinality is mapped from OM to Atlas Cardinality { SINGLE, LIST, SET }.
+         * An OM relationship end def has cardinality always interpreted in the 'optional' sense, so that
+         * the relationship ends are 0..1 or 0..* - allowing us to create a relationship instance between a pair of entity
+         * instances as a one-to-many, many-to-one, many-to-many.
+         */
+        RelationshipEndCardinality omEndDef2Card = omEndDef1.getAttributeCardinality();  // attribute cardinality deliberately transposed as commented a
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasEndDef2Card;
+        switch (omEndDef2Card) {
+            case AT_MOST_ONE:
+                atlasEndDef2Card = SINGLE;
+                break;
+
+            case ANY_NUMBER:
+                atlasEndDef2Card = SET;
+                break;
+
+            default:
+                /* Any other cardinality is unexpected - all OM RelationshipDefs are associations with optional, unordered ends.
+                 * There is no sensible way to proceed here.
+                 */
+                LOG.error("convertOMRelationshipDef: OM cardinality {} not valid for relationship end def 2 in relationship def {}", omEndDef2Card, omRelationshipDef.getName());
+
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage( omRelationshipDef.getName(), omRelationshipDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omRelationshipDef.toString());
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "convertOMRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+        atlasEndDef2.setCardinality(atlasEndDef2Card);
+        atlasRelationshipDef.setEndDef2(atlasEndDef2);
+
+        /* If in future OM RelationshipDef supports COMPOSITION and/or AGGREGATION, then set the container end.
+         * Whilst only ASSOCIATION is supported, neither end is a container.
+         */
+         //RelationshipContainerEnd omRCE = omRelationshipDef.getRelationshipContainerEnd();
+         //switch (omRCE) {
+         //   case END1:
+         //       atlasEndDef1.setIsContainer(true);
+         //       break;
+         //   case END2:
+         //       atlasEndDef2.setIsContainer(true);
+         //       break;
+         //   default:
+         //       LOG.debug("Cannot convert OM RelationshipContainerEnd {} to Atlas value", omRCE);
+         //       break;
+         //}
+        /*
+         * For now a RelationshipDef is always an ASSOCIATION, so neither end is a container
+         */
+        atlasEndDef1.setIsContainer(false);
+        atlasEndDef2.setIsContainer(false);
+
+        /* Set Atlas Attribute defs
+         * OMRS ArrayList<TypeDefAttribute> --> Atlas List<AtlasAttributeDef>
+         * Retrieve the OM RelationshipDef attributes:
+         */
+        List<TypeDefAttribute> omAttrs = omRelationshipDef.getPropertiesDefinition();
+        ArrayList<AtlasStructDef.AtlasAttributeDef> atlasAttrs = convertOMAttributeDefs(omAttrs);
+        atlasRelationshipDef.setAttributeDefs(atlasAttrs);
+
+        /*
+         * Return the AtlasRelationshipDef
+         */
+        LOG.debug("AtlasRelationshipDef is {}", atlasRelationshipDef);
+        return atlasRelationshipDef;
+    }
+
+
+    /*
+     * Parse the OM ClassificationDef and create an AtlasClassificationDef
+     * @param omClassificationDef - the OM classification def to convert
+     * @return - the Atlas classification def
+     */
+    private AtlasClassificationDef convertOMClassificationDefToAtlasClassificationDef(ClassificationDef omClassificationDef) {
+
+
+        LOG.debug("convertOMClassificationDef: OM ClassificationDef {}", omClassificationDef);
+
+        if (omClassificationDef == null) {
+            return null;
+        }
+
+        /*
+         * OM ClassificationDef                                             AtlasClassificationDef
+         * --------------------                                             ----------------------
+         * ArrayList<TypeDefLink>               validEntityDefs          -> entityTypes
+         * . boolean                            propagatable             -> IGNORED
+         * TypeDefLink                          superType                -> superTypes
+         * . String                             description              -> description
+         * . String                             descriptionGUID          -> IGNORED
+         * . String                             origin                   -> IGNORED
+         * . String                             createdBy                -> createdBy
+         * . String                             updatedBy                -> updatedBy
+         * . Date                               createTime               -> createTime
+         * . Date                               updateTime               -> updateTime
+         * . Map<String, String>                options                  -> options
+         * . ArrayList<ExternalStandardMapping> externalStandardMappings -> IGNORED
+         * . ArrayList<InstanceStatus>          validInstanceStatusList  -> IGNORED
+         * . InstanceStatus                     initialStatus            -> IGNORED
+         * . ArrayList<TypeDefAttribute>        propertiesDefinition     -> attributeDefs
+         * . Long                               version                  -> version
+         * . String                             versionName              -> typeVersion
+         * . TypeDefCategory                    category                 -> NOT NEEDED Atlas Cat set by CTOR
+         * . String                             uid                      -> guid
+         * . String                             name                     -> name
+         *
+         */
+
+        // Convert OM type into a valid Atlas type
+
+        // Allocate AtlasClassificationDef, which will set TypeCategory automatically
+        AtlasClassificationDef atlasClassificationDef = new AtlasClassificationDef();
+
+        // Set common fields
+        atlasClassificationDef.setGuid(omClassificationDef.getGUID());
+        atlasClassificationDef.setName(omClassificationDef.getName());
+        atlasClassificationDef.setDescription(omClassificationDef.getDescription());
+        atlasClassificationDef.setVersion(omClassificationDef.getVersion());
+        atlasClassificationDef.setTypeVersion(omClassificationDef.getVersionName());
+        atlasClassificationDef.setCreatedBy(omClassificationDef.getCreatedBy());
+        atlasClassificationDef.setUpdatedBy(omClassificationDef.getUpdatedBy());
+        atlasClassificationDef.setCreateTime(omClassificationDef.getCreateTime());
+        atlasClassificationDef.setUpdateTime(omClassificationDef.getUpdateTime());
+        atlasClassificationDef.setOptions(omClassificationDef.getOptions());
+
+        // Handle fields that require conversion - i.e. supertypes and validEntityDefs
+
+        // Set the (at most one) superType
+        // Note that there is no error or existence checking on this
+        TypeDefLink omSuperType = omClassificationDef.getSuperType();
+        atlasClassificationDef.setSuperTypes(null);
+        if (omSuperType != null) {
+            String atlasSuperType = omSuperType.getName();
+            Set<String> atlasSuperTypes = new HashSet<>();
+            atlasSuperTypes.add(atlasSuperType);
+            atlasClassificationDef.setSuperTypes(atlasSuperTypes);
+        }
+
+        // Set the validEntityDefs
+        // For each TypeDefLink in the OM list of VEDs, extract the name into a Set<String> for Atlas.
+        // Note that there is no error or existence checking on this
+        List<TypeDefLink> omVEDs = omClassificationDef.getValidEntityDefs();
+        Set<String> atlasEntityTypes = null;
+        if (omVEDs != null) {
+            atlasEntityTypes = new HashSet<>();
+            for (TypeDefLink tdl : omVEDs) {
+                LOG.debug("convertOMClassificationDef: process OM VED {}", tdl.getName());
+                String omEntityTypeName = tdl.getName();
+                String omEntityTypeGUID = tdl.getGUID();
+                String atlasEntityTypeName = omEntityTypeName;
+                if (FamousFive.omTypeRequiresSubstitution(omEntityTypeName)) {
+                    atlasEntityTypeName = FamousFive.getAtlasTypeName(omEntityTypeName, omEntityTypeGUID);
+                    LOG.debug("convertOMClassificationDef: substituted type name {}", atlasEntityTypeName);
+                }
+                atlasEntityTypes.add(atlasEntityTypeName);
+            }
+        }
+        atlasClassificationDef.setEntityTypes(atlasEntityTypes);
+
+        // Set Atlas Attribute defs
+        List<TypeDefAttribute> omAttrs = omClassificationDef.getPropertiesDefinition();
+        ArrayList<AtlasStructDef.AtlasAttributeDef> atlasAttrs = convertOMAttributeDefs(omAttrs);
+        atlasClassificationDef.setAttributeDefs(atlasAttrs);
+
+        // Return the AtlasClassificationDef
+        return atlasClassificationDef;
+    }
+
+
+    // Accept an AtlasTypesDef and populate the typeDefsForAPI so it contains all OM defs corresponding to
+    // defs encountered in the AtlasTypesDef
+    //
+    private void convertAtlasTypeDefs(String        userId,
+                                      AtlasTypesDef atd)
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> convertAtlasTypeDefs(userId={}, atd={}", userId, atd);
+        }
+
+        if (atd == null) {
+            return;
+        }
+
+        // This method could walk the AtlasTypesDef in any order because discovered defs are marshalled
+        // by the typeDefsForAPI and converted into desired output order later. In order to allow the
+        // connector to discover dependencies before they are required, use the following order:
+        //
+        // i.e. enums -> entities -> relationships -> classifications ( structs are ignored )
+        //
+        // For example a classificationDef may refer to an entityDef in its list of validEntityDefs.
+        //
+        // Each category method will handle all the typedefs it can - i.e. all those that result in valid
+        // OM typedefs. Not all Atlas type defs can be modelled - e.g. an Atlas def could have multiple
+        // superTypes. Any problems with conversion of the AtlasTypeDefs are handled internally by the individual
+        // parsing methods, and each method returns a list of the OM defs it could
+        // generate from the given AtlasTypeDefs.
+
+        // Process enums
+        List<AtlasEnumDef> enumDefs = atd.getEnumDefs();
+        processAtlasEnumDefs(enumDefs);
+        LOG.debug("convertAtlasTypeDefs: process enums returned {}", typeDefsForAPI.getEnumDefs());
+
+        // Process entities
+        List<AtlasEntityDef> entityDefs = atd.getEntityDefs();
+        processAtlasEntityDefs(userId, entityDefs);
+        LOG.debug("convertAtlasTypeDefs: process entities returned {}", typeDefsForAPI.getEntityDefs());
+
+        // Process relationships
+        List<AtlasRelationshipDef> relationshipDefs = atd.getRelationshipDefs();
+        processAtlasRelationshipDefs(userId, relationshipDefs);
+        LOG.debug("convertAtlasTypeDefs: process relationships returned {}", typeDefsForAPI.getRelationshipDefs());
+
+        // Process classifications
+        List<AtlasClassificationDef> classificationDefs = atd.getClassificationDefs();
+        processAtlasClassificationDefs(userId, classificationDefs);
+        LOG.debug("convertAtlasTypeDefs: process classifications returned {}", typeDefsForAPI.getClassificationDefs());
+
+        // Structs are explicitly ignored
+
+        //LOG.debug("convertAtlasTypeDefs: complete, typeDefsForAPI {}", typeDefsForAPI);
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== convertAtlasTypeDefs(atd={}", atd);
+        }
+
+    }
+
+
+    // Convert a list of AtlasEnumDef to a typeDefsForAPI; each convertible typedef is added to the typeDefsForAPI member variable.
+    //
+    private void processAtlasEnumDefs(List<AtlasEnumDef> atlasEnumDefs) {
+
+        if (atlasEnumDefs != null) {
+            for (AtlasEnumDef atlasEnumDef : atlasEnumDefs) {
+                try {
+                    processAtlasEnumDef(atlasEnumDef);
+                } catch (TypeErrorException e) {
+                    LOG.error("processAtlasEnumDefs: gave up on AtlasEnumDef {}", atlasEnumDef.getName(), e);
+                    // swallow the exception to proceed with the next type...
+                }
+            }
+        }
+    }
+
+
+
+    // Convert a list of AtlasEntityDef saving each into the typeDefsForAPI
+    //
+    private void processAtlasEntityDefs(String               userId,
+                                        List<AtlasEntityDef> atlasEntityDefs)
+    {
+
+        if (atlasEntityDefs != null) {
+            for (AtlasEntityDef atlasEntityDef : atlasEntityDefs) {
+                try {
+                    processAtlasEntityDef(userId, atlasEntityDef);
+                }
+                catch (TypeErrorException | RepositoryErrorException e) {
+                    LOG.error("processAtlasEntityDefs: gave up on AtlasEntityDef {}",atlasEntityDef.getName(), e);
+                    // swallow the exception to proceed with the next type...
+                }
+            }
+        }
+    }
+
+    // Convert a list of AtlasClassificationDef to a typeDefsForAPI
+    //
+    private void processAtlasClassificationDefs(String                       userId,
+                                                List<AtlasClassificationDef> atlasClassificationDefs) {
+
+        if (atlasClassificationDefs != null) {
+            for (AtlasClassificationDef atlasClassificationDef : atlasClassificationDefs) {
+                try {
+                    processAtlasClassificationDef(userId, atlasClassificationDef);
+                }
+                catch (TypeErrorException | RepositoryErrorException e) {
+                    LOG.error("processAtlasClassificationDefs: gave up on AtlasClassificationDef {}",atlasClassificationDef.getName(), e);
+                    // swallow the exception to proceed with the next type...
+                }
+
+            }
+        }
+    }
+
+
+
+    // Convert a list of AtlasRelationshipDef to a typeDefsForAPI
+    //
+    private void processAtlasRelationshipDefs(String                     userId,
+                                              List<AtlasRelationshipDef> atlasRelationshipDefs) {
+
+        if (atlasRelationshipDefs != null) {
+            for (AtlasRelationshipDef atlasRelationshipDef : atlasRelationshipDefs) {
+                try {
+                    processAtlasRelationshipDef(userId, atlasRelationshipDef);
+                }
+                catch (TypeErrorException | RepositoryErrorException e) {
+                    LOG.error("processAtlasRelationshipDefs: gave up on AtlasRelationshipDef {}", atlasRelationshipDef.getName(), e);
+                    // swallow the exception to proceed with the next type...
+                }
+
+            }
+        }
+    }
+
+
+
+
+    // Convert an AtlasEnumDef to an OM EnumDef
+    //
+    // 1. Convert the AtlasEnumDef into the corresponding OM EnumDef and (implicitly) validate the content of the OM EnumDef
+    // 2. Query RCM to find whether it knows of an EnumDef with the same name:
+    //    a. If exists, retrieve the known typedef from RCM and deep compare the known and new EnumDefs.
+    //       i.  If same use the existing type's GUID; add def to TypeDefGallery;
+    //       ii. If different fail (audit log)
+    //    b. If not exists (in RCM), generate a GUID and add to TypeDefGallery.
+    //
+    // Error handling: If at any point we decide not to proceed with the conversion of this EnumDef, we must log
+    // the details of the error condition and return to the caller without having added the OM EnumDef to typeDefsForAPI.
+    //
+    // package private
+    void processAtlasEnumDef(AtlasEnumDef atlasEnumDef)
+            throws
+            TypeErrorException
+    {
+
+        final String methodName = "processAtlasEnumDef";
+
+        LOG.debug("processAtlasEnumDef: convert AtlasEnumDef {}", atlasEnumDef);
+
+        if (atlasEnumDef == null) {
+            return;
+        }
+
+        String typeName = atlasEnumDef.getName();
+
+        // 1. Convert Atlas type into a valid OM type
+
+        // Allocate OMRS EnumDef, which will set AttributeTypeDefCategory automatically
+        EnumDef omrsEnumDef = new EnumDef();
+
+        // Set common fields
+        omrsEnumDef.setGUID(atlasEnumDef.getGuid());
+        omrsEnumDef.setName(atlasEnumDef.getName());
+        omrsEnumDef.setDescription(atlasEnumDef.getDescription());
+        // DescriptionGUID is set below iff this is a new typedef.
+
+        // Additional fields on an AtlasEnumDef and OM EnumDef are elementDefs and defaultValue
+        // Initialize the Atlas and OMRS default values so we can test and set default value in the loop
+        String atlasDefaultValue = atlasEnumDef.getDefaultValue();
+        EnumElementDef omrsDefaultValue = null;
+
+        List<AtlasEnumDef.AtlasEnumElementDef> atlasElemDefs = atlasEnumDef.getElementDefs();
+        ArrayList<EnumElementDef> omrsElementDefs = null;
+        if (atlasElemDefs != null) {
+            omrsElementDefs = new ArrayList<>();
+            for (AtlasEnumDef.AtlasEnumElementDef atlasElementDef : atlasElemDefs) {
+                EnumElementDef omrsEnumElementDef = new EnumElementDef();
+                omrsEnumElementDef.setValue(atlasElementDef.getValue());
+                omrsEnumElementDef.setDescription(atlasElementDef.getDescription());
+                omrsEnumElementDef.setOrdinal(atlasElementDef.getOrdinal());
+                omrsElementDefs.add(omrsEnumElementDef);
+                if (atlasElementDef.getValue().equals(atlasDefaultValue)) {
+                    omrsDefaultValue = omrsEnumElementDef;
+                }
+            }
+        }
+        omrsEnumDef.setElementDefs(omrsElementDefs);
+        omrsEnumDef.setDefaultValue(omrsDefaultValue);
+
+        // 2. Query RepositoryContentManager to find whether it knows of an EnumDef with the same name
+        // If the type already exists (by name) perform a deep compare.
+        // If there is no existing type (with this name) or there is an exact (deep) match we can publish the type
+        // If there is an existing type that does not deep match exactly then we cannot publish the type.
+
+        // Ask RepositoryContentManager whether there is an EnumDef with same name as typeName
+        String source = metadataCollectionId;
+        AttributeTypeDef existingAttributeTypeDef;
+        try {
+            existingAttributeTypeDef = repositoryHelper.getAttributeTypeDefByName(source, typeName);
+
+        } catch (OMRSLogicErrorException e) {
+            // Fail the conversion - this can be achieved by simply returning before completion
+            LOG.error("processAtlasEnumDef: caught exception from RepositoryHelper", e);
+            return;
+        }
+
+        if (existingAttributeTypeDef == null) {
+            LOG.debug("processAtlasEnumDef: repository content manager returned name not found - proceed to publish");
+            // Use the candidate attribute type def
+            // Check (by name) whether we have already added one to current TDBC - e.g. if there are
+            // multiple attributes of the same type - they should refer to the same ATD in TDBC.
+
+            // No existing ATD was found in RH.
+            // If it does not already exist add the new ATD to the ATDs in the TypeDefGallery and use it in TDA.
+            // If there is already a TDBC copy of the ATD then use that - avoid duplication.
+            EnumDef tdbcCopy = typeDefsForAPI.getEnumDef(omrsEnumDef.getName());
+            if (tdbcCopy != null)
+                omrsEnumDef = tdbcCopy;
+            // Add the OM typedef to TDBC - this will get it into the TypeDefGallery
+            typeDefsForAPI.addEnumDef(omrsEnumDef);
+            // In future may want to generate a descriptionGUID here, but for now these are not used
+            omrsEnumDef.setDescriptionGUID(null);
+
+        } else {
+
+            LOG.debug("processAtlasEnumDef: repositoryHelper has an AttributeTypeDef with name {} : {}", typeName, existingAttributeTypeDef);
+            if (existingAttributeTypeDef.getCategory() == ENUM_DEF) {
+                // LOG.debug("processAtlasEnumDef: existing AttributeTypeDef has category {} ", existingAttributeTypeDef.getCategory());
+                // There is an EnumDef with this name - perform deep compare and only publish if exact match
+                // Perform a deep compare of the known type and new type
+                Comparator comp = new Comparator();
+                EnumDef existingEnumDef = (EnumDef) existingAttributeTypeDef;
+                boolean typematch = comp.compare(existingEnumDef, omrsEnumDef);
+                // If compare matches then we can proceed to publish the def
+                if (typematch) {
+                    // There is exact match in the ReposHelper - we will add that to our TypeDefGallery
+                    omrsEnumDef = existingEnumDef;
+                    // Add the OM typedef to TDBC - this will get it into the TypeDefGallery
+                    typeDefsForAPI.addEnumDef(omrsEnumDef);
+                } else {
+                    // If compare failed abandon processing of this EnumDef
+                    LOG.debug("processAtlasEnumDef: existing AttributeTypeDef did not match");
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(typeName, omrsEnumDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omrsEnumDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "processAtlasEnumDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+
+            } else {
+                // There is a type of this name but it is not an EnumDef - fail!
+                LOG.debug("processAtlasEnumDef: existing AttributeTypeDef not an EnumDef - has category {} ", existingAttributeTypeDef.getCategory());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(typeName, omrsEnumDef.getGUID(), "omRelationshipDef", methodName, repositoryName, omrsEnumDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "processAtlasEnumDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+
+    }
+
+
+    // Convert an AtlasClassificationDef to an OMRS ClassificationDef
+    //
+    // 1. Convert the AtlasClassificationDef into the corresponding OM ClassificationDef and (implicitly) validate the content of the OM ClassificationDef
+    // 2. Query RCM to find whether it knows of an ClassificationDef with the same name:
+    //    a. If exists, retrieve the known typedef from RCM and deep compare the known and new ClassificationDefs.
+    //       i.  If same use the existing type's GUID; add def to TypeDefGallery;
+    //       ii. If different fail (audit log)
+    //    b. If not exists (in RCM), generate a GUID and add to TypeDefGallery.
+    //
+    // Error handling: If at any point we decide not to proceed with the conversion of this ClassificationDef, we must log
+    // the details of the error condition and return to the caller without having added the omrsClassificationDef to typeDefsForAPI.
+    //
+    private void processAtlasClassificationDef(String                 userId,
+                                               AtlasClassificationDef atlasClassificationDef)
+        throws
+            TypeErrorException,
+            RepositoryErrorException
+    {
+
+        final String methodName = "processAtlasClassificationDef";
+
+        LOG.debug("processAtlasClassificationDef: AtlasClassificationDef {}", atlasClassificationDef);
+
+        String typeName = atlasClassificationDef.getName();
+
+        // Create an AtlasClassificationDefMapper to convert to an OM ClassificationDef, then invoke the RH to verify
+        // whether a type with the same name is already known, and if it compares.
+        // Finally add the ClassificationDef to the TDBC typeDefsForAPI.
+
+        ClassificationDef classificationDef;
+        AtlasClassificationDefMapper atlasClassificationDefMapper;
+        try {
+            atlasClassificationDefMapper = new AtlasClassificationDefMapper(this, userId, atlasClassificationDef);
+            classificationDef = atlasClassificationDefMapper.toOMClassificationDef();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("processAtlasClassificationDef: could not initialise mapper", e);
+            throw e;
+        }
+        catch (TypeErrorException e) {
+            LOG.error("processAtlasClassificationDef: could not convert AtlasEntityDef {} to OM EntityDef", typeName, e);
+            throw e;
+        }
+
+        if (classificationDef == null) {
+            LOG.error("processAtlasClassificationDef: could not convert AtlasClassificationDef {} to OM ClassificationDef", typeName);
+            return;
+        }
+
+        LOG.debug("processAtlasClassificationDef: AtlasClassificationDef mapped to OM ClassificationDef {}", classificationDef);
+
+        // Query RepositoryContentManager to find whether it knows of a TypeDef with the same name
+        // If the type already exists (by name) perform a deep compare.
+        // If there is no existing type (with this name) or there is an exact (deep) match we can publish the type
+        // If there is an existing type that does not deep match exactly then we cannot publish the type.
+
+        // Error handling:
+        // If at any point we decide not to proceed with the conversion of this ClassificationDef, we must log
+        // the details of the error condition and return to the caller without having added the omrsClassificationDef to typeDefsForAPI.
+
+        // Ask RepositoryContentManager whether there is a known TypeDef with same name
+        String source = metadataCollectionId;
+        TypeDef existingTypeDef;
+        try {
+            existingTypeDef = repositoryHelper.getTypeDefByName(source, typeName);
+        } catch (OMRSLogicErrorException e) {
+            // Fail the conversion by returning without adding the type def to the TDBC
+            LOG.error("processAtlasClassificationDef: caught exception from RepositoryHelper", e);
+            return;
+        }
+
+        if (existingTypeDef == null) {
+            LOG.debug("processAtlasClassificationDef: repository content manager returned name not found - proceed to publish");
+            // In future may want to generate a descriptionGUID, but for now these are not used
+            classificationDef.setDescriptionGUID(null);
+        }
+        else {
+            LOG.debug("processAtlasClassificationDef: there is a TypeDef with name {} : {}", typeName, existingTypeDef);
+
+            if (existingTypeDef.getCategory() == CLASSIFICATION_DEF) {
+                LOG.debug("processAtlasClassificationDef: existing TypeDef has category {} ", existingTypeDef.getCategory());
+                // There is a ClassificationDef with this name - perform deep compare and only publish if exact match
+                // Perform a deep compare of the known type and new type
+                Comparator comp = new Comparator();
+                ClassificationDef existingClassificationDef = (ClassificationDef) existingTypeDef;
+                boolean typematch = comp.equivalent(existingClassificationDef, classificationDef);
+                // If compare matches use the known type
+                if (typematch) {
+                    // We will add the typedef to the TypeDefGallery
+                    LOG.debug("processAtlasClassificationDef: repository content manager found matching def with name {}", typeName);
+                    classificationDef = existingClassificationDef;
+                }
+                else {
+                    // If compare failed abandon processing of this ClassificationDef
+                    LOG.debug("processAtlasClassificationDef: existing TypeDef did not match");
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(classificationDef.getName(), classificationDef.getGUID(), "classificationDef", methodName, repositoryName, classificationDef.toString());
+
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "processAtlasClassificationDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+            else {
+                // There is a type of this name but it is not a ClassificationDef - fail!
+                LOG.debug("processAtlasClassificationDef: existing TypeDef not a ClassificationDef - has category {} ", existingTypeDef.getCategory());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(classificationDef.getName(), classificationDef.getGUID(), "classificationDef", methodName, repositoryName, classificationDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "processAtlasClassificationDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+
+        }
+
+        // If we reached this point then we are good to go
+        // Add the OM typedef to discoveredTypeDefs - this will get it into the TypeDefGallery
+        LOG.debug("convertClassificationDef: OMRS ClassificationDef {}", classificationDef);
+        // Add the OM typedef to TDBC - this will ultimately get it into the TypeDefGallery
+        typeDefsForAPI.addClassificationDef(classificationDef);
+
+    }
+
+
+
+
+
+    private void processAtlasEntityDef(String userId, AtlasEntityDef atlasEntityDef)
+            throws TypeErrorException, RepositoryErrorException
+    {
+
+        final String methodName = "processAtlasEntityDef";
+
+        // Create an AtlasEntityDefMapper to convert to an OM EntityDef, then invoke the RH to verify
+        // whether a type with the same name is already known, and if it compares.
+        // Finally add the EntityDef to the TDBC typeDefsForAPI.
+
+        String typeName = atlasEntityDef.getName();
+
+        // Famous Five
+        // Here we need to ensure that we do not process an Atlas Famous Five type
+        // This may look odd because we use the omXX query method - this is because we need to to know whether,
+        // if the Atlas type name were an OM type name, would it have been substituted?
+        if (FamousFive.omTypeRequiresSubstitution(typeName)) {
+            LOG.debug("processAtlasEntityDef: skip type {}", typeName);
+            return;
+        }
+
+        AtlasEntityDefMapper atlasEntityDefMapper;
+        EntityDef entityDef;
+        try {
+            atlasEntityDefMapper = new AtlasEntityDefMapper(this, userId, atlasEntityDef);
+            entityDef = atlasEntityDefMapper.toOMEntityDef();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("processAtlasEntityDef: could not initialize mapper", e);
+            throw e;
+        }
+        catch (TypeErrorException e) {
+            LOG.error("processAtlasEntityDef: could not convert AtlasEntityDef {} to OM EntityDef", typeName, e);
+            throw e;
+        }
+
+        if (entityDef == null) {
+            LOG.error("processAtlasEntityDef: no OM EntityDef for type {}", typeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("entityDef", "load", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "processAtlasEntityDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        LOG.debug("processAtlasEntityDef: AtlasEntityDef mapped to OM EntityDef {}", entityDef);
+
+        // Query RepositoryContentManager to find whether it knows of a TypeDef with the same name
+        // If the type already exists (by name) perform a deep compare.
+        // If there is no existing type (with this name) or there is an exact (deep) match we can publish the type
+        // If there is an existing type that does not deep match exactly then we cannot publish the type.
+        //
+        // Error handling:
+        // If at any point we decide not to proceed with the conversion of this EntityDef, we must log
+        // the details of the error condition and return to the caller without having added the omEntityDef to typeDefsForAPI.
+
+        // Ask RepositoryContentManager whether there is a known TypeDef with same name
+        String source = metadataCollectionId;
+        TypeDef existingTypeDef;
+        try {
+            existingTypeDef = repositoryHelper.getTypeDefByName(source, entityDef.getName());
+        } catch (OMRSLogicErrorException e) {
+            // Fail the conversion by returning without adding the type def to the TDBC
+            LOG.error("processAtlasEntityDef: caught exception from RepositoryHelper", e);
+            return;
+        }
+
+        if (existingTypeDef == null) {
+            LOG.debug("processAtlasEntityDef: repository content manager returned name not found - proceed to publish");
+            // In future may want to generate a descriptionGUID, but for now these are not used
+            entityDef.setDescriptionGUID(null);
+        }
+        else {
+            LOG.debug("processAtlasEntityDef: there is a TypeDef with name {} : {}", entityDef.getName(), existingTypeDef);
+
+            if (existingTypeDef.getCategory() == ENTITY_DEF) {
+                LOG.debug("processAtlasEntityDef: existing TypeDef has category {} ", existingTypeDef.getCategory());
+                // There is a EntityDef with this name - perform deep compare and only publish if exact match
+                // Perform a deep compare of the known type and new type
+                Comparator comp = new Comparator();
+                EntityDef existingEntityDef = (EntityDef) existingTypeDef;
+                boolean typematch = comp.equivalent(existingEntityDef, entityDef);
+                // If compare matches use the known type
+                if (typematch) {
+                    // We will add the typedef to the TypeDefGallery
+                    LOG.debug("processAtlasEntityDef: repository content manager found matching def with name {}", entityDef.getName());
+                    entityDef = existingEntityDef;
+                }
+                else {
+                    // If compare failed abandon processing of this EntityDef
+                    LOG.debug("processAtlasEntityDef: existing TypeDef did not match");
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage( entityDef.getName(), entityDef.getGUID(), "atlasEntityDef", methodName, repositoryName, entityDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "processAtlasEntityDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+            else {
+                // There is a type of this name but it is not an EntityDef - fail!
+                LOG.debug("processAtlasEntityDef: existing TypeDef not an EntityDef - has category {} ", existingTypeDef.getCategory());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage( entityDef.getName(), entityDef.getGUID(), "atlasEntityDef", methodName, repositoryName, entityDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "processAtlasEntityDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        // Add the OM typedef to TDBC - this will ultimately get it into the TypeDefGallery
+        typeDefsForAPI.addEntityDef(entityDef);
+
+    }
+
+
+    private void processAtlasRelationshipDef(String userId, AtlasRelationshipDef atlasRelationshipDef)
+            throws TypeErrorException, RepositoryErrorException
+    {
+
+        final String methodName = "processAtlasRelationshipDef";
+
+        // Create an AtlasRelationshipDefMapper to convert to an OM RelationshipDef, then invoke the RH to verify
+        // whether a type with the same name is already known, and if it compares.
+        // Finally add the EntityDef to the TDBC typeDefsForAPI.
+
+        String typeName = atlasRelationshipDef.getName();
+
+        RelationshipDef relationshipDef;
+        try {
+            AtlasRelationshipDefMapper atlasRelationshipDefMapper = new AtlasRelationshipDefMapper(this, userId, atlasRelationshipDef);
+            relationshipDef = atlasRelationshipDefMapper.toOMRelationshipDef();
+        }
+        catch (RepositoryErrorException e) {
+            LOG.error("processAtlasClassificationDef: could not initialize mapper", e);
+            throw e;
+        }
+        catch (TypeErrorException e) {
+            LOG.error("processAtlasClassificationDef: could not convert AtlasEntityDef {} to OM EntityDef", typeName, e);
+            throw e;
+        }
+
+        if (relationshipDef == null) {
+            LOG.error("processAtlasRelationshipDef: could not convert AtlasRelationshipDef {} to OM RelationshipDef", typeName);
+            return;
+        }
+
+        LOG.debug("processAtlasRelationshipDef: AtlasRelationshipDef mapped to OM EntityDef {}", relationshipDef);
+
+
+        // Query RepositoryContentManager to find whether it knows of a RelationshipDef with the same name
+        // If the type already exists (by name) perform a deep compare.
+        // If there is no existing type (with this name) or there is an exact (deep) match we can publish the type
+        // If there is an existing type that does not deep match exactly then we cannot publish the type.
+
+        // Ask RepositoryContentManager whether there is a RelationshipDef with same name as typeName
+
+        String source = metadataCollectionId;
+        TypeDef existingTypeDef;
+        try {
+            existingTypeDef = repositoryHelper.getTypeDefByName(source, typeName);
+        } catch (OMRSLogicErrorException e) {
+            // Fail the conversion by returning without adding the def to the TypeDefGallery
+            LOG.error("processAtlasRelationshipDef: caught exception from RepositoryHelper", e);
+            return;
+        }
+        if (existingTypeDef == null) {
+            LOG.debug("processAtlasRelationshipDef: repository content manager returned name not found - proceed to publish");
+            // In future may want to generate a descriptionGUID, but for now these are not used
+            relationshipDef.setDescriptionGUID(null);
+        } else {
+            LOG.debug("processAtlasRelationshipDef: there is a TypeDef with name {} : {}", typeName, existingTypeDef);
+
+            if (existingTypeDef.getCategory() == RELATIONSHIP_DEF) {
+                // There is a RelationshipDef with this name - perform deep compare and only publish if exact match
+                // Perform a deep compare of the known type and new type
+                Comparator comp = new Comparator();
+                RelationshipDef existingRelationshipDef = (RelationshipDef) existingTypeDef;
+                boolean typematch = comp.equivalent(existingRelationshipDef, relationshipDef);
+                // If compare matches use the known type
+                if (typematch) {
+                    // We will add the typedef to the TypeDefGallery
+                    LOG.debug("processAtlasRelationshipDef: repository content manager found matching def with name {}", typeName);
+                    relationshipDef = existingRelationshipDef;
+                } else {
+
+                    // If compare failed abandon processing of this RelationshipDef
+                    LOG.debug("processAtlasRelationshipDef: existing TypeDef did not match");
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage( relationshipDef.getName(), relationshipDef.getGUID(), "atlasRelationshipDef", methodName, repositoryName, relationshipDef.toString());
+
+                    throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            "processAtlasRelationshipDef",
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+            else {
+                // There is a type of this name but it is not a RelationshipDef - fail!
+                LOG.error("processAtlasRelationshipDef: existing TypeDef not an RelationshipDef - has category {} ", existingTypeDef.getCategory());
+                OMRSErrorCode errorCode = OMRSErrorCode.INVALID_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage( relationshipDef.getName(), relationshipDef.getGUID(), "atlasRelationshipDef", methodName, repositoryName, relationshipDef.toString());
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "processAtlasRelationshipDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+        }
+
+        // If we reached this point then we are good to go
+        // Add the OM typedef to discoveredTypeDefs - this will get it into the TypeDefGallery
+        LOG.debug("processAtlasRelationshipDef: OMRS RelationshipDef {}", relationshipDef);
+        typeDefsForAPI.addRelationshipDef(relationshipDef);
+
+    }
+
+
+
+
+
+    // Convert a List of OMRS TypeDefAttribute to a List of AtlasAttributeDef
+    private ArrayList<AtlasStructDef.AtlasAttributeDef> convertOMAttributeDefs(List<TypeDefAttribute> omAttrs) {
+        ArrayList<AtlasStructDef.AtlasAttributeDef> atlasAttributes;
+        if (omAttrs == null || omAttrs.isEmpty()) {
+            return null;
+        }
+        else {
+            atlasAttributes = new ArrayList<>();
+
+            for (TypeDefAttribute tda : omAttrs) {
+                // Map from OMRS TypeDefAttribute to AtlasAttributeDef
+                AtlasStructDef.AtlasAttributeDef aad = convertOMAttributeDef(tda);
+                atlasAttributes.add(aad);
+            }
+        }
+        return atlasAttributes;
+
+    }
+
+
+
+
+    private AtlasStructDef.AtlasAttributeDef convertOMAttributeDef(TypeDefAttribute tda) {
+
+        // Convert OM TypeDefAttribute to AtlasAttributeDef
+        //
+
+        //
+        // The AttributeTypeDef attributeType has:
+        // AttributeTypeDefCategory category:
+        //   OM defines the following values { UNKNOWN_DEF | PRIMITIVE | COLLECTION | ENUM_DEF }
+        //   The corresponding Atlas TypeCategory in each case is:
+        //     [OM]               [Atlas]
+        //   UNKNOWN_DEF         error condition
+        //   PRIMITIVE           PRIMITIVE
+        //   COLLECTION          ARRAY or MAP - we can tell which by looking in the (subclass) CollectionDef CollectionDefCategory
+        //                                    - which will be one of:
+        //                                      OM_COLLECTION_UNKNOWN - treat as an error condition
+        //                                      OM_COLLECTION_MAP     - convert to Atlas MAP
+        //                                      OM_COLLECTION_ARRAY   - convert to Atlas ARRAY
+        //                                      OM_COLLECTION_STRUCT  - treat as an error condition
+        //   ENUM_DEF            ENUM
+        //   OM guid is ignored - there is no GUID on AtlasAttributeDef
+        //   OM name  -> used for AtlasAttributeDef.typeName
+        //
+        // The OM TypeDefAttribute has some fields that can be copied directly to the AtlasAttributeDef:
+        //    [OM]                      [Atlas]
+        // attributeName         ->   String name
+        // valuesMinCount        ->   int valuesMinCount
+        // valuesMaxCount        ->   int valuesMaxCount
+        // isIndexable           ->   boolean isIndexable
+        // isUnique              ->   boolean isUnique
+        // defaultValue          ->   String defaultValue
+        // attributeDescription  ->   String description
+        //
+        // OM attributeDescription --> AtlasAttributeDef.description
+        //
+        // Map OM Cardinality ----> combination of Atlas boolean isOptional & Cardinality cardinality  - use mapping function
+        //   OM                       ->    ATLAS
+        //   UNKNOWN                  ->    treat as an error condition
+        //   AT_MOST_ONE              ->    isOptional && SINGLE
+        //   ONE_ONLY                 ->    !isOptional && SINGLE
+        //   AT_LEAST_ONE_ORDERED     ->    !isOptional && LIST
+        //   AT_LEAST_ONE_UNORDERED   ->    !isOptional && SET
+        //   ANY_NUMBER_ORDERED       ->    isOptional && LIST
+        //   ANY_NUMBER_UNORDERED     ->    isOptional && SET
+
+        // There are no constraints in OM so no Atlas constraints are set  List<AtlasConstraintDef> null
+        // OM externalStandardMappings is ignored
+        //
+        LOG.debug("convertOMAttributeDef: OMAttributeDef is {}", tda);
+
+        if (tda == null) {
+            return null;
+        }
+
+        AtlasStructDef.AtlasAttributeDef aad = null;
+
+        // We need to set the Atlas aad depending on what category of OM typedef we are converting.
+        // If the OM def is a primitive or collection then there is no actual Atlas type to create;
+        // we are just looking to set the Atlas typeName to one of the primitive type names or to
+        // array<x> or map<x,y> as appropriate.
+        // If the OM def is an EnumDef then we need to create an AtlasEnumDef and set the typename to
+        // refer to it.
+        AttributeTypeDef atd = tda.getAttributeType();
+        AttributeTypeDefCategory category = atd.getCategory();
+        switch (category) {
+            case PRIMITIVE:
+                aad = convertOMPrimitiveDef(tda);
+                break;
+            case COLLECTION:
+                aad = convertOMCollectionDef(tda);
+                break;
+            case ENUM_DEF:
+                // This is handled by setting the typeName to that of an AtlasEnumDef
+                // created by an earlier call to addAttributeTypeDef. If this has not
+                // been done then it is valid to bounce this call as an error condition.
+                // OM has a TDA with an ATD that has an ATDCategory of ENUM_DEF
+                // We want an AAD that uses the typeName of the AtlasEnumDef set to the ATD.name
+                aad = convertOMEnumDefToAtlasAttributeDef(tda);
+                break;
+            case UNKNOWN_DEF:
+                LOG.debug("convertOMAttributeDef: cannot convert OM attribute type def with category {}", category);
+                break;
+        }
+
+        return aad;
+    }
+
+
+    private AtlasStructDef.AtlasAttributeDef convertOMPrimitiveDef(TypeDefAttribute tda) {
+
+
+        if (tda == null) {
+            return null;
+        }
+        AtlasStructDef.AtlasAttributeDef aad = new AtlasStructDef.AtlasAttributeDef();
+        aad.setName(tda.getAttributeName());
+        aad.setValuesMinCount(tda.getValuesMinCount());
+        aad.setValuesMaxCount(tda.getValuesMaxCount());
+        aad.setIsIndexable(tda.isIndexable());
+        aad.setIsUnique(tda.isUnique());
+        aad.setDefaultValue(tda.getDefaultValue());
+        aad.setDescription(tda.getAttributeDescription());
+        // Currently setting Atlas cardinality and optionality using a pair of method calls.
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality = convertOMCardinalityToAtlasCardinality(tda.getAttributeCardinality());
+        aad.setCardinality(atlasCardinality);
+        boolean atlasOptionality = convertOMCardinalityToAtlasOptionality(tda.getAttributeCardinality());
+        aad.setIsOptional(atlasOptionality);
+        aad.setConstraints(null);
+        AttributeTypeDef atd = tda.getAttributeType();
+        PrimitiveDef omPrimDef = (PrimitiveDef) atd;
+        PrimitiveDefCategory primDefCat = omPrimDef.getPrimitiveDefCategory();
+        aad.setTypeName(primDefCat.getName());
+        return aad;
+    }
+
+
+    private AtlasStructDef.AtlasAttributeDef convertOMCollectionDef(TypeDefAttribute tda) {
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==>convertOMAttributeDef: TypeDefAttribute {}", tda);
+        }
+        if (tda == null) {
+            return null;
+        }
+        AtlasStructDef.AtlasAttributeDef aad = new AtlasStructDef.AtlasAttributeDef();
+        aad.setName(tda.getAttributeName());
+        LOG.debug("==>convertOMAttributeDef: attribute name {}", tda.getAttributeName());
+        aad.setValuesMinCount(tda.getValuesMinCount());
+        aad.setValuesMaxCount(tda.getValuesMaxCount());
+        aad.setIsIndexable(tda.isIndexable());
+        aad.setIsUnique(tda.isUnique());
+        aad.setDefaultValue(tda.getDefaultValue());
+        aad.setDescription(tda.getAttributeDescription());
+        // Currently setting Atlas cardinality and optionality using a pair of method calls.
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality = convertOMCardinalityToAtlasCardinality(tda.getAttributeCardinality());
+        aad.setCardinality(atlasCardinality);
+        boolean atlasOptionality = convertOMCardinalityToAtlasOptionality(tda.getAttributeCardinality());
+        aad.setIsOptional(atlasOptionality);
+        aad.setConstraints(null);
+        AttributeTypeDef atd = tda.getAttributeType();
+        CollectionDef omCollDef = (CollectionDef) atd;
+        String collectionTypeName = omCollDef.getName();
+        LOG.debug("==>convertOMAttributeDef: collection type name {}",collectionTypeName);
+        CollectionDefCategory collDefCat = omCollDef.getCollectionDefCategory();
+        String atlasTypeName;
+        switch (collDefCat) {
+            case OM_COLLECTION_ARRAY:
+                String OM_ARRAY_PREFIX = "array<";
+                String OM_ARRAY_SUFFIX = ">";
+                int arrayStartIdx = OM_ARRAY_PREFIX.length();
+                int arrayEndIdx = collectionTypeName.length() - OM_ARRAY_SUFFIX.length();
+                String elementTypeName = collectionTypeName.substring(arrayStartIdx, arrayEndIdx);
+                LOG.debug("convertOMAttributeDef: handling an OM array of elements of type {}", elementTypeName);
+                atlasTypeName = ATLAS_TYPE_ARRAY_PREFIX + elementTypeName + ATLAS_TYPE_ARRAY_SUFFIX;
+                break;
+            case OM_COLLECTION_MAP:
+                String OM_MAP_PREFIX = "map<";
+                String OM_MAP_SUFFIX = ">";
+                int mapStartIdx = OM_MAP_PREFIX.length();
+                int mapEndIdx = collectionTypeName.length() - OM_MAP_SUFFIX.length();
+                String kvTypeString = collectionTypeName.substring(mapStartIdx, mapEndIdx);
+                String[] parts = kvTypeString.split(",");
+                String keyType = parts[0];
+                String valType = parts[1];
+                atlasTypeName = ATLAS_TYPE_MAP_PREFIX + keyType + ATLAS_TYPE_MAP_KEY_VAL_SEP + valType + ATLAS_TYPE_MAP_SUFFIX;
+                LOG.debug("convertOMAttributeDef: atlas type name is {}", atlasTypeName);
+                break;
+            default:
+                LOG.debug("convertOMCollectionDef: cannot convert a collection def with category {}", collDefCat);
+                return null;
+        }
+        aad.setTypeName(atlasTypeName);
+        return aad;
+    }
+
+    /*
+     * Utility functions to convert OM cardinality to Atlas cardinality and optionality
+     */
+
+    private AtlasStructDef.AtlasAttributeDef.Cardinality convertOMCardinalityToAtlasCardinality(AttributeCardinality omCard) {
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCard;
+        switch (omCard) {
+            case AT_MOST_ONE:
+            case ONE_ONLY:
+                atlasCard = SINGLE;
+                break;
+            case AT_LEAST_ONE_ORDERED:
+            case ANY_NUMBER_ORDERED:
+                atlasCard = LIST;
+                break;
+            case AT_LEAST_ONE_UNORDERED:
+            case ANY_NUMBER_UNORDERED:
+                atlasCard = SET;
+                break;
+            case UNKNOWN:
+            default:
+                LOG.info("convertOMCardinalityToAtlasCardinality: not specified by caller, defaulting to SINGLE");
+                // There is no 'good' choice for return code here but default to single...
+                atlasCard = SINGLE;
+                break;
+        }
+        return atlasCard;
+    }
+
+    private boolean convertOMCardinalityToAtlasOptionality(AttributeCardinality omCard) {
+        switch (omCard) {
+            case AT_MOST_ONE:
+            case ANY_NUMBER_ORDERED:
+            case ANY_NUMBER_UNORDERED:
+                return true;
+            case ONE_ONLY:
+            case AT_LEAST_ONE_ORDERED:
+            case AT_LEAST_ONE_UNORDERED:
+                return false;
+            case UNKNOWN:
+            default:
+                LOG.info("convertOMCardinalityToAtlasOptionality: not specified by caller, defaulting to TRUE");
+                // There is no 'good' choice for return code here - but default to optional
+                return true;
+        }
+    }
+
+    /**
+     * Method to convert an OM EnumDef into an AtlasAttributeDef - they are handled differently by the two type systems
+     * @param tda - the TypeDefAttribute to be converted
+     * @return    - AtlasStructDef resulting from conversion of the OM EnumDef
+     */
+    private AtlasStructDef.AtlasAttributeDef convertOMEnumDefToAtlasAttributeDef(TypeDefAttribute tda) {
+
+        if (tda == null) {
+            return null;
+        }
+        AtlasStructDef.AtlasAttributeDef aad = new AtlasStructDef.AtlasAttributeDef();
+        aad.setName(tda.getAttributeName());
+        aad.setValuesMinCount(tda.getValuesMinCount());
+        aad.setValuesMaxCount(tda.getValuesMaxCount());
+        aad.setIsIndexable(tda.isIndexable());
+        aad.setIsUnique(tda.isUnique());
+        aad.setDefaultValue(tda.getDefaultValue());
+        aad.setDescription(tda.getAttributeDescription());
+        // Currently setting Atlas cardinality and optionality using a pair of method calls.
+        AtlasStructDef.AtlasAttributeDef.Cardinality atlasCardinality = convertOMCardinalityToAtlasCardinality(tda.getAttributeCardinality());
+        aad.setCardinality(atlasCardinality);
+        boolean atlasOptionality = convertOMCardinalityToAtlasOptionality(tda.getAttributeCardinality());
+        aad.setIsOptional(atlasOptionality);
+        aad.setConstraints(null);
+
+        AttributeTypeDef atd = tda.getAttributeType();
+        String atlasTypeName = atd.getName();
+        aad.setTypeName(atlasTypeName);
+        return aad;
+
+    }
+
+
+
+
+    // Convert from an OM relCat to equivalent Atlas type
+    //private AtlasRelationshipDef.RelationshipCategory convertOMRelationshipCategoryToAtlasRelationshipCategory(RelationshipCategory omRelCat) {
+    //    AtlasRelationshipDef.RelationshipCategory ret;
+    //    switch (omRelCat) {
+    //        case ASSOCIATION:
+    //            ret = AtlasRelationshipDef.RelationshipCategory.ASSOCIATION;
+    //            break;
+    //        case AGGREGATION:
+    //            ret = AtlasRelationshipDef.RelationshipCategory.AGGREGATION;
+    //            break;
+    //        case COMPOSITION:
+    //            ret = AtlasRelationshipDef.RelationshipCategory.COMPOSITION;
+    //            break;
+    //        default:
+    //            // Anything else is invalid
+    //            LOG.debug("convertOMRelCatToAtlas: unknown relationship category {}", omRelCat);
+    //            ret = null;
+    //            break;
+    //    }
+    //    return ret;
+    //}
+
+
+
+
+    // This class loads all the Atlas TypeDefs into the typeDefsCache
+    private void loadAtlasTypeDefs(String userId)
+            throws RepositoryErrorException
+    {
+
+        final String methodName = "loadAtlasTypeDefs";
+
+        // Retrieve the typedefs from Atlas, and return a TypeDefGallery that contains two lists, each sorted by category
+        // as follows:
+        // TypeDefGallery.attributeTypeDefs contains:
+        // 1. PrimitiveDefs
+        // 2. CollectionDefs
+        // 3. EnumDefs
+        // TypeDefGallery.newTypeDefs contains:
+        // 1. EntityDefs
+        // 2. RelationshipDefs
+        // 3. ClassificationDefs
+
+        // The result of the load is constructed in typeDefsForAPI - a copy of which is made in the typeDefsCache.
+
+        // Strategy: use searchTypesDef with a null (default) SearchFilter.
+        SearchFilter emptySearchFilter = new SearchFilter();
+        AtlasTypesDef atd;
+        try {
+
+            atd = typeDefStore.searchTypesDef(emptySearchFilter);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("loadAtlasTypeDefs: caught exception from Atlas searchTypesDef", e);
+
+            // This is pretty serious - if Atlas cannot retrieve any types we are in trouble...
+            OMRSErrorCode errorCode = OMRSErrorCode.REPOSITORY_LOGIC_ERROR;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(repositoryName, methodName, e.getMessage());
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "convertAtlasAttributeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        // Parse the Atlas TypesDef
+        // Strategy is to walk the Atlas TypesDef object - i.e. looking at each list of enumDefs, classificationDefs, etc..
+        // and for each list try to convert each element (i.e. each type def) to a corresponding OM type def. If a problem
+        // is encountered within a typedef - for example we encounter a reference attribute or anything else that is not
+        // supported in OM - then we skip (silently) over the Atlas type def. i.e. The metadatacollection will convert the
+        // things that it understands, and will silently ignore anything that it doesn't understand (e.g. structDefs) or
+        // anything that contains something that it does not understand (e.g. a reference attribute or a collection that
+        // contains anything other than primitives).
+
+        // This method will populate the typeDefsForAPI object.
+        if (atd != null) {
+            convertAtlasTypeDefs(userId, atd);
+        }
+
+    }
+
+
+    // ------------------------------------------------------------------------------------------------
+    private AtlasRelationshipDef.PropagateTags convertOMPropagationRuleToAtlasPropagateTags(ClassificationPropagationRule omPropRule)
+        throws
+        TypeErrorException
+    {
+        final String methodName = "convertOMPropagationRuleToAtlasPropagateTags";
+        AtlasRelationshipDef.PropagateTags atlasPropTags;
+        switch (omPropRule) {
+            case NONE:
+                atlasPropTags = AtlasRelationshipDef.PropagateTags.NONE;
+                break;
+            case ONE_TO_TWO:
+                atlasPropTags = AtlasRelationshipDef.PropagateTags.ONE_TO_TWO;
+                break;
+            case TWO_TO_ONE:
+                atlasPropTags = AtlasRelationshipDef.PropagateTags.TWO_TO_ONE;
+                break;
+            case BOTH:
+                atlasPropTags = AtlasRelationshipDef.PropagateTags.BOTH;
+                break;
+            default:
+                LOG.debug("convertOMPropagationRuleToAtlasPropagateTags: could not convert OM propagation rule {}", omPropRule);
+
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_PROPAGATION_RULE;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(omPropRule.toString(), methodName, repositoryName);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+        }
+        return atlasPropTags;
+    }
+
+    // Utility method to convert from OM properties to Atlas attributes map
+    //
+    private Map<String, Object> convertOMPropertiesToAtlasAttributes(InstanceProperties instanceProperties) {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> convertOMPropertiesToAtlasAttributes(instanceProperties={})", instanceProperties);
+        }
+        Map<String, Object> atlasAttrs = null;
+
+        if (instanceProperties != null) {
+            Iterator<String> propNames = instanceProperties.getPropertyNames();
+            if (propNames.hasNext()) {
+                atlasAttrs = new HashMap<>();
+                while (propNames.hasNext()) {
+                    // Create an atlas attribute for this property
+                    String propName = propNames.next();
+                    // Retrieve the IPV - this will actually be of a concrete class such as PrimitivePropertyValue....
+                    InstancePropertyValue ipv = instanceProperties.getPropertyValue(propName);
+                    InstancePropertyCategory ipvCat = ipv.getInstancePropertyCategory();
+                    switch (ipvCat) {
+                        case PRIMITIVE:
+                            LOG.debug("==> convertOMPropertiesToAtlasAttributes: handling primitive value ipv={}",ipv);
+                            PrimitivePropertyValue primitivePropertyValue = (PrimitivePropertyValue) ipv;
+                            Object primValue = primitivePropertyValue.getPrimitiveValue();
+                            atlasAttrs.put(propName, primValue);
+                            break;
+                        case ARRAY:
+                            // Get the ArrayPropertyValue and then use getArrayCount and getArrayValues to get the length and an
+                            // InstanceProperties object. You can then use the map contained in the InstanceProperties to construct
+                            // and Array object that you can set sa the value for Atlas...
+                            ArrayPropertyValue apv = (ArrayPropertyValue) ipv;
+                            int arrayLen = apv.getArrayCount();
+                            ArrayList<Object> atlasArray = null;
+                            if (arrayLen > 0) {
+                                atlasArray = new ArrayList<>();
+                                InstanceProperties arrayProperties = apv.getArrayValues();
+                                Iterator<String> keys = arrayProperties.getPropertyNames();
+                                while (keys.hasNext()) {
+                                    String key = keys.next();
+                                    Object val = arrayProperties.getPropertyValue(key);
+                                    atlasArray.add(val);
+                                }
+                            }
+                            atlasAttrs.put(propName,atlasArray);
+                            break;
+                        case MAP:
+                            // Get the MapPropertyValue and then use getMapElementCount and getMapValues to get the length and an
+                            // InstanceProperties object. You can then use the map contained in the InstanceProperties to construct
+                            // a Map object that you can set sa the value for Atlas...
+                            MapPropertyValue mpv = (MapPropertyValue) ipv;
+                            int mapLen = mpv.getMapElementCount();
+                            HashMap<String,Object> atlasMap = null;
+                            if (mapLen > 0) {
+                                atlasMap = new HashMap<>();
+                                InstanceProperties mapProperties = mpv.getMapValues();
+                                Iterator<String> keys = mapProperties.getPropertyNames();
+                                while (keys.hasNext()) {
+                                    String key = keys.next();
+                                    Object val = mapProperties.getPropertyValue(key);
+                                    atlasMap.put(key,val);
+                                }
+                            }
+                            atlasAttrs.put(propName,atlasMap);
+                            break;
+                        case ENUM:
+                            EnumPropertyValue enumPropertyValue = (EnumPropertyValue) ipv;
+                            Object enumValue = enumPropertyValue.getSymbolicName();
+                            atlasAttrs.put(propName, enumValue);
+                            break;
+                        case STRUCT:
+                        case UNKNOWN:
+                        default:
+                            LOG.debug("convertOMPropertiesToAtlasAttributes: Unsupported attribute {} ignored", propName);
+                            break;
+                    }
+                }
+            }
+        }
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== convertOMPropertiesToAtlasAttributes(atlasAttrs={})", atlasAttrs);
+        }
+        return atlasAttrs;
+    }
+
+    /*
+     * Convenience method to translate an Atlas status enum value to the corresponding OM InstanceValue enum value
+     */
+    private InstanceStatus convertAtlasStatusToOMInstanceStatus(AtlasEntity.Status atlasStatus) {
+        switch (atlasStatus) {
+            case ACTIVE:
+                return InstanceStatus.ACTIVE;
+            case DELETED:
+                return InstanceStatus.DELETED;
+            default:
+                return null;
+        }
+    }
+
+
+    private  List<EntityDetail>  findEntitiesByPropertyUsingDSL(String               userId,
+                                                                String               entityTypeGUID,
+                                                                String               searchCriteria,
+                                                                List<InstanceStatus> limitResultsByStatus,
+                                                                List<String>         limitResultsByClassification,
+                                                                int                  offset,
+                                                                int                  pageSize)
+
+            throws TypeErrorException, RepositoryErrorException, PropertyErrorException
+    {
+
+        final String methodName = "findEntitiesByPropertyUsingDSL";
+        final String entityTypeGUIDParameterName = "entityTypeGUID";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingDSL(userId={}, entityTypeGUID={}, searchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={})",
+                    userId, entityTypeGUID, searchCriteria, limitResultsByStatus, limitResultsByClassification);
+        }
+
+        // This method is used from findEntitiesByPropertyValue which needs to search string properties
+        // only, with the string contained in searchCriteria.
+
+        // Find the type def, examine the properties and add each string property to an InstanceProperties
+        // object with the string given in searchCriteria, then formulate a DSL query by delegating to the
+        // companion method that accepts InstanceProperties
+
+        // Use the entityTypeGUID to retrieve the type name
+        TypeDef typeDef;
+        try {
+
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            // Handle below
+            LOG.error("findEntitiesByPropertyUsingDSL: Caught exception from _getTypeDefByGUID {}", e);
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+
+            LOG.error("findEntitiesByPropertyUsingDSL: Could not retrieve entity type using GUID {}", entityTypeGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, "entityTypeGUID", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        List<EntityDetail> retList;
+
+        try {
+            // Retrieve the type def attributes from the type def
+            InstanceProperties matchStringProperties = null;
+            List<String> matchStringPropertyNames = null; // used for debug
+            List<TypeDefAttribute> attrDefs = getAllDefinedProperties(userId, typeDef);
+            if (attrDefs != null) {
+                for (TypeDefAttribute tda : attrDefs) {
+                    AttributeTypeDef atd = tda.getAttributeType();
+                    AttributeTypeDefCategory atdCat = atd.getCategory();
+                    if (atdCat == AttributeTypeDefCategory.PRIMITIVE) {
+                        PrimitiveDef pDef = (PrimitiveDef) atd;
+                        PrimitiveDefCategory pDefCat = pDef.getPrimitiveDefCategory();
+                        if (pDefCat == PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING) {
+                            // this is a string property...
+                            if (matchStringProperties == null) {
+                                // first string property...
+                                matchStringProperties = new InstanceProperties();
+                                matchStringPropertyNames = new ArrayList<>();
+                            }
+                            PrimitivePropertyValue ppv = new PrimitivePropertyValue();
+                            ppv.setPrimitiveDefCategory(pDefCat);
+                            ppv.setPrimitiveValue(searchCriteria);
+                            matchStringProperties.setProperty(tda.getAttributeName(), ppv);
+                            matchStringPropertyNames.add(tda.getAttributeName());
+                        }
+                    }
+                }
+            }
+            LOG.debug("findEntitiesByPropertyUsingDSL: will look for {} in the following properties {}",searchCriteria,matchStringPropertyNames);
+
+
+            // Delegate
+            /* Because there is no post-processing in this method (this one, not the one it is about to call) it is
+             * safe to pass offset and pageSize through to the delegated-to method.
+             */
+            retList = findEntitiesByPropertyUsingDSL(userId, entityTypeGUID, matchStringProperties,
+                    MatchCriteria.ANY, limitResultsByStatus, limitResultsByClassification, offset, pageSize);
+
+        } catch (TypeDefNotKnownException e) {
+
+            LOG.error("findEntitiesByPropertyUsingDSL: Could not retrieve properties of entity type with GUID {}", entityTypeGUID, e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("unknown", entityTypeGUID, entityTypeGUIDParameterName, methodName, repositoryName);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByPropertyUsingDSL(userId={}, entityTypeGUID={}, searchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={}): retList={}",
+                    userId, entityTypeGUID, searchCriteria, limitResultsByStatus, limitResultsByClassification, retList);
+        }
+        return retList;
+
+    }
+
+    /**
+     * findEntitiesByPropertyUsingDSL is a helper method for compiling a DSL query
+     * @param userId                   - unique identifier for requesting user.
+     * @param entityTypeGUID           - the GUID of the EntityDef
+     * @param matchProperties          - a set of properties that must match
+     * @param matchCriteria            - nature of the properties match: ALL, ANY, NONE
+     * @param limitResultsByStatus     - whether to permit results with only these status values
+     * @param limitResultsByClassification  - whether to permit only results with these classifications
+     * @return a list of entities that satisfy the search criteria
+     * @throws TypeErrorException        - entityTypeGUID does not relate to a valid EntityDef
+     * @throws RepositoryErrorException  - internal error in underlying repository
+     * @throws PropertyErrorException    - a specified property is not valid
+     */
+    private  List<EntityDetail>   findEntitiesByPropertyUsingDSL(String                    userId,
+                                                                 String                    entityTypeGUID,
+                                                                 InstanceProperties        matchProperties,
+                                                                 MatchCriteria             matchCriteria,
+                                                                 List<InstanceStatus>      limitResultsByStatus,
+                                                                 List<String>              limitResultsByClassification,
+                                                                 int                       offset,
+                                                                 int                       pageSize)
+
+            throws
+            TypeErrorException,
+            RepositoryErrorException,
+            PropertyErrorException
+
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingDSL(userId={}, entityTypeGUID={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={})",
+                    userId, entityTypeGUID, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification);
+        }
+
+        final String methodName = "findEntitiesByPropertyUsingDSL";
+
+        // Where a property is of type String the match value should be used as a substring (fuzzy) match.
+        // For all other types of property the match value needs to be an exact match.
+
+        // Use the entityTypeGUID to retrieve the type name
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+        }
+        catch (TypeDefNotKnownException | RepositoryErrorException e) {
+            LOG.error("findEntitiesByPropertyUsingDSL: Caught exception from _getTypeDefByGUID", e);
+            // handle below...
+            typeDef = null;
+        }
+        if (typeDef == null) {
+            LOG.debug("findEntitiesByPropertyUsingDSL: could not retrieve typedef for guid {}", entityTypeGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, "entityTypeGUID", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+        String typeName = typeDef.getName();
+
+
+        // Formulate the query string...
+        StringBuilder dslString = new StringBuilder();
+        dslString.append(typeName);
+
+        DSLQueryHelper dslQueryHelper = new DSLQueryHelper();
+
+        // Add a WHERE clause if needed...
+        try {
+            String whereClause = dslQueryHelper.createWhereClause(typeName, matchProperties, matchCriteria, limitResultsByClassification);
+            LOG.debug("findEntitiesByPropertyUsingDSL: whereClause is {}", whereClause);
+            if (whereClause != null)
+                dslString.append(whereClause);
+        }
+        catch (RepositoryErrorException | PropertyErrorException e) {
+            LOG.error("findEntitiesByPropertyUsingDSL: re-throwing exception from createWhereClause", e);
+            throw e;
+        }
+
+        LOG.debug("findEntitiesByPropertyUsingDSL: query string is <{}>", dslString);
+
+        String dslSearchString = dslString.toString();
+
+        /* Care is needed at this point. If this method were to pass offset and pageSize (limit) through to the
+         * entityDisocveryService we could miss valid results. This is because any instanceStatus checking is
+         * performed as a post-process in the current method, so we must not offset or limit the search performed
+         * by the discovery service.
+         *
+         * To understand why this would be a problen consider the following:
+         * Suppose there are 100 entities that would match our search, including classification filtering.
+         * If we were to specify an offset of 20 and pageSize of 30 we would receive back entities 20 - 49.
+         * If any of those entities fails the subsequent instance status filter then we will get a subset of
+         * a page of entities - none of the current method, the caller nor the end user can tell whether there
+         * are other entities outside the range 20-49 that would have been valid and passed the status filter.
+         * To provide a valid and maximal result we must only apply offset and pageSize once the post-filtering
+         * is complete.
+         *
+         * In theory, we could allow Atlas to perform a narrower search where we know we will be filtering by
+         * instanceStatus by testing (limitResultsByStatus != null). However, there is also filtering out of
+         * entity proxies and since we do not know which entities are proxies until after the search is complete,
+         * we must always search as widely as Atlas will allow.
+         */
+        int atlasSearchLimit = AtlasConfiguration.SEARCH_MAX_LIMIT.getInt();
+        int atlasSearchOffset = 0;
+        AtlasSearchResult atlasSearchResult;
+        try {
+            atlasSearchResult = entityDiscoveryService.searchUsingDslQuery(dslSearchString, atlasSearchLimit, atlasSearchOffset);
+
+        }
+        catch (AtlasBaseException e) {
+            LOG.error("findEntitiesByPropertyUsingDSL: Atlas DSL query threw exception {}", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, "entityTypeGUID", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+
+        // Construct the result
+
+        ArrayList<EntityDetail> returnList = null;
+        List<AtlasEntityHeader> atlasEntities = atlasSearchResult.getEntities();
+        if (atlasEntities != null) {
+            returnList = new ArrayList<>();
+            for (AtlasEntityHeader aeh : atlasEntities) {
+                // Filter by status if requested...
+                if (limitResultsByStatus != null) {
+                    // Need to check that the AEH status is in the list of allowed status values
+                    AtlasEntity.Status atlasStatus = aeh.getStatus();
+                    InstanceStatus effectiveInstanceStatus = convertAtlasStatusToOMInstanceStatus(atlasStatus);
+                    boolean match = false;
+                    for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                        if (effectiveInstanceStatus == allowedStatus) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if ( !match ) {
+                        continue;  // skip this AEH and process the next, if any remain
+                    }
+                }
+                // We need to use the AEH to look up the real AtlasEntity then we can use the relevant converter method
+                // to get an EntityDetail object.
+
+                /* An AtlasEntityHeader has:
+                 * String                    guid
+                 * AtlasEntity.Status        status
+                 * String                    displayText
+                 * List<String>              classificationNames
+                 * List<AtlasClassification> classifications
+                 */
+                AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+                try {
+                    atlasEntityWithExt = entityStore.getById(aeh.getGuid());
+                } catch (AtlasBaseException e) {
+
+                    LOG.error("findEntitiesByPropertyUsingDSL: caught exception from Atlas entity store getById {}", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+                AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+                LOG.debug("findEntitiesByPropertyUsingDSL: atlasEntity {}", atlasEntity);
+
+
+                if (atlasEntity.isProxy()) {
+                    // This entity is only a proxy - do not include it in the search result.
+                    LOG.debug("findEntitiesByPropertyUsingDSL: ignoring atlasEntity because it is a proxy {}", atlasEntity);
+                    continue;
+                }
+
+                // Project the AtlasEntity as an EntityDetail
+
+                try {
+
+                    AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+                    EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+                    LOG.debug("findEntitiesByPropertyUsingDSL: om entity {}", omEntityDetail);
+                    returnList.add(omEntityDetail);
+
+                } catch (TypeErrorException | InvalidEntityException e) {
+
+                    LOG.error("findEntitiesByPropertyUsingDSL: could not map AtlasEntity to EntityDetail", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+            }
+        }
+
+        /* We did not apply offset or pageSize earlier due to the existence of post-filtering (for status and proxy). So we
+         * must apply offset and pageSize now.
+         */
+        LOG.debug("findEntitiesByPropertyUsingDSL: returnList={}", returnList);
+        LOG.debug("findEntitiesByPropertyUsingDSL: apply offset and pageSize");
+        List<EntityDetail> limitedReturnList;
+        try {
+            limitedReturnList = formatEntityResults(returnList, offset, null, null, pageSize);
+        }
+        catch (PagingErrorException e) {
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from result formatter", e);
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.PAGING_ERROR;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(String.valueOf(offset), String.valueOf(pageSize), methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingDSL(userId={}, entityTypeGUID={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={}: returnList={})",
+                    userId, entityTypeGUID, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification, limitedReturnList);
+        }
+        return limitedReturnList;
+    }
+
+
+    private  List<EntityDetail>   findEntitiesByPropertyUsingSearchParameters(String                  userId,
+                                                                              String                  searchCriteria,
+                                                                              List<InstanceStatus>    limitResultsByStatus,
+                                                                              List<String>            limitResultsByClassification,
+                                                                              int                     offset,
+                                                                              int                     pageSize)
+            throws
+            PropertyErrorException,
+            RepositoryErrorException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingSearchParameters(userId={}, searchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={})",
+                    userId, searchCriteria, limitResultsByStatus, limitResultsByClassification);
+        }
+
+        final String methodName = "findEntitiesByPropertyUsingSearchParameters";
+
+        // Special case when searchCriteria is null or empty string - return an empty list
+        if (searchCriteria == null || searchCriteria.equals("")) {
+            // Nothing to search for
+            LOG.debug("findEntitiesByPropertyUsingSearchParameters: no search criteria supplied, returning null");
+            return null;
+        }
+
+        // This method is used from findEntitiesByPropertyValue which needs to search string properties
+        // only, with the string contained in searchCriteria.
+
+        // We have no entityTypeGUID - so we are operating across all types. We therefore do not have
+        // a specified set of properties to examine. But we only want to match string properties. We can
+        // therefore use a full text search.
+
+        SearchParameters searchParameters = new SearchParameters();
+        searchParameters.setTypeName(null);
+
+        boolean postFilterClassifications = false;
+        if (limitResultsByClassification != null) {
+            if (limitResultsByClassification.size() == 1) {
+                searchParameters.setClassification(limitResultsByClassification.get(0));          // with exactly one classification, classification will be part of search
+            } else {
+                postFilterClassifications = true;
+                searchParameters.setClassification(null);                                         // classifications will be post-filtered if requested
+            }
+        } else {
+            searchParameters.setClassification(null);
+        }
+
+        // We know we have no typeGUID. We have enforced that there must be a non-empty searchCriteria string.
+
+        // Frame the query string in asterisks so that it can appear anywhere in a value...
+        String searchPattern = "*"+searchCriteria+"*";
+        searchParameters.setQuery(searchPattern);
+
+
+        searchParameters.setExcludeDeletedEntities(false);
+        searchParameters.setIncludeClassificationAttributes(false);
+        searchParameters.setIncludeSubTypes(false);
+        searchParameters.setIncludeSubClassifications(false);
+
+        /* Care is needed at this point. If this method were to pass offset and pageSize (limit) through to the
+         * entityDiscoveryService we could miss valid results. This is because any instanceStatus checking is
+         * performed as a post-process in the current method, so we must not offset or limit the search performed
+         * by the discovery service.
+         *
+         * To understand why this would be a problem consider the following:
+         * Suppose there are 100 entities that would match our search.
+         * If we were to specify an offset of 20 and pageSize of 30 we would receive back entities 20 - 49.
+         * If any of those entities fails the subsequent instance status or classification filter then we will get
+         * a subset of a page of entities - none of the current method, the caller nor the end user can tell whether
+         * there are other entities outside the range 20-49 that would have been valid and passed the status filter.
+         * To provide a valid and maximal result we must only apply offset and pageSize once the post-filtering
+         * is complete.
+         *
+         * In theory, we could allow Atlas to perform a narrower search where we know we will be filtering by
+         * instanceStatus by testing (limitResultsByStatus != null). However, there is also filtering out of
+         * entity proxies and since we do not know which entities are proxies until after the search is complete,
+         * we must always search as widely as Atlas will allow.
+         */
+        int atlasSearchLimit = AtlasConfiguration.SEARCH_MAX_LIMIT.getInt();
+        int atlasSearchOffset = 0;
+        searchParameters.setLimit(atlasSearchLimit);
+        searchParameters.setOffset(atlasSearchOffset);
+        searchParameters.setTagFilters(null);
+        searchParameters.setAttributes(null);
+        searchParameters.setEntityFilters(null);
+
+        AtlasSearchResult atlasSearchResult;
+        try {
+
+            atlasSearchResult = entityDiscoveryService.searchWithParameters(searchParameters);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: entity discovery service searchWithParameters threw exception", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(searchCriteria, "searchCriteria", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        ArrayList<EntityDetail> returnList = null;
+
+
+        List<AtlasEntityHeader> atlasEntities = atlasSearchResult.getEntities();
+        if (atlasEntities != null) {
+            returnList = new ArrayList<>();
+            for (AtlasEntityHeader aeh : atlasEntities) {
+                if (limitResultsByStatus != null) {
+                    // Need to check that the AEH status is in the list of allowed status values
+                    AtlasEntity.Status atlasStatus = aeh.getStatus();
+                    InstanceStatus effectiveInstanceStatus = convertAtlasStatusToOMInstanceStatus(atlasStatus);
+                    boolean match = false;
+                    for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                        if (effectiveInstanceStatus == allowedStatus) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if (!match) {
+                        continue;  // skip this AEH and process the next, if any remain
+                    }
+                }
+                // We need to use the AEH to look up the real AtlasEntity then we can use the relevant converter method
+                // to get an EntityDetail object.
+
+                /* An AtlasEntityHeader has:
+                 * String                    guid
+                 * AtlasEntity.Status        status
+                 * String                    displayText
+                 * List<String>              classificationNames
+                 * List<AtlasClassification> classifications
+                 */
+                AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+
+                try {
+
+                    atlasEntityWithExt = entityStore.getById(aeh.getGuid());
+
+                } catch (AtlasBaseException e) {
+
+                    LOG.error("findEntitiesByPropertyUsingSearchParameters: entity store getById threw exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+                AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+
+                if (atlasEntity.isProxy()) {
+                    // This entity is only a proxy - do not include it in the search result.
+                    LOG.debug("findEntitiesByPropertyUsingSearchParameters: ignoring atlasEntity because it is a proxy {}", atlasEntity);
+                    continue;
+                }
+
+                if (postFilterClassifications) {
+                    // We need to ensure that this entity has all of the specified filter classifications...
+                    List<AtlasClassification> entityClassifications = atlasEntity.getClassifications();
+                    int numFilterClassifications = limitResultsByClassification.size();
+                    int cursor = 0;
+                    boolean missingClassification = false;
+                    while (!missingClassification && cursor < numFilterClassifications - 1) {
+                        // Look for this filterClassification in the entity's classifications
+                        String filterClassificationName = limitResultsByClassification.get(cursor);
+                        boolean match = false;
+                        for (AtlasClassification atlasClassification : entityClassifications) {
+                            if (atlasClassification.getTypeName().equals(filterClassificationName)) {
+                                match = true;
+                                break;
+                            }
+                        }
+                        if ( !match ) {
+                            missingClassification = true;     // stop looking, one miss is enough
+                        }
+                        cursor++;
+                    }
+                    if (missingClassification)
+                        continue;                  // skip this entity and process the next, if any remain
+                }
+
+
+                // Project the AtlasEntity as an EntityDetail
+
+                try {
+
+                    AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+                    EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+                    LOG.debug("findEntitiesByPropertyUsingSearchParameters: om entity {}", omEntityDetail);
+                    returnList.add(omEntityDetail);
+
+                } catch (TypeErrorException | InvalidEntityException e) {
+
+                    LOG.error("findEntitiesByPropertyUsingSearchParameters: could not map AtlasEntity to entityDetail, exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+        }
+
+        /* We did not apply offset or pageSize earlier due to the existence of post-filtering (for status and proxy). So we
+         * must apply offset and pageSize now.
+         */
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: returnList={}", returnList);
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: apply offset and pageSize");
+        List<EntityDetail> limitedReturnList;
+        try {
+            limitedReturnList = formatEntityResults(returnList, offset, null, null, pageSize);
+        }
+        catch (PagingErrorException e) {
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from result formatter", e);
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.PAGING_ERROR;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(String.valueOf(offset), String.valueOf(pageSize), methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByPropertyUsingSearchParameters(userId={}, searchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={}): returnList={}",
+                    userId, searchCriteria, limitResultsByStatus, limitResultsByClassification, limitedReturnList);
+        }
+        return limitedReturnList;
+    }
+
+
+    /*
+     *
+     * Internal method for search using SearchParameters
+     *
+     */
+    private  List<EntityDetail>   findEntitiesByPropertyUsingSearchParameters(String                   userId,
+                                                                              InstanceProperties       matchProperties,
+                                                                              MatchCriteria            matchCriteria,
+                                                                              List<InstanceStatus>     limitResultsByStatus,
+                                                                              List<String>             limitResultsByClassification,
+                                                                              int                      offset,
+                                                                              int                      pageSize)
+            throws
+            PropertyErrorException,
+            RepositoryErrorException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingSearchParameters(userId={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={})",
+                    userId, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification);
+        }
+
+        final String methodName = "findEntitiesByPropertyUsingSearchParameters";
+
+        // This is the hardest case of a findEntitiesByProperty - you do not have a typeGUID so the search applies to all entity
+        // types. The method will therefore find all the entity types and do a query for each type, then union the results.
+        // You may have match properties - although the case of exactly one property could be delegated to basic query
+        // it seems simpler to always delegate to searchWithParameters with optionally 0, 1 or many entityFilters.
+        // You may also have status and/or classification filters. Those are both post-filtered.
+        //
+
+        List<TypeDef> allEntityTypes;
+        try {
+            allEntityTypes = _findTypeDefsByCategory(userId, TypeDefCategory.ENTITY_DEF);
+        }
+        catch (InvalidParameterException | UserNotAuthorizedException e) {
+
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from _findTypeDefsByCategory", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("any EntityDef", "TypeDefCategory.ENTITY_DEF", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        if (allEntityTypes == null) {
+            LOG.debug("findEntitiesByPropertyUsingSearchParameters: found no entity types");
+            return null;
+        }
+
+        ArrayList<EntityDetail> returnEntities = null;
+
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: There are {} entity types defined",allEntityTypes.size());
+
+        if (allEntityTypes.size() > 0) {
+
+            // Iterate over the known entity types performing a search for each...
+
+            for (TypeDef typeDef : allEntityTypes) {
+                LOG.debug("findEntitiesByPropertyUsingSearchParameters: checking entity type {}", typeDef.getName());
+
+                // If there are any matchProperties
+                if (matchProperties != null) {
+                    // Validate that the type has the specified properties...
+                    // Whether matchCriteria is ALL | ANY | NONE we need ALL the match properties to be defined in the type definition
+                    // For a property definition to match a property in the matchProperties, we need name and type to match.
+
+                    // Find what properties are defined on the type
+                    // getAllDefinedProperties() will recurse up the supertype hierarchy
+                    List<TypeDefAttribute> definedAttributes;
+                    try {
+
+                        definedAttributes = getAllDefinedProperties(userId, typeDef);
+
+                    }
+                    catch (TypeDefNotKnownException e) {
+
+                        LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from property finder", e);
+
+                        OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage("find properties", "TypeDef", methodName, metadataCollectionId);
+
+                        throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                methodName,
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+                    }
+                    if (definedAttributes == null) {
+                        // It is obvious that this type does not have the match properties - because it has no properties
+                        // Proceed to the next entity type
+                        LOG.debug("findEntitiesByPropertyUsingSearchParameters: entity type {} has no properties - will be ignored", typeDef.getName());
+                        // continue;
+                    }
+                    else {
+                        // We know this type has some properties...
+                        // Iterate over the match properties... (matching on name and type)
+                        Iterator<String> matchPropNames = matchProperties.getPropertyNames();
+                        boolean allPropsDefined = true;
+                        while (matchPropNames.hasNext()) {
+                            String matchPropName = matchPropNames.next();
+                            InstancePropertyValue matchPropValue = matchProperties.getPropertyValue(matchPropName);
+                            String matchPropType = matchPropValue.getTypeName();
+                            LOG.debug("findEntitiesByPropertyUsingSearchParameters: matchProp has name {} type {}", matchPropName, matchPropType);
+                            // Find the current match prop in the type def
+                            boolean propertyDefined = false;
+                            for (TypeDefAttribute defType: definedAttributes) {
+                                AttributeTypeDef atd = defType.getAttributeType();
+                                String defTypeName = atd.getName();
+                                if (defType.getAttributeName().equals(matchPropName) && defTypeName.equals(matchPropType)) {
+                                    // Entity type def has the current match property...
+                                    LOG.debug("findEntitiesByPropertyUsingSearchParameters: entity type {} has property name {} type {}", typeDef.getName(),matchPropName,matchPropType);
+                                    propertyDefined = true;
+                                    break;
+                                }
+                            }
+                            if (!propertyDefined) {
+                                // this property is missing from the def
+                                LOG.debug("findEntitiesByPropertyUsingSearchParameters: entity type {} does not have property name {} type {}", typeDef.getName(),matchPropName,matchPropType);
+                                allPropsDefined = false;
+                            }
+                        }
+                        if (!allPropsDefined) {
+                            // At least one property in the match props is not defined on the type - skip the type
+                            LOG.debug("findEntitiesByPropertyUsingSearchParameters: entity type {} does not have all match properties - will be ignored", typeDef.getName());
+                            //continue;
+                        }
+                        else {
+                            // The current type is suitable for a find of instances of this type.
+                            LOG.debug("findEntitiesByPropertyUsingSearchParameters: entity type {} will be searched", typeDef.getName());
+
+                            // Extract the type guid and invoke a type specific search...
+                            String typeDefGUID = typeDef.getGUID();
+
+                            /* Do not pass on the offset and pageSize - these need to applied once on the aggregated result (from all types)
+                             * So make this search as broad as possible - i.e. set offset to 0 and pageSze to MAX.
+                             */
+
+                            ArrayList<EntityDetail> entitiesForCurrentType = findEntitiesByPropertyUsingSearchParameters(
+                                    userId, typeDefGUID, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification, 0, AtlasConfiguration.SEARCH_MAX_LIMIT.getInt());
+
+                            if (entitiesForCurrentType != null && !entitiesForCurrentType.isEmpty()) {
+                                if (returnEntities == null) {
+                                    returnEntities = new ArrayList<>();
+                                }
+                                LOG.debug("findEntitiesByPropertyUsingSearchParameters: for type {} found {} entities", typeDef.getName(),entitiesForCurrentType.size());
+                                returnEntities.addAll(entitiesForCurrentType);
+                            }
+                            else {
+                                LOG.debug("findEntitiesByPropertyUsingSearchParameters: for type {} found no entities", typeDef.getName());
+                            }
+                        }
+                    }
+                }
+            }
+        }
+
+        int resultSize = 0;
+        if (returnEntities!=null)
+            resultSize = returnEntities.size();
+
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: Atlas found {} entities", resultSize);
+
+        /* We did not apply offset or pageSize earlier due to the aggregation across types, so we
+         * must apply offset and pageSize now.
+         */
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: returnEntities={}", returnEntities);
+        LOG.debug("findEntitiesByPropertyUsingSearchParameters: apply offset and pageSize");
+        List<EntityDetail> limitedReturnList;
+        try {
+            limitedReturnList = formatEntityResults(returnEntities, offset, null, null, pageSize);
+        }
+        catch (PagingErrorException e) {
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from result formatter", e);
+
+            LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.PAGING_ERROR;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(String.valueOf(offset), String.valueOf(pageSize), methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByPropertyUsingSearchParameters(userId={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={}): returnEntities={}",
+                    userId, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification, limitedReturnList);
+        }
+        return limitedReturnList;
+    }
+
+
+
+    // Utility method to recurse up supertype hierarchy fetching property defs
+    // Deliberately not scoped for access - default to package private
+    List<TypeDefAttribute> getAllDefinedProperties(String userId, TypeDef tdef)
+    throws RepositoryErrorException, TypeDefNotKnownException
+    {
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> getAllDefinedProperties(userId={}, typedef={})", userId, tdef);
+        }
+
+        List<TypeDefAttribute> propDefs = new ArrayList<>();
+
+        // Look at the supertype (if any) and then get the properties for the current type def (if any)
+        if (tdef.getSuperType() != null) {
+            // recurse up the supertype hierarchy until you hit the top
+            // Get the supertype's type def
+            TypeDefLink superTypeDefLink = tdef.getSuperType();
+            String superTypeName = superTypeDefLink.getName();
+            try {
+                TypeDef superTypeDef = _getTypeDefByName(userId, superTypeName);
+                List<TypeDefAttribute> inheritedProps = getAllDefinedProperties(userId, superTypeDef);
+                if (inheritedProps != null && !inheritedProps.isEmpty()) {
+                    propDefs.addAll(inheritedProps);
+                }
+            }
+            catch (RepositoryErrorException | TypeDefNotKnownException e) {
+                LOG.error("getAllDefinedProperties: caught exception from _getTypeDefByName", e);
+                throw e;
+            }
+        }
+        // Add the properties defined for the current type
+        List<TypeDefAttribute> currentTypePropDefs = tdef.getPropertiesDefinition();
+        if (currentTypePropDefs != null && !currentTypePropDefs.isEmpty()) {
+            propDefs.addAll(currentTypePropDefs);
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== getAllDefinedProperties(userId={}, typedef={}): propDefs={}", userId, tdef, propDefs);
+        }
+        return propDefs;
+    }
+
+
+    private  ArrayList<EntityDetail>   findEntitiesByPropertyUsingSearchParameters(String                   userId,
+                                                                                   String                   entityTypeGUID,
+                                                                                   InstanceProperties       matchProperties,
+                                                                                   MatchCriteria            matchCriteria,
+                                                                                   List<InstanceStatus>     limitResultsByStatus,
+                                                                                   List<String>             limitResultsByClassification,
+                                                                                   int                      offset,
+                                                                                   int                      pageSize)
+            throws
+            PropertyErrorException,
+            RepositoryErrorException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByPropertyUsingSearchParameters(userId={}, entityTypeGUID={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={})",
+                    userId, entityTypeGUID, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification);
+        }
+
+        final String methodName = "findEntitiesByPropertyUsingSearchParameters";
+
+        SearchParameters searchParameters = new SearchParameters();
+
+        // If there is a non-null type specified find the type name for use in SearchParameters
+
+        String typeName = null;
+        if (entityTypeGUID != null) {
+            // find the entity type name
+            TypeDef tDef;
+            try {
+                tDef = _getTypeDefByGUID(userId, entityTypeGUID);
+            }
+            catch (TypeDefNotKnownException e) {
+                LOG.error("findEntitiesByPropertyUsingSearchParameters: caught exception from attempt to look up type by GUID {}", entityTypeGUID, e);
+                return null;
+            }
+            if (tDef == null) {
+                LOG.error("findEntitiesByPropertyUsingSearchParameters: null returned by look up of type with GUID {}", entityTypeGUID);
+                return null;
+            }
+            typeName = tDef.getName();
+        }
+        searchParameters.setTypeName(typeName);
+
+        boolean postFilterClassifications = false;
+        if (limitResultsByClassification != null) {
+            if (limitResultsByClassification.size() == 1) {
+                searchParameters.setClassification(limitResultsByClassification.get(0));          // with exactly one classification, classification will be part of search
+            } else {
+                postFilterClassifications = true;
+                searchParameters.setClassification(null);                                         // classifications will be post-filtered if requested
+            }
+        } else {
+            searchParameters.setClassification(null);
+        }
+
+        // We know we have no typeGUID. If we also have no classifications in the search parameters (due to no
+        // classifications being specified or multiple classifications and hence post-filtering) then you must have
+        // a fulltext component to the search otherwise there will be no search processor in the SearchContext.
+        // Attribute filtering (entityFilters) alone is not sufficient. So must fake up a fulltext search on "*"
+        if (searchParameters.getClassification() == null) {
+            searchParameters.setQuery("*");
+        } else {
+            searchParameters.setQuery(null);
+        }
+
+
+        searchParameters.setExcludeDeletedEntities(false);
+        searchParameters.setIncludeClassificationAttributes(false);
+        searchParameters.setIncludeSubTypes(false);
+        searchParameters.setIncludeSubClassifications(false);
+        // offset and limit are set from offset and pageSize
+        searchParameters.setLimit(pageSize);
+        searchParameters.setOffset(offset);
+        searchParameters.setTagFilters(null);
+        searchParameters.setAttributes(null);
+
+        searchParameters.setEntityFilters(null);
+        if (matchProperties != null) {
+
+            SearchParameters.Operator operator;                    // applied to a single filter criterion
+            SearchParameters.FilterCriteria.Condition condition;   // applied to a list of filter criteria
+            if (matchCriteria == null) {
+                matchCriteria = MatchCriteria.ALL;                        // default to matchCriteria of ALL
+            }
+            switch (matchCriteria) {
+                case ALL:
+                    operator = EQ;
+                    condition = SearchParameters.FilterCriteria.Condition.AND;
+                    break;
+                case ANY:
+                    operator = EQ;
+                    condition = SearchParameters.FilterCriteria.Condition.OR;
+                    break;
+                case NONE:
+                    // Temporary restriction until figured out how to perform equivalent of a negative regex
+                    //operator = NEQ;
+                    //condition = SearchParameters.FilterCriteria.Condition.AND;
+                    //break;
+                default:
+                    LOG.error("findEntitiesByPropertyUsingSearchParameters: only supports matchCriteria ALL, ANY");
+                    return null;
+            }
+
+            List<SearchParameters.FilterCriteria> filterCriteriaList = new ArrayList<>();
+
+            Iterator<String> matchNames = matchProperties.getPropertyNames();
+            while (matchNames.hasNext()) {
+
+                // For the next property allocate and initialise a filter criterion and add it to the list...
+
+                // Extract the name and value as strings for the filter criterion
+                String matchPropertyName = matchNames.next();
+                boolean stringProp = false;
+                String strValue;
+                InstancePropertyValue matchValue = matchProperties.getPropertyValue(matchPropertyName);
+                InstancePropertyCategory cat = matchValue.getInstancePropertyCategory();
+                switch (cat) {
+                    case PRIMITIVE:
+                        // matchValue is a PPV
+                        PrimitivePropertyValue ppv = (PrimitivePropertyValue) matchValue;
+                        // Find out if this is a string property
+                        PrimitiveDefCategory pdc = ppv.getPrimitiveDefCategory();
+                        if (pdc == PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING) {
+                            stringProp = true;
+                            String actualValue = ppv.getPrimitiveValue().toString();
+                            // Frame the actual value so it is suitable for regex search
+                            strValue = "'*" + actualValue + "*'";
+                            LOG.debug("findEntitiesByPropertyUsingSearchParameters: string property {} has filter value {}", matchPropertyName, strValue);
+                        } else {
+                            // We need a string for DSL query - this does not reflect the property type
+                            strValue = ppv.getPrimitiveValue().toString();
+                            LOG.debug("findEntitiesByPropertyUsingSearchParameters: non-string property {} has filter value {}", matchPropertyName, strValue);
+                        }
+                        break;
+                    case ARRAY:
+                    case MAP:
+                    case ENUM:
+                    case STRUCT:
+                    case UNKNOWN:
+                    default:
+                        LOG.error("findEntitiesByPropertyUsingSearchParameters: match property of cat {} not supported", cat);
+
+                        LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_PROPERTY_CATEGORY;
+
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(cat.toString(), methodName, repositoryName);
+
+                        throw new PropertyErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                methodName,
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+
+
+                }
+
+                // Override the operator (locally, only for this property) if it is a string
+                SearchParameters.Operator localOperator = stringProp ? SearchParameters.Operator.LIKE : operator;
+
+                // Set up a criterion for this property
+                SearchParameters.FilterCriteria filterCriterion = new SearchParameters.FilterCriteria();
+                filterCriterion.setAttributeName(matchPropertyName);
+                filterCriterion.setAttributeValue(strValue);
+                filterCriterion.setOperator(localOperator);
+                filterCriteriaList.add(filterCriterion);
+            }
+            // Finalize with a FilterCriteria that contains the list of FilterCriteria and applies the appropriate condition (based on matchCriteria)
+            SearchParameters.FilterCriteria entityFilters = new SearchParameters.FilterCriteria();
+            entityFilters.setCriterion(filterCriteriaList);
+            entityFilters.setCondition(condition);
+            searchParameters.setEntityFilters(entityFilters);
+        }
+
+
+        AtlasSearchResult atlasSearchResult;
+        try {
+            atlasSearchResult = entityDiscoveryService.searchWithParameters(searchParameters);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("findEntitiesByPropertyUsingSearchParameters: entity discovery service searchWithParameters threw exception", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("searchWithParameters", "searchParameters", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        ArrayList<EntityDetail> returnList = null;
+
+        List<AtlasEntityHeader> atlasEntities = atlasSearchResult.getEntities();
+        if (atlasEntities != null) {
+            returnList = new ArrayList<>();
+            for (AtlasEntityHeader aeh : atlasEntities) {
+                if (limitResultsByStatus != null) {
+                    // Need to check that the AEH status is in the list of allowed status values
+                    AtlasEntity.Status atlasStatus = aeh.getStatus();
+                    InstanceStatus effectiveInstanceStatus = convertAtlasStatusToOMInstanceStatus(atlasStatus);
+                    boolean match = false;
+                    for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                        if (effectiveInstanceStatus == allowedStatus) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if ( !match ) {
+                        continue;  // skip this AEH and process the next, if any remain
+                    }
+                }
+                /* We need to use the AEH to look up the real AtlasEntity then we can use the relevant converter method
+                 * to get an EntityDetail object.
+                 *
+                 * An AtlasEntityHeader has:
+                 * String                    guid
+                 * AtlasEntity.Status        status
+                 * String                    displayText
+                 * List<String>              classificationNames
+                 * List<AtlasClassification> classifications
+                 */
+                AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+                try {
+
+                    atlasEntityWithExt = entityStore.getById(aeh.getGuid());
+
+                } catch (AtlasBaseException e) {
+
+                    LOG.debug("findEntitiesByPropertyUsingSearchParameters: Caught exception from Atlas entity store getById method {}", e.getMessage());
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+                }
+
+                AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+                if (postFilterClassifications) {
+                    // We need to ensure that this entity has all of the specified filter classifications...
+                    List<AtlasClassification> entityClassifications = atlasEntity.getClassifications();
+                    int numFilterClassifications = limitResultsByClassification.size();
+                    int cursor = 0;
+                    boolean missingClassification = false;
+                    while (!missingClassification && cursor < numFilterClassifications - 1) {
+                        // Look for this filterClassification in the entity's classifications
+                        String filterClassificationName = limitResultsByClassification.get(cursor);
+                        boolean match = false;
+                        for (AtlasClassification atlasClassification : entityClassifications) {
+                            if (atlasClassification.getTypeName().equals(filterClassificationName)) {
+                                match = true;
+                                break;
+                            }
+                        }
+                        missingClassification = !match;   // stop looking, one miss is enough
+                        cursor++;
+                    }
+                    if (missingClassification)
+                        continue;                  // skip this entity and process the next, if any remain
+                }
+
+
+                // Project the AtlasEntity as an EntityDetail
+
+                try {
+
+                    AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+                    EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+                    LOG.debug("findEntitiesByProperty: om entity {}", omEntityDetail);
+                    returnList.add(omEntityDetail);
+
+                } catch (Exception e) {
+
+                    LOG.error("findEntitiesByPropertyUsingSearchParameters: could not map AtlasEntity to EntityDetail", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasEntity.getGuid(), "atlasEntity", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByPropertyUsingSearchParameters(userId={}, matchProperties={}, matchCriteria={}, limitResultsByStatus={}, limitResultsByClassification={}): returnList={}",
+                    userId, matchProperties, matchCriteria, limitResultsByStatus, limitResultsByClassification, returnList);
+        }
+        return returnList;
+
+    }
+
+
+
+    /*
+     * Internal method for constructing search using DSL
+     */
+
+    private  List<EntityDetail>   findEntitiesByClassificationUsingDSL(String                 userId,
+                                                                       String                 entityTypeGUID,
+                                                                       String                 classificationName,
+                                                                       InstanceProperties     matchClassificationProperties,
+                                                                       MatchCriteria          matchCriteria,
+                                                                       List<InstanceStatus>   limitResultsByStatus,
+                                                                       int                    offset,
+                                                                       int                    pageSize)
+
+            throws
+            TypeErrorException,
+            RepositoryErrorException,
+            PropertyErrorException
+
+    {
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByClassificationUsingDSL(userId={}, entityTypeGUID={}, classificationName={}, matchClassificationProperties={}, matchCriteria={}, limitResultsByStatus={})",
+                    userId, entityTypeGUID, classificationName, matchClassificationProperties, matchCriteria, limitResultsByStatus);
+        }
+
+        final String methodName = "findEntitiesByClassificationUsingDSL";
+
+        // Use the entityTypeGUID to retrieve the type name
+        TypeDef typeDef;
+        try {
+            typeDef = _getTypeDefByGUID(userId, entityTypeGUID);
+        }
+        catch (RepositoryErrorException | TypeDefNotKnownException e) {
+            LOG.error("findEntitiesByClassificationUsingDSL: caught exception from _getTypeDefByGUID", e);
+            // handle below
+            typeDef = null;
+        }
+
+        if (typeDef == null) {
+
+            LOG.error("findEntitiesByClassificationUsingDSL: could not retrieve typedef for guid {}", entityTypeGUID);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(entityTypeGUID, "entityTypeGUID", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        String typeName = typeDef.getName();
+
+        // Formulate the query string...
+        StringBuilder dslString = new StringBuilder();
+        dslString.append(typeName);
+
+        DSLQueryHelper dslQueryHelper = new DSLQueryHelper();
+
+        ArrayList<String> classificationsFilter = new ArrayList<>();
+        classificationsFilter.add(classificationName);
+
+        // Add a WHERE clause if needed...
+        try {
+            String whereClause = dslQueryHelper.createWhereClause(typeName, matchClassificationProperties, matchCriteria, classificationsFilter);
+            LOG.debug("findEntitiesByClassificationUsingDSL: whereClause is {}", whereClause);
+            if (whereClause != null)
+                dslString.append(whereClause);
+        }
+        catch (PropertyErrorException e) {
+            LOG.error("findEntitiesByClassificationUsingDSL: re-throwing exception from createWhereClause", e);
+            throw e;
+
+        }
+
+        LOG.debug("findEntitiesByClassificationUsingDSL: query string is <{}>", dslString);
+
+        String dslSearchString = dslString.toString();
+        int limit = pageSize;
+        //int offset = offset;
+        AtlasSearchResult atlasSearchResult;
+        try {
+            atlasSearchResult = entityDiscoveryService.searchUsingDslQuery(dslSearchString, limit, offset);
+
+        }
+        catch (AtlasBaseException e) {
+
+            LOG.error("findEntitiesByClassificationUsingDSL: Atlas searchUsingDslQuery threw exception", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(dslSearchString, "dslSearchString", methodName, metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+
+        // Filter by status if requested...
+
+        ArrayList<EntityDetail> returnList = null;
+        List<AtlasEntityHeader> atlasEntities = atlasSearchResult.getEntities();
+        if (atlasEntities != null) {
+            returnList = new ArrayList<>();
+            for (AtlasEntityHeader aeh : atlasEntities) {
+                if (limitResultsByStatus != null) {
+                    // Need to check that the AEH status is in the list of allowed status values
+                    AtlasEntity.Status atlasStatus = aeh.getStatus();
+                    InstanceStatus effectiveInstanceStatus = convertAtlasStatusToOMInstanceStatus(atlasStatus);
+                    boolean match = false;
+                    for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                        if (effectiveInstanceStatus == allowedStatus) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if ( !match  ) {
+                        continue;  // skip this AEH and process the next, if any remain
+                    }
+                }
+                /* We need to use the AEH to look up the real AtlasEntity then we can use the relevant converter method
+                 * to get an EntityDetail object.
+                 *
+                 * An AtlasEntityHeader has:
+                 * String                    guid
+                 * AtlasEntity.Status        status
+                 * String                    displayText
+                 * List<String>              classificationNames
+                 * List<AtlasClassification> classifications
+                 */
+                AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+                try {
+
+                    atlasEntityWithExt = entityStore.getById(aeh.getGuid());
+
+                } catch (AtlasBaseException e) {
+
+                    LOG.error("findEntitiesByClassificationUsingDSL: Atlas entity store getById threw exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+                AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+                // Project the AtlasEntity as an EntityDetail
+
+                try {
+
+                    AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+                    EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+                    LOG.debug("findEntitiesByClassificationUsingDSL: om entity {}", omEntityDetail);
+                    returnList.add(omEntityDetail);
+
+                } catch (Exception e) {
+
+                    LOG.error("findEntitiesByClassificationUsingDSL: could not map AtlasEntity to EntityDetail, exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasEntity.getGuid(), "Atlas entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByClassificationUsingDSL(userId={}, entityTypeGUID={}, classificationName={}, matchClassificationProperties={}, matchCriteria={}, limitResultsByStatus={}): returnList={}",
+                    userId, entityTypeGUID, classificationName, matchClassificationProperties, matchCriteria, limitResultsByStatus, returnList);
+        }
+        return returnList;
+    }
+
+
+    private  List<EntityDetail>   findEntitiesByClassificationUsingSearchParameters(String               userId,
+                                                                                    String               classificationName,
+                                                                                    InstanceProperties   matchClassificationProperties,
+                                                                                    MatchCriteria        matchCriteria,
+                                                                                    List<InstanceStatus> limitResultsByStatus,
+                                                                                    int                  offset,
+                                                                                    int                  pageSize)
+
+
+            throws
+            PropertyErrorException,
+            RepositoryErrorException
+    {
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> findEntitiesByClassificationUsingSearchParameters(userId={}, classificationName={}, matchClassificationProperties={}, matchCriteria={}, limitResultsByStatus={})",
+                    userId, classificationName, matchClassificationProperties, matchCriteria, limitResultsByStatus);
+        }
+
+
+        final String methodName = "findEntitiesByClassificationUsingSearchParameters";
+
+        SearchParameters searchParameters = new SearchParameters();
+
+        searchParameters.setQuery(null);
+        searchParameters.setTypeName(null);
+        searchParameters.setClassification(classificationName);
+        searchParameters.setExcludeDeletedEntities(false);
+        searchParameters.setIncludeClassificationAttributes(false);
+        searchParameters.setIncludeSubTypes(false);
+        searchParameters.setIncludeSubClassifications(false);
+        searchParameters.setLimit(pageSize);
+        searchParameters.setOffset(offset);
+        searchParameters.setEntityFilters(null);
+        searchParameters.setAttributes(null);
+
+
+        searchParameters.setTagFilters(null);
+        if (matchClassificationProperties != null) {
+
+            SearchParameters.Operator operator;                    // applied to a single filter criterion
+            SearchParameters.FilterCriteria.Condition condition;   // applied to a list of filter criteria
+            if (matchCriteria == null) {
+                matchCriteria = MatchCriteria.ALL;                        // default to matchCriteria of ALL
+            }
+            switch (matchCriteria) {
+                case ALL:
+                    operator = EQ;
+                    condition = SearchParameters.FilterCriteria.Condition.AND;
+                    break;
+                case ANY:
+                    operator = EQ;
+                    condition = SearchParameters.FilterCriteria.Condition.OR;
+                    break;
+                case NONE:
+                    //operator = NEQ;
+                    //condition = SearchParameters.FilterCriteria.Condition.AND;
+                    //break;
+                default:
+                    LOG.error("findEntitiesByClassificationUsingSearchParameters: only supports matchCriteria ALL, ANY");
+                    return null;
+            }
+
+            List<SearchParameters.FilterCriteria> filterCriteriaList = new ArrayList<>();
+
+            Iterator<String> matchNames = matchClassificationProperties.getPropertyNames();
+            while (matchNames.hasNext()) {
+
+                // For the next property allocate and initialise a filter criterion and add it to the list...
+
+                // Extract the name and value as strings for the filter criterion
+                String matchPropertyName = matchNames.next();
+                boolean stringProp = false;
+                String strValue;
+                InstancePropertyValue matchValue = matchClassificationProperties.getPropertyValue(matchPropertyName);
+                InstancePropertyCategory cat = matchValue.getInstancePropertyCategory();
+                switch (cat) {
+                    case PRIMITIVE:
+                        // matchValue is a PPV
+                        PrimitivePropertyValue ppv = (PrimitivePropertyValue) matchValue;
+                        // Find out if this is a string property
+                        PrimitiveDefCategory pdc = ppv.getPrimitiveDefCategory();
+                        if (pdc == PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING) {
+                            String actualValue = ppv.getPrimitiveValue().toString();
+                            // Frame the actual value so it is suitable for regex search
+                            strValue = "'*" + actualValue + "*'";
+                            LOG.debug("findEntitiesByClassificationUsingSearchParameters: string property {} has filter value {}", matchPropertyName,strValue);
+                        }
+                        else {
+                            // We need a string for DSL query - this does not reflect the property type
+                            strValue = ppv.getPrimitiveValue().toString();
+                            LOG.debug("findEntitiesByClassificationUsingSearchParameters: non-string property {} has filter value {}", matchPropertyName,strValue);
+                        }
+                        break;
+                    case ARRAY:
+                    case MAP:
+                    case ENUM:
+                    case STRUCT:
+                    case UNKNOWN:
+                    default:
+                        LOG.error("findEntitiesByClassificationUsingSearchParameters: match property of cat {} not supported", cat);
+
+                        LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_PROPERTY_CATEGORY;
+
+                        String errorMessage = errorCode.getErrorMessageId()
+                                + errorCode.getFormattedErrorMessage(cat.toString(), methodName, repositoryName);
+
+                        throw new PropertyErrorException(errorCode.getHTTPErrorCode(),
+                                this.getClass().getName(),
+                                methodName,
+                                errorMessage,
+                                errorCode.getSystemAction(),
+                                errorCode.getUserAction());
+
+                }
+                // Set up a criterion for this property
+                SearchParameters.FilterCriteria filterCriterion = new SearchParameters.FilterCriteria();
+                filterCriterion.setAttributeName(matchPropertyName);
+                filterCriterion.setAttributeValue(strValue);
+                filterCriterion.setOperator(operator);
+                filterCriteriaList.add(filterCriterion);
+            }
+            // Finalize with a FilterCriteria that contains the list of FilterCriteria and applies the appropriate condition (based on matchCriteria)
+            SearchParameters.FilterCriteria tagFilters = new SearchParameters.FilterCriteria();
+            tagFilters.setCriterion(filterCriteriaList);
+            tagFilters.setCondition(condition);
+            searchParameters.setTagFilters(tagFilters);
+        }
+
+
+        AtlasSearchResult atlasSearchResult;
+        try {
+            atlasSearchResult = entityDiscoveryService.searchWithParameters(searchParameters);
+
+        } catch (AtlasBaseException e) {
+
+            LOG.error("findEntitiesByClassificationUsingSearchParameters: entity discovery service searchWithParameters threw exception", e);
+
+            OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage(classificationName, "classificationName", methodName, metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    methodName,
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        ArrayList<EntityDetail> returnList = null;
+
+        List<AtlasEntityHeader> atlasEntities = atlasSearchResult.getEntities();
+        if (atlasEntities != null) {
+            returnList = new ArrayList<>();
+            for (AtlasEntityHeader aeh : atlasEntities) {
+                if (limitResultsByStatus != null) {
+                    // Need to check that the AEH status is in the list of allowed status values
+                    AtlasEntity.Status atlasStatus = aeh.getStatus();
+                    InstanceStatus effectiveInstanceStatus = convertAtlasStatusToOMInstanceStatus(atlasStatus);
+                    boolean match = false;
+                    for (InstanceStatus allowedStatus : limitResultsByStatus) {
+                        if (effectiveInstanceStatus == allowedStatus) {
+                            match = true;
+                            break;
+                        }
+                    }
+                    if (!match) {
+                        continue;  // skip this AEH and process the next, if any remain
+                    }
+                }
+                // We need to use the AEH to look up the real AtlasEntity then we can use the relevant converter method
+                // to get an EntityDetail object.
+
+                // An AtlasEntityHeader has:
+                // String                    guid
+                // AtlasEntity.Status        status
+                // String                    displayText
+                // List<String>              classificationNames
+                // List<AtlasClassification> classifications
+                AtlasEntity.AtlasEntityWithExtInfo atlasEntityWithExt;
+                try {
+
+                    atlasEntityWithExt = entityStore.getById(aeh.getGuid());
+
+                } catch (AtlasBaseException e) {
+
+                    LOG.error("findEntitiesByClassificationUsingSearchParameters: entity store getById threw exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.ENTITY_NOT_KNOWN;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(aeh.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+                AtlasEntity atlasEntity = atlasEntityWithExt.getEntity();
+
+                // Project the AtlasEntity as an EntityDetail
+
+                try {
+
+                    AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(this, userId, atlasEntity);
+                    EntityDetail omEntityDetail = atlasEntityMapper.toEntityDetail();
+                    LOG.debug("findEntitiesByClassificationUsingSearchParameters: om entity {}", omEntityDetail);
+                    returnList.add(omEntityDetail);
+
+                } catch (Exception e) {
+
+                    LOG.error("findEntitiesByClassificationUsingSearchParameters: could not map AtlasEntity to EntityDetail, exception", e);
+
+                    OMRSErrorCode errorCode = OMRSErrorCode.INVALID_ENTITY_FROM_STORE;
+
+                    String errorMessage = errorCode.getErrorMessageId()
+                            + errorCode.getFormattedErrorMessage(atlasEntity.getGuid(), "entity GUID", methodName, metadataCollectionId);
+
+                    throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                            this.getClass().getName(),
+                            methodName,
+                            errorMessage,
+                            errorCode.getSystemAction(),
+                            errorCode.getUserAction());
+
+                }
+            }
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== findEntitiesByClassificationUsingSearchParameters(userId={}, classificationName={}, matchClassificationProperties={}, matchCriteria={}, limitResultsByStatus={}): returnList={}",
+                    userId, classificationName, matchClassificationProperties, matchCriteria, limitResultsByStatus, returnList);
+        }
+
+
+        return returnList;
+
+    }
+
+
+
+    /*
+     * Helper method to avoid needing to pass all the store references to the various mappers
+     */
+    List<TypeDefAttribute> convertAtlasAttributeDefs(String userId, List<AtlasStructDef.AtlasAttributeDef> aads)
+        throws
+            RepositoryErrorException,
+            TypeErrorException
+    {
+        // Get a mapper, do the conversion and pass back the result
+        AtlasAttributeDefMapper aadm;
+        try {
+            aadm = new AtlasAttributeDefMapper(this, userId, typeDefStore, typeRegistry, repositoryHelper, typeDefsForAPI, aads);
+        } catch (RepositoryErrorException e) {
+            LOG.error("convertAtlasAttributeDefs: could not create mapper", e);
+            throw e;
+        }
+        List<TypeDefAttribute> result = aadm.convertAtlasAttributeDefs();
+
+        return result;
+    }
+
+
+    /*
+     * Helper method for mappers so that they can retrieve Atlas types from the store
+     * The results can be filtered by Atlas TypeCategory if the filter param is not null
+     */
+
+    // package private
+    TypeDefLink constructTypeDefLink(String typeName, TypeCategory categoryFilter) {
+        TypeDefLink tdl = new TypeDefLink();
+        try {
+            AtlasBaseTypeDef atlasType = typeDefStore.getByName(typeName);
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                atlasType = typeDefStore.getByName(typeName);
+            }
+            else {
+                // Using registry
+                atlasType = typeRegistry.getTypeDefByName(typeName);
+            }
+            TypeCategory atlasCategory = atlasType.getCategory();
+            if (categoryFilter != null && atlasCategory != categoryFilter) {
+                // the category does not match the specific filter
+                return null;
+            }
+            else {
+                // there is no category filter or there is and the atlasCategory matches it
+                tdl.setName(typeName);
+                tdl.setGUID(atlasType.getGuid());
+            }
+        }
+        catch (AtlasBaseException e) {
+            return null;
+        }
+        return tdl;
+    }
+
+    /**
+     * Validate that type's identifier is not null.
+     *
+     * @param sourceName - source of the request (used for logging)
+     * @param guidParameterName - name of the parameter that passed the guid.
+     * @param guid - unique identifier for a type or an instance passed on the request
+     * @param methodName - method receiving the call
+     * @throws TypeErrorException - no guid provided
+     */
+    public  void validateTypeGUID(String userId,
+                                  String sourceName,
+                                  String guidParameterName,
+                                  String guid,
+                                  String methodName) throws TypeErrorException
+    {
+        if  (guid != null)
+        {
+            TypeDef foundDef;
+
+            try {
+                foundDef = _getTypeDefByGUID(userId, guid);
+            }
+            catch (Exception e) {
+                // swallow this exception - we are throwing TypeErrorException below, if def was not found
+                foundDef = null;
+            }
+
+            if (foundDef == null) {
+                OMRSErrorCode errorCode = OMRSErrorCode.TYPEDEF_ID_NOT_KNOWN;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(guid, guidParameterName, methodName, sourceName);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        methodName,
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+
+            }
+        }
+    }
+
+    /**
+     * Use the paging and sequencing parameters to format the results for a repository call that returns a list of
+     * entity instances.
+     *
+     * @param fullResults - the full list of results in an arbitrary order
+     * @param fromElement - the starting element number of the instances to return. This is used when retrieving elements
+     *                    beyond the first page of results. Zero means start from the first element.
+     * @param sequencingProperty - String name of the property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result entities that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return results array as requested
+     * @throws PropertyErrorException - the sequencing property specified is not valid for any of the requested types of
+     *                                  entity.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     */
+    private List<EntityDetail>    formatEntityResults(List<EntityDetail>   fullResults,
+                                                      int                  fromElement,
+                                                      String               sequencingProperty,
+                                                      SequencingOrder      sequencingOrder,
+                                                      int                  pageSize)
+            throws
+            PagingErrorException,
+            PropertyErrorException
+    {
+        if (fullResults == null)
+        {
+            return null;
+        }
+
+        if (fullResults.isEmpty())
+        {
+            return null;
+        }
+
+        if (fromElement > fullResults.size())
+        {
+            return null;
+        }
+
+        List<EntityDetail>  sortedResults = fullResults;
+        // TODO!! sort list according to properties
+
+        if ((pageSize == 0) || (pageSize > sortedResults.size()))
+        {
+            return sortedResults;
+        }
+
+        return new ArrayList<>(fullResults.subList(fromElement, fromElement + pageSize - 1));
+    }
+
+
+    /**
+     * Use the paging and sequencing parameters to format the results for a repository call that returns a list of
+     * entity instances.
+     *
+     * @param fullResults - the full list of results in an arbitrary order
+     * @param fromElement - the starting element number of the instances to return. This is used when retrieving elements
+     *                    beyond the first page of results. Zero means start from the first element.
+     * @param sequencingProperty - String name of the property that is to be used to sequence the results.
+     *                           Null means do not sequence on a property name (see SequencingOrder).
+     * @param sequencingOrder - Enum defining how the results should be ordered.
+     * @param pageSize - the maximum number of result entities that can be returned on this request.  Zero means
+     *                 unrestricted return results size.
+     * @return results array as requested
+     * @throws PropertyErrorException - the sequencing property specified is not valid for any of the requested types of
+     *                                  entity.
+     * @throws PagingErrorException - the paging/sequencing parameters are set up incorrectly.
+     */
+    private List<Relationship>    formatRelationshipResults(List<Relationship>   fullResults,
+                                                            int                  fromElement,
+                                                            String               sequencingProperty,
+                                                            SequencingOrder      sequencingOrder,
+                                                            int                  pageSize)
+            throws
+            PagingErrorException,
+            PropertyErrorException
+    {
+        if (fullResults == null)
+        {
+            return null;
+        }
+
+        if (fullResults.isEmpty())
+        {
+            return null;
+        }
+
+        if (fromElement > fullResults.size())
+        {
+            return null;
+        }
+
+        List<Relationship>  sortedResults = fullResults;
+        // TODO sort list according to properties
+
+        if ((pageSize == 0) || (pageSize > sortedResults.size()))
+        {
+            return sortedResults;
+        }
+
+        return new ArrayList<>(fullResults.subList(fromElement, fromElement + pageSize - 1));
+    }
+
+
+
+    private TypeDef convertAtlasTypeDefToOMTypeDef(String userId, AtlasBaseTypeDef abtd)
+        throws TypeErrorException, RepositoryErrorException
+    {
+
+        final String methodName = "convertAtlasTypeDefToOMTypeDef";
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> convertAtlasTypeDefToOMTypeDef: AtlasBaseTypeDef {}", abtd);
+        }
+
+        if (abtd == null) {
+            LOG.debug("convertAtlasTypeDefToOMTypeDef: cannot convert null type");
+
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("abtd", "convertAtlasTypeDefToOMTypeDef", metadataCollectionId);
+
+            throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "convertAtlasTypeDefToOMTypeDef",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+
+        }
+
+        String name = abtd.getName();
+
+        // Generate a candidate OM TypeDef
+        TypeDef candidateTypeDef;
+
+        // Find the category of the Atlas typedef and invoke the relevant conversion method.
+        // The only Atlas type categories that we can convert to OM TypeDef are:
+        // ENTITY, RELATIONSHIP & CLASSIFICATION
+        // Anything else we will bounce and return null.
+        // Each of the processAtlasXXXDef methods will convert from Atlas to OM,
+        // perform the RCM helper check, and finally populate the TDBC with the
+        // appropriate OM type.
+        // On return we just need to retrieve the TypeDef nd return it.
+        TypeCategory atlasCat = abtd.getCategory();
+        switch (atlasCat) {
+
+            case ENTITY:
+                // Detect whether the OM Type is one of the Famous Five
+                if (FamousFive.atlasTypeRequiresSubstitution(name)) {
+                    // Translate the type name
+                    name = FamousFive.getOMTypeName(name);
+                }
+                AtlasEntityDef atlasEntityDef = (AtlasEntityDef) abtd;
+                processAtlasEntityDef(userId, atlasEntityDef);
+                candidateTypeDef = typeDefsForAPI.getEntityDef(name);
+                break;
+
+            case RELATIONSHIP:
+                AtlasRelationshipDef atlasRelationshipDef = (AtlasRelationshipDef) abtd;
+                processAtlasRelationshipDef(userId, atlasRelationshipDef);
+                candidateTypeDef = typeDefsForAPI.getRelationshipDef(name);
+                break;
+
+            case CLASSIFICATION:
+                AtlasClassificationDef atlasClassificationDef = (AtlasClassificationDef) abtd;
+                processAtlasClassificationDef(userId, atlasClassificationDef);
+                candidateTypeDef = typeDefsForAPI.getClassificationDef(name);
+                break;
+
+            case PRIMITIVE:
+            case ENUM:
+            case ARRAY:
+            case MAP:
+            case STRUCT:
+            case OBJECT_ID_TYPE:
+            default:
+                LOG.debug("convertAtlasTypeDefToOMTypeDef: Atlas type has category cannot be converted to OM TypeDef, category {} ", atlasCat);
+                LocalAtlasOMRSErrorCode errorCode = LocalAtlasOMRSErrorCode.INVALID_TYPEDEF_CATEGORY;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage(atlasCat.toString(), name, methodName, repositoryName);
+
+                throw new TypeErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "convertAtlasTypeDefToOMTypeDef",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+        }
+
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("<== convertAtlasTypeDefToOMTypeDef: returning TypeDef {}", candidateTypeDef);
+        }
+        return candidateTypeDef;
+    }
+
+
+    // package-private
+    OMRSRepositoryHelper getRepositoryHelper() {
+        return this.repositoryHelper;
+    }
+
+    /*
+     * Utility method to validate status fields can be modelled in Atlas
+     */
+    private boolean validateStatusFields(TypeDef typeDef) {
+
+        // Validate the initialStatus and validInstanceStatus fields of the passed TypeDef
+        ArrayList<InstanceStatus> statusValuesCorrespondingToAtlas = new ArrayList<>(); // These are OM status values that relate to values valid in Atlas
+        statusValuesCorrespondingToAtlas.add(InstanceStatus.ACTIVE);
+        statusValuesCorrespondingToAtlas.add(InstanceStatus.DELETED);
+
+        InstanceStatus initialStatus = typeDef.getInitialStatus();
+        boolean isInitialStatusOK;
+        if (initialStatus != null) {
+            isInitialStatusOK = statusValuesCorrespondingToAtlas.contains(initialStatus);
+            if (isInitialStatusOK)
+                LOG.debug("validateStatusFields initialStatus {} is OK",initialStatus);
+            else
+                LOG.debug("validateStatusFields initialStatus {} is not OK",initialStatus);
+        } else {
+            isInitialStatusOK = true;
+            LOG.debug("validateStatusFields - initialStatus is null - which is OK",isInitialStatusOK);
+        }
+
+        List<InstanceStatus> validStatusList = typeDef.getValidInstanceStatusList();
+        boolean isStatusListOK = true;
+        if (validStatusList != null) {
+            for (InstanceStatus thisStatus : validStatusList) {
+                if (!statusValuesCorrespondingToAtlas.contains(thisStatus)) {
+                    isStatusListOK = false;
+                    LOG.debug("validateStatusFields - validInstanceStatusList contains {} - which is not OK",thisStatus);
+                    break;
+                }
+            }
+            if (isStatusListOK)
+                LOG.debug("validateStatusFields - all members of validInstanceStatusList are OK");
+        } else {
+            isStatusListOK = true;
+            LOG.debug("validateStatusFields - validInstanceStatusList is null - which is OK");
+        }
+
+        return (isInitialStatusOK && isStatusListOK);
+
+    }
+
+
+    /*
+     * Helper method for event mapper
+     */
+
+
+    public String _getTypeDefGUIDByAtlasTypeName(String userId,
+                                                 String atlasTypeName)
+            throws
+            RepositoryErrorException,
+            TypeDefNotKnownException
+    {
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getTypeDefGUIDByAtlasTypeName(userId={}, atlasTypeName={})", userId, atlasTypeName);
+        }
+        // Strategy:
+        // Check name is not null. null => throw
+        // Use Atlas typedef store getByName(), retrieve the GUID and return it.
+
+
+        // Look in the Atlas type def store
+
+        AtlasBaseTypeDef abtd;
+        try {
+            if (!useRegistry) {
+                // Look in the Atlas type def store
+                abtd = typeDefStore.getByName(atlasTypeName);
+            }
+            else {
+                // Using registry
+                abtd = typeRegistry.getTypeDefByName(atlasTypeName);
+            }
+
+        } catch (AtlasBaseException e) {
+
+            if (e.getAtlasErrorCode() == AtlasErrorCode.TYPE_NAME_NOT_FOUND) {
+                LOG.debug("_getTypeDefByName: Atlas does not have the type with name {} ", atlasTypeName);
+                // The AttributeTypeDef was not found - return null
+                return null;
+
+            } else {
+                LOG.error("_getTypeDefByName: Caught exception trying to retrieve Atlas type with name {} ", atlasTypeName, e);
+                OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+                String errorMessage = errorCode.getErrorMessageId()
+                        + errorCode.getFormattedErrorMessage("name", "_getTypeDefByName", metadataCollectionId);
+
+                throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                        this.getClass().getName(),
+                        "_getTypeDefByName",
+                        errorMessage,
+                        errorCode.getSystemAction(),
+                        errorCode.getUserAction());
+            }
+        }
+
+        if (abtd == null) {
+            LOG.debug("_getTypeDefByName: Atlas does not have the type with name {} ", atlasTypeName);
+            OMRSErrorCode errorCode = OMRSErrorCode.NO_TYPEDEF;
+            String errorMessage = errorCode.getErrorMessageId()
+                    + errorCode.getFormattedErrorMessage("name", "_getTypeDefByName", metadataCollectionId);
+
+            throw new RepositoryErrorException(errorCode.getHTTPErrorCode(),
+                    this.getClass().getName(),
+                    "_getTypeDefByName",
+                    errorMessage,
+                    errorCode.getSystemAction(),
+                    errorCode.getUserAction());
+        }
+
+
+        String typeDefGUID = abtd.getGuid();
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("==> _getTypeDefGUIDByAtlasTypeName: atlasTypeDefGUID={}", typeDefGUID);
+        }
+        return typeDefGUID;
+
+    }
+
+
+    public void setEventMapper(AtlasOMRSRepositoryEventMapper eventMapper) {
+        LOG.debug("setEventMapper: eventMapper being set to {}", eventMapper);
+        this.eventMapper = eventMapper;
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnector.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnector.java
new file mode 100644
index 000000000..4b6b21943
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnector.java
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryConnector;
+
+
+/**
+ * The LocalAtlasOMRSRepositoryConnector is a connector to a local Apache Atlas repository. This is the connector
+ * used by the EnterpriseOMRSRepositoryConnector to make a direct call to a local Atlas repository.
+ */
+public class LocalAtlasOMRSRepositoryConnector extends OMRSRepositoryConnector
+{
+    /**
+     * Default constructor used by the OCF Connector Provider.
+     */
+    public LocalAtlasOMRSRepositoryConnector()
+    {
+        /*
+         * Nothing to do (yet !)
+         */
+    }
+
+
+    /**
+     * Set up the unique Id for this metadata collection.
+     *
+     * @param metadataCollectionId - String unique Id
+     */
+    public void setMetadataCollectionId(String     metadataCollectionId)
+    {
+        this.metadataCollectionId = metadataCollectionId;
+
+        /*
+         * Initialize the metadata collection only once the connector is properly set up.
+         */
+        super.metadataCollection = new LocalAtlasOMRSMetadataCollection(
+                this,
+                super.serverName,
+                repositoryHelper,
+                repositoryValidator,
+                metadataCollectionId);
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnectorProvider.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnectorProvider.java
new file mode 100644
index 000000000..5996038eb
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/LocalAtlasOMRSRepositoryConnectorProvider.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector.OMRSRepositoryConnectorProviderBase;
+
+/**
+ * In the Open Connector Framework (OCF), a ConnectorProvider is a factory for a specific type of connector.
+ * The LocalAtlasOMRSRepositoryConnectorProvider is the connector provider for the LocalAtlasOMRSRepositoryConnector.
+ * It extends OMRSRepositoryConnectorProviderBase which in turn extends the OCF ConnectorProviderBase.
+ * ConnectorProviderBase supports the creation of connector instances.
+ *
+ * The LocalAtlasOMRSRepositoryConnectorProvider must initialize ConnectorProviderBase with the Java class
+ * name of the OMRS Connector implementation (by calling super.setConnectorClassName(className)).
+ * Then the connector provider will work.
+ */
+public class LocalAtlasOMRSRepositoryConnectorProvider extends OMRSRepositoryConnectorProviderBase
+{
+    /**
+     * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific
+     * OMRS Connector implementation.
+     */
+    public LocalAtlasOMRSRepositoryConnectorProvider()
+    {
+        Class connectorClass = LocalAtlasOMRSRepositoryConnector.class;
+
+        super.setConnectorClassName(connectorClass.getName());
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/SpringBridge.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/SpringBridge.java
new file mode 100644
index 000000000..bc9f72a20
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/SpringBridge.java
@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.discovery.EntityDiscoveryService;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+import org.apache.atlas.repository.store.graph.AtlasRelationshipStore;
+import org.apache.atlas.store.AtlasTypeDefStore;
+import org.apache.atlas.type.AtlasTypeRegistry;
+import org.springframework.beans.BeansException;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.context.ApplicationContext;
+import org.springframework.context.ApplicationContextAware;
+import org.springframework.stereotype.Component;
+
+/*
+ * This class provides a means of bridging between the Spring framework and
+ * the injection of the Atlas stores needed by the AtlasConnector.
+ */
+
+/**
+ * Register this SpringBridgeEventMapper as a Spring Component.
+ */
+@Component
+public class SpringBridge implements ISpringBridge, ApplicationContextAware {
+
+    private static ApplicationContext applicationContext;
+
+    @Autowired
+    private AtlasTypeDefStore typeDefStore;
+    @Autowired
+    private AtlasTypeRegistry typeRegistry;
+    @Autowired
+    private AtlasEntityStore entityStore;
+    @Autowired
+    private AtlasRelationshipStore relationshipStore;
+    @Autowired
+    private EntityDiscoveryService entityDiscoveryService;
+
+    @Override
+    public void setApplicationContext(ApplicationContext applicationContext)
+            throws BeansException {
+        this.applicationContext = applicationContext;
+    }
+
+    /**
+     * A static method to lookup the ISpringBridgeEventMapper Bean in
+     * the applicationContext. It is an instance of itself, which
+     * was registered by the @Component annotation.
+     *
+     * @return the ISpringBridgeEventMapper, which exposes all the
+     * Spring services that are bridged from the Spring context.
+     */
+    public static ISpringBridge services() {
+        return applicationContext.getBean(ISpringBridge.class);
+    }
+
+    @Override
+    public AtlasTypeRegistry getTypeRegistry() {
+        return typeRegistry;
+    }
+    @Override
+    public AtlasTypeDefStore getTypeDefStore() {
+        return typeDefStore;
+    }
+    @Override
+    public AtlasEntityStore getEntityStore() {
+        return entityStore;
+    }
+    @Override
+    public AtlasRelationshipStore getRelationshipStore() {
+        return relationshipStore;
+    }
+    @Override
+    public EntityDiscoveryService getEntityDiscoveryService() {
+        return entityDiscoveryService;
+    }
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeDefsByCategory.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeDefsByCategory.java
new file mode 100644
index 000000000..64ac675a7
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeDefsByCategory.java
@@ -0,0 +1,231 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Helper class to marshall typedefs as they are discovered - which can then be used for
+ * existence checks and can be projected as a list or gallery of lists in specified order
+ */
+
+public class TypeDefsByCategory {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TypeDefsByCategory.class);
+
+    private ArrayList<AttributeTypeDef> primitiveDefs      = null;
+    private ArrayList<AttributeTypeDef> collectionDefs     = null;
+    private ArrayList<AttributeTypeDef> enumDefs           = null;
+    private ArrayList<TypeDef>          entityDefs         = null;
+    private ArrayList<TypeDef>          relationshipDefs   = null;
+    private ArrayList<TypeDef>          classificationDefs = null;
+
+    public TypeDefsByCategory() {
+        primitiveDefs      = new ArrayList<>();
+        collectionDefs     = new ArrayList<>();
+        enumDefs           = new ArrayList<>();
+        entityDefs         = new ArrayList<>();
+        relationshipDefs   = new ArrayList<>();
+        classificationDefs = new ArrayList<>();
+    }
+
+    public TypeDefGallery convertTypeDefsToGallery() {
+        // Produce the output gallery by converting from this TypeDefsByCategory object
+        TypeDefGallery typeDefGallery = new TypeDefGallery();
+        ArrayList<AttributeTypeDef> attrTypeDefs = new ArrayList<>();
+        ArrayList<TypeDef> typeDefs = new ArrayList<>();
+        if (this.getPrimitiveDefs() != null)
+            attrTypeDefs.addAll(this.getPrimitiveDefs());
+        if (this.getCollectionDefs() != null)
+            attrTypeDefs.addAll(this.getCollectionDefs());
+        if (this.getEnumDefs() != null)
+            attrTypeDefs.addAll(this.getEnumDefs());
+        if (this.getEntityDefs() != null)
+            typeDefs.addAll(this.getEntityDefs());
+        if (this.getRelationshipDefs() != null)
+            typeDefs.addAll(this.getRelationshipDefs());
+        if (this.getClassificationDefs() != null)
+            typeDefs.addAll(this.getClassificationDefs());
+        typeDefGallery.setAttributeTypeDefs(attrTypeDefs);
+        typeDefGallery.setTypeDefs(typeDefs);
+        LOG.debug("TypeDefsByCategory: typeDefGallery {}", typeDefGallery);
+        return typeDefGallery;
+    }
+
+    public List<AttributeTypeDef> getPrimitiveDefs() {
+        return primitiveDefs;
+    }
+
+    public void setPrimitiveDefs(ArrayList<AttributeTypeDef> listPrimitiveDefs) {
+        primitiveDefs = listPrimitiveDefs;
+    }
+
+    public PrimitiveDef getPrimitiveDef(String name) {
+        if (primitiveDefs != null) {
+            for (AttributeTypeDef e : primitiveDefs) {
+                if (e.getName().equals(name))
+                    return (PrimitiveDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addPrimitiveDef(AttributeTypeDef def) {
+        if (getPrimitiveDef(def.getName()) == null) {
+            primitiveDefs.add(def);
+        }
+    }
+
+    public List<AttributeTypeDef> getCollectionDefs() {
+        return collectionDefs;
+    }
+
+    public void setCollectionDefs(ArrayList<AttributeTypeDef> listCollectionDefs) {
+        collectionDefs = listCollectionDefs;
+    }
+
+    public CollectionDef getCollectionDef(String name) {
+        if (collectionDefs != null) {
+            for (AttributeTypeDef e : collectionDefs) {
+                if (e.getName().equals(name))
+                    return (CollectionDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addCollectionDef(AttributeTypeDef def) {
+        if (getCollectionDef(def.getName()) == null) {
+            collectionDefs.add(def);
+        }
+    }
+
+    public List<AttributeTypeDef> getEnumDefs() {
+        return enumDefs;
+    }
+
+    public void setEnumDefs(ArrayList<AttributeTypeDef> listEnumDefs) {
+        enumDefs = listEnumDefs;
+    }
+
+    public EnumDef getEnumDef(String name) {
+        if (enumDefs != null) {
+            for (AttributeTypeDef e : enumDefs) {
+                if (e.getName().equals(name))
+                    return (EnumDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addEnumDef(AttributeTypeDef def) {
+        if (getEnumDef(def.getName()) == null) {
+            enumDefs.add(def);
+        }
+    }
+
+    public List<TypeDef> getEntityDefs() {
+        return entityDefs;
+    }
+
+    public void setEntityDefs(ArrayList<TypeDef> listEntityDefs) {
+        entityDefs = listEntityDefs;
+    }
+
+    public EntityDef getEntityDef(String name) {
+        if (entityDefs != null) {
+            for (TypeDef e : entityDefs) {
+                if (e.getName().equals(name))
+                    return (EntityDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addEntityDef(TypeDef def) {
+        if (getEntityDef(def.getName()) == null) {
+            entityDefs.add(def);
+        }
+    }
+
+    public List<TypeDef> getRelationshipDefs() {
+        return relationshipDefs;
+    }
+
+    public void setRelationshipDefs(ArrayList<TypeDef> listRelationshipDefs) {
+        relationshipDefs = listRelationshipDefs;
+    }
+
+    public RelationshipDef getRelationshipDef(String name) {
+        if (relationshipDefs != null) {
+            for (TypeDef e : relationshipDefs) {
+                if (e.getName().equals(name))
+                    return (RelationshipDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addRelationshipDef(TypeDef def) {
+        if (getRelationshipDef(def.getName()) == null) {
+            relationshipDefs.add(def);
+        }
+    }
+
+    public List<TypeDef> getClassificationDefs() {
+        return classificationDefs;
+    }
+
+    public void setClassificationDefs(ArrayList<TypeDef> listClassificationDefs) {
+        classificationDefs = listClassificationDefs;
+    }
+
+    public ClassificationDef getClassificationDef(String name) {
+        if (classificationDefs != null) {
+            for (TypeDef e : classificationDefs) {
+                if (e.getName().equals(name))
+                    return (ClassificationDef) e;
+            }
+        }
+        return null;
+    }
+
+    public void addClassificationDef(TypeDef def) {
+        if (getClassificationDef(def.getName()) == null) {
+            classificationDefs.add(def);
+        }
+    }
+
+    @Override
+    public String toString() {
+        return "TypeDefsByCategory{" +
+                "primitiveDefs=" + primitiveDefs +
+                ", collectionDefs=" + collectionDefs +
+                ", enumDefs=" + enumDefs +
+                ", entityDefs=" + entityDefs +
+                ", relationshipDefs=" + relationshipDefs +
+                ", classificationDefs=" + classificationDefs +
+                '}';
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeNameUtils.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeNameUtils.java
new file mode 100644
index 000000000..1ac391dcf
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TypeNameUtils.java
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.PrimitiveDefCategory;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.PrimitiveDefCategory.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.apache.atlas.model.typedef.AtlasBaseTypeDef.*;
+
+
+
+public class TypeNameUtils {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TypeNameUtils.class);
+
+    // Utility method to convert frm an Atlas typename to an OM primitive def category.
+    // Most of the Atlas types are primitives in Atlas but DAT is not - that doesn't matter
+    // as DATE is a primitive in OM so it is just a question of mapping the Atlas DATE
+    // type to the corresponding OM PrimitiveDefCategory.
+
+    // package-private
+    static PrimitiveDefCategory convertAtlasTypeNameToPrimitiveDefCategory(String name) {
+        switch (name) {
+            // No breaks because every case returns
+            case ATLAS_TYPE_BOOLEAN:
+                return OM_PRIMITIVE_TYPE_BOOLEAN;
+            case ATLAS_TYPE_BYTE:
+                return OM_PRIMITIVE_TYPE_BYTE;
+            case ATLAS_TYPE_SHORT:
+                return OM_PRIMITIVE_TYPE_SHORT;
+            case ATLAS_TYPE_INT:
+                return OM_PRIMITIVE_TYPE_INT;
+            case ATLAS_TYPE_LONG:
+                return OM_PRIMITIVE_TYPE_LONG;
+            case ATLAS_TYPE_FLOAT:
+                return OM_PRIMITIVE_TYPE_FLOAT;
+            case ATLAS_TYPE_DOUBLE:
+                return OM_PRIMITIVE_TYPE_DOUBLE;
+            case ATLAS_TYPE_BIGINTEGER:
+                return OM_PRIMITIVE_TYPE_BIGINTEGER;
+            case ATLAS_TYPE_BIGDECIMAL:
+                return OM_PRIMITIVE_TYPE_BIGDECIMAL;
+            case ATLAS_TYPE_STRING:
+                return OM_PRIMITIVE_TYPE_STRING;
+            case ATLAS_TYPE_DATE:
+                // Note - technically not a primitive in Atlas, but it is in OM
+                return OM_PRIMITIVE_TYPE_DATE;
+            default:
+                LOG.debug("Cannot map Atlas primitive type {}", name);
+                return OM_PRIMITIVE_TYPE_UNKNOWN;
+        }
+    }
+
+}
diff --git a/open-metadata/src/main/java/org/apache/atlas/openmetadata/admin/server/spring/OpenMetadataAdminResource.java b/open-metadata/src/main/java/org/apache/atlas/openmetadata/admin/server/spring/OpenMetadataAdminResource.java
new file mode 100644
index 000000000..c86f85e86
--- /dev/null
+++ b/open-metadata/src/main/java/org/apache/atlas/openmetadata/admin/server/spring/OpenMetadataAdminResource.java
@@ -0,0 +1,647 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.admin.server.spring;
+
+import org.apache.atlas.openmetadata.adapters.eventmapper.AtlasOMRSRepositoryEventMapperProvider;
+import org.apache.atlas.openmetadata.adapters.repositoryconnector.LocalAtlasOMRSMetadataCollection;
+import org.apache.atlas.openmetadata.adapters.repositoryconnector.LocalAtlasOMRSRepositoryConnectorProvider;
+import org.odpi.openmetadata.adapters.repositoryservices.ConnectorConfigurationFactory;
+import org.odpi.openmetadata.adapters.repositoryservices.graphrepository.repositoryconnector.GraphOMRSRepositoryConnectorProvider;
+import org.odpi.openmetadata.adminservices.OMAGServerAdminServices;
+import org.odpi.openmetadata.adminservices.configuration.properties.*;
+import org.odpi.openmetadata.adminservices.ffdc.OMAGErrorCode;
+import org.odpi.openmetadata.adminservices.ffdc.exception.OMAGCheckedExceptionBase;
+import org.odpi.openmetadata.adminservices.ffdc.exception.OMAGConfigurationErrorException;
+import org.odpi.openmetadata.adminservices.ffdc.exception.OMAGInvalidParameterException;
+import org.odpi.openmetadata.adminservices.ffdc.exception.OMAGNotAuthorizedException;
+import org.odpi.openmetadata.adminservices.properties.OMAGAPIResponse;
+import org.odpi.openmetadata.adminservices.properties.OMAGServerConfigResponse;
+import org.odpi.openmetadata.adminservices.properties.VoidResponse;
+import org.odpi.openmetadata.adminservices.store.OMAGServerConfigStore;
+import org.odpi.openmetadata.frameworks.connectors.Connector;
+import org.odpi.openmetadata.frameworks.connectors.ConnectorBroker;
+import org.odpi.openmetadata.frameworks.connectors.properties.beans.*;
+import org.odpi.openmetadata.repositoryservices.admin.OMRSConfigurationFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.web.bind.annotation.*;
+
+import java.util.List;
+import java.util.Map;
+import java.util.UUID;
+
+/**
+ * OpenMetadataAdminResource provides the spring annotations for the administrative
+ * interface for configuring the Open Metadata connector for Atlas.
+ * It provides the configuration properties and delegates administration requests
+ * to the Open Metadata Repository Services (OMRS).
+ * <p>
+ * There are four types of operations defined by the interface:
+ * </p>
+ * <ul>
+ * <li>
+ * Basic configuration - these methods use the minimum of configuration information to run the
+ * server using default properties.
+ * </li>
+ * <li>
+ * Advanced Configuration - provides access to all configuration properties to provide
+ * fine-grained control of the server.
+ * </li>
+ * <li>
+ * Initialization and shutdown - these methods control the initialization and shutdown of the
+ * open metadata and governance service instance based on the supplied configuration.
+ * </li>
+ * </ul>
+ */
+@RestController
+@RequestMapping("/open-metadata/admin-services/users/{userId}/servers/{serverName}")
+public class OpenMetadataAdminResource
+{
+
+    private static final Logger LOG = LoggerFactory.getLogger(OpenMetadataAdminResource.class);
+
+    private OMAGServerAdminServices adminAPI = new OMAGServerAdminServices();
+
+
+    /*
+     * =============================================================
+     * Help the client discover the type of the server
+     */
+
+
+    /**
+     * Return the origin of this server implementation.
+     *
+     * @return Open Metadata Server Origin
+     */
+    @RequestMapping(method = RequestMethod.GET, path = "/server-origin")
+    public String getServerOrigin()
+    {
+        return "Atlas Server";
+    }
+
+
+    /*
+     * =============================================================
+     * Configure server - basic options using defaults
+     */
+
+    /**
+     * Set up the root URL for this server that is used to construct full URL paths to calls for
+     * this server's REST interfaces.  The default value is "localhost:8080".
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param url  String url.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or serverURLRoot parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/server-url-root")
+    public VoidResponse setServerURLRoot(@PathVariable String userId,
+                                         @PathVariable String serverName,
+                                         @RequestParam String url)
+    {
+        return adminAPI.setServerURLRoot(userId, serverName, url);
+    }
+
+
+    /**
+     * Set up the descriptive type of the server.  This value is added to distributed events to
+     * make it easier to understand the source of events.  The default value is "Open Metadata and Governance Server".
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param typeName  short description for the type of server.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or serverType parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/server-type")
+    public VoidResponse setServerType(@PathVariable String userId,
+                                      @PathVariable String serverName,
+                                      @RequestParam String typeName)
+    {
+        return adminAPI.setServerType(userId, serverName, typeName);
+    }
+
+
+    /**
+     * Set up the name of the organization that is running this server.  This value is added to distributed events to
+     * make it easier to understand the source of events.  The default value is null.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param name  String name of the organization.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or organizationName parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/organization-name")
+    public VoidResponse setOrganizationName(@PathVariable String userId,
+                                            @PathVariable String serverName,
+                                            @RequestParam String name)
+    {
+        return adminAPI.setOrganizationName(userId, serverName, name);
+    }
+
+
+    /**
+     * Set up the user id to use when there is no external user driving the work (for example when processing events
+     * from another server).
+     *
+     * @param userId - user that is issuing the request.
+     * @param serverName - local server name.
+     * @param id - String user id for the server.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or serverURLRoot parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/server-user-id")
+    public VoidResponse setServerUserId(@PathVariable String userId,
+                                        @PathVariable String serverName,
+                                        @RequestParam String id)
+    {
+        return adminAPI.setServerUserId(userId, serverName, id);
+    }
+
+
+    /**
+     * Set an upper limit on the page size that can be requested on a REST call to the server.  The default
+     * value is 1000.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param limit  max number of elements that can be returned on a request.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or maxPageSize parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/max-page-size")
+    public VoidResponse setMaxPageSize(@PathVariable String  userId,
+                                       @PathVariable String  serverName,
+                                       @RequestParam int     limit)
+    {
+        return adminAPI.setMaxPageSize(userId, serverName, limit);
+    }
+
+
+    /**
+     * Set up the default event bus for embedding in event-driven connector.   The resulting connector will
+     * be used in the OMRS Topic Connector for each cohort, and the in and out topics for the local repository's
+     * event mapper.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName local server name.
+     * @param connectorProvider  connector provider for the event bus (if it is null then Kafka is assumed).
+     * @param topicURLRoot the common root of the topics used by the open metadata server.
+     * @param additionalProperties  property name/value pairs used to configure the connection to the event bus connector
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGConfigurationErrorException it is too late to configure the event bus - other configuration already exists or
+     * OMAGInvalidParameterException invalid serverName or serviceMode parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/event-bus")
+    public VoidResponse setEventBus(@PathVariable                   String              userId,
+                                    @PathVariable                   String              serverName,
+                                    @RequestParam(required = false) String              connectorProvider,
+                                    @RequestParam(required = false) String              topicURLRoot,
+                                    @RequestBody (required = false) Map<String, Object> additionalProperties)
+    {
+        return adminAPI.setEventBus(userId, serverName, connectorProvider, topicURLRoot, additionalProperties);
+    }
+
+    /**
+     * Provide the connection to the local repository - used when the local repository is Atlas.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or repositoryProxyConnection parameter or
+     * OMAGConfigurationErrorException the local repository mode has not been set
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/atlas-repository")
+    public VoidResponse setRepositoryProxyConnection(@PathVariable                    String     userId,
+                                                     @PathVariable                    String     serverName)
+
+    {
+        // No request body because this method will create an Atlas Connection object
+        LOG.debug("setRepositoryProxyConnection: userId={} serverName={}", userId, serverName);
+        Connection atlasConnection = getLocalAtlasRepositoryLocalConnection(serverName);
+        LOG.debug("setRepositoryProxyConnection: repository connector connection={} ", atlasConnection);
+        adminAPI.setRepositoryProxyConnection(userId, serverName, atlasConnection);
+        LOG.debug("setRepositoryProxyConnection: create connection for Atlas event mapper", userId, serverName);
+        Connection atlasEventMapperConnection = getAtlasEventMapperConnection(serverName);
+        LOG.debug("setRepositoryProxyConnection: event mapper connection={} ", atlasEventMapperConnection);
+        return adminAPI.setLocalRepositoryEventMapper(userId, serverName, atlasEventMapperConnection);
+    }
+
+
+    /**
+     * Provide the connection to the local repository - used when the local repository is Atlas.
+     *
+     * @param userId   user that is issuing the request.
+     * @param serverName   local server name.
+     * @param additionalProperties      additional parameters to pass to the repository connector
+     * @return void response or
+     * OMAGNotAuthorizedException     the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or repositoryProxyConnection parameter or
+     * OMAGConfigurationErrorException the local repository mode has not been set.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/atlas-repository/details")
+    public VoidResponse setRepositoryProxyConnection(@PathVariable                   String               userId,
+                                                     @PathVariable                   String               serverName,
+                                                     @RequestBody(required = false)  Map<String, Object>  additionalProperties)
+    {
+        LOG.debug("setRepositoryProxyConnection: userId={} serverName={}", userId, serverName);
+        String connectorProvider = "LocalAtlasOMRSRepositoryConnectorProvider";
+        LOG.debug("setRepositoryProxyConnection: additionalProperties={} ", additionalProperties);
+        return adminAPI.setRepositoryProxyConnection(userId, serverName, connectorProvider, additionalProperties);
+    }
+
+
+    /**
+     * Provide the connection to the local repository's event mapper if needed.  The default value is null which
+     * means no event mapper.  An event mapper is needed if the local repository has additional APIs that can change
+     * the metadata in the repository without going through the open metadata and governance services.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param connection  connection to the OMRS repository event mapper.
+     * @return void response
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or localRepositoryEventMapper parameter or
+     * OMAGConfigurationErrorException the local repository mode, or the event mapper has not been set
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/local-repository/event-mapper-connection")
+    public VoidResponse setLocalRepositoryEventMapper(@PathVariable String     userId,
+                                                      @PathVariable String     serverName,
+                                                      @RequestBody  Connection connection)
+    {
+        return adminAPI.setLocalRepositoryEventMapper(userId, serverName, connection);
+    }
+
+
+    /**
+     * Provide the connection to the local repository's event mapper if needed.  The default value is null which
+     * means no event mapper.  An event mapper is needed if the local repository has additional APIs that can change
+     * the metadata in the repository without going through the open metadata and governance services.
+     *
+     * @param userId                      user that is issuing the request.
+     * @param serverName                  local server name.
+     * @param connectorProvider           Java class name of the connector provider for the OMRS repository event mapper.
+     * @param eventSource                 topic name or URL to the native event source.
+     * @param additionalProperties        additional properties for the event mapper connection
+     * @return void response or
+     * OMAGNotAuthorizedException    the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or localRepositoryEventMapper parameter or
+     * OMAGConfigurationErrorException the local repository mode has not been set.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/local-repository/event-mapper-details")
+    public VoidResponse setLocalRepositoryEventMapper(@PathVariable                 String               userId,
+                                                      @PathVariable                 String               serverName,
+                                                      @RequestParam                 String               connectorProvider,
+                                                      @RequestParam                 String               eventSource,
+                                                      @RequestBody(required=false)  Map<String, Object>  additionalProperties)
+    {
+        return adminAPI.setLocalRepositoryEventMapper(userId, serverName, connectorProvider, eventSource, additionalProperties);
+    }
+
+
+    /**
+     * Enable registration of server to an open metadata repository cohort.  This is a group of open metadata
+     * repositories that are sharing metadata.  An Atlas server can connect to zero, one or more cohorts.
+     * Each cohort needs a unique name.  The members of the cohort use a shared topic to exchange registration
+     * information and events related to changes in their supported metadata types and instances.
+     * They are also able to query each other's metadata directly through REST calls.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param cohortName  name of the cohort.
+     * @param additionalProperties additional properties for the event bus connection
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName, cohortName or serviceMode parameter or
+     * OMAGConfigurationErrorException the event bus is not set.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/cohorts/{cohortName}")
+    public VoidResponse enableCohortRegistration(@PathVariable                   String               userId,
+                                                 @PathVariable                   String               serverName,
+                                                 @PathVariable                   String               cohortName,
+                                                 @RequestBody(required = false)  Map<String, Object>  additionalProperties)
+    {
+        return adminAPI.enableCohortRegistration(userId, serverName, cohortName, additionalProperties);
+    }
+
+
+    /**
+     * Unregister this server from an open metadata repository cohort.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param cohortName  name of the cohort.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName, cohortName or serviceMode parameter.
+     */
+    @RequestMapping(method = RequestMethod.DELETE, path = "/cohorts/{cohortName}")
+    public VoidResponse disableCohortRegistration(@PathVariable String          userId,
+                                                  @PathVariable String          serverName,
+                                                  @PathVariable String          cohortName)
+    {
+        return adminAPI.disableCohortRegistration(userId, serverName, cohortName);
+    }
+
+
+    /*
+     * =============================================================
+     * Configure server - advanced options overriding defaults
+     */
+
+    /**
+     * Set up the configuration for the local repository.  This overrides the current values.
+     *
+     * @param userId  user that is issuing the request.
+     * @param serverName  local server name.
+     * @param localRepositoryConfig  configuration properties for the local repository.
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName or localRepositoryConfig parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/local-repository/configuration")
+    public VoidResponse setLocalRepositoryConfig(@PathVariable String                userId,
+                                                 @PathVariable String                serverName,
+                                                 @RequestBody  LocalRepositoryConfig localRepositoryConfig)
+    {
+        return adminAPI.setLocalRepositoryConfig(userId, serverName, localRepositoryConfig);
+    }
+
+
+
+    /**
+     * Set up the configuration properties for a cohort.  This may reconfigure an existing cohort or create a
+     * cohort.  Use setCohortMode to delete a cohort.
+     *
+     * @param userId  user that is issuing the request
+     * @param serverName  local server name
+     * @param cohortName  name of the cohort
+     * @param cohortConfig  configuration for the cohort
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName, cohortName or cohortConfig parameter.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/cohorts/{cohortName}/configuration")
+    public VoidResponse setCohortConfig(@PathVariable String       userId,
+                                        @PathVariable String       serverName,
+                                        @PathVariable String       cohortName,
+                                        @RequestBody  CohortConfig cohortConfig)
+    {
+        return adminAPI.setCohortConfig(userId, serverName, cohortName, cohortConfig);
+    }
+
+
+    /*
+     * =============================================================
+     * Query current configuration
+     */
+
+
+    /**
+     * Return the stored configuration document for the server.
+     *
+     * @param userId  user that is issuing the request
+     * @param serverName  local server name
+     * @return OMAGServerConfig properties or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException invalid serverName parameter.
+     */
+    @RequestMapping(method = RequestMethod.GET, path = "/configuration")
+    public OMAGServerConfigResponse getCurrentConfiguration(@PathVariable String userId,
+                                                            @PathVariable String serverName)
+    {
+        return adminAPI.getCurrentConfiguration(userId, serverName);
+    }
+
+
+    /*
+     * ========================================================================================
+     * Activate and deactivate the open metadata and governance capabilities in the Atlas Server
+     */
+
+    /**
+     * Activate the open metadata and governance services using the stored configuration information.
+     *
+     * @param userId  user that is issuing the request
+     * @param serverName  local server name
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException the server name is invalid or
+     * OMAGConfigurationErrorException there is a problem using the supplied configuration.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/instance")
+    public VoidResponse activateWithStoredConfig(@PathVariable String userId,
+                                                 @PathVariable String serverName)
+    {
+        return adminAPI.activateWithStoredConfig(userId, serverName);
+    }
+
+
+    /**
+     * Activate the open metadata and governance services using the supplied configuration
+     * document.
+     *
+     * @param userId  user that is issuing the request
+     * @param configuration  properties used to initialize the services
+     * @param serverName  local server name
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException the server name is invalid or
+     * OMAGConfigurationErrorException there is a problem using the supplied configuration.
+     */
+    @RequestMapping(method = RequestMethod.POST, path = "/instance/configuration")
+    public VoidResponse activateWithSuppliedConfig(@PathVariable String           userId,
+                                                   @PathVariable String           serverName,
+                                                   @RequestParam OMAGServerConfig configuration)
+    {
+        return adminAPI.activateWithSuppliedConfig(userId, serverName, configuration);
+    }
+
+
+    /**
+     * Temporarily deactivate any open metadata and governance services.
+     *
+     * @param userId  user that is issuing the request
+     * @param serverName  local server name
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException the serverName is invalid.
+     */
+    @RequestMapping(method = RequestMethod.DELETE, path = "/instance")
+    public VoidResponse deactivateTemporarily(@PathVariable String  userId,
+                                              @PathVariable String  serverName)
+    {
+        return adminAPI.deactivateTemporarily(userId, serverName);
+    }
+
+
+    /**
+     * Permanently deactivate any open metadata and governance services and unregister from
+     * any cohorts.
+     *
+     * @param userId  user that is issuing the request
+     * @param serverName  local server name
+     * @return void response or
+     * OMAGNotAuthorizedException the supplied userId is not authorized to issue this command or
+     * OMAGInvalidParameterException the serverName is invalid.
+     */
+    @RequestMapping(method = RequestMethod.DELETE, path = "")
+    public VoidResponse deactivatePermanently(@PathVariable String  userId,
+                                              @PathVariable String  serverName)
+    {
+        return adminAPI.deactivatePermanently(userId, serverName);
+    }
+
+
+    /*
+     * Return an Atlas graph repository connection using the LocalAtlasOMRSRepositoryConnector.
+     *
+     * @param localServerName   name of the local server
+     * @return Connection object
+     */
+    private Connection getLocalAtlasRepositoryLocalConnection(String localServerName)
+    {
+        final String connectorTypeGUID = "9d086f0b-81e3-46ec-a4a9-520038e99c12";
+        final String connectionGUID    = "2119a4cd-2666-46dd-9487-c8b6122de59a";
+
+        final String connectorTypeDescription   = "Local Atlas OMRS repository connector type.";
+        final String connectorTypeJavaClassName = LocalAtlasOMRSRepositoryConnectorProvider.class.getName();
+
+        String connectorTypeName = "LocalAtlasOMRSRepository.ConnectorType." + localServerName;
+
+        ConnectorType connectorType = new ConnectorType();
+
+        connectorType.setType(this.getConnectorTypeType());
+        connectorType.setGUID(connectorTypeGUID);
+        connectorType.setQualifiedName(connectorTypeName);
+        connectorType.setDisplayName(connectorTypeName);
+        connectorType.setDescription(connectorTypeDescription);
+        connectorType.setConnectorProviderClassName(connectorTypeJavaClassName);
+
+
+        final String connectionDescription = "Local Atlas OMRS repository connection.";
+
+        String connectionName = "LocalAtlasOMRSRepository.Connection." + localServerName;
+
+        Connection connection = new Connection();
+
+        connection.setType(this.getConnectionType());
+        connection.setGUID(connectionGUID);
+        connection.setQualifiedName(connectionName);
+        connection.setDisplayName(connectionName);
+        connection.setDescription(connectionDescription);
+        connection.setConnectorType(connectorType);
+
+        return connection;
+    }
+
+
+    /*
+     * Return an Atlas repository event mapper connection.
+     *
+     * @param localServerName   name of the local server
+     * @return Connection object
+     */
+    private Connection getAtlasEventMapperConnection(String serverName) {
+
+        final String endpointGUID             = UUID.randomUUID().toString();
+        final String connectorTypeGUID        = UUID.randomUUID().toString();
+        final String connectionGUID           = UUID.randomUUID().toString();
+        final String endpointDescription      = "Atlas event mapper endpoint.";
+        final String connectorTypeDescription = "Atlas event mapper connector type.";
+        final String connectionDescription    = "Atlas event mapper connection.";
+        final String eventSource              = "Atlas repository notifications";
+
+        final String connectorProviderClassName = AtlasOMRSRepositoryEventMapperProvider.class.getName();
+
+        String endpointName    = "AtlasEventMapper.Endpoint." + serverName;
+
+        Endpoint endpoint = new Endpoint();
+
+        endpoint.setType(this.getEndpointType());
+        endpoint.setGUID(endpointGUID);
+        endpoint.setQualifiedName(endpointName);
+        endpoint.setDisplayName(endpointName);
+        endpoint.setDescription(endpointDescription);
+        endpoint.setAddress(eventSource);
+
+        String connectorTypeName = "AtlasEventMapper.ConnectorType." + serverName;
+
+        ConnectorType connectorType = new ConnectorType();
+
+        connectorType.setType(this.getConnectorTypeType());
+        connectorType.setGUID(connectorTypeGUID);
+        connectorType.setQualifiedName(connectorTypeName);
+        connectorType.setDisplayName(connectorTypeName);
+        connectorType.setDescription(connectorTypeDescription);
+        connectorType.setConnectorProviderClassName(connectorProviderClassName);
+
+        String connectionName = "AtlasEventMapper.Connection." + serverName;
+
+        Connection connection = new Connection();
+
+        connection.setType(this.getConnectionType());
+        connection.setGUID(connectionGUID);
+        connection.setQualifiedName(connectionName);
+        connection.setDisplayName(connectionName);
+        connection.setDescription(connectionDescription);
+        connection.setEndpoint(endpoint);
+        connection.setConnectorType(connectorType);
+
+        return connection;
+    }
+
+
+    private ElementType getConnectorTypeType()
+    {
+        ElementType elementType = ConnectorType.getConnectorTypeType();
+
+        elementType.setElementOrigin(ElementOrigin.CONFIGURATION);
+
+        return elementType;
+    }
+
+    private ElementType getConnectionType()
+    {
+        ElementType elementType = Connection.getConnectionType();
+
+        elementType.setElementOrigin(ElementOrigin.CONFIGURATION);
+
+        return elementType;
+    }
+
+    private ElementType getEndpointType()
+    {
+        ElementType elementType = Endpoint.getEndpointType();
+
+        elementType.setElementOrigin(ElementOrigin.CONFIGURATION);
+
+        return elementType;
+    }
+
+}
diff --git a/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasClassificationDefMapper.java b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasClassificationDefMapper.java
new file mode 100644
index 000000000..c959eba6d
--- /dev/null
+++ b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasClassificationDefMapper.java
@@ -0,0 +1,394 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyList;
+import static org.mockito.Matchers.anyString;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.fail;
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasClassificationDef;
+import org.apache.atlas.model.typedef.AtlasEntityDef;
+import org.apache.atlas.model.typedef.AtlasStructDef;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import java.util.*;
+
+/*
+ * Test the AtlasClassificationDefMapper component of the AtlasConnector
+ *
+ * The constructor is trivial; it is the toOMClassificationDef that is of primary interest.
+ *
+ */
+
+public class TestAtlasClassificationDefMapper {
+
+
+    private static final Logger LOG = LoggerFactory.getLogger(TestAtlasClassificationDefMapper.class);
+
+    // Background types - these are used and reused across multiple tests
+    private Map<String,TypeDefLink> backgroundEntityTypes = new HashMap<>();
+    private Map<String,TypeDefLink> backgroundClassificationTypes = new HashMap<>();
+
+    @BeforeClass
+    public void setup() {
+
+        TypeDefLink referenceable = new TypeDefLink(UUID.randomUUID().toString(),"Referenceable");
+        backgroundEntityTypes.put(referenceable.getName(), referenceable);
+
+        TypeDefLink asset = new TypeDefLink(UUID.randomUUID().toString(),"Asset");
+        backgroundEntityTypes.put(asset.getName(), asset);
+
+        TypeDefLink infrastructure = new TypeDefLink(UUID.randomUUID().toString(),"Infrastructure");
+        backgroundEntityTypes.put(infrastructure.getName(), infrastructure);
+
+        TypeDefLink process = new TypeDefLink(UUID.randomUUID().toString(),"Process");
+        backgroundEntityTypes.put(process.getName(), process);
+
+        TypeDefLink dataset = new TypeDefLink(UUID.randomUUID().toString(),"DataSet");
+        backgroundEntityTypes.put(dataset.getName(), dataset);
+
+        TypeDefLink type1 = new TypeDefLink(UUID.randomUUID().toString(),"type1");
+        backgroundEntityTypes.put(type1.getName(), type1);
+
+        TypeDefLink type2 = new TypeDefLink(UUID.randomUUID().toString(),"type2");
+        backgroundEntityTypes.put(type2.getName(), type2);
+
+        TypeDefLink type3 = new TypeDefLink(UUID.randomUUID().toString(),"type3");
+        backgroundEntityTypes.put(type3.getName(), type3);
+
+        TypeDefLink type10 = new TypeDefLink(UUID.randomUUID().toString(),"type10");
+        backgroundClassificationTypes.put(type10.getName(), type10);
+
+        TypeDefLink type11 = new TypeDefLink(UUID.randomUUID().toString(),"type11");
+        backgroundClassificationTypes.put(type11.getName(), type11);
+
+        TypeDefLink type12 = new TypeDefLink(UUID.randomUUID().toString(),"type12");
+        backgroundClassificationTypes.put(type12.getName(), type12);
+
+
+        /*
+         * Need to get valid responses from FamousFive, but cannot mock because static, so initialize it instead.
+         * The following calls populate the GUIDs as the names are mapped.
+         * This emulates the addition of the F5 types during OMRS startup.
+         */
+        FamousFive.getAtlasTypeName( referenceable.getName(),   referenceable.getGUID() );
+        FamousFive.getAtlasTypeName( asset.getName(),           asset.getGUID() );
+        FamousFive.getAtlasTypeName( infrastructure.getName(),  infrastructure.getGUID() );
+        FamousFive.getAtlasTypeName( process.getName(),         process.getGUID() );
+        FamousFive.getAtlasTypeName( dataset.getName(),         dataset.getGUID() );
+
+    }
+
+
+    /*
+     * Each object provided by the data provider is an AtlasEntityDef and the expected result.
+     *
+     */
+    public enum TestResult {
+        OK,
+        TypeErrorException
+    }
+
+    public class TestData {
+        String                 testCaption;
+        AtlasClassificationDef atlasClassificationDef;
+        TestResult             expectedResult;
+        List<TypeDefLink>      expectedSuperTypes;
+        List<TypeDefLink>      expectedValidEntityDefs;
+    }
+
+    @DataProvider(name = "provideAtlasClassificationDefs")
+    public Object[][] provideData() {
+
+
+        // 1. Test with no atlasClassificationDef
+        AtlasClassificationDef atlasClassificationDefNull = null;
+
+        // 2. AtlasClassificationDef with no name
+        AtlasClassificationDef atlasClassificationDefNoName = new AtlasClassificationDef();
+
+        // 3. AtlasClassificationDef with no guid
+        AtlasClassificationDef atlasClassificationDefNoGUID = new AtlasClassificationDef();
+        atlasClassificationDefNoGUID.setName(backgroundClassificationTypes.get("type10").getName());
+
+        // 4. AtlasClassificationDef with no version
+        AtlasClassificationDef atlasClassificationDefNoVersion = new AtlasClassificationDef();
+        atlasClassificationDefNoVersion.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefNoVersion.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+
+        // 5. AtlasClassificationDef with no supertype
+        AtlasClassificationDef atlasClassificationDefNotF5SupertypesNone = new AtlasClassificationDef();
+        atlasClassificationDefNotF5SupertypesNone.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefNotF5SupertypesNone.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefNotF5SupertypesNone.setVersion(7l);
+
+        // 6. AtlasClassificationDef with one supertype
+        // expected supertypes
+        List<TypeDefLink> expectedSuperTypes6 = new ArrayList<>();
+        TypeDefLink type11 = backgroundClassificationTypes.get("type11");
+        expectedSuperTypes6.add(type11);
+        // atlas classification def
+        // has type type10, supertype type11
+        AtlasClassificationDef atlasClassificationDefSupertypeOne = new AtlasClassificationDef();
+        atlasClassificationDefSupertypeOne.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefSupertypeOne.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefSupertypeOne.setVersion(7l);
+        Set<String> superTypes6 = new HashSet<>();
+        superTypes6.add(backgroundClassificationTypes.get("type11").getName());
+        atlasClassificationDefSupertypeOne.setSuperTypes(superTypes6);
+
+        // 7. AtlasClassificationDef with two supertypes
+        // atlas classification def
+        // has type type10, supertypes are type11 and type12 - should fail hence no expectedSuperTypes
+        AtlasClassificationDef atlasClassificationDefSupertypeTwo = new AtlasClassificationDef();
+        atlasClassificationDefSupertypeTwo.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefSupertypeTwo.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefSupertypeTwo.setVersion(7l);
+        Set<String> superTypes7 = new HashSet<>();
+        superTypes7.add("type11");
+        superTypes7.add("type12");
+        atlasClassificationDefSupertypeTwo.setSuperTypes(superTypes7);
+
+        // 8. AtlasClassificationDef with valid entity def
+        // expected valid entity defs
+        List<TypeDefLink> expectedValidEntityDefs8 = new ArrayList<>();
+        TypeDefLink type1 = backgroundEntityTypes.get("type1");
+        expectedValidEntityDefs8.add(type1);
+        // atlas classification def
+        // has type type10, validEntityDef of type1
+        AtlasClassificationDef atlasClassificationDefValidEntityDefOne = new AtlasClassificationDef();
+        atlasClassificationDefValidEntityDefOne.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefValidEntityDefOne.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefValidEntityDefOne.setVersion(7l);
+        Set<String> entityTypes8 = new HashSet<>();
+        entityTypes8.add("type1");
+        atlasClassificationDefValidEntityDefOne.setEntityTypes(entityTypes8);
+
+        // 9. AtlasClassificationDef with valid entity def in F5
+        // expected valid entity defs
+        List<TypeDefLink> expectedValidEntityDefs9 = new ArrayList<>();
+        TypeDefLink asset = backgroundEntityTypes.get("Asset");
+        expectedValidEntityDefs9.add(asset);
+        // atlas classification def
+        // has type type10, validEntityDef of Asset
+        AtlasClassificationDef atlasClassificationDefValidEntityDefOneF5 = new AtlasClassificationDef();
+        atlasClassificationDefValidEntityDefOneF5.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefValidEntityDefOneF5.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefValidEntityDefOneF5.setVersion(7l);
+        Set<String> entityTypes9 = new HashSet<>();
+        entityTypes9.add("OM_Asset");
+        atlasClassificationDefValidEntityDefOneF5.setEntityTypes(entityTypes9);
+
+
+        // 10. AtlasClassificationDef with attributes
+        // atlas classification def
+        // has type type10
+        AtlasClassificationDef atlasClassificationDefAttributeOne = new AtlasClassificationDef();
+        atlasClassificationDefAttributeOne.setName(backgroundClassificationTypes.get("type10").getName());
+        atlasClassificationDefAttributeOne.setGuid(backgroundClassificationTypes.get("type10").getGUID());
+        atlasClassificationDefAttributeOne.setVersion(7l);
+        // Attributes
+        AtlasStructDef.AtlasAttributeDef atlasAttr10_1 = new AtlasStructDef.AtlasAttributeDef("attr10_1","string");
+        List<AtlasStructDef.AtlasAttributeDef> atlasAttributeDefs = new ArrayList<>();
+        atlasAttributeDefs.add(atlasAttr10_1);
+        atlasClassificationDefAttributeOne.setAttributeDefs(atlasAttributeDefs);
+        Map<String,TypeDefAttribute> expectedAttributes10 = new HashMap<>();
+        TypeDefAttribute expectedAttribute10_1 = new TypeDefAttribute();
+        expectedAttribute10_1.setAttributeName("attr10_1");
+        AttributeTypeDef atd10_1 = new PrimitiveDef(OM_PRIMITIVE_TYPE_STRING);
+        atd10_1.setName("string");
+        expectedAttribute10_1.setAttributeType(atd10_1);
+        expectedAttributes10.put("1",expectedAttribute10_1);
+
+        Object[][] test_data = new Object[][] {
+                { "1. no entity def",     atlasClassificationDefNull,                 TestResult.TypeErrorException,  null,                 null,                      null},
+                { "2. no name",           atlasClassificationDefNoName,               TestResult.TypeErrorException,  null,                 null,                      null},
+                { "3. no guid",           atlasClassificationDefNoGUID,               TestResult.TypeErrorException,  null,                 null,                      null},
+                { "4. no version",        atlasClassificationDefNoVersion,            TestResult.TypeErrorException,  null,                 null,                      null},
+                { "5. no supertypes",     atlasClassificationDefNotF5SupertypesNone,  TestResult.OK,                  null,                 null,                      null},
+                { "6. one supertype",     atlasClassificationDefSupertypeOne,         TestResult.OK,                  expectedSuperTypes6,  null,                      null},
+                { "7. two supertypes",    atlasClassificationDefSupertypeTwo,         TestResult.TypeErrorException,  null,                 null,                      null},
+                { "8. valid entity def",  atlasClassificationDefValidEntityDefOne,    TestResult.OK,                  null,                 expectedValidEntityDefs8,  null},
+                { "9. F5 entity def",     atlasClassificationDefValidEntityDefOneF5,  TestResult.OK,                  null,                 expectedValidEntityDefs9,  null},
+                { "10. with attribute",   atlasClassificationDefAttributeOne,         TestResult.OK,                  null,                 null,                      expectedAttributes10},
+        };
+
+        return test_data;
+
+    }
+
+    /*
+     * Parameters to the test method:
+     * String            testCaption;
+     * AtlasClassificationDef    atlasClassificationDef;
+     * TestResult        expectedResult;
+     * List<TypeDefLink> expectedSuperTypes;
+     */
+    @Test(dataProvider = "provideAtlasClassificationDefs")
+    public void test_AtlasClassificationDef(String                       testCaption,
+                                            AtlasClassificationDef       atlasClassificationDef,
+                                            TestResult                   testResult,
+                                            List<TypeDefLink>            expectedSuperTypes,
+                                            List<TypeDefLink>            expectedValidEntityDefs,
+                                            Map<String,TypeDefAttribute> expectedAttributeDefs )
+            throws
+            RepositoryErrorException,  // not really thrown - but needed for when.thenReturn of getMetadataCollectionId()
+            TypeErrorException
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        // We are not testing the attributeDef conversion - just the handling of the attribute def list in classification def mapper
+        if (expectedAttributeDefs != null) {
+            ArrayList<TypeDefAttribute> expectedAttrDefList = new ArrayList<>();
+            Iterator<TypeDefAttribute> it = expectedAttributeDefs.values().iterator();
+            while (it.hasNext())
+                expectedAttrDefList.add(it.next());
+
+            when(metadataCollection.convertAtlasAttributeDefs(any(String.class),anyList())).thenReturn(expectedAttrDefList);
+        }
+        else
+            when(metadataCollection.convertAtlasAttributeDefs(any(String.class),anyList())).thenReturn(null);
+
+
+        /*
+         * Prepare the mock of constructTypeDefLink so that it will serve up names and guids of any background types
+         */
+        if (backgroundClassificationTypes != null) {
+            for (TypeDefLink backgroundType : backgroundClassificationTypes.values()) {
+                when(metadataCollection.constructTypeDefLink(backgroundType.getName(), TypeCategory.CLASSIFICATION)).
+                        thenReturn(backgroundType);
+            }
+        }
+        if (backgroundEntityTypes != null) {
+            for (TypeDefLink backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection.constructTypeDefLink(backgroundType.getName(), TypeCategory.ENTITY)).
+                        thenReturn(backgroundType);
+            }
+        }
+
+        String userId = "test_user";
+
+        ClassificationDef omClassificationDef = null;
+
+        LOG.debug("TestAtlasClassificationDefMapper: Construct AtlasClassificationDefMapper");
+        try {
+
+            AtlasClassificationDefMapper atlasClassificationDefMapper = new AtlasClassificationDefMapper(metadataCollection, userId, atlasClassificationDef);
+            omClassificationDef = atlasClassificationDefMapper.toOMClassificationDef();
+
+        } catch (TypeErrorException e) {
+            LOG.debug("TestAtlasClassificationDefMapper: Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug("TestAtlasClassificationDefMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasClassificationDefMapper: Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM EntityDef
+        assertNotNull(omClassificationDef);
+
+        Comparator c;
+        boolean match;
+
+        switch(testResult) {
+
+            case OK:
+                // Not using Comparator because we are directly comparing Atlas vs OM
+                // We know that atlasClassificationDef is not null
+
+                // OM ClassificationDef should have same name as Atlas ClassificationDef
+                String expectedName = atlasClassificationDef.getName();
+                assertEquals(omClassificationDef.getName(), expectedName);
+
+                // OM ClassificationDef should have same guid as AtlasClassificationDef
+                assertEquals(omClassificationDef.getGUID(), atlasClassificationDef.getGuid());
+
+                // OM ClassificationDef should have same version as AtlasClassificationDef
+                assertEquals(omClassificationDef.getVersion(), atlasClassificationDef.getVersion().longValue());
+
+                // OM ClassificationDef should have correct superTypes
+                if (expectedSuperTypes != null) {
+                    // Compare the supertypes
+                    c = new Comparator();
+                    match = c.compare(omClassificationDef.getSuperType(), expectedSuperTypes.get(0));
+                    assertEquals(match, true);
+                }
+
+                // OM ClassificationDef should have correct superTypes
+                if (expectedValidEntityDefs != null) {
+                    // Compare the supertypes
+                    c = new Comparator();
+                    match = c.compareListTypeDefLink(omClassificationDef.getValidEntityDefs(), expectedValidEntityDefs);
+                    assertEquals(match, true);
+                }
+
+                // Check the attributes are intact
+                if (expectedAttributeDefs != null) {
+                    TypeDefAttribute expectedAttr1TDA = expectedAttributeDefs.get("1");
+                    String expectedAttr1Name = expectedAttr1TDA.getAttributeName();
+                    String expectedAttr1TypeName = expectedAttr1TDA.getAttributeType().getName();
+                    List<TypeDefAttribute> propsDef = omClassificationDef.getPropertiesDefinition();
+                    LOG.debug("TestAtlasClassificationDefMapper: propsDef = {}", propsDef);
+                    TypeDefAttribute actualAttr1TDA = omClassificationDef.getPropertiesDefinition().get(0);
+                    String actualAttr1Name = expectedAttr1TDA.getAttributeName();
+                    String actualAttr1TypeName = expectedAttr1TDA.getAttributeType().getName();
+                    assertEquals(actualAttr1Name, expectedAttr1Name);
+                    assertEquals(actualAttr1TypeName, expectedAttr1TypeName);
+                }
+
+                LOG.debug("TestAtlasClassificationDefMapper: Test Passed");
+                break;
+
+
+            default:
+                LOG.debug("TestAtlasClassificationDefMapper: Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+}
diff --git a/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityDefMapper.java b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityDefMapper.java
new file mode 100644
index 000000000..161a8a659
--- /dev/null
+++ b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityDefMapper.java
@@ -0,0 +1,342 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyString;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.fail;
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasEntityDef;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.*;
+
+/*
+ * Test the AtlasEntityDefMapper component of the AtlasConnector
+ *
+ * The constructor is trivial; it is the toOMEntityDef that is of primary interest.
+ *
+ */
+public class TestAtlasEntityDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TestAtlasEntityDefMapper.class);
+
+    // Background types - these are used and reused across multiple tests
+    private Map<String,TypeDefLink> backgroundEntityTypes = new HashMap<>();
+
+    @BeforeClass
+    public void setup() {
+
+        TypeDefLink referenceable = new TypeDefLink(UUID.randomUUID().toString(),"Referenceable");
+        backgroundEntityTypes.put(referenceable.getName(), referenceable);
+
+        TypeDefLink asset = new TypeDefLink(UUID.randomUUID().toString(),"Asset");
+        backgroundEntityTypes.put(asset.getName(), asset);
+
+        TypeDefLink infrastructure = new TypeDefLink(UUID.randomUUID().toString(),"Infrastructure");
+        backgroundEntityTypes.put(infrastructure.getName(), infrastructure);
+
+        TypeDefLink process = new TypeDefLink(UUID.randomUUID().toString(),"Process");
+        backgroundEntityTypes.put(process.getName(), process);
+
+        TypeDefLink dataset = new TypeDefLink(UUID.randomUUID().toString(),"DataSet");
+        backgroundEntityTypes.put(dataset.getName(), dataset);
+
+        TypeDefLink type1 = new TypeDefLink(UUID.randomUUID().toString(),"type1");
+        backgroundEntityTypes.put(type1.getName(), type1);
+
+        TypeDefLink type2 = new TypeDefLink(UUID.randomUUID().toString(),"type2");
+        backgroundEntityTypes.put(type2.getName(), type2);
+
+        TypeDefLink type3 = new TypeDefLink(UUID.randomUUID().toString(),"type3");
+        backgroundEntityTypes.put(type3.getName(), type3);
+
+        /*
+         * Need to get valid responses from FamousFive, but cannot mock because static, so initialize it instead.
+         * The following calls populate the GUIDs as the names are mapped.
+         * This emulates the addition of the F5 types during OMRS startup.
+         */
+        FamousFive.getAtlasTypeName( referenceable.getName(),   referenceable.getGUID() );
+        FamousFive.getAtlasTypeName( asset.getName(),           asset.getGUID() );
+        FamousFive.getAtlasTypeName( infrastructure.getName(),  infrastructure.getGUID() );
+        FamousFive.getAtlasTypeName( process.getName(),         process.getGUID() );
+        FamousFive.getAtlasTypeName( dataset.getName(),         dataset.getGUID() );
+
+    }
+
+
+    /*
+     * Each object provided by the data provider is an AtlasEntityDef and the expected result.
+     *
+     */
+    public enum TestResult {
+        OK,
+        TypeErrorException
+    }
+
+    public class TestData {
+        String            testCaption;
+        AtlasEntityDef    atlasEntityDef;
+        TestResult        expectedResult;
+        List<TypeDefLink> expectedSuperTypes;
+    }
+
+    @DataProvider(name = "provideAtlasEntityDefs")
+    public Object[][] provideData() {
+
+
+        // 1. Test with no atlasEntityDef
+        AtlasEntityDef atlasEntityDefNull = null;
+
+        // 2. AtlasEntityDef with no name
+        AtlasEntityDef atlasEntityDefNoName = new AtlasEntityDef();
+
+        // 3. AtlasEntityDef with no guid
+        AtlasEntityDef atlasEntityDefNoGUID = new AtlasEntityDef();
+        atlasEntityDefNoGUID.setName(backgroundEntityTypes.get("type1").getName());
+
+        // 4. AtlasEntityDef with no version
+        AtlasEntityDef atlasEntityDefNoVersion = new AtlasEntityDef();
+        atlasEntityDefNoVersion.setName(backgroundEntityTypes.get("type1").getName());
+        atlasEntityDefNoVersion.setGuid(backgroundEntityTypes.get("type1").getGUID());
+
+        // 5. AtlasEntityDef with no supertype
+        AtlasEntityDef atlasEntityDefNotF5SupertypesNone = new AtlasEntityDef();
+        atlasEntityDefNotF5SupertypesNone.setName(backgroundEntityTypes.get("type1").getName());
+        atlasEntityDefNotF5SupertypesNone.setGuid(backgroundEntityTypes.get("type1").getGUID());
+        atlasEntityDefNotF5SupertypesNone.setVersion(7l);
+
+        // 6. AtlasEntityDef with one non-F5 supertype
+        // expected supertypes
+        List<TypeDefLink> expectedSuperTypes6 = new ArrayList<>();
+        TypeDefLink type2 = backgroundEntityTypes.get("type2");
+        expectedSuperTypes6.add(type2);
+        // atlas entity def
+        // has type backgroundType1, supertype is backgroundType2
+        AtlasEntityDef atlasEntityDefNotF5SupertypeOne = new AtlasEntityDef();
+        atlasEntityDefNotF5SupertypeOne.setName(backgroundEntityTypes.get("type1").getName());
+        atlasEntityDefNotF5SupertypeOne.setGuid(backgroundEntityTypes.get("type1").getGUID());
+        atlasEntityDefNotF5SupertypeOne.setVersion(7l);
+        Set<String> superTypes6 = new HashSet<>();
+        superTypes6.add(backgroundEntityTypes.get("type2").getName());
+        atlasEntityDefNotF5SupertypeOne.setSuperTypes(superTypes6);
+
+        // 7. AtlasEntityDef with two non-F5 supertypes
+        // atlas entity def
+        // has type type1, supertypes are type2 and type3 - should fail hence no expectedSuperTypes
+        AtlasEntityDef atlasEntityDefNotF5SupertypeTwo = new AtlasEntityDef();
+        atlasEntityDefNotF5SupertypeTwo.setName(backgroundEntityTypes.get("type1").getName());
+        atlasEntityDefNotF5SupertypeTwo.setGuid(backgroundEntityTypes.get("type1").getGUID());
+        atlasEntityDefNotF5SupertypeTwo.setVersion(7l);
+        Set<String> superTypes7 = new HashSet<>();
+        superTypes7.add("type2");
+        superTypes7.add("type3");
+        atlasEntityDefNotF5SupertypeTwo.setSuperTypes(superTypes7);
+
+        // 8. AtlasEntityDef with one F5 supertype
+        // expected supertypes
+        List<TypeDefLink> expectedSuperTypes8 = new ArrayList<>();
+        expectedSuperTypes8.add(backgroundEntityTypes.get("Referenceable"));
+        // atlas entity def
+        // has type type1, supertype is referenceable
+        AtlasEntityDef atlasEntityDefNotF5SupertypeOneF5 = new AtlasEntityDef();
+        atlasEntityDefNotF5SupertypeOneF5.setName(backgroundEntityTypes.get("type1").getName());
+        atlasEntityDefNotF5SupertypeOneF5.setGuid(backgroundEntityTypes.get("type1").getGUID());
+        atlasEntityDefNotF5SupertypeOneF5.setVersion(7l);
+        Set<String> superTypes8 = new HashSet<>();
+        // The Atlas supertype will be using the converted F5 name
+        superTypes8.add("OM_Referenceable");
+        atlasEntityDefNotF5SupertypeOneF5.setSuperTypes(superTypes8);
+
+        // 9. AtlasEntityDef F5 with no supertypes
+        // expected supertypes
+        // This configuration should throw an exception so no supertypes on completion
+        // atlas entity def
+        // has type type1, supertype is referenceable
+        AtlasEntityDef atlasEntityDefF5SupertypeNone = new AtlasEntityDef();
+        atlasEntityDefF5SupertypeNone.setName("OM_Referenceable");
+        atlasEntityDefF5SupertypeNone.setGuid(FamousFive.getRecordedGUID("Referenceable"));
+        atlasEntityDefF5SupertypeNone.setVersion(7l);
+        // Deliberately omit supertypes..
+
+        // 10. AtlasEntityDef F5 with one F5 supertype
+        // expected supertypes
+        // This configuration is one that should have no supertypes on completion
+        // atlas entity def
+        // has type type1, supertype is referenceable
+        AtlasEntityDef atlasEntityDefF5SupertypeOneF5 = new AtlasEntityDef();
+        atlasEntityDefF5SupertypeOneF5.setName("OM_Referenceable");
+        atlasEntityDefF5SupertypeOneF5.setGuid(FamousFive.getRecordedGUID("Referenceable"));
+        atlasEntityDefF5SupertypeOneF5.setVersion(7l);
+        Set<String> superTypes9 = new HashSet<>();
+        // The Atlas supertype is the auto-added original Atlas type
+        superTypes9.add("Referenceable");
+        atlasEntityDefF5SupertypeOneF5.setSuperTypes(superTypes9);
+
+
+        // 11. AtlasEntityDef F5 with two F5 supertypes
+        // expected supertypes
+        List<TypeDefLink> expectedSuperTypes11 = new ArrayList<>();
+        expectedSuperTypes11.add(backgroundEntityTypes.get("Referenceable"));
+        // This configuration is one that should have no supertypes on completion
+        // atlas entity def
+        // has type type1, supertype is referenceable
+        AtlasEntityDef atlasEntityDefF5SupertypeTwoF5 = new AtlasEntityDef();
+        atlasEntityDefF5SupertypeTwoF5.setName("OM_Asset");
+        atlasEntityDefF5SupertypeTwoF5.setGuid(FamousFive.getRecordedGUID("Asset"));
+        atlasEntityDefF5SupertypeTwoF5.setVersion(7l);
+        Set<String> superTypes11 = new HashSet<>();
+        // The Atlas supertype is the auto-added original Atlas type
+        superTypes11.add("OM_Referenceable");
+        superTypes11.add("Asset");
+        atlasEntityDefF5SupertypeTwoF5.setSuperTypes(superTypes11);
+
+
+
+        Object[][] test_data = new Object[][] {
+                { "1. no entity def",            atlasEntityDefNull,                 TestResult.TypeErrorException,  null},
+                { "2. no name",                  atlasEntityDefNoName,               TestResult.TypeErrorException,  null},
+                { "3. no guid",                  atlasEntityDefNoGUID,               TestResult.TypeErrorException,  null},
+                { "4. no version",               atlasEntityDefNoVersion,            TestResult.TypeErrorException,  null},
+                { "5. not F5 no supertypes",     atlasEntityDefNotF5SupertypesNone,  TestResult.OK,                  null},
+                { "6. not F5 one !F5 supertype", atlasEntityDefNotF5SupertypeOne,    TestResult.OK,                  expectedSuperTypes6},
+                { "7. not F5 one F5 supertype",  atlasEntityDefNotF5SupertypeTwo,    TestResult.TypeErrorException,  null},
+                { "8. not F5 one F5 supertype",  atlasEntityDefNotF5SupertypeOneF5,  TestResult.OK,                  expectedSuperTypes8},
+                { "9. not F5 no supertypes",     atlasEntityDefF5SupertypeNone,      TestResult.TypeErrorException,  null},
+                { "10. not F5 one F5 supertype", atlasEntityDefF5SupertypeOneF5,     TestResult.OK,                  null},
+                { "11. not F5 one F5 supertype", atlasEntityDefF5SupertypeTwoF5,     TestResult.OK,                  expectedSuperTypes11},
+        };
+
+        return test_data;
+
+    }
+
+    /*
+     * Parameters to the test method:
+     * String            testCaption;
+     * AtlasEntityDef    atlasEntityDef;
+     * TestResult        expectedResult;
+     * List<TypeDefLink> expectedSuperTypes;
+     */
+    @Test(dataProvider = "provideAtlasEntityDefs")
+    public void test_AtlasEntityDef(String             testCaption,
+                                    AtlasEntityDef     atlasEntityDef,
+                                    TestResult         testResult,
+                                    List<TypeDefLink>  expectedSuperTypes  )
+        throws
+            RepositoryErrorException  // not really thrown - but needed for when.thenReturn of getMetadataCollectionId()
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        /*
+         * Prepare the mock of constructTypeDefLink so that it will serve up names and guids of any background types
+         */
+        if (backgroundEntityTypes != null) {
+            for (TypeDefLink backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection.constructTypeDefLink(backgroundType.getName(),TypeCategory.ENTITY)).
+                        thenReturn(backgroundType);
+            }
+        }
+
+        String userId = "test_user";
+
+        EntityDef omEntityDef = null;
+
+        LOG.debug("TestAtlasEntityDefMapper: Construct AtlasEntityDefMapper");
+        try {
+
+            AtlasEntityDefMapper atlasEntityDefMapper = new AtlasEntityDefMapper(metadataCollection, userId, atlasEntityDef);
+            omEntityDef = atlasEntityDefMapper.toOMEntityDef();
+
+        } catch (TypeErrorException e) {
+            LOG.debug("TestAtlasEntityDefMapper: Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug("TestAtlasEntityDefMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasEntityDefMapper: Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM EntityDef
+        assertNotNull(omEntityDef);
+
+        Comparator c;
+        boolean match;
+
+        switch(testResult) {
+
+            case OK:
+                // Not using Comparator because we are directly comparing Atlas vs OM
+                // We know that atlasEntityDef is not null
+
+                // OM EntityDef should have same name as Atlas EntityDef unless F5
+                String expectedName = atlasEntityDef.getName();
+                if (FamousFive.atlasTypeRequiresSubstitution(atlasEntityDef.getName()))
+                    expectedName = FamousFive.getOMTypeName(atlasEntityDef.getName());
+                assertEquals(omEntityDef.getName(), expectedName);
+
+                // OM EntityDef should have same guid as Atlas EntityDef
+                assertEquals(omEntityDef.getGUID(), atlasEntityDef.getGuid());
+
+                // OM EntityDef should have same version as Atlas EntityDef
+                assertEquals(omEntityDef.getVersion(), atlasEntityDef.getVersion().longValue());
+
+                // OM EntityDef should have correct superTypes
+                if (expectedSuperTypes != null) {
+                    // Compare the supertypes
+                    c = new Comparator();
+                    match = c.compare(omEntityDef.getSuperType(), expectedSuperTypes.get(0));
+                    assertEquals(match, true);
+                }
+                LOG.debug("TestAtlasEntityDefMapper: Test Passed");
+                break;
+
+
+            default:
+                LOG.debug("TestAtlasEntityDefMapper: Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityMapper.java b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityMapper.java
new file mode 100644
index 000000000..c1f49008a
--- /dev/null
+++ b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasEntityMapper.java
@@ -0,0 +1,746 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.model.instance.AtlasClassification;
+import org.apache.atlas.model.instance.AtlasEntity;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.InvalidEntityException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeDefNotKnownException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+//import javax.print.DocFlavor;
+import java.util.*;
+
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.fail;
+
+
+/*
+ * Test the AtlasEntityMapper component of the AtlasConnector
+ *
+ * The constructor is trivial; it is the toOMEntityDetail, etc methods that are of primary interest.
+ *
+ */
+
+public class TestAtlasEntityMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TestAtlasEntityMapper.class);
+
+    // Background types - these are used and reused across multiple tests
+    private Map<String,TypeDef> backgroundEntityTypes = new HashMap<>();
+    private Map<String,TypeDef> backgroundClassificationTypes = new HashMap<>();
+
+
+    @BeforeClass
+    public void setup() {
+
+        TypeDef referenceable = new EntityDef();
+        referenceable.setName("Referenceable");
+        referenceable.setGUID(UUID.randomUUID().toString());
+        backgroundEntityTypes.put(referenceable.getName(), referenceable);
+
+        TypeDef asset = new EntityDef();
+        asset.setName("Asset");
+        asset.setGUID(UUID.randomUUID().toString());
+        backgroundEntityTypes.put(referenceable.getName(), asset);
+
+        TypeDef infrastructure = new EntityDef();
+        infrastructure.setName("Infrastructure");
+        infrastructure.setGUID(UUID.randomUUID().toString());
+        backgroundEntityTypes.put(referenceable.getName(), infrastructure);
+
+        TypeDef process = new EntityDef();
+        process.setName("Process");
+        process.setGUID(UUID.randomUUID().toString());
+        backgroundEntityTypes.put(referenceable.getName(), process);
+
+        TypeDef dataset = new EntityDef();
+        dataset.setName("DataSet");
+        dataset.setGUID(UUID.randomUUID().toString());
+        backgroundEntityTypes.put(referenceable.getName(), dataset);
+
+        // type1 entity def has no attributes defined
+        EntityDef type1 = new EntityDef();
+        type1.setName("type1");
+        type1.setGUID(UUID.randomUUID().toString());
+        //type1.setCategory(TypeDefCategory.ENTITY_DEF);
+        backgroundEntityTypes.put(type1.getName(), type1);
+
+        // type2 entity def has one string attribute called attr1 defined
+        // This is a unique attribute - it should appear in an EntityProxy
+        EntityDef type2 = new EntityDef();
+        type2.setName("type2");
+        type2.setGUID(UUID.randomUUID().toString());
+        //type2.setCategory(TypeDefCategory.ENTITY_DEF);
+        List<TypeDefAttribute> properties = new ArrayList<>();
+        TypeDefAttribute attr1Def = new TypeDefAttribute();
+        attr1Def.setAttributeName("attr1");
+        attr1Def.setUnique(true);
+        AttributeTypeDef atd1 = new PrimitiveDef(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING);
+        atd1.setName(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getName());
+        atd1.setGUID(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getGUID());
+        attr1Def.setAttributeType(atd1);
+        properties.add(attr1Def);
+        type2.setPropertiesDefinition(properties);
+        backgroundEntityTypes.put(type2.getName(), type2);
+
+
+        ClassificationDef type10 = new ClassificationDef();
+        type10.setName("type10");
+        type10.setGUID(UUID.randomUUID().toString());
+        type10.setCategory(TypeDefCategory.CLASSIFICATION_DEF);
+        backgroundClassificationTypes.put(type10.getName(), type10);
+
+
+        /*
+         * Need to get valid responses from FamousFive, but cannot mock because static, so initialize it instead.
+         * The following calls populate the GUIDs as the names are mapped.
+         * This emulates the addition of the F5 types during OMRS startup.
+         */
+        FamousFive.getAtlasTypeName( referenceable.getName(),   referenceable.getGUID() );
+        FamousFive.getAtlasTypeName( asset.getName(),           asset.getGUID() );
+        FamousFive.getAtlasTypeName( infrastructure.getName(),  infrastructure.getGUID() );
+        FamousFive.getAtlasTypeName( process.getName(),         process.getGUID() );
+        FamousFive.getAtlasTypeName( dataset.getName(),         dataset.getGUID() );
+
+    }
+
+
+    /*
+     * Each object provided by the data provider is an AtlasEntity and the expected result.
+     *
+     */
+    public enum TestResult {
+        OK,
+        TypeErrorException,
+        RepositoryErrorException,
+        InvalidEntityException,
+        OKForSummaryAndProxy        // if expected results get more complex then split this class into 2 or 3, by method under test
+    }
+
+    public class TestData {
+        String                 testCaption;
+        AtlasEntity            atlasEntity;
+        TestResult             expectedResult;
+    }
+
+    @DataProvider(name = "provideAtlasEntity")
+    public Object[][] provideData() {
+
+
+        // 1. Test with no atlasEntity
+        AtlasEntity atlasEntityNull = null;
+
+        // 2. Test with atlasEntity with unknown type
+        AtlasEntity atlasEntityUnknownType = new AtlasEntity();
+        atlasEntityUnknownType.setTypeName("unknown-type");
+
+        // 3. Test with atlasEntity with valid type
+        AtlasEntity atlasEntity = new AtlasEntity();
+        atlasEntity.setTypeName("type1");
+
+        // 4. Test with atlasEntity with null version
+        AtlasEntity atlasEntityVersionNull = new AtlasEntity();
+        atlasEntityVersionNull.setTypeName("type1");
+        atlasEntityVersionNull.setVersion(null);
+
+        // 5. Test with atlasEntity with homeId
+        AtlasEntity atlasEntityHomeId = new AtlasEntity();
+        atlasEntityHomeId.setTypeName("type1");
+        atlasEntityHomeId.setVersion(13L);
+        String a_homeId = "recognizable_metadata_collection_id";
+        atlasEntityHomeId.setHomeId(a_homeId);
+        // expected values
+        Map<String,Object> expectedFields5 = new HashMap<>();
+        expectedFields5.put("metadataCollectionId",a_homeId);
+
+        // 6. Test with atlasEntity with null homeId
+        AtlasEntity atlasEntityNullHomeId = new AtlasEntity();
+        atlasEntityNullHomeId.setTypeName("type1");
+        atlasEntityNullHomeId.setVersion(13L);
+        atlasEntityNullHomeId.setHomeId(null);
+        // expected values
+        Map<String,Object> expectedFields6 = new HashMap<>();
+        expectedFields6.put("metadataCollectionId",null);
+
+        // 7. Test with atlasEntity with status DELETED
+        AtlasEntity atlasEntityStatusDeleted = new AtlasEntity();
+        atlasEntityStatusDeleted.setTypeName("type1");
+        atlasEntityStatusDeleted.setVersion(13L);
+        atlasEntityStatusDeleted.setStatus(AtlasEntity.Status.DELETED);
+        // expected values
+        Map<String,Object> expectedFields7 = new HashMap<>();
+        expectedFields7.put("status", InstanceStatus.DELETED);
+
+        // 8. Test with atlasEntity with classification
+        AtlasEntity atlasEntityClassification = new AtlasEntity();
+        atlasEntityClassification.setTypeName("type1");
+        atlasEntityClassification.setVersion(13L);
+        String entityGUID = UUID.randomUUID().toString();
+        atlasEntityClassification.setGuid(entityGUID);
+        List<AtlasClassification> atlasClassifications8 = new ArrayList<>();
+        AtlasClassification atlasClassification8_1 = new AtlasClassification("type10");
+        atlasClassification8_1.setEntityGuid(entityGUID);
+        atlasClassifications8.add(atlasClassification8_1);
+        atlasEntityClassification.setClassifications(atlasClassifications8);
+        // expected values
+        Map<String,Object> expectedFields8 = new HashMap<>();
+        expectedFields8.put("entityGUID",entityGUID );
+        expectedFields8.put("classification_name","type10");
+
+        // Attributes - these are not represented in EntitySummary
+
+        // 9. Test with atlasEntity with undefined attribute (i.e. attribute not in EntityDef)
+        AtlasEntity atlasEntityWithUndefinedAttribute = new AtlasEntity();
+        atlasEntityWithUndefinedAttribute.setTypeName("type1");
+        atlasEntityWithUndefinedAttribute.setVersion(13L);
+        String entityGUID9 = UUID.randomUUID().toString();
+        atlasEntityWithUndefinedAttribute.setGuid(entityGUID9);
+        // attributes
+        Map<String, Object> atlasAttributes9 = new HashMap<>();
+        String attr9_1 = "attr9_1-value";
+        atlasAttributes9.put("attr9_1",attr9_1);
+        atlasEntityWithUndefinedAttribute.setAttributes(atlasAttributes9);
+        // expected values
+        Map<String,Object> expectedFields9 = new HashMap<>();
+        expectedFields9.put("attributes",null);
+
+        // 10. Test with atlasEntity with defined attribute (i.e. attribute in EntityDef)
+        AtlasEntity atlasEntityWithDefinedAttribute = new AtlasEntity();
+        atlasEntityWithDefinedAttribute.setTypeName("type2");
+        atlasEntityWithDefinedAttribute.setVersion(13L);
+        String entityGUID10 = UUID.randomUUID().toString();
+        atlasEntityWithDefinedAttribute.setGuid(entityGUID10);
+        // attributes
+        Map<String, Object> atlasAttributes10 = new HashMap<>();
+        String valueAttr10_1 = "test10-attr1-value";
+        atlasAttributes10.put("attr1", valueAttr10_1);
+        atlasEntityWithDefinedAttribute.setAttributes(atlasAttributes10);
+        // expected values
+        Map<String,Object> expectedFields10 = new HashMap<>();
+        InstanceProperties expectedProps10 = new InstanceProperties();
+        PrimitivePropertyValue instancePropertyValue10_1 = new PrimitivePropertyValue();
+        instancePropertyValue10_1.setPrimitiveDefCategory(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING);
+        instancePropertyValue10_1.setTypeName("string");
+        instancePropertyValue10_1.setTypeGUID(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getGUID());
+        instancePropertyValue10_1.setPrimitiveValue(valueAttr10_1);
+        expectedProps10.setProperty("attr1",instancePropertyValue10_1 );
+        expectedFields10.put("attributes",expectedProps10);
+
+        // 11. Test with atlasEntity with isProxy set to true
+        AtlasEntity atlasEntityProxy = new AtlasEntity();
+        atlasEntityProxy.setTypeName("type1");
+        atlasEntityProxy.setVersion(13L);
+        String homeId_11 = "recognizable_metadata_collection_id";
+        atlasEntityProxy.setHomeId(homeId_11);
+        atlasEntityProxy.setIsProxy(true);
+        // expected values
+        Map<String,Object> expectedFields11 = new HashMap<>();
+        expectedFields5.put("metadataCollectionId",homeId_11);
+
+
+        Object[][] test_data = new Object[][] {
+                { "1. no entity",           atlasEntityNull,                   TestResult.RepositoryErrorException, null},
+                { "2. entity unknown type", atlasEntityUnknownType,            TestResult.TypeErrorException,       null},
+                { "3. entity OK",           atlasEntity,                       TestResult.OK,                       null},
+                { "4. entity null version", atlasEntityVersionNull,            TestResult.InvalidEntityException,   null},
+                { "5. entity homeId",       atlasEntityHomeId,                 TestResult.OK,                       expectedFields5},
+                { "6. entity null homeId",  atlasEntityHomeId,                 TestResult.OK,                       expectedFields6},
+                { "7. entity DELETED",      atlasEntityStatusDeleted,          TestResult.OK,                       expectedFields7},
+                { "8. entity DELETED",      atlasEntityClassification,         TestResult.OK,                       expectedFields8},
+                { "9. entity undef attr",   atlasEntityWithUndefinedAttribute, TestResult.OK,                       expectedFields9},
+                { "10. entity def attr",    atlasEntityWithDefinedAttribute,   TestResult.OK,                       expectedFields10},
+                { "11. entity isProxy",     atlasEntityProxy,                  TestResult.OKForSummaryAndProxy,     expectedFields11},
+
+        };
+
+        return test_data;
+
+    }
+
+    /*
+     * Parameters to the test methods:
+     * String              testCaption;
+     * AtlasEntity         atlasEntity;
+     * TestResult          expectedResult;
+     * Map<String,Object>  expectedFields;
+     */
+
+    @Test(dataProvider = "provideAtlasEntity")
+    public void test_ToEntitySummary(String                       testCaption,
+                                     AtlasEntity                  atlasEntity,
+                                     TestResult                   testResult,
+                                     Map<String,Object>           expectedFields)
+            throws
+                TypeDefNotKnownException,
+                RepositoryErrorException
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        if (testResult == TestResult.OKForSummaryAndProxy) {
+            testResult = TestResult.OK;
+        }
+
+        String userId = "test_user";
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        if (backgroundEntityTypes != null) {
+            for (TypeDef backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).
+                        thenReturn(backgroundType);
+            }
+        }
+        if (backgroundClassificationTypes != null) {
+            for (TypeDef backgroundType : backgroundClassificationTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).thenReturn(backgroundType);
+            }
+        }
+
+
+
+
+        // Specifically testing EntitySummary
+
+        EntitySummary omEntitySummary = null;
+
+        LOG.debug("TestAtlasEntityMapper: Construct AtlasEntityMapper");
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(metadataCollection, userId, atlasEntity);
+            omEntitySummary = atlasEntityMapper.toEntitySummary();
+
+        } catch (TypeErrorException e) {
+            LOG.debug("TestAtlasEntityMapper: Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug("TestAtlasEntityMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasEntityMapper: Exception was unexpected");
+                fail();
+            }
+        } catch (RepositoryErrorException e) {
+            LOG.debug("TestAtlasEntityMapper: Caught RepositoryErrorException exception");
+            if (testResult.equals(TestResult.RepositoryErrorException)) {
+                LOG.debug("TestAtlasEntityMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasEntityMapper: Exception was unexpected");
+                fail();
+            }
+        }
+        catch (InvalidEntityException e) {
+            LOG.debug("TestAtlasEntityMapper: Caught InvalidEntityException exception");
+            if (testResult.equals(TestResult.InvalidEntityException)) {
+                LOG.debug("TestAtlasEntityMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasEntityMapper: Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM EntityDef
+        assertNotNull(omEntitySummary);
+
+        switch(testResult) {
+
+            case OK:
+
+                // OM EntitySummary should have same version as AtlasEntity
+                assertEquals(omEntitySummary.getVersion(), atlasEntity.getVersion().longValue());
+
+                // Check GUID
+                if (expectedFields != null && expectedFields.get("entityGUID") != null) {
+                    LOG.debug("TestAtlasEntityMapper: entity GUID {}", omEntitySummary.getGUID());
+                    assertEquals(omEntitySummary.getGUID(), expectedFields.get("entityGUID"));
+                }
+
+                // Check the InstanceType -
+                InstanceType instanceType = omEntitySummary.getType();
+                String typeName = instanceType.getTypeDefName();
+                assertEquals(typeName,atlasEntity.getTypeName());
+
+                // Check metadataCollectionId
+                assertEquals(omEntitySummary.getMetadataCollectionId(), atlasEntity.getHomeId());
+
+                // Check status
+                if (expectedFields != null && expectedFields.get("status") != null) {
+                    LOG.debug("TestAtlasEntityMapper: status {}", omEntitySummary.getStatus());
+                    assertEquals(omEntitySummary.getStatus(), expectedFields.get("status"));
+                }
+
+                // Check classifications
+                if (expectedFields != null && expectedFields.get("classification_name") != null) {
+                    LOG.debug("TestAtlasEntityMapper: classification name {}", omEntitySummary.getClassifications().get(0).getName());
+                    assertEquals(omEntitySummary.getClassifications().get(0).getName(), expectedFields.get("classification_name"));
+                }
+
+
+                LOG.debug("TestAtlasEntityMapper: Test Passed");
+                break;
+
+
+            default:
+                LOG.debug("TestAtlasEntityMapper: Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+
+    @Test(dataProvider = "provideAtlasEntity")
+    public void test_ToEntityDetail(String                       testCaption,
+                                    AtlasEntity                  atlasEntity,
+                                    TestResult                   testResult,
+                                    Map<String,Object>           expectedFields)
+            throws
+            TypeDefNotKnownException,
+            RepositoryErrorException
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        if (testResult == TestResult.OKForSummaryAndProxy) {
+            testResult = TestResult.InvalidEntityException;
+        }
+
+        final String methodName = "test_ToEntityDetail";
+
+        String userId = "test_user";
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        if (backgroundEntityTypes != null) {
+            for (TypeDef backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).
+                        thenReturn(backgroundType);
+            }
+        }
+        if (backgroundClassificationTypes != null) {
+            for (TypeDef backgroundType : backgroundClassificationTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).thenReturn(backgroundType);
+            }
+        }
+
+        // Specifically testing EntityDetail
+
+        EntityDetail omEntityDetail = null;
+
+        LOG.debug(methodName+": Construct AtlasEntityMapper");
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(metadataCollection, userId, atlasEntity);
+            omEntityDetail = atlasEntityMapper.toEntityDetail();
+
+        } catch (TypeErrorException e) {
+            LOG.debug(methodName+": Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (RepositoryErrorException e) {
+            LOG.debug(methodName+": Caught RepositoryErrorException exception");
+            if (testResult.equals(TestResult.RepositoryErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        }
+        catch (InvalidEntityException e) {
+            LOG.debug(methodName+": Caught InvalidEntityException exception");
+            if (testResult.equals(TestResult.InvalidEntityException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM EntityDef
+        assertNotNull(omEntityDetail);
+
+        switch(testResult) {
+
+            case OK:
+
+                // OM EntitySummary should have same version as AtlasEntity
+                assertEquals(omEntityDetail.getVersion(), atlasEntity.getVersion().longValue());
+
+                // Check GUID
+                if (expectedFields != null && expectedFields.get("entityGUID") != null) {
+                    LOG.debug(methodName+": entity GUID {}", omEntityDetail.getGUID());
+                    assertEquals(omEntityDetail.getGUID(), expectedFields.get("entityGUID"));
+                }
+
+                // Check the InstanceType -
+                InstanceType instanceType = omEntityDetail.getType();
+                String typeName = instanceType.getTypeDefName();
+                assertEquals(typeName,atlasEntity.getTypeName());
+
+                // Check metadataCollectionId
+                assertEquals(omEntityDetail.getMetadataCollectionId(), atlasEntity.getHomeId());
+
+                // Check status
+                if (expectedFields != null && expectedFields.get("status") != null) {
+                    LOG.debug(methodName+": status {}", omEntityDetail.getStatus());
+                    assertEquals(omEntityDetail.getStatus(), expectedFields.get("status"));
+                }
+
+                // Check classifications
+                if (expectedFields != null && expectedFields.get("classification_name") != null) {
+                    LOG.debug(methodName+": classification name {}", omEntityDetail.getClassifications().get(0).getName());
+                    assertEquals(omEntityDetail.getClassifications().get(0).getName(), expectedFields.get("classification_name"));
+                }
+
+                // check attributes
+                if (expectedFields != null && expectedFields.get("attributes") != null) {
+                    InstanceProperties actualProperties = omEntityDetail.getProperties();
+                    LOG.debug(methodName+": actualProperties {}", actualProperties);
+                    InstanceProperties expectedProperties = (InstanceProperties)(expectedFields.get("attributes"));
+                    LOG.debug(methodName+": expectedProperties {}", expectedProperties);
+                    // Test each expected property...
+                    Iterator<String> expectedPropertyNames = expectedProperties.getPropertyNames();
+                    while (expectedPropertyNames.hasNext()) {
+                        String propName = expectedPropertyNames.next();
+                        InstancePropertyValue expectedPropValue = expectedProperties.getPropertyValue(propName);
+                        InstancePropertyValue actualPropValue   = actualProperties.getPropertyValue(propName);
+                        assertEquals(expectedPropValue.getInstancePropertyCategory()  , actualPropValue.getInstancePropertyCategory());
+                        LOG.debug(methodName+": expected type {}",expectedPropValue.getTypeName());
+                        LOG.debug(methodName+": actual type {}", actualPropValue.getTypeName());
+                        assertEquals(expectedPropValue.getTypeName()  , actualPropValue.getTypeName());
+                        assertEquals(expectedPropValue.getTypeGUID()  , actualPropValue.getTypeGUID());
+                    }
+                }
+
+
+                LOG.debug(methodName+": Test Passed");
+                break;
+
+
+            default:
+                LOG.debug(methodName+": Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+
+
+    @Test(dataProvider = "provideAtlasEntity")
+    public void test_ToEntityProxy(String                       testCaption,
+                                   AtlasEntity                  atlasEntity,
+                                   TestResult                   testResult,
+                                   Map<String,Object>           expectedFields)
+            throws
+            TypeDefNotKnownException,
+            RepositoryErrorException
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        if (testResult == TestResult.OKForSummaryAndProxy) {
+            testResult = TestResult.OK;
+        }
+
+        final String methodName = "test_ToEntityProxy";
+
+        String userId = "test_user";
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        if (backgroundEntityTypes != null) {
+            for (TypeDef backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).
+                        thenReturn(backgroundType);
+            }
+        }
+        if (backgroundClassificationTypes != null) {
+            for (TypeDef backgroundType : backgroundClassificationTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).thenReturn(backgroundType);
+            }
+        }
+
+        // Specifically testing EntityProxy
+
+        EntityProxy omEntityProxy = null;
+
+        LOG.debug(methodName+": Construct AtlasEntityMapper");
+        try {
+
+            AtlasEntityMapper atlasEntityMapper = new AtlasEntityMapper(metadataCollection, userId, atlasEntity);
+            omEntityProxy = atlasEntityMapper.toEntityProxy();
+
+        } catch (TypeErrorException e) {
+            LOG.debug(methodName+": Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (RepositoryErrorException e) {
+            LOG.debug(methodName+": Caught RepositoryErrorException exception");
+            if (testResult.equals(TestResult.RepositoryErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        }
+        catch (InvalidEntityException e) {
+            LOG.debug(methodName+": Caught InvalidEntityException exception");
+            if (testResult.equals(TestResult.InvalidEntityException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM EntityDef
+        assertNotNull(omEntityProxy);
+
+        switch(testResult) {
+
+            case OK:
+
+                // OM EntitySummary should have same version as AtlasEntity
+                assertEquals(omEntityProxy.getVersion(), atlasEntity.getVersion().longValue());
+
+                // Check GUID
+                if (expectedFields != null && expectedFields.get("entityGUID") != null) {
+                    LOG.debug(methodName+": entity GUID {}", omEntityProxy.getGUID());
+                    assertEquals(omEntityProxy.getGUID(), expectedFields.get("entityGUID"));
+                }
+
+                // Check the InstanceType -
+                InstanceType instanceType = omEntityProxy.getType();
+                String typeName = instanceType.getTypeDefName();
+                assertEquals(typeName,atlasEntity.getTypeName());
+
+                // Check metadataCollectionId
+                assertEquals(omEntityProxy.getMetadataCollectionId(), atlasEntity.getHomeId());
+
+                // Check status
+                if (expectedFields != null && expectedFields.get("status") != null) {
+                    LOG.debug(methodName+": status {}", omEntityProxy.getStatus());
+                    assertEquals(omEntityProxy.getStatus(), expectedFields.get("status"));
+                }
+
+                // Check classifications
+                if (expectedFields != null && expectedFields.get("classification_name") != null) {
+                    LOG.debug(methodName+": classification name {}", omEntityProxy.getClassifications().get(0).getName());
+                    assertEquals(omEntityProxy.getClassifications().get(0).getName(), expectedFields.get("classification_name"));
+                }
+
+                // check attributes
+                if (expectedFields != null && expectedFields.get("attributes") != null) {
+                    InstanceProperties actualProperties = omEntityProxy.getUniqueProperties();
+                    LOG.debug(methodName+": actualProperties {}", actualProperties);
+                    InstanceProperties expectedProperties = (InstanceProperties)(expectedFields.get("attributes"));
+                    LOG.debug(methodName+": expectedProperties {}", expectedProperties);
+
+                    // Test each expected property...
+                    Iterator<String> expectedPropertyNames = expectedProperties.getPropertyNames();
+                    while (expectedPropertyNames.hasNext()) {
+                        String propName = expectedPropertyNames.next();
+                        // For entityProxy need to filter out any non-unique attributes...
+                        InstanceType instanceType1 = omEntityProxy.getType();
+                        String typeName1 = instanceType1.getTypeDefName();
+                        TypeDef td1 = backgroundEntityTypes.get(typeName1);
+                        List<TypeDefAttribute> typeDefAttributes = td1.getPropertiesDefinition();
+                        for (TypeDefAttribute tda : typeDefAttributes ) {
+                            if (tda.getAttributeType().getName().equals(propName)) {
+                                // check whether unique - if so check it - otherwise skip this attribute
+                                if (tda.isUnique()) {
+                                    InstancePropertyValue expectedPropValue = expectedProperties.getPropertyValue(propName);
+                                    InstancePropertyValue actualPropValue   = actualProperties.getPropertyValue(propName);
+                                    assertEquals(expectedPropValue.getInstancePropertyCategory()  , actualPropValue.getInstancePropertyCategory());
+                                    LOG.debug(methodName+": expected type {}",expectedPropValue.getTypeName());
+                                    LOG.debug(methodName+": actual type {}", actualPropValue.getTypeName());
+                                    assertEquals(expectedPropValue.getTypeName()  , actualPropValue.getTypeName());
+                                    assertEquals(expectedPropValue.getTypeGUID()  , actualPropValue.getTypeGUID());
+                                }
+                            }
+                        }
+                    }
+                }
+
+
+                LOG.debug(methodName+": Test Passed");
+                break;
+
+
+            default:
+                LOG.debug(methodName+": Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+
+}
\ No newline at end of file
diff --git a/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipDefMapper.java b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipDefMapper.java
new file mode 100644
index 000000000..f3ba5505a
--- /dev/null
+++ b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipDefMapper.java
@@ -0,0 +1,514 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+
+import org.apache.atlas.exception.AtlasBaseException;
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.typedef.AtlasRelationshipDef;
+import org.apache.atlas.model.typedef.AtlasRelationshipEndDef;
+import org.apache.atlas.model.typedef.AtlasStructDef;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.RepositoryErrorException;
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.TypeErrorException;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyList;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.fail;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.*;
+
+
+/*
+ * Test the AtlasRelationshipDefMapper component of the AtlasConnector
+ *
+ * The constructor is trivial; it is the toOMRelationshipDef that is of primary interest.
+ *
+ */
+public class TestAtlasRelationshipDefMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TestAtlasRelationshipDefMapper.class);
+
+    // Background types - these are used and reused across multiple tests
+    private Map<String,TypeDefLink> backgroundEntityTypes = new HashMap<>();
+    private Map<String,TypeDefLink> backgroundRelationshipTypes = new HashMap<>();
+
+    @BeforeClass
+    public void setup() {
+
+        TypeDefLink referenceable = new TypeDefLink(UUID.randomUUID().toString(),"Referenceable");
+        backgroundEntityTypes.put(referenceable.getName(), referenceable);
+
+        TypeDefLink asset = new TypeDefLink(UUID.randomUUID().toString(),"Asset");
+        backgroundEntityTypes.put(asset.getName(), asset);
+
+        TypeDefLink infrastructure = new TypeDefLink(UUID.randomUUID().toString(),"Infrastructure");
+        backgroundEntityTypes.put(infrastructure.getName(), infrastructure);
+
+        TypeDefLink process = new TypeDefLink(UUID.randomUUID().toString(),"Process");
+        backgroundEntityTypes.put(process.getName(), process);
+
+        TypeDefLink dataset = new TypeDefLink(UUID.randomUUID().toString(),"DataSet");
+        backgroundEntityTypes.put(dataset.getName(), dataset);
+
+        TypeDefLink type1 = new TypeDefLink(UUID.randomUUID().toString(),"type1");
+        backgroundEntityTypes.put(type1.getName(), type1);
+
+        TypeDefLink type2 = new TypeDefLink(UUID.randomUUID().toString(),"type2");
+        backgroundEntityTypes.put(type2.getName(), type2);
+
+        TypeDefLink type3 = new TypeDefLink(UUID.randomUUID().toString(),"type3");
+        backgroundEntityTypes.put(type3.getName(), type3);
+
+        TypeDefLink type4 = new TypeDefLink(UUID.randomUUID().toString(),"type4");
+        backgroundRelationshipTypes.put(type4.getName(), type4);
+
+        TypeDefLink type5 = new TypeDefLink(UUID.randomUUID().toString(),"type5");
+        backgroundRelationshipTypes.put(type5.getName(), type5);
+
+        /*
+         * Need to get valid responses from FamousFive, but cannot mock because static, so initialize it instead.
+         * The following calls populate the GUIDs as the names are mapped.
+         * This emulates the addition of the F5 types during OMRS startup.
+         */
+        FamousFive.getAtlasTypeName( referenceable.getName(),   referenceable.getGUID() );
+        FamousFive.getAtlasTypeName( asset.getName(),           asset.getGUID() );
+        FamousFive.getAtlasTypeName( infrastructure.getName(),  infrastructure.getGUID() );
+        FamousFive.getAtlasTypeName( process.getName(),         process.getGUID() );
+        FamousFive.getAtlasTypeName( dataset.getName(),         dataset.getGUID() );
+
+    }
+
+
+    /*
+     * Each object provided by the data provider is an AtlasRelationshipDef and the expected result.
+     *
+     */
+    public enum TestResult {
+        OK,
+        TypeErrorException
+    }
+
+    public class TestData {
+        String                           testCaption;
+        AtlasRelationshipDef             atlasRelationshipDef;
+        TestResult                       expectedResult;
+        Map<String,RelationshipEndDef>   expectedEnds;
+        Map<String,TypeDefAttribute>     expectedAttributes;
+    }
+
+    @DataProvider(name = "provideAtlasRelationshipDefs")
+    public Object[][] provideData() {
+
+
+        // 1. Test with no atlasRelationshipDef
+        AtlasRelationshipDef atlasRelationshipDefNull = null;
+
+        // 2. AtlasRelationshipDef with no name
+        AtlasRelationshipDef atlasRelationshipDefNoName;
+        try {
+            atlasRelationshipDefNoName = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+
+        // 3. AtlasRelationshipDef with no guid
+        AtlasRelationshipDef atlasRelationshipDefNoGUID;
+        try {
+            atlasRelationshipDefNoGUID = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefNoGUID.setName(backgroundRelationshipTypes.get("type4").getName());
+
+        // 4. AtlasRelationshipDef with no version
+        AtlasRelationshipDef atlasRelationshipDefNoVersion;
+        try {
+            atlasRelationshipDefNoVersion = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefNoVersion.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefNoVersion.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+
+        // 5. AtlasRelationshipDef with no ends
+        AtlasRelationshipDef atlasRelationshipDefNoEnds;
+        try {
+            atlasRelationshipDefNoEnds = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefNoEnds.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefNoEnds.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefNoEnds.setVersion(7l);
+
+
+        // 6. AtlasRelationshipDef with ends but no relationship category
+        AtlasRelationshipDef atlasRelationshipDefNoCat;
+        try {
+            atlasRelationshipDefNoCat = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefNoCat.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefNoCat.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefNoCat.setVersion(7l);
+        // Get some ends...
+        AtlasRelationshipEndDef ared1 = new AtlasRelationshipEndDef("type1","test6_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        AtlasRelationshipEndDef ared2 = new AtlasRelationshipEndDef("type2","test6_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        atlasRelationshipDefNoCat.setEndDef1(ared1);
+        atlasRelationshipDefNoCat.setEndDef2(ared2);
+
+        // 7. AtlasRelationshipDef with ends and relationship category but no prop tags
+        AtlasRelationshipDef atlasRelationshipDefNoPropTags;
+        try {
+            atlasRelationshipDefNoPropTags = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefNoPropTags.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefNoPropTags.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefNoPropTags.setVersion(7l);
+        // Get some ends...
+        AtlasRelationshipEndDef ared7_1 = new AtlasRelationshipEndDef("type1","test7_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        AtlasRelationshipEndDef ared7_2 = new AtlasRelationshipEndDef("type2","test7_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        atlasRelationshipDefNoPropTags.setEndDef1(ared7_1);
+        atlasRelationshipDefNoPropTags.setEndDef2(ared7_2);
+        atlasRelationshipDefNoPropTags.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+
+        // 8. AtlasRelationshipDef between non-F5 entity types
+        AtlasRelationshipDef atlasRelationshipDef;
+        try {
+            atlasRelationshipDef = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDef.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDef.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDef.setVersion(7l);
+        // expected end defs
+        Map<String,RelationshipEndDef> expectedEnds8 = new HashMap<>();
+        RelationshipEndDef expectedEndDef8_1 = new RelationshipEndDef();
+        expectedEndDef8_1.setEntityType(backgroundEntityTypes.get("type1"));
+        expectedEndDef8_1.setAttributeCardinality(RelationshipEndCardinality.AT_MOST_ONE);
+        expectedEnds8.put("1",expectedEndDef8_1);
+        RelationshipEndDef expectedEndDef8_2 = new RelationshipEndDef();
+        expectedEndDef8_2.setEntityType(backgroundEntityTypes.get("type2"));
+        expectedEndDef8_2.setAttributeCardinality(RelationshipEndCardinality.ANY_NUMBER);
+        expectedEnds8.put("2",expectedEndDef8_2);
+        // Get some ends...
+        // Note the reversal of the attribute cardinality - i.e. the setting for end1 is the one for end2 in OM and vice versa....
+        AtlasRelationshipEndDef ared8_1 = new AtlasRelationshipEndDef("type1","test8_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SET);
+        AtlasRelationshipEndDef ared8_2 = new AtlasRelationshipEndDef("type2","test8_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        atlasRelationshipDef.setEndDef1(ared8_1);
+        atlasRelationshipDef.setEndDef2(ared8_2);
+        atlasRelationshipDef.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+        atlasRelationshipDef.setPropagateTags(AtlasRelationshipDef.PropagateTags.ONE_TO_TWO);
+
+
+
+        // 9. AtlasRelationshipDef with one F5 entity type
+        AtlasRelationshipDef atlasRelationshipDefOneF5;
+        try {
+            atlasRelationshipDefOneF5 = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefOneF5.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefOneF5.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefOneF5.setVersion(7l);
+        // expected end defs
+        Map<String,RelationshipEndDef> expectedEnds9 = new HashMap<>();
+        RelationshipEndDef expectedEndDef9_1 = new RelationshipEndDef();
+        expectedEndDef9_1.setEntityType(backgroundEntityTypes.get("type1"));
+        expectedEndDef9_1.setAttributeCardinality(RelationshipEndCardinality.AT_MOST_ONE);
+        expectedEnds9.put("1",expectedEndDef9_1);
+        RelationshipEndDef expectedEndDef9_2 = new RelationshipEndDef();
+        expectedEndDef9_2.setEntityType(backgroundEntityTypes.get("Asset"));
+        expectedEndDef9_2.setAttributeCardinality(RelationshipEndCardinality.ANY_NUMBER);
+        expectedEnds9.put("2",expectedEndDef9_2);
+        // Get some ends...
+        // Note the reversal of the attribute cardinality - i.e. the setting for end1 is the one for end2 in OM and vice versa....
+        AtlasRelationshipEndDef ared9_1 = new AtlasRelationshipEndDef("type1","test9_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SET);
+        AtlasRelationshipEndDef ared9_2 = new AtlasRelationshipEndDef("OM_Asset","test9_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        atlasRelationshipDefOneF5.setEndDef1(ared9_1);
+        atlasRelationshipDefOneF5.setEndDef2(ared9_2);
+        atlasRelationshipDefOneF5.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+        atlasRelationshipDefOneF5.setPropagateTags(AtlasRelationshipDef.PropagateTags.ONE_TO_TWO);
+
+        // 10. AtlasRelationshipDef with ends and relationship category but with containership inappropriate for association
+        AtlasRelationshipDef atlasRelationshipDefInappropriateContainership;
+        try {
+            atlasRelationshipDefInappropriateContainership = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefInappropriateContainership.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefInappropriateContainership.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefInappropriateContainership.setVersion(7l);
+        // expected end defs
+        Map<String,RelationshipEndDef> expectedEnds10 = new HashMap<>();
+        RelationshipEndDef expectedEndDef10_1 = new RelationshipEndDef();
+        expectedEndDef10_1.setEntityType(backgroundEntityTypes.get("type1"));
+        expectedEndDef10_1.setAttributeCardinality(RelationshipEndCardinality.AT_MOST_ONE);
+        expectedEnds10.put("1",expectedEndDef10_1);
+        RelationshipEndDef expectedEndDef10_2 = new RelationshipEndDef();
+        expectedEndDef10_2.setEntityType(backgroundEntityTypes.get("Asset"));
+        expectedEndDef10_2.setAttributeCardinality(RelationshipEndCardinality.ANY_NUMBER);
+        expectedEnds10.put("2",expectedEndDef10_2);
+        // Get some ends...
+        AtlasRelationshipEndDef ared10_1 = new AtlasRelationshipEndDef("type1","test7_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        AtlasRelationshipEndDef ared10_2 = new AtlasRelationshipEndDef("type2","test7_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        ared10_2.setIsContainer(true);
+        atlasRelationshipDefInappropriateContainership.setEndDef1(ared10_1);
+        atlasRelationshipDefInappropriateContainership.setEndDef2(ared10_2);
+        atlasRelationshipDefInappropriateContainership.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+        atlasRelationshipDefInappropriateContainership.setPropagateTags(AtlasRelationshipDef.PropagateTags.ONE_TO_TWO);
+
+
+        // 11. AtlasRelationshipDef (between non-F5 entity types) with attributes
+        AtlasRelationshipDef atlasRelationshipDefWithAttributes;
+        try {
+            atlasRelationshipDefWithAttributes = new AtlasRelationshipDef();
+        } catch (AtlasBaseException e) {
+            LOG.debug("Data provider could not create AtlasRelationshipDef - aborting test");
+            return null;
+        }
+        atlasRelationshipDefWithAttributes.setName(backgroundRelationshipTypes.get("type4").getName());
+        atlasRelationshipDefWithAttributes.setGuid(backgroundRelationshipTypes.get("type4").getGUID());
+        atlasRelationshipDefWithAttributes.setVersion(7l);
+        // expected end defs
+        Map<String,RelationshipEndDef> expectedEnds11 = new HashMap<>();
+        RelationshipEndDef expectedEndDef11_1 = new RelationshipEndDef();
+        expectedEndDef11_1.setEntityType(backgroundEntityTypes.get("type1"));
+        expectedEndDef11_1.setAttributeCardinality(RelationshipEndCardinality.AT_MOST_ONE);
+        expectedEnds11.put("1",expectedEndDef11_1);
+        RelationshipEndDef expectedEndDef11_2 = new RelationshipEndDef();
+        expectedEndDef11_2.setEntityType(backgroundEntityTypes.get("type2"));
+        expectedEndDef11_2.setAttributeCardinality(RelationshipEndCardinality.ANY_NUMBER);
+        expectedEnds11.put("2",expectedEndDef11_2);
+        // Get some ends...
+        // Note the reversal of the attribute cardinality - i.e. the setting for end1 is the one for end2 in OM and vice versa....
+        AtlasRelationshipEndDef ared11_1 = new AtlasRelationshipEndDef("type1","test11_end1", AtlasStructDef.AtlasAttributeDef.Cardinality.SET);
+        AtlasRelationshipEndDef ared11_2 = new AtlasRelationshipEndDef("type2","test11_end2", AtlasStructDef.AtlasAttributeDef.Cardinality.SINGLE);
+        atlasRelationshipDefWithAttributes.setEndDef1(ared11_1);
+        atlasRelationshipDefWithAttributes.setEndDef2(ared11_2);
+        atlasRelationshipDefWithAttributes.setRelationshipCategory(AtlasRelationshipDef.RelationshipCategory.ASSOCIATION);
+        atlasRelationshipDefWithAttributes.setPropagateTags(AtlasRelationshipDef.PropagateTags.ONE_TO_TWO);
+        // Attributes
+        AtlasStructDef.AtlasAttributeDef atlasAttr11_1 = new AtlasStructDef.AtlasAttributeDef("attr11_1","string");
+        List<AtlasStructDef.AtlasAttributeDef> atlasAttributeDefs = new ArrayList<>();
+        atlasAttributeDefs.add(atlasAttr11_1);
+        atlasRelationshipDefWithAttributes.setAttributeDefs(atlasAttributeDefs);
+        Map<String,TypeDefAttribute> expectedAttributes11 = new HashMap<>();
+        TypeDefAttribute expectedAttribute11_1 = new TypeDefAttribute();
+        expectedAttribute11_1.setAttributeName("attr11_1");
+        AttributeTypeDef atd11_1 = new PrimitiveDef(OM_PRIMITIVE_TYPE_STRING);
+        atd11_1.setName("string");
+        expectedAttribute11_1.setAttributeType(atd11_1);
+        expectedAttributes11.put("1",expectedAttribute11_1);
+
+
+
+        Object[][] test_data = new Object[][] {
+                { "1. no relationship def",  atlasRelationshipDefNull,                        TestResult.TypeErrorException,  null,            null},
+                { "2. no name",              atlasRelationshipDefNoName,                      TestResult.TypeErrorException,  null,            null},
+                { "3. no guid",              atlasRelationshipDefNoGUID,                      TestResult.TypeErrorException,  null,            null},
+                { "4. no version",           atlasRelationshipDefNoVersion,                   TestResult.TypeErrorException,  null,            null},
+                { "5. no ends",              atlasRelationshipDefNoEnds,                      TestResult.TypeErrorException,  null,            null},
+                { "6. no category",          atlasRelationshipDefNoCat,                       TestResult.TypeErrorException,  null,            null},
+                { "7. no prop tags",         atlasRelationshipDefNoPropTags,                  TestResult.TypeErrorException,  null,            null},
+                { "8. with ends",            atlasRelationshipDef,                            TestResult.OK,                  expectedEnds8,   null},
+                { "9. with one F5 end",      atlasRelationshipDefOneF5,                       TestResult.OK,                  expectedEnds9,   null},
+                { "10. with bad container",  atlasRelationshipDefInappropriateContainership,  TestResult.TypeErrorException,  expectedEnds10,  null},
+                { "11. with attributes",     atlasRelationshipDefWithAttributes,              TestResult.OK,                  expectedEnds11,  expectedAttributes11},
+
+        };
+
+        return test_data;
+
+    }
+
+    /*
+     * Parameters to the test method:
+     * String                    testCaption;
+     * AtlasRelationshipDef      atlasRelationshipDef;
+     * TestResult                expectedResult;
+     * Map<RelationshipEndDef>   expectedEnds;
+     */
+    @Test(dataProvider = "provideAtlasRelationshipDefs")
+    public void test_AtlasRelationshipDef(String                          testCaption,
+                                           AtlasRelationshipDef            atlasRelationshipDef,
+                                           TestResult                      testResult,
+                                           Map<String,RelationshipEndDef>  expectedEndDefs,
+                                           Map<String,TypeDefAttribute>    expectedAttributeDefs )
+            throws
+            RepositoryErrorException,  // not really thrown - but needed for when.thenReturn of getMetadataCollectionId()
+            TypeErrorException
+    {
+
+        LOG.debug("TEST: {}", testCaption);
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        // We are not testing the attributeDef conversion - just the handling of the attribute def list in relationship def mapper
+        if (expectedAttributeDefs != null) {
+            ArrayList<TypeDefAttribute> expectedAttrDefList = new ArrayList<>();
+            Iterator<TypeDefAttribute> it = expectedAttributeDefs.values().iterator();
+            while (it.hasNext())
+                expectedAttrDefList.add(it.next());
+
+            when(metadataCollection.convertAtlasAttributeDefs(any(String.class), anyList())).thenReturn(expectedAttrDefList);
+        }
+        else
+            when(metadataCollection.convertAtlasAttributeDefs(any(String.class), anyList())).thenReturn(null);
+
+
+        /*
+         * Prepare the mock of constructTypeDefLink so that it will serve up names and guids of any background types
+         */
+        if (backgroundEntityTypes != null) {
+            for (TypeDefLink backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection.constructTypeDefLink(backgroundType.getName(), TypeCategory.ENTITY)).
+                        thenReturn(backgroundType);
+            }
+        }
+        if (backgroundRelationshipTypes != null) {
+            for (TypeDefLink backgroundType : backgroundRelationshipTypes.values()) {
+                when(metadataCollection.constructTypeDefLink(backgroundType.getName(), TypeCategory.RELATIONSHIP)).
+                        thenReturn(backgroundType);
+            }
+        }
+
+        String userId = "test_user";
+
+        RelationshipDef omRelationshipDef = null;
+
+        LOG.debug("TestAtlasRelationshipDefMapper: Construct AtlasRelationshipDefMapper");
+        try {
+
+            AtlasRelationshipDefMapper atlasRelationshipDefMapper = new AtlasRelationshipDefMapper(metadataCollection, userId, atlasRelationshipDef);
+            omRelationshipDef = atlasRelationshipDefMapper.toOMRelationshipDef();
+
+        } catch (TypeErrorException e) {
+            LOG.debug("TestAtlasRelationshipDefMapper: Caught TypeErrorException exception");
+            if (testResult.equals(TestResult.TypeErrorException)) {
+                LOG.debug("TestAtlasRelationshipDefMapper: Test Passed");
+                return;
+            }
+            else {
+                LOG.debug("TestAtlasRelationshipDefMapper: Exception was unexpected");
+                fail();
+            }
+        }
+        // Should have returned an OM RelationshipDef
+        assertNotNull(omRelationshipDef);
+
+        Comparator c;
+        boolean match;
+
+        switch(testResult) {
+
+            case OK:
+                // Not using Comparator because we are directly comparing Atlas vs OM
+                // We know that atlasRelationshipDef is not null
+
+                // OM RelationshipDef should have same name as Atlas RelationshipDef
+                String expectedName = atlasRelationshipDef.getName();
+                assertEquals(omRelationshipDef.getName(), expectedName);
+
+                // OM RelationshipDef should have same guid as Atlas RelationshipDef
+                assertEquals(omRelationshipDef.getGUID(), atlasRelationshipDef.getGuid());
+
+                // OM RelationshipDef should have same version as Atlas RelationshipDef
+                assertEquals(omRelationshipDef.getVersion(), atlasRelationshipDef.getVersion().longValue());
+
+                // OM RelationshipDef should have sensible ends
+                // end1 name
+                if (expectedEndDefs != null) {
+                    String end1TypeName = omRelationshipDef.getEndDef1().getEntityType().getName();
+                    String expectedEnd1TypeName = expectedEndDefs.get("1").getEntityType().getName();
+                    assertEquals(end1TypeName, expectedEnd1TypeName);
+                    // end2 name
+                    String end2TypeName = omRelationshipDef.getEndDef2().getEntityType().getName();
+                    String expectedEnd2TypeName = expectedEndDefs.get("2").getEntityType().getName();
+                    assertEquals(end2TypeName, expectedEnd2TypeName);
+                    // end1 cardinality
+                    RelationshipEndCardinality actualEnd1Cardinality = omRelationshipDef.getEndDef1().getAttributeCardinality();
+                    RelationshipEndCardinality expectedEnd1Cardinality = expectedEndDefs.get("1").getAttributeCardinality();
+                    assertEquals(actualEnd1Cardinality, expectedEnd1Cardinality);
+                    // end2 cardinality
+                    RelationshipEndCardinality actualEnd2Cardinality = omRelationshipDef.getEndDef2().getAttributeCardinality();
+                    RelationshipEndCardinality expectedEnd2Cardinality = expectedEndDefs.get("2").getAttributeCardinality();
+                    assertEquals(actualEnd2Cardinality, expectedEnd2Cardinality);
+                }
+
+                // Check the attributes are intact
+                if (expectedAttributeDefs != null) {
+                    TypeDefAttribute expectedAttr1TDA = expectedAttributeDefs.get("1");
+                    String expectedAttr1Name = expectedAttr1TDA.getAttributeName();
+                    String expectedAttr1TypeName = expectedAttr1TDA.getAttributeType().getName();
+                    List<TypeDefAttribute> propsDef = omRelationshipDef.getPropertiesDefinition();
+                    LOG.debug("TestAtlasRelationshipDefMapper: propsDef = {}", propsDef);
+                    TypeDefAttribute actualAttr1TDA = omRelationshipDef.getPropertiesDefinition().get(0);
+                    String actualAttr1Name = expectedAttr1TDA.getAttributeName();
+                    String actualAttr1TypeName = expectedAttr1TDA.getAttributeType().getName();
+                    assertEquals(actualAttr1Name, expectedAttr1Name);
+                    assertEquals(actualAttr1TypeName, expectedAttr1TypeName);
+                }
+
+                LOG.debug("TestAtlasRelationshipDefMapper: Test Passed");
+                break;
+
+
+            default:
+                LOG.debug("TestAtlasRelationshipDefMapper: Unexpected result from mapper");
+                fail();
+                break;
+        }
+    }
+}
\ No newline at end of file
diff --git a/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipMapper.java b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipMapper.java
new file mode 100644
index 000000000..2439ea8cb
--- /dev/null
+++ b/open-metadata/src/test/java/org/apache/atlas/openmetadata/adapters/repositoryconnector/TestAtlasRelationshipMapper.java
@@ -0,0 +1,568 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.atlas.openmetadata.adapters.repositoryconnector;
+
+import org.apache.atlas.exception.AtlasBaseException;
+import org.apache.atlas.model.TypeCategory;
+import org.apache.atlas.model.instance.AtlasEntity;
+import org.apache.atlas.model.instance.AtlasObjectId;
+import org.apache.atlas.model.instance.AtlasRelationship;
+import org.apache.atlas.repository.store.graph.AtlasEntityStore;
+
+import org.odpi.openmetadata.repositoryservices.ffdc.exception.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.instances.*;
+import org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.properties.typedefs.*;
+
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.fail;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.*;
+
+
+public class TestAtlasRelationshipMapper {
+
+    private static final Logger LOG = LoggerFactory.getLogger(TestAtlasRelationshipMapper.class);
+
+    // Background types - these are used and reused across multiple tests
+
+    private Map<String,TypeDef> backgroundEntityTypes = new HashMap<>();
+
+    // deliberately vague about the typedefs - they will generally be relationshipDefs - but not always for error testing
+    private Map<String,TypeDef> backgroundRelationshipTypes = new HashMap<>();
+    private Map<String,AtlasEntity.AtlasEntityWithExtInfo> backgroundEntities = new HashMap<>();
+
+    @BeforeClass
+    public void setup() {
+
+        TypeDef referenceable = new EntityDef();
+        referenceable.setGUID(UUID.randomUUID().toString());
+        referenceable.setName("Referenceable");
+        backgroundEntityTypes.put(referenceable.getName(), referenceable);
+
+        TypeDef asset = new EntityDef();
+        asset.setGUID(UUID.randomUUID().toString());
+        asset.setName("Asset");
+        backgroundEntityTypes.put(asset.getName(), asset);
+
+        TypeDef infrastructure = new EntityDef();
+        infrastructure.setGUID(UUID.randomUUID().toString());
+        infrastructure.setName("Infrastructure");
+        backgroundEntityTypes.put(infrastructure.getName(), infrastructure);
+
+        TypeDef process = new EntityDef();
+        process.setGUID(UUID.randomUUID().toString());
+        process.setName("Process");
+        backgroundEntityTypes.put(process.getName(), process);
+
+        TypeDef dataset = new EntityDef();
+        dataset.setGUID(UUID.randomUUID().toString());
+        dataset.setName("DataSet");
+        backgroundEntityTypes.put(dataset.getName(), dataset);
+
+        TypeDef type1 = new EntityDef();
+        type1.setGUID(UUID.randomUUID().toString());
+        type1.setName("type1");
+        backgroundEntityTypes.put(type1.getName(), type1);
+
+        TypeDef type2 = new EntityDef();
+        type2.setGUID(UUID.randomUUID().toString());
+        type2.setName("type2");
+        backgroundEntityTypes.put(type2.getName(), type2);
+
+        // type20 has no category - it should cause failures XX THIS IS NOW PREVENTED BY EGERIA CHANGE TO abstract TypeDef
+        //TypeDef type20 = new TypeDef();
+        //type20.setName("type20");
+        //type20.setGUID(UUID.randomUUID().toString());
+        //backgroundRelationshipTypes.put(type20.getName(), type20);
+
+        // type21 is a TypeDef but is not a RelationshipDef - it should not be accepted for the relationship
+        // This test is now particularly devious - it creates an EntityDef (as TypeDef is now abstract) but
+        // it then uses the setCategory method of TypeDefSummary to subvert the category to make it look like
+        // a relationship def... this should hopefully get bounced....
+        TypeDef type21 = new EntityDef();
+        type21.setName("type21");
+        type21.setGUID(UUID.randomUUID().toString());
+        type21.setCategory(TypeDefCategory.RELATIONSHIP_DEF);
+        backgroundRelationshipTypes.put(type21.getName(), type21);
+
+        // type22 is a RelationshipDef - but it does not have valid end defs
+        RelationshipDef type22 = new RelationshipDef();
+        type22.setName("type22");
+        type22.setGUID(UUID.randomUUID().toString());
+        type22.setCategory(TypeDefCategory.RELATIONSHIP_DEF);
+        backgroundRelationshipTypes.put(type22.getName(), type22);
+
+        // type23 is a RelationshipDef with sufficient end defs (attributeName and entityType are set) and no defined attributes
+        RelationshipDef type23 = new RelationshipDef();
+        type23.setName("type23");
+        type23.setGUID(UUID.randomUUID().toString());
+        type23.setCategory(TypeDefCategory.RELATIONSHIP_DEF);
+        RelationshipEndDef endDef1 = new RelationshipEndDef();
+        endDef1.setAttributeName("type23_end1");
+        endDef1.setEntityType(type1);
+        type23.setEndDef1(endDef1);
+        RelationshipEndDef endDef2 = new RelationshipEndDef();
+        endDef2.setAttributeName("type23_end2");
+        endDef2.setEntityType(type2);
+        type23.setEndDef2(endDef2);
+        backgroundRelationshipTypes.put(type23.getName(), type23);
+
+
+        // type24 is a RelationshipDef with sufficient end defs (attributeName and entityType are set) and defined attributes
+        RelationshipDef type24 = new RelationshipDef();
+        type24.setName("type24");
+        type24.setGUID(UUID.randomUUID().toString());
+        type24.setCategory(TypeDefCategory.RELATIONSHIP_DEF);
+        RelationshipEndDef endDef24_1 = new RelationshipEndDef();
+        endDef24_1.setAttributeName("type24_end1");
+        endDef24_1.setEntityType(type1);
+        type24.setEndDef1(endDef24_1);
+        RelationshipEndDef endDef24_2 = new RelationshipEndDef();
+        endDef24_2.setAttributeName("type24_end2");
+        endDef24_2.setEntityType(type2);
+        type24.setEndDef2(endDef24_2);
+        List<TypeDefAttribute> properties = new ArrayList<>();
+        TypeDefAttribute attr1Def = new TypeDefAttribute();
+        attr1Def.setAttributeName("attr1");
+        AttributeTypeDef atd1 = new PrimitiveDef(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING);
+        atd1.setName(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getName());
+        atd1.setGUID(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getGUID());
+        attr1Def.setAttributeType(atd1);
+        properties.add(attr1Def);
+        type24.setPropertiesDefinition(properties);
+        backgroundRelationshipTypes.put(type24.getName(), type24);
+
+
+        // Ability to serve up AtlasEntityWithExt objects in response to mocked calls to entityStore
+        AtlasEntity atlasEntity1 = new AtlasEntity();
+        String guid1 = UUID.randomUUID().toString();
+        atlasEntity1.setGuid(guid1);
+        atlasEntity1.setTypeName("type1");
+        LOG.debug("AtlasEntity is {}", atlasEntity1);
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityExt1 = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity1, null);
+        backgroundEntities.put(guid1, atlasEntityExt1);
+
+        AtlasEntity atlasEntity2 = new AtlasEntity();
+        String guid2 = UUID.randomUUID().toString();
+        atlasEntity2.setGuid(guid2);
+        atlasEntity2.setTypeName("type2");
+        AtlasEntity.AtlasEntityWithExtInfo atlasEntityExt2 = new AtlasEntity.AtlasEntityWithExtInfo(atlasEntity2, null);
+        backgroundEntities.put(guid2, atlasEntityExt2);
+
+
+
+        /*
+         * Need to get valid responses from FamousFive, but cannot mock because static, so initialize it instead.
+         * The following calls populate the GUIDs as the names are mapped.
+         * This emulates the addition of the F5 types during OMRS startup.
+         */
+        FamousFive.getAtlasTypeName( referenceable.getName(),   referenceable.getGUID() );
+        FamousFive.getAtlasTypeName( asset.getName(),           asset.getGUID() );
+        FamousFive.getAtlasTypeName( infrastructure.getName(),  infrastructure.getGUID() );
+        FamousFive.getAtlasTypeName( process.getName(),         process.getGUID() );
+        FamousFive.getAtlasTypeName( dataset.getName(),         dataset.getGUID() );
+
+    }
+
+
+    /*
+     * Each object provided by the data provider is an AtlasRelationship and the expected result.
+     *
+     */
+    public enum TestResult {
+        OK,
+        TypeErrorException,
+        RepositoryErrorException,
+        EntityNotKnownException,
+        InvalidParameterException,
+        InvalidRelationshipException,
+        ClassCastException
+    }
+
+    public class TestData {
+        String                                     testCaption;
+        AtlasRelationship                          atlasRelationship;
+        TestAtlasRelationshipMapper.TestResult     expectedResult;
+    }
+
+    @DataProvider(name = "provideAtlasRelationships")
+    public Object[][] provideData() {
+
+
+        // 1. Test with no atlasRelationship
+        AtlasRelationship atlasRelationshipNull = null;
+
+        // 2. Test with atlasRelationship with no type
+        AtlasRelationship atlasRelationshipNoType = new AtlasRelationship();
+
+        // 3. Test with atlasRelationship of type with no category
+        //AtlasRelationship atlasRelationshipNoCat = new AtlasRelationship();
+        //atlasRelationshipNoCat.setTypeName("type20");
+
+        // 4. Test with atlasRelationship of type with category but is not a RelationshipDef
+        AtlasRelationship atlasRelationshipNotRelDef = new AtlasRelationship();
+        atlasRelationshipNotRelDef.setTypeName("type21");
+
+        // 5. Test with atlasRelationship category and a RelationshipDef, but with no ends
+        AtlasRelationship atlasRelationshipNoEnds = new AtlasRelationship();
+        atlasRelationshipNoEnds.setTypeName("type22");
+
+        // 6. Test with atlasRelationship category and a RelationshipDef, with ends that have guid and typeName
+        AtlasRelationship atlasRelationship = new AtlasRelationship();
+        atlasRelationship.setTypeName("type23");
+        String relationshipGUID = UUID.randomUUID().toString();
+        atlasRelationship.setGuid(relationshipGUID);
+        atlasRelationship.setStatus(AtlasRelationship.Status.DELETED);
+        // Need to set the entity guid to something that is able to be mocked
+        Iterator<String> entityGUIDs = backgroundEntities.keySet().iterator();
+        AtlasObjectId end1 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end1.setGuid(guid);
+            end1.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship.setEnd1(end1);
+        AtlasObjectId end2 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end2.setGuid(guid);
+            end2.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship.setEnd2(end2);
+        // expected values
+        Map<String,Object> expectedFields6 = new HashMap<>();
+        expectedFields6.put("relationshipGUID",relationshipGUID );
+        expectedFields6.put("status", InstanceStatus.DELETED);
+
+
+        // 7. Test with atlasRelationship with undefined attribute (i.e. attribute not in RelationshipDef)
+        AtlasRelationship atlasRelationship7 = new AtlasRelationship();
+        atlasRelationship7.setTypeName("type23");
+        atlasRelationship7.setVersion(23L);
+        String relationshipGUID7 = UUID.randomUUID().toString();
+        atlasRelationship7.setGuid(relationshipGUID7);
+        atlasRelationship7.setStatus(AtlasRelationship.Status.DELETED);
+        // Need to set the entity guid to something that is able to be mocked
+        entityGUIDs = backgroundEntities.keySet().iterator();
+        AtlasObjectId end7_1 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end7_1.setGuid(guid);
+            end7_1.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship7.setEnd1(end7_1);
+        AtlasObjectId end7_2 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end7_2.setGuid(guid);
+            end7_2.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship7.setEnd2(end7_2);
+        // attributes
+        Map<String, Object> atlasAttributes7 = new HashMap<>();
+        String attr7_1 = "attr7_1-value";
+        atlasAttributes7.put("attr7_1",attr7_1);
+        atlasRelationship7.setAttributes(atlasAttributes7);
+        // expected values
+        Map<String,Object> expectedFields7 = new HashMap<>();
+        expectedFields7.put("relationshipGUID",relationshipGUID7 );
+        expectedFields7.put("status", InstanceStatus.DELETED);
+        expectedFields7.put("attributes",null);    // the attributes are not in the RelationshipDef so do not expect them
+
+
+        // 8. Test with atlasRelationship with undefined attribute (i.e. attribute not in RelationshipDef)
+        AtlasRelationship atlasRelationship8 = new AtlasRelationship();
+        atlasRelationship8.setTypeName("type24");
+        atlasRelationship8.setVersion(24L);
+        String relationshipGUID8 = UUID.randomUUID().toString();
+        atlasRelationship8.setGuid(relationshipGUID8);
+        atlasRelationship8.setStatus(AtlasRelationship.Status.DELETED);
+        // Need to set the entity guid to something that is able to be mocked
+        entityGUIDs = backgroundEntities.keySet().iterator();
+        AtlasObjectId end8_1 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end8_1.setGuid(guid);
+            end8_1.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship8.setEnd1(end8_1);
+        AtlasObjectId end8_2 = new AtlasObjectId();
+        if (entityGUIDs.hasNext()) {
+            String guid = entityGUIDs.next();
+            LOG.debug("entity with guid {} is {}", guid, backgroundEntities.get(guid).getEntity() );
+            end8_2.setGuid(guid);
+            end8_2.setTypeName(backgroundEntities.get(guid).getEntity().getTypeName());
+        }
+        atlasRelationship8.setEnd2(end8_2);
+        // attributes
+        Map<String, Object> atlasAttributes8 = new HashMap<>();
+        String valueAttr8_1 = "test8-attr1-value";
+        atlasAttributes8.put("attr1",valueAttr8_1);
+        atlasRelationship8.setAttributes(atlasAttributes8);
+        // expected values
+        Map<String,Object> expectedFields8 = new HashMap<>();
+        InstanceProperties expectedProps8 = new InstanceProperties();
+        PrimitivePropertyValue instancePropertyValue8_1 = new PrimitivePropertyValue();
+        instancePropertyValue8_1.setPrimitiveDefCategory(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING);
+        instancePropertyValue8_1.setTypeName("string");
+        instancePropertyValue8_1.setTypeGUID(PrimitiveDefCategory.OM_PRIMITIVE_TYPE_STRING.getGUID());
+        instancePropertyValue8_1.setPrimitiveValue(valueAttr8_1);
+        expectedProps8.setProperty("attr1",instancePropertyValue8_1 );
+        expectedFields8.put("attributes",expectedProps8);
+        // expect the ends as well - the EntityProxy mapper has separate UTs so just test tha the correct proxy is conveyed
+        EntityProxy expectedEntityProxy1 = new EntityProxy();
+        expectedEntityProxy1.setGUID(end8_1.getGuid());
+        expectedFields8.put("end1",expectedEntityProxy1);
+        EntityProxy expectedEntityProxy2 = new EntityProxy();
+        expectedEntityProxy2.setGUID(end8_2.getGuid());
+        expectedFields8.put("end2",expectedEntityProxy2);
+
+
+
+        Object[][] test_data = new Object[][] {
+                { "1. no relationship",       atlasRelationshipNull,        TestResult.InvalidParameterException, null},
+                { "2. relationship no type",  atlasRelationshipNoType,      TestResult.TypeErrorException,        null},
+                // No longer possible - TypeDef is now abstract { "3. relationship no cat",   atlasRelationshipNoCat,       TestResult.TypeErrorException,        null},
+                { "4. relationship inv type", atlasRelationshipNotRelDef,   TestResult.TypeErrorException,        null},
+                { "5. relationship no ends",  atlasRelationshipNoEnds,      TestResult.TypeErrorException,        null},
+                { "6. relationship",          atlasRelationship,            TestResult.OK,                        expectedFields6},
+                { "7. relationship",          atlasRelationship7,           TestResult.OK,                        expectedFields7},
+                { "8. relationship",          atlasRelationship8,           TestResult.OK,                        expectedFields8},
+
+        };
+
+        return test_data;
+    }
+
+    @Test(dataProvider = "provideAtlasRelationships")
+    public void test_AtlasRelationship(String              testCaption,
+                                       AtlasRelationship   atlasRelationship,
+                                       TestResult          testResult,
+                                       Map<String,Object>  expectedFields)
+        throws
+            RepositoryErrorException,  // not really thrown - but needed for when.thenReturn of getMetadataCollectionId()
+            AtlasBaseException,
+            InvalidEntityException,
+            TypeDefNotKnownException
+    {
+
+        final String methodName = "test_AtlasRelationship";
+
+        LOG.debug("TEST: {}", testCaption);
+
+        String userId = "test_user";
+
+        /*
+         * Set up mocks
+         */
+
+        // MetadataCollection
+        LocalAtlasOMRSMetadataCollection metadataCollection = mock(LocalAtlasOMRSMetadataCollection.class);
+        when(metadataCollection.getMetadataCollectionId()).thenReturn("mock_metadata_collection");
+
+        if (backgroundEntityTypes != null) {
+            for (TypeDef backgroundType : backgroundEntityTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).
+                        thenReturn(backgroundType);
+            }
+        }
+
+        if (backgroundRelationshipTypes != null) {
+            for (TypeDef backgroundType : backgroundRelationshipTypes.values()) {
+                when(metadataCollection._getTypeDefByName(userId, backgroundType.getName())).
+                        thenReturn(backgroundType);
+            }
+        }
+
+        // EntityStore
+        AtlasEntityStore entityStore = mock(AtlasEntityStore.class);
+        if (backgroundEntities != null) {
+            for (AtlasEntity.AtlasEntityWithExtInfo backgroundEntity : backgroundEntities.values()) {
+                when(entityStore.getById(backgroundEntity.getEntity().getGuid())).
+                        thenReturn(backgroundEntity);
+            }
+        }
+
+
+        Relationship omRelationship = null;
+
+        LOG.debug(methodName+": Construct AtlasRelationshipMapper");
+        try {
+
+            AtlasRelationshipMapper atlasRelationshipMapper =
+                    new AtlasRelationshipMapper(metadataCollection, userId, atlasRelationship, entityStore);
+            omRelationship = atlasRelationshipMapper.toOMRelationship();
+
+        } catch (TypeErrorException e) {
+            LOG.debug(methodName+": Caught TypeErrorException exception");
+            if (testResult.equals(TestAtlasRelationshipMapper.TestResult.TypeErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (RepositoryErrorException e) {
+            LOG.debug(methodName+": Caught RepositoryErrorException exception");
+            if (testResult.equals(TestAtlasRelationshipMapper.TestResult.RepositoryErrorException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (EntityNotKnownException e) {
+            LOG.debug(methodName+": Caught EntityNotKnownException exception");
+            if (testResult.equals(TestAtlasRelationshipMapper.TestResult.EntityNotKnownException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (InvalidParameterException e) {
+            LOG.debug(methodName+": Caught InvalidParameterException exception");
+            if (testResult.equals(TestAtlasRelationshipMapper.TestResult.InvalidParameterException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        } catch (InvalidRelationshipException e) {
+            LOG.debug(methodName+": Caught InvalidRelationshipException exception");
+            if (testResult.equals(TestAtlasRelationshipMapper.TestResult.InvalidRelationshipException)) {
+                LOG.debug(methodName+": Test Passed");
+                return;
+            }
+            else {
+                LOG.debug(methodName+": Exception was unexpected");
+                fail();
+            }
+        }
+
+
+        // Should have returned an OM Relationship
+        assertNotNull(omRelationship);
+
+        Comparator c;
+        boolean match;
+
+        switch(testResult) {
+
+            case OK:
+                // Not using Comparator because we are directly comparing Atlas vs OM
+                // We know that atlasRelationship is not null
+
+                // OM Relationship should have same version as AtlasEntity
+                assertEquals(omRelationship.getVersion(), atlasRelationship.getVersion().longValue());
+
+                // Check GUID
+                if (expectedFields != null && expectedFields.get("relationshipGUID") != null) {
+                    LOG.debug("TestAtlasRelationshipMapper: relationship GUID {}", omRelationship.getGUID());
+                    assertEquals(omRelationship.getGUID(), expectedFields.get("relationshipGUID"));
+                }
+
+                // Check the InstanceType -
+                InstanceType instanceType = omRelationship.getType();
+                String typeName = instanceType.getTypeDefName();
+                assertEquals(typeName, atlasRelationship.getTypeName());
+
+                // Check metadataCollectionId
+                assertEquals(omRelationship.getMetadataCollectionId(), atlasRelationship.getHomeId());
+
+                // Check status
+                if (expectedFields != null && expectedFields.get("status") != null) {
+                    LOG.debug("TestAtlasRelationshipMapper: status {}", omRelationship.getStatus());
+                    assertEquals(omRelationship.getStatus(), expectedFields.get("status"));
+                }
+
+                // check attributes
+                if (expectedFields != null && expectedFields.get("attributes") != null) {
+                    InstanceProperties actualProperties = omRelationship.getProperties();
+                    LOG.debug(methodName + ": actualProperties {}", actualProperties);
+                    InstanceProperties expectedProperties = (InstanceProperties) (expectedFields.get("attributes"));
+                    LOG.debug(methodName + ": expectedProperties {}", expectedProperties);
+                    // Test each expected property...
+                    Iterator<String> expectedPropertyNames = expectedProperties.getPropertyNames();
+                    while (expectedPropertyNames.hasNext()) {
+                        String propName = expectedPropertyNames.next();
+                        InstancePropertyValue expectedPropValue = expectedProperties.getPropertyValue(propName);
+                        InstancePropertyValue actualPropValue = actualProperties.getPropertyValue(propName);
+                        assertEquals(expectedPropValue.getInstancePropertyCategory(), actualPropValue.getInstancePropertyCategory());
+                        LOG.debug(methodName + ": expected type {}", expectedPropValue.getTypeName());
+                        LOG.debug(methodName + ": actual type {}", actualPropValue.getTypeName());
+                        assertEquals(expectedPropValue.getTypeName(), actualPropValue.getTypeName());
+                        assertEquals(expectedPropValue.getTypeGUID(), actualPropValue.getTypeGUID());
+                    }
+                }
+
+
+                // check ends
+                if (expectedFields != null && expectedFields.get("end1") != null) {
+                    /* The content of the proxy is tested byEntityMapper UTs, so just interested here in whether the
+                     * the correct proxy is conveyed by the relationship mapper.
+                     */
+                    EntityProxy entityProxy1 = omRelationship.getEntityOneProxy();
+                    EntityProxy expectedProxy1 = (EntityProxy)(expectedFields.get("end1"));
+                    // Just compare the GUIDs
+                    assertEquals(entityProxy1.getGUID(),expectedProxy1.getGUID() );
+                }
+                if (expectedFields != null && expectedFields.get("end2") != null) {
+                    /* The content of the proxy is tested byEntityMapper UTs, so just interested here in whether the
+                     * the correct proxy is conveyed by the relationship mapper.
+                     */
+                    EntityProxy entityProxy2 = omRelationship.getEntityTwoProxy();
+                    EntityProxy expectedProxy2 = (EntityProxy)(expectedFields.get("end2"));
+                    // Just compare the GUIDs
+                    assertEquals(entityProxy2.getGUID(),expectedProxy2.getGUID() );
+                }
+
+
+                LOG.debug(methodName+": Test Passed");
+                break;
+
+
+            default:
+                LOG.debug(methodName+": Unexpected result from mapper");
+                fail();
+                break;
+        }
+
+    }
+}
diff --git a/pom.xml b/pom.xml
index c60a53b0e..d4d227ec3 100644
--- a/pom.xml
+++ b/pom.xml
@@ -660,6 +660,7 @@
         <guava.version>19.0</guava.version>
         <scala.version>2.11.12</scala.version>
         <antlr4.version>4.7</antlr4.version>
+        <egeria.version>0.1-SNAPSHOT</egeria.version>
 
         <!-- Needed for hooks -->
         <aopalliance.version>1.0</aopalliance.version>
@@ -731,7 +732,7 @@
     <modules>
         <module>build-tools</module>
         <module>test-tools</module>
-
+        <module>open-metadata</module>
         <module>intg</module>
         <module>common</module>
         <module>server-api</module>
@@ -1408,6 +1409,12 @@
                 <type>war</type>
             </dependency>
 
+            <dependency>
+                <groupId>org.apache.atlas</groupId>
+                <artifactId>open-metadata</artifactId>
+                <version>${project.version}</version>
+            </dependency>
+
             <dependency>
                 <groupId>org.apache.atlas</groupId>
                 <artifactId>atlas-hbase-client-shaded</artifactId>
diff --git a/webapp/pom.xml b/webapp/pom.xml
index 78aa81e80..4f7ded26b 100755
--- a/webapp/pom.xml
+++ b/webapp/pom.xml
@@ -121,6 +121,49 @@
             <artifactId>atlas-intg</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.atlas</groupId>
+            <artifactId>open-metadata</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>repository-services-spring</artifactId>
+            <version>${egeria.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>repository-services-implementation</artifactId>
+            <version>${egeria.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>ch.qos.logback</groupId>
+                    <artifactId>*</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.slf4j</groupId>
+                    <artifactId>log4j-over-slf4j</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>org.odpi.egeria</groupId>
+            <artifactId>admin-services-server</artifactId>
+            <version>${egeria.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>ch.qos.logback</groupId>
+                    <artifactId>*</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.slf4j</groupId>
+                    <artifactId>log4j-over-slf4j</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
         <dependency>
             <groupId>org.apache.hadoop</groupId>
             <artifactId>hadoop-common</artifactId>
diff --git a/webapp/src/main/webapp/WEB-INF/openMetadataContext.xml b/webapp/src/main/webapp/WEB-INF/openMetadataContext.xml
new file mode 100644
index 000000000..8789d341a
--- /dev/null
+++ b/webapp/src/main/webapp/WEB-INF/openMetadataContext.xml
@@ -0,0 +1,33 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor
+    license agreements. See the NOTICE file distributed with this work for additional
+    information regarding copyright ownership. The ASF licenses this file to
+    You under the Apache License, Version 2.0 (the "License"); you may not use
+    this file except in compliance with the License. You may obtain a copy of
+    the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required
+    by applicable law or agreed to in writing, software distributed under the
+    License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS
+    OF ANY KIND, either express or implied. See the License for the specific
+    language governing permissions and limitations under the License. -->
+
+<beans xmlns="http://www.springframework.org/schema/beans"
+       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+       xmlns:context="http://www.springframework.org/schema/context"
+       xmlns:aop="http://www.springframework.org/schema/aop"
+       xmlns:mvc="http://www.springframework.org/schema/mvc"
+       xsi:schemaLocation="http://www.springframework.org/schema/beans
+            http://www.springframework.org/schema/beans/spring-beans.xsd
+            http://www.springframework.org/schema/context
+            http://www.springframework.org/schema/context/spring-context.xsd
+            http://www.springframework.org/schema/aop
+            http://www.springframework.org/schema/aop/spring-aop.xsd
+            http://www.springframework.org/schema/mvc
+            http://www.springframework.org/schema/mvc/spring-mvc.xsd">
+
+    <context:annotation-config/>
+    <aop:config proxy-target-class="true"/>
+    <context:component-scan base-package="org.apache.atlas.openmetadata,org.odpi.openmetadata"/>
+    <mvc:annotation-driven>
+        <mvc:path-matching suffix-pattern="false" />
+    </mvc:annotation-driven>
+</beans>
\ No newline at end of file
diff --git a/webapp/src/main/webapp/WEB-INF/web.xml b/webapp/src/main/webapp/WEB-INF/web.xml
index 23dc0637a..a0796ce23 100755
--- a/webapp/src/main/webapp/WEB-INF/web.xml
+++ b/webapp/src/main/webapp/WEB-INF/web.xml
@@ -41,6 +41,24 @@
         <url-pattern>/api/atlas/*</url-pattern>
     </servlet-mapping>
 
+
+    <servlet>
+        <servlet-name>open-metadata</servlet-name>
+        <servlet-class>
+            org.springframework.web.servlet.DispatcherServlet
+        </servlet-class>
+        <init-param>
+            <param-name>contextConfigLocation</param-name>
+            <param-value>/WEB-INF/openMetadataContext.xml</param-value>
+        </init-param>
+        <load-on-startup>2</load-on-startup>
+    </servlet>
+
+    <servlet-mapping>
+        <servlet-name>open-metadata</servlet-name>
+        <url-pattern>/egeria/*</url-pattern>
+    </servlet-mapping>
+
     <filter>
         <filter-name>springSecurityFilterChain</filter-name>
         <filter-class>org.springframework.web.filter.DelegatingFilterProxy</filter-class>
-- 
2.18.0

